<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>【MIT6.824】lab2B-log replication 实现笔记</title>
    <link href="/2024/03/19/MIT6-824lab2B/"/>
    <url>/2024/03/19/MIT6-824lab2B/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>lab2B的实验要求如下：</p><p>Implement the leader and follower code to append new log entries, so that the go test -run 2B tests pass.</p><ul><li><strong>Hint:</strong> Run git pull to get the latest lab software.</li><li><strong>Hint:</strong> Your first goal should be to pass TestBasicAgree2B(). Start by implementing Start(), then write the code to send and receive new log entries via AppendEntries RPCs, following Figure 2. Send each newly committed entry on applyCh on each peer.</li><li><strong>Hint:</strong> You will need to implement the election restriction (section 5.4.1 in the paper).</li><li><strong>Hint:</strong> One way to fail to reach agreement in the early Lab 2B tests is to hold repeated elections even though the leader is alive. Look for bugs in election timer management, or not sending out heartbeats immediately after winning an election.</li><li><strong>Hint:</strong> Your code may have loops that repeatedly check for certain events. Don’t have these loops execute continuously without pausing, since that will slow your implementation enough that it fails tests. Use Go’s condition variables, or insert a time.Sleep(10 * time.Millisecond) in each loop iteration.</li><li><strong>Hint:</strong> Do yourself a favor for future labs and write (or re-write) code that’s clean and clear. For ideas, re-visit our the Guidance page with tips on how to develop and debug your code.</li><li><strong>Hint:</strong> If you fail a test, look over the code for the test in config.go and test_test.go to get a better understanding what the test is testing. config.go also illustrates how the tester uses the Raft API.</li></ul><p>主要的要求就是在lab2A完成领导者选举的基础上实现日志的复制，代码可以在<a href="https://github.com/slipegg/MIT6.824">https://github.com/slipegg/MIT6.824</a>中得到。</p><h1 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h1><p>由于整个lab是在模拟环境中进行的，所以我们需要先简单连接一下实验是如何测试和运行的。</p><p>查看测试脚本可知，每次客户端提交用户请求都是通过调用leader的Start函数来实现的，故Start函数在接收到了日志后就需要主动开始日志复制的过程。</p><p>而当leader将日志复制到大多数节点后，除了各个节点自己需要标定这个日志已经提交了外，还需要将这个日志已经提交了的信息返回给客户端，这个信息的结构为ApplyMsg，它通过applyCh这个channel来实现的，实际代码中我们可能需要启用一个go协程来在需要时进行异步执行，如下所示。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> ApplyMsg <span class="hljs-keyword">struct</span> &#123;<br>CommandValid <span class="hljs-type">bool</span><br>Command      <span class="hljs-keyword">interface</span>&#123;&#125;<br>CommandIndex <span class="hljs-type">int</span><br><br><span class="hljs-comment">// For 2D:</span><br>SnapshotValid <span class="hljs-type">bool</span><br>Snapshot      []<span class="hljs-type">byte</span><br>SnapshotTerm  <span class="hljs-type">int</span><br>SnapshotIndex <span class="hljs-type">int</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> applier() &#123;<br><span class="hljs-keyword">for</span> !rf.killed() &#123;<br>rf.mu.Lock()<br><span class="hljs-keyword">for</span> rf.lastApplied &gt;= rf.commitIndex &#123;<br>rf.applyCond.Wait()<br>&#125;<br><br>commitIndex, lastApplied := rf.commitIndex, rf.lastApplied<br>entries := <span class="hljs-built_in">make</span>([]LogEntry, commitIndex-lastApplied)<br><span class="hljs-built_in">copy</span>(entries, rf.logs[lastApplied+<span class="hljs-number">1</span>:commitIndex+<span class="hljs-number">1</span>])<br>Debug(dTest, <span class="hljs-string">&quot;S%v commitIndex: %v, lastApplied: %v, entries: %v&quot;</span>, rf.me, commitIndex, lastApplied, entries)<br>rf.mu.Unlock()<br><br><span class="hljs-keyword">for</span> _, entry := <span class="hljs-keyword">range</span> entries &#123;<br><span class="hljs-comment">// entry: committed log entry</span><br>rf.applyCh &lt;- ApplyMsg&#123;<br>CommandValid: <span class="hljs-literal">true</span>,<br>Command:      entry.Command,<br>CommandIndex: entry.Index,<br>&#125;<br>&#125;<br><br>rf.mu.Lock()<br>Debug(dCommit, <span class="hljs-string">&quot;S%v applies log entries(startId: %v, length: %v)&quot;</span>, rf.me, lastApplied+<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(entries))<br>rf.lastApplied = commitIndex<br>rf.mu.Unlock()<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="日志复制代码"><a href="#日志复制代码" class="headerlink" title="日志复制代码"></a>日志复制代码</h1><p>在具体实现时，发现Raft论文中的代码结构图对于编写整个代码非常有帮助，所以在这里也贴出来。</p><p><img src="/2024/03/19/MIT6-824lab2B/RaftStruct.jpg" alt="Raft论文中的代码结构图"></p><p>项目的整体流程及思路我整理成了如下的过程.</p><p><img src="/2024/03/19/MIT6-824lab2B/p1.jpg" alt="客户端发送日志后触发日志复制"></p><ul><li><strong>Start:</strong> leader节点接受新的命令，将命令添加到自己的日志中，并向其他所有节点发送日志复制请求。</li><li><strong>ReplicateLog:</strong> 由于日志复制可能会失败，所以需要一个循环来不断重试，直到日志复制成功。复制时通过RPC来调度其他节点的AppendEntires函数，并在得到返回结果后调用handleAppendResponse进行处理.</li></ul><p><img src="/2024/03/19/MIT6-824lab2B/p2.jpg" alt="节点处理日志添加请求及处理日志添加返回结果"></p><ul><li><strong>AppendEntires:</strong> 节点接受到日志复制请求后，必须先要判定对方是不是term大于等于自己的term，如果不是就是过时的leader，直接拒绝。由于这个函数也会被当做心跳包来使用，所以收到后还需要自动转变为follower。然后再判断leader中记录的要复制的前一个日志preLog是不是和自己的一致，如果不一致，有两种可能：<ol><li>自己的日志更短，都没复制到preLog这一步，所以直接拒绝，并主动在reply中返回自己的最后一个日志的id。</li><li>有preLog，但是日志的term不一致，也就是自己有冗余的错误的日志，这里是可删可不删后面的日志，论文中采取的方法是返回错误，然后一个一个往前找对得上的日志，而由于这个速度太慢了，会导致测试不通过，所以这里采取的方法是返回本节点的preLog的term，这个term肯定是比leader更小的，然后等待leader找到这个term的最后一个日志，尝试全部复制过来，这样可以加速日志的复制。<br>如果都一致了，就加入到自己的日志中，然后再去对比参看leader有没有新commit日志，如果有就更新自己的commitIndex，并将他们apply，返回给客户端。</li></ol></li><li><strong>handleAppendResponse:</strong> 这个函数是用来处理AppendEntires的返回结果的，首先需要判定自己还是不是leader，term有没有变，如果不是leader或者term变了，就不继续处理。如果返回成功，那么就更新自身记录的对应节点的matchId和nextId，如果返回失败,则对应有几种可能：<ol><li>发现比自己term还高的节点，说明自己的term过时了，需要转变为follower。</li><li>对方的日志比自己以为的要短，需要将该节点nextId往前移动到对应的位置。</li><li>对方的preLog的term不一致，那么就需要找到perLog的term对应的最后一个日志，然后将nextId移动到这个位置的下一个位置。</li></ol></li></ul><p><img src="/2024/03/19/MIT6-824lab2B/p3.jpg" alt="leader尝试更新日志及新的投票规则"></p><ul><li><strong>TryApplyForLeader:</strong> 这里把所有的matchId倒序排序，然后查看中间这个位置的matchId是不是变化了，如果变化了，就去查看这个最新的newCommitId对应的term是不是等于自己的term，如果不是，还是不处理，这对应了论文中的5.4.2节中的规则；如果是，就更新自己的commitIndex，并将这个日志apply。</li><li><strong>Vote:</strong> 如果投票的请求的term比自己的term小，那么就是过时的请求，直接拒绝。如果相同，同时自己已经投票给了其他节点，那么也拒绝。如果请求的term比自己的term大，那么就转变为follower，并更新term。（这一步是为了处理有些时候有的节点进入了网络分区，term不断变大，新接入之后发起投票，这是否应该大伙都转为follower，但是可能受限于日志不符合，不能成为leader，然后大家在新的term中重新选举，统一得到一个leader。）然后检查请求的前一个日志是否是最新的，最新的规则是要么这个前一个日志的term比自己的term大，要么term相同但是index相同或者更大，如果不是，就拒绝。最后如果都通过了，就投票给对方。</li></ul><h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p>使用了之前写的自动测试实验脚本的测试结果如下，可以看到它通过了1000次的测试。</p><p><img src="/2024/03/19/MIT6-824lab2B/result.jpg" alt="实验结果"></p><h1 id="测试实例-TestBackup2B分享"><a href="#测试实例-TestBackup2B分享" class="headerlink" title="测试实例-TestBackup2B分享"></a>测试实例-TestBackup2B分享</h1><p>测试过程中被TestBackup2B困扰了很久这里分享一下这个测试示例。</p><p><img src="/2024/03/19/MIT6-824lab2B/p4.jpg" alt="TestBackup2B"></p><p>可以看到测试主要是通过网络中断来进行测试的。一开始这个测试没通过，经过查看日志得知是在T5时刻没有选举出正确的leader，两个原因：</p><ol><li>在选举时判断每个节点最后的日志是不是最新的时候写错了，只比较自己的最后的日志相较于Candidate的最后的日志是不是一样长，而没有比较Candidate的最后的日志的term是不是比自己的大，这就导致了在T5时刻本来应该只有S2才能被选举出来，但是我确认S0和S1也可以被选举出来。</li><li>在比较最后的日志前没有提前先判断对方的term是不是比自己的term大，由于S1在disconnect阶段一直在尝试重新选举，所以其term会很大，如果其他节点在接收到S1投票请求后没有转变为follower，并更新term会导致S1一直拒绝其他人的选举投票，而自己又由于日志不够新，被S2拒绝，导致选举一直无法完成。</li></ol>]]></content>
    
    
    <categories>
      
      <category>MIT6.824</category>
      
      <category>lab2</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>go</tag>
      
      <tag>分布式</tag>
      
      <tag>MIT6.824</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文阅读】Not All Resources are Visible:Exploiting Fragmented Shadow Resources in Shared-State Scheduler Architecture</title>
    <link href="/2024/03/14/ShadowResources/"/>
    <url>/2024/03/14/ShadowResources/</url>
    
    <content type="html"><![CDATA[<h1 id="论文信息"><a href="#论文信息" class="headerlink" title="论文信息"></a>论文信息</h1><p><strong>论文地址：</strong> <a href="https://dl.acm.org/doi/10.1145/3620678.3624650">Not All Resources are Visible: Exploiting Fragmented Shadow Resources in Shared-State Scheduler Architecture</a></p><p><strong>收录会议：</strong> 云计算顶会-ACM Symposium on Cloud Computing(SoCC2023)</p><p><strong>作者：</strong> 交通大学-李超教授团队</p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p><strong>资源</strong>：一个集群中有成千上万台机器。</p><p><strong>请求：</strong> 百万级的请求并发，请求需求更低，运行时间更短，到达秒级甚至毫秒级的运行时间，如下图所示。</p><p><img src="/2024/03/14/ShadowResources/requestTrace.png" alt="图1. a为谷歌集群数据集中任务的cpu和内存占用率的分布，b为阿里巴巴集群数据集中任务运行时间的分布"></p><p><strong>调度：</strong> 主要有三种集群调度架构，如图2所示，单体式架构由于拓展性和灵活性不足，不适合大规模集群，两级式架构资源利用率低，共享状态架构具有高拓展性，更为流行。</p><p><img src="/2024/03/14/ShadowResources/scheduleArc.png" alt="图2. a为单体式架构，b为两级式架构，c为共享状态调度架构"></p><p>共享状态架构的具体介绍：</p><ul><li>有一个管理员维护了中央状态视图CSV。</li><li>存在多个并行调度器，调度范围是全局，调度依据是本地状态视图LSV，并将调度决策提交到CSV中，以避免与其他调度器发生冲突。</li><li>CSV 定期更新每个调度器拥有的本地状态视图 (LSV)，并具有固定的更新延迟。</li><li>最初的共享状态设计会在每次成功的资源分配操作时更新，但在实际集群中，更新延迟通常为秒级，以减少更新带来的系统开销。</li></ul><p>对低开销的追求使得每个调度器的LSV间歇性地过时，因为它们在更新延迟内对于已释放资源的最新状态是不可见的，本文将这些资源称为“影子资源”。<br>影子资源的数量与同步时间间隔和任务运行时间有关，根据理论和实验分析，它会占到已分配资源的2~13%，同时减少同步时间间隔会给调度系统带来较高的同步开销，难以实现，同时云中任务粒度小，会导致影子分散，所以考虑对其的利用是必要的。</p><p>但是之前的相关研究主要集中在优化调度策略来有效管理可见资源，如更高的利用率，更低的延迟，而忽略了对于影子资源利用的研究。</p><h1 id="创新与贡献"><a href="#创新与贡献" class="headerlink" title="创新与贡献"></a>创新与贡献</h1><p>考虑利用影子资源有两点需要注意：</p><ol><li>由于影子资源存在时间短，所以需要敏捷、高效地利用。</li><li>要灵活、透明，避免干扰正常的调度。</li></ol><p>故本文提出了RMiner机制来对影子资源进行利用，它包含三个协作组件：</p><ol><li>shadow resource manager：负责收集影子资源。</li><li>RM filter：筛选适合给影子资源利用的任务。</li><li>RM scheduler：负责将筛选出的任务分配给影子资源。</li></ol><p>针对不同的集群管理目标，RMiner 提供 SafeRM 和 SmartRM 两种资源挖掘模式，以平衡资源利用率最大化和冲突最小化</p><p>总体创新点如下：</p><ol><li>发现了共享状态调度架构中的影子资源，并从理论上和实验上对其进行了分析。</li><li>提出了RMiner机制，对影子资源进行了利用。</li><li>构建了RMiner的模拟器，实验证明了RMiner可以以较小的开销极大地提高集群性能。</li></ol><h1 id="理论分析"><a href="#理论分析" class="headerlink" title="理论分析"></a>理论分析</h1><p>经过理论分析，本文得出了瞬时影子资源的期望式：</p><p><img src="/2024/03/14/ShadowResources/expectation.jpg" alt="影子资源期望式"></p><p>即影子资源总量主要与状态更新延迟d<sub>u</sub>和集群中分配的资源数量r<sub>run</sub>成正比，而与任务的平均执行时间η成反比。</p><p>根据谷歌数据集、fuxi2.0、Borg的数据，假设任务的执行时间为4s<del>5s,状态更新延迟为0.3\</del>1.0s，那么影子资源占已分配资源的3~12.5%。<br>这是值得被考虑的，同时随着轻量云任务的增多，影子资源的利用也会变得更加重要。</p><p>通过对阿里巴巴集群数据集的随机采样，并进行了10中不同配置的实验，记录了影子资源的分布情况，与实验分析基本一致，如图3所示。</p><p><img src="/2024/03/14/ShadowResources/fig3.jpg" alt="图3. 影子资源理论与实验结果对比"></p><h1 id="RMiner机制设计"><a href="#RMiner机制设计" class="headerlink" title="RMiner机制设计"></a>RMiner机制设计</h1><p><img src="/2024/03/14/ShadowResources/fig4.jpg" alt="图4. RMiner机制"></p><p>RMiner机制包含三个协作组件，如图4中的蓝色所示：</p><ol><li>Shadow Resource Manager 通过新设计的索引，探测并管理最新的影子资源。</li><li>RM Filter选择适合影子资源的任务（RM Tasks）到任务队列中</li><li>RM Scheduler负责灵活地将影子资源分配给RM任务。</li></ol><p>RMiner的两大设计原则：</p><ol><li>避免入侵：不对原始调度系统做侵入式修改，原始调度系统依旧不需要知道影子资源的存在，并且不会和影子资源的分配发生冲突。</li><li>平衡性能：RMiner 面临着最大化利用不可见资源和最小化与可见调度冲突的权衡。过度利用影子资源可能会导致大量抢占式执行，从而降低集群的整体性能，反之亦然。</li></ol><h2 id="Shadow-Resource-Manager"><a href="#Shadow-Resource-Manager" class="headerlink" title="Shadow Resource Manager"></a>Shadow Resource Manager</h2><p><img src="/2024/03/14/ShadowResources/fig5.jpg" alt="图5. Shadow Resource Manager"></p><p>Shadow Resource Manager 通过图5所示的6种索引来探测并管理最新的影子资源：</p><ol><li>Shadow Resource Id: 用于标识影子资源的唯一ID。</li><li>Survival Time: 用于标识影子资源的存活时间。</li><li>Machine Id: 用于标识影子资源所在的机器。(注意同一机器的影子资源会被合并)</li><li>Available Resource: 用于标识影子资源的可用资源。</li><li>Occupied Resource: 用于标识影子资源的已占用资源。</li><li>Allocated Tasks: 用于标识影子资源已分配的任务。</li></ol><p>当中央状态视图同步集群状态并监控资源R的释放时，影子状态视图立即通过Echo State机制感知到该信息，并通过Echo State机制将新发现的影子资源合并到影子状态视图中。</p><p>注意在每次状态更新时，Shadow Resource Manager 会将所有空闲的影子资源释放，而只会继续管理已经被占用了的影子资源。</p><p>RM任务分配和运行结束释放都不用更新CSV，即CSV还是会一直认为这时候这些资源是空闲的，这样做是为了不影响原本的整个系统。</p><p>具体来说，它通过Echo State机制来迅速侦测新的影子资源，这种机制使得影子资源视图能够与CSV同步，但是主机影子资源的状态更新信息会被CSV忽略，而只会被Shadow Resource Manager处理，以避免影响原本的系统</p><pre><code class="hljs">问题：相当于是一种增量式的更新？但是问题在于这种大规模增量式的更新是否也会导致manager的状态更新延迟？延迟会有多严重？而且如果这里假设了这样子可以与最新的资源状态保持同步，那么这种方法能不能用到普通的调度器的同步上。或许直接预测可能的影子资源状态会更好？</code></pre><h2 id="RM-Filter"><a href="#RM-Filter" class="headerlink" title="RM Filter"></a>RM Filter</h2><p>RM Filter 是会在任务分配给各个调度器之前提前进行，任务选取有以下3个原则：</p><ol><li>过滤的任务应该与影子资源的短暂和碎片化属性相匹配。</li><li>其次，过滤后的任务应该能被抢先杀死或迁移，因为为了避免入侵，我们优先执行普通任务而不是 RM 任务，这样可以避免影响原始调度系统。</li><li>不选取太多任务，以免形成性能瓶颈。具体来说会考虑5个因素：<ol><li>RM任务队列的长度，表示RM调度器的工作负载；（负相关）</li><li>来自影子资源管理器的当前影子资源量； （正相关）</li><li>当前任务提交率，表示集群的工作负载；（正相关）</li><li>RM任务调度的成功率；（正相关）</li><li>调度系统当前的更新延迟。（正相关）</li></ol></li></ol><p>实际上还可以通过强化学习来进行任务的筛选，但是这不是本文的重点。</p><h2 id="RM-Scheduler"><a href="#RM-Scheduler" class="headerlink" title="RM Scheduler"></a>RM Scheduler</h2><p><img src="/2024/03/14/ShadowResources/fig6.jpg" alt="图6. RM Scheduler"></p><p>RM Scheduler 的执行如图6所示。它有两种调度模式：</p><ol><li><strong>虚线：</strong> 调度足够在影子资源上执行的任务，直接分配给影子资源，对CSV透明。（这种才叫RM任务）实际上就是将影子资源倒序排列，遍历选取合适的资源进行分配。</li><li><strong>实线：</strong> 调度不能在影子资源上执行的任务，当做是普通的调度器进行调度。流程如下：<ol><li>提交资源分配决定给影子状态管理视图；</li><li>影子资源管理视图返回信号没有足够的影子资源；</li><li>提交调度决策给CSV，就像普通的调度器一样；</li><li>如果调度成功就直接执行。</li></ol></li></ol><p>可以看出实际上RM Scheduler在执行时既需要拥有对影子资源的视图，也需要拥有对CSV的视图。</p><h2 id="Resource-Miner-优化"><a href="#Resource-Miner-优化" class="headerlink" title="Resource Miner 优化"></a>Resource Miner 优化</h2><p><strong>影子资源等待延迟：</strong> 当通过CSV更新，调度器对影子资源可见到这部分影子资源实际上被分配出去的这段时间。</p><p>可以探索RMiner去利用这段时间的资源。</p><p>举例，如图7所示，T0时刻R释放，成为了一种影子资源，CSV通过echo state更新给了RMiner，RMiner在T1时刻将任务放置到了这部分资源上（注意这时候不需要更新CSV），T2时刻进行了CSV更新，注意这时候调度器也认为原本被分配的影子资源也还是可以利用的，在T3时刻，调度器进行了一次普通的任务分配，没有冲突，但是在T4时刻，调度器将任务发送给了影子资源，这时候和影子资源的分配产生了冲突。其中T2~T4这段时间就是影子资源的<strong>等待延迟</strong>。</p><p>   <strong>问题：</strong> 为什么不告诉CSV这部分资源已经被分配了？这样就可以避免后续的冲突了。</p><p><img src="/2024/03/14/ShadowResources/fig7.jpg" alt="图7. 影子资源的等待延迟"></p><p>对影子资源的高利用率和低冲突率的权衡，所导致的对等待延迟时刻的影子资源的利用方式，使得本文提出了两种资源挖掘模式：</p><p><img src="/2024/03/14/ShadowResources/fig8.jpg" alt="图8. RMiner的两种资源挖掘模式对比"></p><h3 id="SafeRM-Mode"><a href="#SafeRM-Mode" class="headerlink" title="SafeRM Mode"></a>SafeRM Mode</h3><p>RMiner只在影子资源的存在时间对其进行利用，而不再等待延迟时间内对其进行利用，以最大程度避免冲突。在SafeRM模式下，RM Filter会优先考虑任务运行时间短的任务。RM调度器主要将短任务给小的影子资源。</p><p>当然由于RM任务的工作时长难以确定，所以RM任务也可能会超过影子资源存活时间，这是会尝试先迁移，如果不行再杀死。</p><h3 id="SmartRM-Mode"><a href="#SmartRM-Mode" class="headerlink" title="SmartRM Mode"></a>SmartRM Mode</h3><p>在影子资源的存在时间和等待延迟时间内对其进行利用，以最大程度提高资源利用率。在SmartRM模式下，RM Filter首先考虑任务的资源需求和驱逐成本，并优先考虑低优先的任务。RM调度器主要讲资源需求大的任务分配给尽量多空闲资源的合适的影子资源。</p><p>当冲突发生时，RM调度器会先杀死低优先级的RM任务，然后再尝试为其迁移。</p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>实验时，在谷歌集群模拟系统上添加了RM相关的组件。实验任务为2k+。模拟的节点为1500个同构节点，每个节点64个CPU，16个内存。</p><p>实验的任务主要来自阿里巴巴集群数据集。更新延迟为0.5s，调度器调度速率为每秒1000个任务，调度器数量分别设置为8和16，任务平均执行时间为5s，指数分布，平均一个作业包含12个任务，任务达到速率有1.43和0.7，前者在300秒内生成了200多个作业，即约2400个任务。</p><p>实验主要想回答3个问题：</p><ol><li>RMiner 能为共享状态架构带来哪些性能提升？ </li><li>在当前的共享状态调度器中采用RMiner的成本是多少？ </li><li>引入的优化如何有助于性能改进？</li></ol><h2 id="资源利用率"><a href="#资源利用率" class="headerlink" title="资源利用率"></a>资源利用率</h2><p><img src="/2024/03/14/ShadowResources/fig9.jpg" alt="图9. 资源利用率"></p><p>   图是真好看啊！</p><p>条形图表示 CPU 利用率的改进。显然，RMiner 通过挖掘影子资源来提高集群 CPU 利用率。不同场景下，影子资源占用集群资源的1.5%~5.0%。通过利用资源等待延迟方面的资源，SafeRM 的性能优于 NoRM 1.5% 至 4%，SmartRM 的性能优于 NoRM 1.6% 至 5.8%。</p><p>更具体地说，RMiner 在 8 个调度程序场景（平均利用率为 36.9%）下比在 16 个调度程序（平均利用率为 71.8%）下工作得更好，因为更少的调度程序可以更容易地为影子资源找到合适的 RM 任务（因为资源利用率低） 。此外，RMiner 在较高的任务提交率（2 倍）下表现更好，因为更多的任务提供了更多可供利用的已释放资源。</p><p>我们还将每个设置下的影子资源利用率报告为标记线。通过记录总体影子资源和分配的影子资源，SafeRM 使用了 26% 到 82% 的影子资源，SmartRM 使用了 58% 到 112% 的影子资源。 SafeRM 更加保守，仅限制影子资源生存时间的任务，而 SmartRM 则更加激进，在资源等待延迟中利用影子资源，甚至超过了不可见影子资源的上限。</p><h2 id="任务吞吐量"><a href="#任务吞吐量" class="headerlink" title="任务吞吐量"></a>任务吞吐量</h2><p><img src="/2024/03/14/ShadowResources/fig10.jpg" alt="图10. 任务吞吐量"></p><p>图 10 (a) 显示了阿里巴巴跟踪的改进，其中 SafeRM 比 NoRM 实现了高达 10% 的吞吐量提升，SmartRM 实现了高达 28% 的吞吐量提升在高工作负载（任务提交率）下，RMiner 比低工作负载表现更好，因为更多已完成的任务产生更多的影子资源。</p><p>此外，我们在图 10(b) 中比较了 Google 跟踪上三种方案的吞吐量。结果表明，SafeRM 实现了 2% 到 9% 的改进，SmartRM 实现了 10% 到 28% 的改进，这与阿里巴巴的结果类似，进一步验证了 RMiner 的性能。</p><h2 id="任务等待延迟"><a href="#任务等待延迟" class="headerlink" title="任务等待延迟"></a>任务等待延迟</h2><p><img src="/2024/03/14/ShadowResources/fig11.jpg" alt="图11. 任务等待延迟"></p><p>我们在图 11 中展示了作业等待时间的结果。它表明 RMiner 在较低工作负载下的表现与 NoRM 类似，因为在这种情况下任务不需要在队列中等待。然而，在更高的工作负载（1.75x和2x）下，并行提交的任务更多，普通调度器几乎已经达到了调度能力。 RMiner 的表现非常出色，因为它利用了更多短期任务来减少整体排队延迟。 RMiner 在 8 个调度程序下将作业等待时间缩短高达 25.4%，在 16 个调度程序下将作业等待时间缩短高达 10.4%。更多的调度器减少了并发调度任务的压力，但会导致更多的调度冲突。此外，我们进一步在 Google 的跟踪上验证了改进，发现 RMiner 在 8 个调度器下实现了 59.9% 的改进，在 16 个调度器下实现了 24.9% 的改进。</p><h2 id="任务冲突"><a href="#任务冲突" class="headerlink" title="任务冲突"></a>任务冲突</h2><p><img src="/2024/03/14/ShadowResources/fig12.jpg" alt="图12. 任务冲突"></p><p>我们记录了 16 个调度程序设置的不同工作负载级别下的冲突。图 12 报告了性能改进和引发的冲突之间的关系。图 12（a）显示了基线和 SafeRM 之间的比较，这表明 SafeRM 在最坏情况下导致冲突增加不到 3%，从而将资源利用率和任务吞吐量提高了 4%。平均而言，与当前的共享状态调度程序相比，SafeRM 造成的冲突多了 0.5%，这与性能收益相比是可以接受的。</p><p>此外，我们在图 12 (b) 中报告了 SmartRM 的结果。同样，SmartRM 在最坏的情况下会导致冲突增加 3%，资源利用率提高 6%，吞吐量提高 13%。 SmartRM 的平均冲突成本为 0.73%，由于挖矿策略更加激进，比 SafeRM 略高。我们还发现，在较高工作负载下，冲突成本更加严重，因为更多并发任务提交使 SmartRM 更容易与正常调度程序发生冲突。综上所述，从工作冲突的角度来看，成本与绩效的提升相比可以忽略不计。</p><h2 id="总体分析"><a href="#总体分析" class="headerlink" title="总体分析"></a>总体分析</h2><p>RMiner 的额外开销也是回答问题 3 的一个重要方面。不幸的是，工业模拟器没有对调度开销进行建模，因此我们进行了全面的理论分析。 RMiner的开销包括影子资源管理开销和RM调度开销。影子资源管理器占用额外的内存空间来存储和更新影子资源状态索引，大约是CSV空间的3%-12.5%。在较高工作负载下，管理算法的频率很频繁，但通过哈希映射，操作的复杂度为 O(1)，从而导致可接受的计算开销。总体而言，影子资源的管理所产生的开销可以忽略不计。</p><p>至于额外的调度开销，当前的共享状态调度器设计配备了数十个具有全局状态视图的并行分布式调度器。 RMiner 增加了一个 RM 调度器，大大增强了当前设计的可见性，并且 RM 调度器的调度成本比传统的并行调度器要低，因为调度范围和实体都比以前更小。因此，RMiner 的调度开销比当前共享状态设计大约增加了个位数。总体而言，与集群性能的显着提升相比，在当前共享状态调度器中采用 RMiner 的成本可以忽略不计。</p><h2 id="RM模式对比"><a href="#RM模式对比" class="headerlink" title="RM模式对比"></a>RM模式对比</h2><p>实验中，SafeRM保留更新延迟的过滤阈值以保证最小化冲突。 SmartRM的默认阈值也是更新延迟，我们将过滤器阈值调整为2x更新延迟和4x更新延迟来比较性能。前者发生冲突的可能性较低，被定义为保守派SmartRM（SmartRM-C）。相反，后者被定义为激进的SmartRM（SmartRM-A）。此外，我们改变了 0.5 秒的默认更新延迟来调查对结果的影响。实验在 1x 工作负载级别和 16 个并行调度器下进行。</p><p><img src="/2024/03/14/ShadowResources/fig13.jpg" alt="图13. RM模式对比-任务吞吐率和利用率"></p><p><img src="/2024/03/14/ShadowResources/fig14.jpg" alt="图14. RM模式对比-任务冲突"></p><p>查看图13，与直觉相反，将更多任务过滤到 RMiner (SmartRM-A) 会提高资源利用率，同时降低任务吞吐量。这是因为此设置留给普通调度程序的短期任务较少，而普通调度程序往往会将重量级任务调度到集群，集群会同时占用更多资源，但总共完成的任务较少。因此，我们需要仔细控制过滤原则，以避免 RMiner 中的过度过滤和欠过滤任务。更新延迟也会影响 RMiner 的性能。更新延迟越大，资源浪费越大，导致任务吞吐量和资源利用率降低。在较高的更新延迟下，SmartRM-A 在利用率方面的表现比在较低情况下更差，因为 RMiner 的改进被正常调度程序的退化所掩盖，但它在利用率方面的表现几乎相同，因为在这种情况下执行了更多的重量级任务。</p><p>此外，我们在图 14 中报告了冲突的详细信息。我们记录了由于冲突而终止的任务，并将数量标准化为 RM 任务。该指标的值越低意味着与正常调度发生冲突的 RM 任务就越少。显然，SafeRM 很少与正常调度发生冲突。对于SmartRM来说，过滤器阈值越高，杀死RM任务的比例就越高，导致与并行调度器的冲突更多。性能改进和冲突成本之间存在权衡，权衡的两侧代表了RMiner的不同设计目标：最高的性能改进或对正常系统的最低侵入。总体而言，不同的RMiner以可接受的成本实现了相当大的性能提升，并且可以针对不同的目标进行灵活配置。</p>]]></content>
    
    
    <categories>
      
      <category>集群调度</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux控制台输出多种样式彩色字符及原理解析</title>
    <link href="/2024/03/02/colorfulEcho/"/>
    <url>/2024/03/02/colorfulEcho/</url>
    
    <content type="html"><![CDATA[<h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h1><p>之前在做MIT6.824的实验的时候，有<a href="https://blog.josejg.com/debugging-pretty/">助教资料</a>在说明如何输出彩色的字符来让日志更加清晰。所以对Linux控制台如何输出多种样式的彩色字符以及它的原理产生了兴趣，学习了之后在这里记录一下。</p><h1 id="2-原理"><a href="#2-原理" class="headerlink" title="2. 原理"></a>2. 原理</h1><p>Linux控制台输出彩色字符的原理是通过ANSI转义码来实现的。ANSI转义码是一种控制字符，用于控制文本终端的行为。包括但不限于控制光标位置、颜色、清屏等。</p><p>下面这是一段输出蓝色字符的控制台代码：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;\033[34mHello\033[0m&quot;</span><br></code></pre></td></tr></table></figure><p>在vscode的终端显示结果如下：</p><p><img src="/2024/03/02/colorfulEcho/eg1.jpg" alt="输出结果"></p><p>下面对这段代码逐个进行解析：</p><ul><li>-e：表示开启转义字符的解析，如果不加这个参数，\033会被当做普通字符输出。</li><li>\033：表示转义字符的开始。在ASCII字符集中，十进制的33代表了Escape字符（也可以写为\033或\x1B），它通常用于表示控制序列的开始。</li><li>[34m：表示设置颜色。34代表蓝色，m表示设置颜色的转义序列的结束。</li><li>[0m：表示重置为默认设置。0代表默认设置，m表示设置颜色的转义序列的结束。如果不设置为默认设置，后续的字符都会被设置为蓝色。</li></ul><h1 id="3-转义代码"><a href="#3-转义代码" class="headerlink" title="3. 转义代码"></a>3. 转义代码</h1><p>主要与输出字符格式相关的转义代码的格式如下，可以单独使用也可以利用;来混合使用：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">\033[显示方式;前景色;背景色m<br></code></pre></td></tr></table></figure><p>下面是一些常用的转义代码：</p><h2 id="1-显示方式"><a href="#1-显示方式" class="headerlink" title="1. 显示方式"></a>1. 显示方式</h2><p>代码及对应显示方式如下：</p><ul><li>0：所有属性关闭，恢复到默认值。</li><li>1：粗体或者高亮。</li><li>2：弱化（低亮）。(不是所有终端都支持)</li><li>3：斜体。(不是所有终端都支持)</li><li>4：下划线。</li><li>5,6：闪烁。(不是所有终端都支持)</li><li>7：反显，即前景色和背景色交换。</li><li>8：隐藏字符。</li><li>9：删除线。(不是所有终端都支持)</li><li>10：将文本的前景色设置为默认颜色。</li><li>21：双下划线。(不是所有终端都支持)</li></ul><p>在vscode的终端显示结果如下：</p><p><img src="/2024/03/02/colorfulEcho/eg2.jpg" alt="显示方式"></p><h2 id="2-前景色"><a href="#2-前景色" class="headerlink" title="2. 前景色"></a>2. 前景色</h2><p>代码及对应颜色如下：</p><ul><li>30：黑色。</li><li>31：红色。</li><li>32：绿色。</li><li>33：黄色。</li><li>34：蓝色。</li><li>35：洋红。</li><li>36：青色。</li><li>37：白色。</li></ul><p>在vscode的终端显示结果如下（注意37号白色被终端自动修改了以能够显示清楚）：</p><p><img src="/2024/03/02/colorfulEcho/eg3.jpg" alt="前景色"></p><p>而38号前景色是用于设置前景色的其他模式，包括两种：</p><ol><li>使用 ANSI 256 色模式设置前景色，例如：\033[38;5;196m。这里的5表示使用 ANSI 256 色模式，196表示使用ANSI 256 色模式中的第 196 种颜色</li><li>使用 TrueColor 模式设置前景色，例如：\033[38;2;255;0;0m。这里的2表示使用 TrueColor 模式，255;0;0表示RGB颜色值</li></ol><p>39号表示重置前景色为默认颜色。</p><h2 id="3-背景色"><a href="#3-背景色" class="headerlink" title="3. 背景色"></a>3. 背景色</h2><p>代码及对应颜色如下：</p><ul><li>40：黑色。</li><li>41：红色。</li><li>42：绿色。</li><li>43：黄色。</li><li>44：蓝色。</li><li>45：洋红。</li><li>46：青色。</li><li>47：白色。</li></ul><p>在vscode的终端显示结果如下（注意47号白色被终端自动修改了以能够显示清楚）：</p><p><img src="/2024/03/02/colorfulEcho/eg4.jpg" alt="背景色"></p><p>同样的，48号背景色是用于设置背景色的其他模式，包括使用 ANSI 256 色模式设置背景色和使用 TrueColor 模式设置背景色。<br>49号表示重置背景色为默认颜色。</p><h2 id="4-其他"><a href="#4-其他" class="headerlink" title="4. 其他"></a>4. 其他</h2><p>还有一些其他比较有意思的转义代码，不过格式就不是\033[显示方式;前景色;背景色m了，如下：</p><ul><li><code>\033[n*A</code> :光标上移n行 </li><li><code>\033[nB</code>:光标下移n行 </li><li><code>\033[nC</code>:光标右移n行 </li><li><code>\033[nD</code>:光标左移n行 </li><li><code>\033[y</code>;xH :设置光标位置 </li><li><code>\033[2J</code> :清屏 </li><li><code>\033[K</code>:清除从光标到行尾的内容 </li><li><code>\033[s</code>:保存光标位置 </li><li><code>\033[u</code>:恢复光标位置 </li><li><code>\033[?25l</code>:隐藏光标 </li><li><code>\033[?25h</code>:显示光标</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><a href="https://blog.csdn.net/TomorrowAndTuture/article/details/116448273">Linux 命令行输出不同颜色的文本</a></li><li><a href="https://www.linuxquestions.org/questions/linux-software-2/adding-colors-to-your-motd-105038/">Adding colors to your motd?</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Shell</category>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在Unbuntu上安装Go以及解决Vscode上Go插件无法安装的问题</title>
    <link href="/2024/03/01/ubuntuInstallGo/"/>
    <url>/2024/03/01/ubuntuInstallGo/</url>
    
    <content type="html"><![CDATA[<h1 id="1-下载-Go-压缩包"><a href="#1-下载-Go-压缩包" class="headerlink" title="1. 下载 Go 压缩包"></a>1. 下载 Go 压缩包</h1><p>在写这篇文章的时候，Go 的最新版为 1.22.0。在我们下载安装包时，请浏览Go 官方下载页面,并且检查一下是否有新的版本可用。</p><p>以 root 或者其他 sudo 用户身份运行下面的命令，下载并且解压 Go 二进制文件到&#x2F;usr&#x2F;local目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget -c https://dl.google.com/go/go1.22.0.linux-amd64.tar.gz -O - | sudo tar -xz -C /usr/local<br></code></pre></td></tr></table></figure><h1 id="2-调整环境变量"><a href="#2-调整环境变量" class="headerlink" title="2. 调整环境变量"></a>2. 调整环境变量</h1><p>通过将 Go 目录添加到$PATH环境变量，系统将会知道在哪里可以找到 Go 可执行文件。</p><p>这个可以通过添加下面的行到&#x2F;etc&#x2F;profile文件（系统范围内安装）或者$HOME&#x2F;.profile文件（当前用户安装）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:/usr/local/go/bin<br></code></pre></td></tr></table></figure><p>保存文件，并且重新加载新的PATH 环境变量到当前的 shell 会话：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">source</span> ~/.profile<br></code></pre></td></tr></table></figure><h1 id="3-验证-Go-安装过程"><a href="#3-验证-Go-安装过程" class="headerlink" title="3. 验证 Go 安装过程"></a>3. 验证 Go 安装过程</h1><p>通过打印 Go 版本号，验证安装过程。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">go version<br></code></pre></td></tr></table></figure><p>输出应该像下面这样：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">go</span> version go1.<span class="hljs-number">22</span>.<span class="hljs-number">0</span> linux/amd64<br></code></pre></td></tr></table></figure><h1 id="4-安装Vscode插件"><a href="#4-安装Vscode插件" class="headerlink" title="4. 安装Vscode插件"></a>4. 安装Vscode插件</h1><p>首先在vscode中搜索安装Go插件，点击第一个名称为Go的插件进行安装。<br>然后由于网络防火墙的原因，有部分组件无法下载。<br>需要在命令行中输入以下命令替换go的下载源：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">go <span class="hljs-built_in">env</span> -w GO111MODULE=on<br>go <span class="hljs-built_in">env</span> -w GOPROXY=https://goproxy.io,direct<br></code></pre></td></tr></table></figure><p>替换好关闭vscode重新打开，会弹出install all，点击等待安装即可。<br>如果没有弹出就按crtl+shift+p，输入go install&#x2F;update tools，点击等待安装即可。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><a href="https://cloud.tencent.com/developer/article/1623121">如何在 Ubuntu 20.04 上安装 Go</a></li><li><a href="https://zhuanlan.zhihu.com/p/387853200">解决vscode安装go插件失败的问题</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Go</category>
      
      <category>脚本</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在CentOS上使用源码安装Python3.7，不与系统Python2.7冲突，同时支持pip3（脚本安装，亲测有效）</title>
    <link href="/2024/03/01/centosInstallPython/"/>
    <url>/2024/03/01/centosInstallPython/</url>
    
    <content type="html"><![CDATA[<p>该脚本主要是在Centos系统上使用源码安装Python3.7，安装后可以调用python3和pip3来进行使用，同时不与系统Python2.7冲突，还额外加入了腾讯的pip源来加速pip3下载包。</p><p>脚本使用方法如下：</p><ol><li>创建文件 <code>install_py37.sh</code>，写入以下 shell 脚本</li><li>赋予执行权限，<code>chmox +x install_py37.sh</code></li><li>执行脚本，<code>./install_py37.sh</code></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/env bash</span><br><br><span class="hljs-comment">## 下载 Python 源码，如果已下载源码在脚本当前目录下，可注释跳过下载步骤</span><br>wget https://www.python.org/ftp/python/3.7.12/Python-3.7.12.tgz<br><br><span class="hljs-comment">## 安装编译依赖组件</span><br>yum -y install wget zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gcc make libffi-devel xz-devel<br><br><span class="hljs-comment">## 解压安装</span><br><span class="hljs-comment"># 解压到/usr/local/src目录</span><br>tar zvxf Python-3.7.12.tgz -C /usr/local/src<br><span class="hljs-built_in">cd</span> /usr/local/src/Python-3.7.12<br><span class="hljs-comment"># 编译前配置</span><br>./configure prefix=/usr/local/python3 --enable-shared<br><span class="hljs-comment"># 编译构建</span><br>make -j8<br><span class="hljs-comment"># 安装Python</span><br>make install<br><span class="hljs-comment"># 清理编译产出的中间文件</span><br>make clean<br><span class="hljs-comment"># 链接构建产出的Python可执行文件到/usr/local/bin目录</span><br><span class="hljs-built_in">ln</span> -s /usr/local/python3/bin/python3 /usr/local/bin/python3<br><span class="hljs-comment"># 链接构建产出的pip3可执行文件到/usr/local/bin目录</span><br><span class="hljs-built_in">ln</span> -s /usr/local/python3/bin/pip3 /usr/local/bin/pip3<br><span class="hljs-comment"># 链接构建产出的Python动态库</span><br><span class="hljs-built_in">ln</span> -s /usr/local/python3/lib/libpython3.7m.so.1.0 /usr/lib/libpython3.7m.so.1.0<br><span class="hljs-comment"># 配置动态库</span><br>ldconfig<br><br><span class="hljs-comment">## 检查Python版本是否安装成功</span><br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;\033[1;42;37m[<span class="hljs-subst">$(date <span class="hljs-string">&quot;+%Y/%m/%d %H:%M:%S&quot;</span>)</span>] [Check]: 检查Python版本\033[0m&quot;</span><br>python3 --version<br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;\033[1;42;37m[<span class="hljs-subst">$(date <span class="hljs-string">&quot;+%Y/%m/%d %H:%M:%S&quot;</span>)</span>] [Check]: 检查Python版本\033[0m&quot;</span><br><br><span class="hljs-comment">## pypi下载源配置</span><br><span class="hljs-built_in">mkdir</span> ~/.pip3/<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;extra-index-url = https://mirrors.cloud.tencent.com/pypi/simple&quot;</span> &gt;&gt; ~/.pip3/pip.conf<br></code></pre></td></tr></table></figure><p>主要是参考了这篇文章：<a href="https://tencent.github.io/CodeAnalysis/zh/advanced/install_python37_on_centos.html">CentOS 7 安装 Python 3.7</a><br>不同点在于将原本的链接路径和安装结果改为了python3和pip3。</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
      <category>脚本</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【MIT6.824】lab2A实现笔记</title>
    <link href="/2024/02/27/MIT6-824lab2A/"/>
    <url>/2024/02/27/MIT6-824lab2A/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>实现了MIT6.824中的lab2A，即leader选举的部分。</p><h1 id="Raft结构及初始化"><a href="#Raft结构及初始化" class="headerlink" title="Raft结构及初始化"></a>Raft结构及初始化</h1><p>为一个Raft中的节点增加的变量主要有：</p><ul><li>currentTerm: 当前任期</li><li>votedFor: 为谁投票, -1表示没有投票，注意一个任期只能投一次票</li><li>state: 当前节点的状态</li><li>heartbeatTimeout: 心跳超时计数器</li><li>electionTimeout: 选举超时计数器</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// A Go object implementing a single Raft peer.</span><br><span class="hljs-keyword">type</span> Raft <span class="hljs-keyword">struct</span> &#123;<br>mu               sync.RWMutex        <span class="hljs-comment">// Lock to protect shared access to this peer&#x27;s state</span><br>peers            []*labrpc.ClientEnd <span class="hljs-comment">// RPC end points of all peers</span><br>persister        *Persister          <span class="hljs-comment">// Object to hold this peer&#x27;s persisted state</span><br>me               <span class="hljs-type">int</span>                 <span class="hljs-comment">// this peer&#x27;s index into peers[]</span><br>dead             <span class="hljs-type">int32</span>               <span class="hljs-comment">// set by Kill()</span><br>currentTerm      <span class="hljs-type">int</span><br>votedFor         <span class="hljs-type">int</span><br>state            NodeState<br>heartbeatTimeout *time.Timer<br>electionTimeout  *time.Timer<br>&#125;<br><br><span class="hljs-comment">// NodeState represents the state of a node in the raft protocol</span><br><span class="hljs-keyword">type</span> NodeState <span class="hljs-type">uint8</span><br><br><span class="hljs-keyword">const</span> (<br>Follower NodeState = <span class="hljs-literal">iota</span><br>Candidate<br>Leader<br>)<br></code></pre></td></tr></table></figure><p>初始化Make函数如下，注意为新添加的变量进行初始化，可以看到初始化之后就会启动一个ticker的goroutine来让节点不断运行。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Make</span><span class="hljs-params">(peers []*labrpc.ClientEnd, me <span class="hljs-type">int</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">persister *Persister, applyCh <span class="hljs-keyword">chan</span> ApplyMsg)</span></span> *Raft &#123;<br>rf := &amp;Raft&#123;<br>peers:            peers,<br>persister:        persister,<br>me:               me,<br>dead:             <span class="hljs-number">0</span>,<br>currentTerm:      <span class="hljs-number">0</span>,<br>votedFor:         <span class="hljs-number">-1</span>,<br>state:            Follower,<br>heartbeatTimeout: time.NewTimer(time.Duration(StableHeartbeatTimeout())),<br>electionTimeout:  time.NewTimer(time.Duration(RandomizedElectionTimeout())),<br>&#125;<br><br><span class="hljs-comment">// Your initialization code here (2A, 2B, 2C).</span><br><br><span class="hljs-comment">// initialize from state persisted before a crash</span><br>rf.readPersist(persister.ReadRaftState())<br><br><span class="hljs-comment">// start ticker goroutine to start elections</span><br><span class="hljs-keyword">go</span> rf.ticker()<br><br><span class="hljs-keyword">return</span> rf<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="计时函数"><a href="#计时函数" class="headerlink" title="计时函数"></a>计时函数</h1><p>计时函数如上所述有两个：</p><ul><li>heartbeatTimeout: 倒计时结束时，需要向其他节点发送心跳，以维持自己的leader地位</li><li>electionTimeout: 倒计时结束时，需要转化为candidate开始选举，如果在倒计时结束前收到了leader的心跳，则重置倒计时。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> ticker() &#123;<br><span class="hljs-keyword">for</span> rf.killed() == <span class="hljs-literal">false</span> &#123;<br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> &lt;-rf.heartbeatTimeout.C:<br>rf.mu.Lock()<br><span class="hljs-keyword">if</span> rf.state == Leader &#123;<br>rf.broadcastHeartbeat()<br>rf.heartbeatTimeout.Reset(StableHeartbeatTimeout())<br>&#125;<br>rf.mu.Unlock()<br><span class="hljs-keyword">case</span> &lt;-rf.electionTimeout.C:<br>rf.mu.Lock()<br>rf.changeState(Candidate)<br>rf.currentTerm++<br>rf.startElection()<br>rf.electionTimeout.Reset(RandomizedElectionTimeout())<br>rf.mu.Unlock()<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="选举leader"><a href="#选举leader" class="headerlink" title="选举leader"></a>选举leader</h1><p>选举leader主要依靠发送RequestVote RPC来进行，选举的过程如下：</p><ol><li>electionTimeout计时器到期，节点转化为candidate状态，增加currentTerm并开始选举</li><li>发送RequestVote RPC给其他节点，请求投票</li><li>接收到其他节点的投票结果。</li></ol><p>按照Raft论文的描述可以将选举结果分为三种：</p><ol><li>得到了大多数节点的投票，成为leader</li><li>有其他节点成为了leader，自己转化为follower。如何感知到其他节点成为了leader呢？有两种手段：<ol><li>通过RequestVoteReply中的Term字段，如果Term比自己的大，则说明有其他节点成为了leader</li><li>接受到了其他节点的心跳，说明有其他节点成为了leader</li></ol></li><li>大家平分选票，没有leader产生，等待electionTimeout计时器到期，重新开始选举</li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> startElection() &#123;<br>request := rf.genRequestVoteRequest()<br>DPrintf(<span class="hljs-string">&quot;&#123;Node %v&#125; starts election with RequestVoteRequest %v&quot;</span>, rf.me, request)<br>rf.votedFor = rf.me<br>grantedVoteNum := <span class="hljs-number">1</span><br><br><span class="hljs-comment">// Your code here (2A, 2B).</span><br><span class="hljs-keyword">for</span> peer := <span class="hljs-keyword">range</span> rf.peers &#123;<br><span class="hljs-keyword">if</span> peer != rf.me &#123;<br><span class="hljs-keyword">if</span> peer == rf.me &#123;<br><span class="hljs-keyword">continue</span><br>&#125;<br><br><span class="hljs-keyword">go</span> rf.electionRequestOnce(peer, &amp;grantedVoteNum, request)<br>&#125;<br>&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> electionRequestOnce(peer <span class="hljs-type">int</span>, grantedVoteNum *<span class="hljs-type">int</span>, request *RequestVoteArgs) &#123;<br>reply := <span class="hljs-built_in">new</span>(RequestVoteReply)<br><span class="hljs-keyword">if</span> rf.sendRequestVote(peer, request, reply) &#123;<br>rf.mu.Lock()<br><span class="hljs-keyword">defer</span> rf.mu.Unlock()<br>DPrintf(<span class="hljs-string">&quot;&#123;Node %v&#125; received RequestVoteReply &#123;%v&#125; from &#123;Node %v&#125;&quot;</span>, rf.me, reply, peer)<br><span class="hljs-keyword">if</span> rf.currentTerm == request.Term &amp;&amp; rf.state == Candidate &#123;<br><span class="hljs-keyword">if</span> reply.VoteGranted &#123;<br>*grantedVoteNum++<br><span class="hljs-keyword">if</span> *grantedVoteNum &gt; <span class="hljs-built_in">len</span>(rf.peers)/<span class="hljs-number">2</span> &#123;<br>rf.changeState(Leader)<br>rf.broadcastHeartbeat()<br>&#125;<br>&#125;<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> reply.Term &gt; rf.currentTerm &#123;<br>DPrintf(<span class="hljs-string">&quot;&#123;Node %v&#125; found higher term %v in RequestVoteReply %v from &#123;Node %v&#125;&quot;</span>, rf.me, reply.Term, reply, peer)<br>rf.currentTerm = reply.Term<br>rf.votedFor = <span class="hljs-number">-1</span><br>rf.changeState(Follower)<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>节点在进行投票时的规则如下：</p><ol><li>如果自己的term比对方大，则拒绝投票</li><li>如果在当前term中已经投过票给其他candidate，则拒绝投票</li><li>其余情况下投票给对方，并更新自己的term与votedFor，并直接转化为follower状态</li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> RequestVote(args *RequestVoteArgs, reply *RequestVoteReply) &#123;<br><span class="hljs-comment">// Your code here (2A, 2B).</span><br>rf.mu.Lock()<br><span class="hljs-keyword">defer</span> rf.mu.Unlock()<br><span class="hljs-keyword">defer</span> DPrintf(<span class="hljs-string">&quot;&#123;Node %v&#125;&#x27;s state is &#123;state: %v, term: %v&#125;, the RequestVoteReply is &#123;%v&#125;&quot;</span>, rf.me, rf.state, rf.currentTerm, reply)<br><br><span class="hljs-keyword">if</span> args.Term &lt; rf.currentTerm || (args.Term == rf.currentTerm &amp;&amp; rf.votedFor != <span class="hljs-number">-1</span> &amp;&amp; rf.votedFor != args.CandidateId) &#123;<br>reply.Term, reply.VoteGranted = rf.currentTerm, <span class="hljs-literal">false</span><br><span class="hljs-keyword">return</span><br>&#125;<br><span class="hljs-keyword">if</span> args.Term &gt; rf.currentTerm &#123;<br>rf.currentTerm, rf.votedFor = args.Term, <span class="hljs-number">-1</span><br>rf.changeState(Follower)<br>&#125;<br><span class="hljs-keyword">if</span> !rf.isLogUpToDate(args.LastLogIndex, args.LastLogTerm) &#123;<br>reply.Term, reply.VoteGranted = rf.currentTerm, <span class="hljs-literal">false</span><br><span class="hljs-keyword">return</span><br>&#125;<br><br>rf.votedFor = args.CandidateId<br><span class="hljs-comment">// now the term of the candidate must equal to the current term of the rf</span><br>reply.Term, reply.VoteGranted = rf.currentTerm, <span class="hljs-literal">true</span><br>&#125;<br><br><span class="hljs-keyword">type</span> RequestVoteArgs <span class="hljs-keyword">struct</span> &#123;<br>Term         <span class="hljs-type">int</span><br>CandidateId  <span class="hljs-type">int</span><br>LastLogIndex <span class="hljs-type">int</span><br>LastLogTerm  <span class="hljs-type">int</span><br>&#125;<br><span class="hljs-keyword">type</span> RequestVoteReply <span class="hljs-keyword">struct</span> &#123;<br>Term        <span class="hljs-type">int</span><br>VoteGranted <span class="hljs-type">bool</span><br>&#125;<br><br></code></pre></td></tr></table></figure><p>注意在状态转化时需要对计时器进行相应的修改，如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> changeState(newState NodeState) &#123;<br><span class="hljs-keyword">if</span> rf.state == newState &#123;<br><span class="hljs-keyword">return</span><br>&#125;<br>DPrintf(<span class="hljs-string">&quot;&#123;Node %v&#125; changes state from %s to %s&quot;</span>, rf.me, rf.state, newState)<br>rf.state = newState<br><br><span class="hljs-keyword">switch</span> newState &#123;<br><span class="hljs-keyword">case</span> Follower:<br>rf.heartbeatTimeout.Stop()<br>rf.electionTimeout.Reset(RandomizedElectionTimeout())<br><span class="hljs-keyword">case</span> Candidate:<br><span class="hljs-keyword">case</span> Leader:<br>rf.broadcastHeartbeat()<br>rf.heartbeatTimeout.Reset(StableHeartbeatTimeout())<br>rf.electionTimeout.Stop()<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="心跳广播"><a href="#心跳广播" class="headerlink" title="心跳广播"></a>心跳广播</h1><p>理论上心跳发送应该与日志复制用的是同一种RPC，但是lab2A不需要实现日志复制，所以这里的日志复制进行了简化，能发送心跳来维持自己的leader地位即可。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> replicateOneRound(peer <span class="hljs-type">int</span>) &#123;<br><span class="hljs-keyword">if</span> rf.state != Leader &#123;<br><span class="hljs-keyword">return</span><br>&#125;<br><br>request := rf.genAppendEntriesRequest(peer)<br>reply := <span class="hljs-built_in">new</span>(AppendEntriesReply)<br><span class="hljs-keyword">if</span> rf.sendAppendEntries(peer, request, reply) &#123;<br>DPrintf(<span class="hljs-string">&quot;&#123;Node %v&#125; received AppendEntriesReply &#123;%v&#125; from &#123;Node %v&#125;&quot;</span>, rf.me, reply, peer)<br>&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> AppendEntries(args *AppendEntriesRequest, reply *AppendEntriesReply) &#123;<br>DPrintf(<span class="hljs-string">&quot;&#123;Node %v&#125; received AppendEntriesRequest &#123;%v&#125;&quot;</span>, rf.me, args)<br>rf.changeState(Follower)<br>rf.electionTimeout.Reset(RandomizedElectionTimeout())<br>reply.Term, reply.Success = rf.currentTerm, <span class="hljs-literal">true</span><br>&#125;<br><br><span class="hljs-keyword">type</span> AppendEntriesRequest <span class="hljs-keyword">struct</span> &#123;<br>Term     <span class="hljs-type">int</span><br>LeaderId <span class="hljs-type">int</span><br>&#125;<br><span class="hljs-keyword">type</span> AppendEntriesReply <span class="hljs-keyword">struct</span> &#123;<br>Term    <span class="hljs-type">int</span><br>Success <span class="hljs-type">bool</span><br>&#125;<br></code></pre></td></tr></table></figure><h1 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h1><p>运行结果如下，能通过所有测试：</p><p><img src="/2024/02/27/MIT6-824lab2A/result.jpg" alt="运行结果"></p>]]></content>
    
    
    <categories>
      
      <category>MIT6.824</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>go</tag>
      
      <tag>分布式</tag>
      
      <tag>MIT6.824</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【MIT6.824】lab2原代码解析</title>
    <link href="/2024/02/25/%E3%80%90MIT6-824%E3%80%91lab2%E5%8E%9F%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    <url>/2024/02/25/%E3%80%90MIT6-824%E3%80%91lab2%E5%8E%9F%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>主要解析的实lab中6.5840&#x2F;src&#x2F;raft&#x2F;raft.go这个代码</p><h1 id="原代码解析"><a href="#原代码解析" class="headerlink" title="原代码解析"></a>原代码解析</h1><p>首先看到最后的Make函数,这是初始化raft的函数，传进来的参数有所有的peers列表（包括自己），自己在列表中的id，镜像以及网络信息传递接口。初始化完成后进入常规的计时程序。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// the service or tester wants to create a Raft server. the ports</span><br><span class="hljs-comment">// of all the Raft servers (including this one) are in peers[]. this</span><br><span class="hljs-comment">// server&#x27;s port is peers[me]. all the servers&#x27; peers[] arrays</span><br><span class="hljs-comment">// have the same order. persister is a place for this server to</span><br><span class="hljs-comment">// save its persistent state, and also initially holds the most</span><br><span class="hljs-comment">// recent saved state, if any. applyCh is a channel on which the</span><br><span class="hljs-comment">// tester or service expects Raft to send ApplyMsg messages.</span><br><span class="hljs-comment">// Make() must return quickly, so it should start goroutines</span><br><span class="hljs-comment">// for any long-running work.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Make</span><span class="hljs-params">(peers []*labrpc.ClientEnd, me <span class="hljs-type">int</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">persister *Persister, applyCh <span class="hljs-keyword">chan</span> ApplyMsg)</span></span> *Raft &#123;<br>rf := &amp;Raft&#123;&#125;<br>rf.peers = peers<br>rf.persister = persister<br>rf.me = me<br><br><span class="hljs-comment">// Your initialization code here (2A, 2B, 2C).</span><br><br><span class="hljs-comment">// initialize from state persisted before a crash</span><br>rf.readPersist(persister.ReadRaftState())<br><br><span class="hljs-comment">// start ticker goroutine to start elections</span><br><span class="hljs-keyword">go</span> rf.ticker()<br><br><br><span class="hljs-keyword">return</span> rf<br>&#125;<br></code></pre></td></tr></table></figure><p>计时程序如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> ticker() &#123;<br><span class="hljs-keyword">for</span> rf.killed() == <span class="hljs-literal">false</span> &#123;<br><br><span class="hljs-comment">// Your code here (2A)</span><br><span class="hljs-comment">// Check if a leader election should be started.</span><br><br><br><span class="hljs-comment">// pause for a random amount of time between 50 and 350</span><br><span class="hljs-comment">// milliseconds.</span><br>ms := <span class="hljs-number">50</span> + (rand.Int63() % <span class="hljs-number">300</span>)<br>time.Sleep(time.Duration(ms) * time.Millisecond)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
      <category>go</category>
      
      <category>MIT6.824</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文阅读】In Search of an Understandable Consensus Algorithm</title>
    <link href="/2023/12/26/RaftPaperRead/"/>
    <url>/2023/12/26/RaftPaperRead/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>共识一致性算法常用在分布式系统中，一个系统会有一个领导者，如GFS，我们需要有多个领导者副本来提高系统的容错性。但是之前的共识性算法经常采用Paxos，但是该算法很难理解。所以本文的作者重点面向可理解性提出了一个新的共识性算法Raft。主要做法是将大步骤分解成小步骤，然后尽量降低复杂度。</p><p>在具体关注其实现之前强烈建议去<a href="https://thesecretlivesofdata.com/raft/">raft可视化</a>中去学习一下基本的流程，以对其有个大概的印象，然后还可以参考这部分的介绍来学习动画中的内容：<a href="https://www.cnblogs.com/Finley/p/14467602.html">看动画轻松学会 Raft 算法 </a></p><h1 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>raft系统中各个成员有3种状态：<strong>leader, follower, or candidate</strong></p><p><img src="/2023/12/26/RaftPaperRead/serverState.jpg" alt="server state"></p><p>每一次开始选举leader到下一次为止都是一个term，一个term开始选举时也可能因为平分选票而导致选举leader失败，这样就会进入下一term的选举</p><p><img src="/2023/12/26/RaftPaperRead/term.jpg" alt="term"></p><p>服务器采用RPC进行通信，主要有两种信息：</p><ol><li><strong>RequestVote</strong>，选举投票</li><li><strong>AppendEntries</strong>，复制日志条目（也当做心跳使用）</li></ol><h2 id="leader选举"><a href="#leader选举" class="headerlink" title="leader选举"></a>leader选举</h2><p>每一个服务器在一定范围内随机生成一个等待时间，如果在该时间内没有收到leader的心跳，那么就认为leader下线了，就给自己的term+1，然后发起投票，希望自己成为leader。所以这也就需要保证让等待时间大于心跳信息发送的间隔时间。</p><p>服务器发起投票后有以下3种结果：</p><ol><li>获得包括自己在内超过所有服务器半数的投票，自己成为leader</li><li>收到其他term&gt;&#x3D;自己的leader的信息，说明已经有leader了，自己变为follower</li><li>由于平分选票，谁都不能成为leader，再次等待随机时间后，再发起一轮投票</li></ol><p>为了防止选举到的leader没有全部的commit的日志，规定：</p><ol><li>发起投票的服务器如果没有自己拥有的日志新，则不给它投票。因为已经commit的日志肯定在超过半数的服务器上有留存，那么一个没有全部commit的日志的服务器就必然不能拿到超过半数的同意票。</li><li>新leader上台时，不会去尝试复制旧的日志，然后提交，它只会去专注于提交新的日志，并在将新的日志复制给了大半的服务器后，将之前所有的可能没提交的一并提交。这样子就避免了下图中(d)可能出现的错误情况。</li></ol><p><img src="/2023/12/26/RaftPaperRead/errorStatus.jpg" alt="errorStatus"></p><h2 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h2><p>leader会接收用户发来的请求，并生成日志，然后将日志发送给各个follower，如果有包括自己在内超一半的服务器拥有了改日志，就将日志（也包含之前可能未提交的日志）commit，然后返回给用户执行结果。</p><p>raft还通过以下特性来保持日志的一致性：</p><ol><li>相同term相同index的日志内容相同</li><li>如果两个服务器某处日志的term和index都相同，那么他们之前的所有日志也相同</li></ol><p>第一条的保证是来自于每个leader创建了日志之后不会再修改。<br>第二条的保证使用的是归纳法的思想，每次发送的AppendEntries都包含前一个日志的信息，必须要前一个日志信息相同才可以接受，否则就拒绝，然后leader会不断尝试依次递减发送上一个日志（leader会为每一个follower维护一个nextIndex，代表其需要发送的日志id），直到找到相同的为止，然后将往后的日志都发送过去。当然这部分匹配可以进行优化。</p><p>各个主机上的log条目可能千奇百怪，但是注意到只有超过一半的服务器拥有的日志才是可能提交的日志，才需要永久性保存，其他都是没有提交的日志，可以进行删除更新即可分析清楚。</p><p><img src="/2023/12/26/RaftPaperRead/possibleLogStatus.jpg" alt="possible Log Status"></p><h2 id="成员变更"><a href="#成员变更" class="headerlink" title="成员变更"></a>成员变更</h2><p>当集群中成员需要进行改变的，一个方式是停掉集群，然后各自修改配置，这时安全的，但是会导致部分时间集群服务不可用。另一种方法是在线修改，但是直接的在线修改可能会导致如下的问题，即加入server4、5之后，由于部分主机1，,还不知道，所以会导致出现两个leader。</p><p><img src="/2023/12/26/RaftPaperRead/errorMemberChange.jpg" alt="errorMemberChange"></p><p>Raft提出的解决方案是采用两阶段的方法执行成员变更。</p><p>首先集群配置进行更新的时候，会将原本的配置Cold和新配置Cnew联合起来形成Cold，new，leader会将其复制给原本记录的其他人，一旦服务器收到了，就会把最新的配置设置为当前使用的，提交必须要要保证new和old中都有过半的服务器被使用了，然后再将Cnew复制给其他new中的服务器，一旦Cnew也被过半的new中的服务器收到了，就提交，然后整体配置就转为了Cnew。如下图所示，就避免了Cold和Cnew都能同时做决策的情况。</p><p><img src="/2023/12/26/RaftPaperRead/changeConfigure.jpg" alt="changeConfigure"></p><p>但是仍然还有几个问题需要解决：</p><ol><li>新加入的服务器难以快速跟上进度。Raft将其先作为非投票的成为加入到集群中，赶上后再转为正常。</li><li>leader可能不是new中的一部分。在Cnew提交后再进行将leader下线，所以在前面一段时间，其实leader在管理不属于他的集群。</li><li>不在Cnew被删除的服务器可能会影响集群可用性，因为他们不会再收到心跳，然后就会不断发起投票。Raft的解决办法是如果服务器认为leader还存在，即还没有等待超时，就会忽略投票请求，不会更新其term和给他投票。</li></ol><h2 id="日志压缩"><a href="#日志压缩" class="headerlink" title="日志压缩"></a>日志压缩</h2><p>长时间的运行会导致日志的堆积，可以通过生成快照将状态拷贝下来，然后再将不需要的日志删除，如下图所示。</p><p><img src="/2023/12/26/RaftPaperRead/snapshot.jpg" alt="snapshot"></p><p>注意快照需要包含最后一个日志的信息，以让下一个日志生成的时候进行检查。</p><p>每个服务器独立进行快照生成，而不是由leader统一生成和发送，这是为了降低网络带宽消耗，降低系统复杂度。</p><p>新加入的服务器，或者特殊情况下的follower可能会需要leader将快照整个发送给它来初始化状态，follower在接收到到快照后会把快照最后一项之前的所有log删除。</p><p>此外还需要注意快照生成的频率，简单的方法是快照到一定大小后就进行生成。还需要避免写入快照对系统的影响，这可以通过写时复制的方法进行支持。</p><h2 id="客户交互"><a href="#客户交互" class="headerlink" title="客户交互"></a>客户交互</h2><p>客户端启动时，随机选择服务器，如果不是leader，该服务器会返回相关信息来帮助客户找到leader。如果leader宕机，客户请求会超时，然后再次尝试随机选择服务器来连接。</p><p>我们希望提供线性语义，但是raft实际上可能一个操作执行多次，例如leader在提交了之后马上宕机，然后没来得及返回给用户，然后用户可能会再次发送该请求，导致其二次执行。解决方法是让客户的每个请求都分配一个序号，如果接收到已经执行过的序号，就理解响应但是忽略执行。</p><p>对于只读操作，如果返回请求的leader马上被其他服务器替换，那么就面临返回过时信息的问题。所以raft需要保证新上台的leader知道哪些是已经执行了的，所以新上台的leader需要提交一个无操作的条目，来同步。raft也让leader在处理只读请求时与大多数成员交换心跳信息来处理此问题。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><a href="https://raft.github.io/">https://raft.github.io/</a></li><li><a href="https://raft.github.io/raft.pdf">https://raft.github.io/raft.pdf</a></li><li><a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/lecture-06-raft1">https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/lecture-06-raft1</a></li><li><a href="https://willzhuang.github.io/2018/03/04/Raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/">https://willzhuang.github.io/2018/03/04/Raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/</a></li><li><a href="https://thesecretlivesofdata.com/raft/">https://thesecretlivesofdata.com/raft/</a></li><li><a href="https://www.cnblogs.com/Finley/p/14467602.html">https://www.cnblogs.com/Finley/p/14467602.html</a></li><li><a href="https://acehi.github.io/thesecretlivesofdata-cn/raft/">https://acehi.github.io/thesecretlivesofdata-cn/raft/</a></li><li><a href="https://zhuanlan.zhihu.com/p/32052223">https://zhuanlan.zhihu.com/p/32052223</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文阅读】The Design of a Practical System for Fault-Tolerant Virtual Machines</title>
    <link href="/2023/12/12/Fault-TolerantVirtualMachinesPaperRead/"/>
    <url>/2023/12/12/Fault-TolerantVirtualMachinesPaperRead/</url>
    
    <content type="html"><![CDATA[<p><code>为了更有效的做论文阅读笔记，之后都打算将每篇论文笔记的内容控制在较少的字数范围内，毕竟原论文摆在那里，将其翻译照抄过来也没什么意思，将论文读薄才是最重要的。( •̀ ω •́ )✧</code></p><p>“The Design of a Practical System for Fault-Tolerant Virtual Machines”是MIT6.824推荐阅读的论文之一，它介绍了一种通过主备机制来进行单核虚拟机级别的容错方法。</p><h1 id="相关背景"><a href="#相关背景" class="headerlink" title="相关背景"></a>相关背景</h1><p>本文考虑的主要是fail-stop故障，例如电源线拔掉了，爆炸了，网络离线了等情况，而这也才能用复制的方法容错，普通的程序错误导致的故障也无法通过复制来解决。</p><p>容错一般有两种方法：</p><ol><li><strong>状态转移：</strong>拷贝主虚拟机的所有状态到另一个虚拟机上</li><li><strong>复制状态机：</strong>将虚拟机认为是一个状态机，只拷贝具体的操作</li></ol><p>明显复杂状态机对宽带要求更低，但是其设计更为复杂，本文采用的是复制状态机的方法。但是后面VMWare团队有推出多核虚拟机级别的容错，该方法采用的是类似状态转移的方法。</p><p>容错一般还可以分为应用层容错和主机层容错，<strong>本文是主机层</strong>，在这有容错的虚拟机上可以运行任何应用。</p><h1 id="设计概述"><a href="#设计概述" class="headerlink" title="设计概述"></a>设计概述</h1><p><img src="/2023/12/12/Fault-TolerantVirtualMachinesPaperRead/arc.jpg" alt="架构"></p><p>设计主要解决的问题是如何保证两个VM的状态一直保持一致。两个主副VM之间会通过Logging channel进行连接，主VM会将其<strong>任何会导致两者状态不一致的命令或者非确定性事件命令</strong>都通过Logging channel发送给副VM，副VM会读取该channel来执行相同的操作，但是该执行的输出会被忽略掉。</p><p>传递指令需要特别注意的是一些<strong>非确定性事件</strong>，该事件主要有两类分别是随时到达的<strong>客户端输入</strong>和在不同时刻不同的VM上会产生不同的结果的<strong>怪异指令</strong>，例如生成随机数、获取当前时间、获取主机id等。</p><pre><code class="hljs">非确定性事件还包括CPU并发，因为指令交织的顺序难以保证，例如两个并发的线程同时向一块数据加锁，那么主副VM上哪个线程能拿到锁其实是不确定的，但是本文是针对单CPU的，没有提及这个问题</code></pre><p>可以猜测传递的日志中主要有三样东西：</p><ol><li><strong>事件发生时的指令序号</strong>，即自机器启动以来指令的相对序号</li><li><strong>日志类型</strong></li><li><strong>数据</strong>，如果是网络数据包日志，那么就包含对应的数据，如果是怪异指令，那么就是其在主虚拟机上执行的结果</li></ol><p>需要注意的是为了保证副VM的执行不会超过主VM，副VM只有的channel里面有指令的时候才会继续运行，即<strong>副VM永远会落后主VM一个指令</strong>，不然就会一直停止等待，或者检测到主VM挂了，自己上台当主VM</p><h1 id="输出控制"><a href="#输出控制" class="headerlink" title="输出控制"></a>输出控制</h1><p>系统通过网络数据包来与用户进行交互，文章的目标是让用户接收到返回信息时该指令一定是在两个VM上都能执行了的，它避免的是如下的场景：</p><ul><li>主虚拟机给了用户返回，但是由于其马上crash了，没有将指令及时传给副VM，那么后面通过副VM上台时，该命令其实是没执行的，但是用户会以为其已经执行了</li></ul><p><img src="/2023/12/12/Fault-TolerantVirtualMachinesPaperRead/output.jpg" alt="输出控制"></p><p>解决方法是：<strong>主VM输出返回必须要在发送了日志且副VM返回了确认接收之后</strong></p><p>当然这也有可能会导致重复输出，因为主VM输出后马上奔溃，而副VM上台后还没有执行这个命令，那么后面再执行时就会导致重复输出，而文中提到由于有TCP的规则在，由于输出的是完全一致的数据包，该重复输出会被TCP的协议解决掉。</p><h1 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h1><p>主副VM之间需要知道对方有没有存活，文中使用了UDP心跳来检测服务器是否奔溃，此外也通过监控日志流量（因为定时器中断的存在，日志流量应该是有规律的）来探查，如果超过特点时间，就可能发生故障了，但是这依然会存在<strong>脑裂</strong>的问题，如果只是两个VM之间的网络出问题了，那么副VM如果这时上台就会出现两个主VM。文中采用的解决方案是通过<strong>Test-and-Set</strong>方案，它会在共享存储中执行一个原子性的测试设置操作。如果操作成功，VM就会被允许上线，如果不成功就说明另外一个还在运行。如果采用的不是共享存储，那么也会引入一个第三方的决策者来进行判断。</p><p>如果是副VM奔溃了，则会重新起一个副VM，该VM来自对主VM的完全拷贝。</p><p>同时为了保证容错的副VM上台后，不会需要太长时间才能把剩余的命令消费掉，已经为了防止channel的缓冲区被填满，<strong>副VM会和主VM保持一定的指令数间隔</strong>，文中提到执行延迟应不小于100ms，如果副VM跟不上主VM的处理速度，系统会分配给主VM更少的Cpu周期数来平衡两者的速度。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://pdos.csail.mit.edu/6.824/papers/vm-ft.pdf">https://pdos.csail.mit.edu/6.824/papers/vm-ft.pdf</a></li><li><a href="https://zhuanlan.zhihu.com/p/523109983">https://zhuanlan.zhihu.com/p/523109983</a></li><li><a href="https://pdos.csail.mit.edu/6.824/notes/l-vm-ft.txt">https://pdos.csail.mit.edu/6.824/notes/l-vm-ft.txt</a></li><li><a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/lecture-04-vmware-ft">https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/lecture-04-vmware-ft</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文阅读】The Google file System</title>
    <link href="/2023/12/05/TheGoogleFileSystemPaperRead/"/>
    <url>/2023/12/05/TheGoogleFileSystemPaperRead/</url>
    
    <content type="html"><![CDATA[<p>The Google file System论文是MIT6.824中推荐阅读的论文，他是Google早期的三大论文之一，由于课程并不需要实现这个系统，所以就对整部论文中的关键点进行介绍总结。</p><h1 id="相关背景"><a href="#相关背景" class="headerlink" title="相关背景"></a>相关背景</h1><p>为了满足Google快速增长的数据处理需求，Google需要自己构建一套文件系统——The Google file System(GFS)。而这套文件系统也必须是分布式的文件系统才足以满足要求，但是我们都知道这面临着很多困难：</p><ul><li>分布式的文件系统会使用大量的主机，而这会使得主机出错成为常态</li><li>为了解决时不时的一部分主机出错带来的影响，我们需要对文件进行拷贝放置到多个主机上</li><li>一旦文件有多份，我们就需要就其产生的一致性问题进行解决</li><li>而保证一致性就又会导致系统的低性能</li><li>一致性和低性能的取舍一直是一个研究的重点问题</li></ul><p>GFS就在解决上述问题，同时他也着重于解决自己场景下的问题，其设计的特点如下：</p><ul><li>故障设备经常发生</li><li>文件比传统标准更大，数GB大小的文件是十分常见的</li><li>系统负载主要来自两种读操作：大规模的流式读取和小规模的随机读取</li><li>系统负载还来自很多对文件的大规模追加写入</li><li>同时设计应用程序和文件系统API便于提高整个系统的灵活性</li></ul><h1 id="设计概述"><a href="#设计概述" class="headerlink" title="设计概述"></a>设计概述</h1><p><img src="/2023/12/05/TheGoogleFileSystemPaperRead/GFSarch.png" alt="图1 GFS架构"></p><p>如图1所示，一个GFS集群包括单个master（主服务器）和多个chunkserver（块服务器），并被多个client（客户端）访问。每个节点通常为一个运行着用户级服务进程的Linux主机。</p><h2 id="chunk"><a href="#chunk" class="headerlink" title="chunk"></a>chunk</h2><p>文件被划分为若干个64MB大小的chunk（块）。每个chunk被一个不可变的全局唯一的64位chunk handle（块标识符）唯一标识，chunk handle在chunk被创建时由主节点分配。chunkserver将chunk作为Linux文件存储到本地磁盘中，通过chunk handle和byte range（字节范围）来确定需要被读写的chunk和chunk中的数据。为了可靠性考虑，每个chunk会在多个chunkserver中有副本。默认存储三份副本，用户也可以为不同的命名空间的域指定不同的副本级别。</p><p>64MB大小的chunk其实并没有带来内部碎片，因为每个chunk的副本被作为普通的Linux文件存储在chunkserver上，linux文件上是以几KB为单位进行存储空间分配的，其仅在需要时扩展。懒式空间分配（lazy space allocation）避免了内部碎片（internal fragmentation）带来的空间浪费。</p><p>同时一个较大的chunk带来了以下的优势：</p><ol><li>减少了client与master交互的次数，</li><li>使得client可以在一个chunk上执行更多的操作</li><li>减小了master中存储的云数据的大小</li></ol><p>需要注意的是如果多个client访问同一个文件，那么存储这这些文件的chunkserver会成为hot spot（热点）。但是因为应用程序大部分都顺序地读取包含很多chunk的大文件，所以hot spot不是主要问题。而如果出现这个问题，一个潜在的长期解决方案是在让client在这种场景下从其他client读取数据。</p><h2 id="master"><a href="#master" class="headerlink" title="master"></a>master</h2><p>master维护系统所有的元数据。元数据包括命名空间（namespace）、访问控制（access control）信息、文件到chunk的映射和chunk当前的位置。master还控制系统级活动如chunk租约（chunk lease）管理、孤儿chunk垃圾回收（garbage collection of orphaned chunks）和chunkserver间的chunk迁移（migration）。master周期性地通过心跳（HeartBeat）消息与每个chunkserver通信，向其下达指令并采集其状态信息。</p><p>文件和块的命名空间、文件到chunk的映射这两种类型还通过将变更记录到一个操作日志（operation log）的方式持久化存储在master的磁盘上。具体来说需要将操作日志备份到多台远程主机上，且只有当当前操作记录条目被本地和远程主机均写入到了磁盘后才能向客户端发出响应。master会在操作记录被写入前批量合并一些操作记录来减少写入和备份操作对整个系统吞吐量的影响。master会对其状态创建一个检查点（checkpoint），这样master就可以从磁盘加载最后一个检查点并重放该检查点后的日志来恢复状态。因为创建一个检查点需要一段时间，所以master被设计为可以在不推迟新到来的变更的情况下创建检查点。创建检查点时，master会切换到一个新的日志文件并在一个独立的线程中创建检查点，这个新的检查点包含了在切换前的所有变更。</p><p>master不会持久化存储chunk的位置信息，而是在启动时和当chunkserver加入集群时向chunkserver询问其存储的chunk信息。这样相比于持久化，消除了当chunkserver加入或离开集群、更改名称、故障、重启等问题时，保持master和chunkserver同步的问题。</p><h2 id="chunk-server"><a href="#chunk-server" class="headerlink" title="chunk server"></a>chunk server</h2><p>chunk副本分配到chunk server策略有两个目标：最大化数据<strong>可靠性</strong>和<strong>可用性</strong>、<strong>最大化网络带宽利用</strong>。对于这两个目标，仅将副本分散在所有机器上是不够的，这样做只保证了容忍磁盘或机器故障且只充分利用了每台机器的网络带宽。我们必须<strong>在机架间分散chunk的副本</strong>。这样可以保证在一整个机架都被损坏或离线时（例如，由交换机、电源电路等共享资源问题引起的故障），chunk的一些副本仍存在并保持可用状态。除此之外，这样还使对chunk的流量（特别是读流量）<strong>能够充分利用多个机架的总带宽</strong>。而另一方面，其代价就是<strong>写流量必须流经多个机架</strong>，导致一定程度的速度损耗。</p><p>chunk副本的创建可能由三个原因引起：chunk创建、重做副本（re-replication）和重均衡（rebalance）。</p><p><strong>chunk创建</strong>时，选择chunk server主要需要考虑以下因素：</p><ol><li>希望在磁盘利用率低于平均值的chunkserver上放置副本，以平衡chunkserver间的磁盘利用率</li><li>希望限制每台chunkserver上最近创建的chunk的数量。尽管创建chunk本身开销很小，但由于创建后一般会接着马上大量写，所以需要平衡限制写入流量</li><li>希望将chunk的副本跨机架分散。</li></ol><p><strong>重做副本</strong>一般是因为chunk被损坏了或者chunk server不可用了，或者目标副本数增加了，重做副本需要有优先级：</p><ol><li>当前chunk副本数与目标副本数之差越大优先级就越高</li><li>更倾向于优先为还存在的文件的chunk重做副本，而不是优先为最近被删除的文件重做。</li><li>为了最小化故障对正在运行的应用程序的影响，我们提高了所有正在阻塞client进程的chunk的优先级。</li></ol><p>重做副本选择chunk server所考虑的因素与chunk 创建一样，但是为了防止克隆操作的流量远高于client流量的情况发生，master需要对整个集群中活动的克隆操作数和每个chunkserver上活动的<strong>克隆操作数进行限制</strong>。除此之外，在克隆操作中，每个chunkserver还会<strong>限制对源chunkserver的读请求</strong>，以限制每个克隆操作占用的总带宽。</p><p>每隔一段时间master会对副本进行<strong>重均衡</strong>：master会检测当前的副本分布并移动副本位置，使磁盘空间和负载更加均衡。同样，在这个过程中，master会逐渐填充一个新的chunkserver，而不会立刻让来自新chunk的高负荷的写入流量压垮新的chunkserver。新副本放置位置的选择方法与上文中讨论过的类似。此外，master必须删除一个已有副本。通常，master会选择删除空闲磁盘空间低于平均的chunkserver上的副本，以均衡磁盘空间的使用。</p><h2 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h2><p>被链接到应用程序中的GFS client的代码实现了文件系统API并与master和chunkserver通信，代表应用程序来读写数据。</p><p>GFS支持如创建（create）、删除（delete）、打开（open）、关闭（close）、读（read）、写（write）文件等常用操作。此外，GFS还支持快照（snapshot）和追加记录（record append）操作。</p><h2 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h2><p>在文件被删除后，GFS不会立刻回收可用的物理存储空间。master仅在周期性执行懒式垃圾回收时回收物理存储空间，其中垃圾回收分为文件级垃圾回收和chunk级垃圾回收。</p><h3 id="文件级垃圾回收"><a href="#文件级垃圾回收" class="headerlink" title="文件级垃圾回收"></a>文件级垃圾回收</h3><p>当一个文件被应用程序删除时，master会像执行其他操作时一样立刻将删除操作写入日志。但是master不会立刻对资源进行回收，而是将待删除的文件重命名为一个带有删除时间戳的隐藏文件名。当master周期性地扫描文件系统命名空间时，它会删除已经存在超过三天（用户可以配置这个间隔时间）的这种隐藏文件。在文件被彻底删除之前，仍可通过该文件被重命名后的特殊的新文件名对其进行访问，也可以通过将其重命名为正常文件的方式撤销删除。当隐藏文件被从命名空间中移除时，其在内存中的元数据也会被删除。这种方式可以有效地切断文件和其对应的chunk的链接。</p><h3 id="chunk级垃圾回收"><a href="#chunk级垃圾回收" class="headerlink" title="chunk级垃圾回收"></a>chunk级垃圾回收</h3><p>chunk成为无法被任何文件访问到的孤儿chunk的原因可能是chunk的创建可能仅在部分chunkserver上成功而在其他chunkserver上失败，或者chunk在进行删除时某些chunk server没有收到相应的消息。</p><p>在进行chunk级垃圾回收时，master会周期性扫描chunk命名空间，并找出孤儿chunk，删除这些chunk的元数据。在chunkserver周期性地与master进行心跳消息交换时，chunkserver会报告其拥有的chunk的子集，而master会回复这些chunk中元数据已经不存在的chunk的标识。chunkserver可以自由地删除这些元数据已经不存在的chunk的副本。</p><p>该垃圾回收机制的优点：</p><ol><li>这种方法在设备经常出现故障的大规模可伸缩分布式系统中非常简单可靠。chunk的创建可能仅在部分chunkserver上成功而在其他chunkserver上失败，这样会导致系统中出现master不知道的副本。且副本删除消息可能会丢失，这样master在其自身和chunkserver故障时都必须重新发送该消息。垃圾回收机制为清理那些不知道是否有用的副本提供了一个统一且可靠的方法。</li><li>垃圾回收机制将对存储空间的回收操作合并为master的后台活动，如周期性扫描命名空间和周期性地与chunkserver握手。因此，垃圾回收机制可以分批回收存储空间并平摊回收的开销。另外，垃圾回收仅在master相对空闲时执行。这样，master可以更迅速的相应需要及时响应的来自client的请求。</li><li>延迟回收存储空间可以防止意外的不可逆删除操作。</li></ol><p>该垃圾回收机制的缺点：</p><ol><li>当用户存储空间紧张时，延迟回收会让用户难以释放存储空间。</li><li>快速创建并删除临时文件的应用程序可能无法立刻重用存储空间。</li></ol><p>为了解决这个问题，用户可以再次显示删除已删除文件时，加快了对存储空间的回收。同时，允许用户对不同的命名空间应用不同的副本与回收策略。例如，用户可以指定某个目录树下的所有文件都不需要副本，且当这个目录树下的文件被删除时立刻且无法撤销地将其从文件系统中移除。</p><h1 id="读操作"><a href="#读操作" class="headerlink" title="读操作"></a>读操作</h1><p>如图1所示，具体读操作在流程如下：</p><ol><li>client会将读取的文件名，读取的是第几个chunk发送给master</li><li>master返回给client该chunk的chunk handle以及其所在的所有chunkserver</li><li>client接收信息，并进行缓存，然后选择距离其最近的chunkserver（可以直接通过ip规律决定）来发起询问，请求对应chunk handle中byte范围的内容</li><li>被询问的chunkserver根据自己保存的chunk handle与具体linux文件的对应关系来读取文件（实际应该就是以chunk handle命名的文件），并返回对应的内容</li><li>client获取到对应的内容，如果还需要接着读取，可以依据缓存信息直接向client发起读取请求</li></ol><h1 id="写操作"><a href="#写操作" class="headerlink" title="写操作"></a>写操作</h1><p><img src="/2023/12/05/TheGoogleFileSystemPaperRead/write.png" alt="图2 写操作"></p><h2 id="租约"><a href="#租约" class="headerlink" title="租约"></a>租约</h2><p>虽然每个chunk有多个副本，但是为了保证副本间变更的一致性，master向其中一份副本授权一个变更的租约，称这个副本为primary（有时也可代指primary副本所在的chunkserver），其余的副本称为Secondary。租约的时间为60秒。然而，一旦chunk被变更，primary就可以向master请求延长租约时间，或者（通常为）接受来自master的租约时间延长操作。这些租约延长请求和租约授权请求依赖master与chunkserver间周期性地心跳消息来实现。即使master与一个primary的通信丢失，master仍可以在旧租约过期后安全地向另一个副本授权新的租约，以此来避免同时产生多个primary。</p><h2 id="数据流"><a href="#数据流" class="headerlink" title="数据流"></a>数据流</h2><p>在进行写时，需要将数据传递给每个chunk server，为了高效地利用网络，其对数据流与控制流进行了解耦。为了充分利用机器的网络带宽，数据会沿着chunkserver链线性地推送。假设client正准备将数据推送给S1~S4。client会将数据发送给最近的chunkserver，比如S1。S1会将数据传递给S2至S4中离它最近的chunkserver，比如S2。同样，S2会将数据传递给S3至S4中离它最近的chunkserver，以此类推。由于其网络拓扑非常简单，所以可以通过IP地址来准确地估算出网络拓扑中的“距离”。</p><p>当chunkserver收到一部分数据时，它会立刻开始将数据传递给其他chunkserver。因为我们使用全双工的交换网络，所以流水线可以大幅减少时延。发送数据不会减少接受数据的速度。如果没有网络拥塞，理论上将$B$个字节传输给$R$个副本所需的时间为$B&#x2F;T+RL$，其中$T$是网络的吞吐量，$L$是两台机器间的传输时延。通常，我们的网络连接吐吞量$T$为$100Mbps$，传输时延$L$远小于$1ms$。</p><h2 id="写流程"><a href="#写流程" class="headerlink" title="写流程"></a>写流程</h2><p>如图2所示，写流程如下：</p><ol><li>client向master询问哪个chunkserver持有指定chunk的租约及该chunk的其他副本的位置。如果没有chunkserver持有租约，那么master会选择一个副本对其授权（这一步在图中没有展示）</li><li>master回复primary副本的标识符和其他副本（也称secondary）的位置。client也对其进行缓存</li><li>client将数据通过数据流的方式推送到所有副本</li><li>一旦所有副本都确认收到了数据，client会向primary发送一个write请求。primary会为其收到的所有的变更（可能来自多个client）分配连续的编号，这一步提供了重要的顺序。primary对在本地按照该顺序应用变更</li><li>primary将write请求继续传递给其他secondary副本。每个secondary副本都按照primary分配的顺序来应用变更。</li><li>所有的secondary副本通知primary其完成了变更操作。</li><li>primary回复client。任意副本遇到的任何错误都会被报告给client。即使错误发生，write操作可能已经在primary或secondary的任意子集中被成功执行。（如果错误在primary中发生，那么操作将不会被分配顺序，也不会被继续下发到其他副本。）只要错误发生，该请求都会被认为是失败的，且被修改的区域的状态为inconsistent。client中的代码会通过重试失败的变更来处理这种错误。首先它会重试几次步骤（3）到步骤（7），如果还没有成功，再从write请求的初始操作开始重试。成功后该区域会被修正为consistent状态</li></ol><p>如果应用程序发出的一次write请求过大或跨多个chunk，GFS的client代码会将其拆分成多个write操作。拆分后的write请求都按照上文中的控制流执行，但是可能存在与其他client的并发的请求交叉或被其他client的并发请求覆盖的情况。因此，共享的文件区域最终可能包含来自不同client的片段。但共享的文件区域中的内容最终是相同的，因为每个操作在所有副本上都会以相同的顺序被成功执行。</p><h2 id="原子性record-append"><a href="#原子性record-append" class="headerlink" title="原子性record append"></a>原子性record append</h2><p>在传统的write操作中，client会指定数据写入的偏移量。然而在record append中，client仅需指定待追加的数据。GFS会为其选择一个偏移量，在该偏移量处至少一次地原子性地将数据作为一个连续的字节序列追加到文件，并将该偏移量返回给client。</p><p>record append被大量应用在的有多个来自不同机器的client向同一个文件并发append数据的分布式应用程序中。如果通过传统的write操作，那么client还需要额外的复杂且开销很高的同步操作（例如分布式锁管理）。</p><p>record append仅在primary端稍有点额外的逻辑。在client将数据推送到文件中最后一个chunk的所有chunk server之后，client会向primary发送一个请求。primary会检查当新记录追加到该chunk之后，是否会导致该chunk超过其最大大小限制（64MB）。如果会超，primary会将该chunk填充到最大的大小，并通知secondary也做相同的填充操作，再回复客户端，使其在下一个chunk上重试该操作。record append操作限制了每次最多写入最大chunk大小的四分之一的数据，以保证在最坏的情况下产生的碎片在可接受的范围内。在一般情况下，添加的记录大小都在不会超过chunk的最大限制，这样primary会向数据追加到它的副本中，并通知secondary在与其追加的偏移量相同的位置处写入数据，并将最终成功操作的结果返回给client。</p><p>如果record append操作在任何一个副本中失败，就会返回失败，使得client会重试操作。这样会导致同一个chunk的<strong>不同副本中可能包含不同的数据</strong>，这些数据可能是同一条记录的部分或完整的副本。GFS不保证所有副本在字节级别一致，其只保证record append的数据<strong>作为一个单元被原子性地至少写入一次</strong>。这一点很容易证明，因为数据必须在某个chunk的所有副本的相同偏移位置处写入。此外，在record append之后，每个副本都至少与最后一条记录一样长。这样，任何未来的新记录都会被分配到一个更高的偏移位置或者一个新chunk，即使另一个副本成为了primary也能保证这个性质。这样，被record append操作<strong>成功写入的区域</strong>在一致性方面都将是<strong>defined状态</strong>（因此也是consistent的），而这些<strong>defined区域间的文件区域是inconsistent的（因此也是undefined的）</strong>。我们应用程序会通过章节2.7.2中讨论的方式处理inconsistent的区域。</p><h2 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h2><p><img src="/2023/12/05/TheGoogleFileSystemPaperRead/consistent.jpg" alt="图3 一致性"></p><p><strong>一致性：</strong>一个文件区域的任意一个副本被任何client读取总能得到相同的数据<br><strong>确定性：</strong>client总能读取到其写入的信息</p><p>在没有并发的情况下写入成功时，写入的内容是一致且确定的<br>在有并发的情况下写入成功时，写入的内容是一致但非确定的，因为写入的内容可能混合了多个请求</p><p>写入操作操作可能为write或record append，其中对于record append，GFS可能会在记录的中间插入填充（padding）和或重复的记录。它们占用的区域状态为inconsistent的，通常情况下，它们的数量远少于用户数据。</p><p>GFS会保证被写入成功的的区域各个副本都是一致的，主要通过以下手段：</p><ol><li>chunk执行变更时，其所有副本按照相同的顺序应用变更</li><li>使用chunk版本号（chunk version）来检测因chunkserver宕机而错过了变更的陈旧的chunk副本。陈旧的chunk副本永远不会在执行变更时被使用，也不会在master返回client请求的chunk的位置时被使用。它们会尽早地被作为垃圾回收。</li><li>即使在变更被成功应用的很长时间后，设备故障仍然可以损坏（corrupt）会销毁（destroy）数据。GFS通过master和所有chunkserver周期性握手的方式来确定故障的chunkserver，并通过校验和（checksunmming）的方式检测数据损坏。一旦出现问题，数据会尽快地从一个合法的副本恢复。一个chunk只有在GFS作出反应前（通常在几分钟内）失去了所有的副本，chunk才会不可逆地丢失。即使在这种情况下，chunk也仅变得不可用而非返回错误的数据。</li></ol><h3 id="应用程序影响"><a href="#应用程序影响" class="headerlink" title="应用程序影响"></a>应用程序影响</h3><p>GFS应用程序可以通过一些简单的技术来使用其宽松的一致性模型，且这些技术已经因其他目标而被使用。</p><p>在实际使用中，我们所有的应用程序都通过append而不是overwrite的方式对文件进行变更。其中一个典型的引用场景是：一个write从头到尾地生成一个文件。它会周期性地为已经写入的文件数据创建检查点，并在所有数据都被写入文件后自动将其重命名为一个永久的文件名。检查点可能包含应用程序级别的校验和。reader会验证文件仅处理跟上最新的检查点的文件区域，这些区域的状态一定的“defined”的。尽管这种方法有一致性和并发问题，它仍很好地满足了我们的需求。append的效率远高于随机写入，且在应用程序故障时更容易恢复。检查点机制允许writer在重启时增量写入，并能够防止reader处理那些虽然已经被成功写入文件但是从应用程序的角度看仍然不完整的文件数据。</p><p>另一种典型的用途是，许多write并发地向同一个文件append数据以获得合并后的结果或文件作为生产者-消费者队列使用。record append的“至少一次追加（append-at-least-once）”语义保证了每个write的输出。</p><p>而reader偶尔需要<strong>处理填充和重复的数据</strong>。每条被writer准备好的记录包含如校验和的额外信息，这样，记录的合法性就可被校验。一个reader通过校验和来识别并丢弃额外的填充和记录。如果rearder无法容忍偶尔发生的重复（如果重复的记录可能触发非幂等（non-idempotent）运算），它可以使用记录中的唯一标识符来对齐进行过滤。通常，在命名应用程序相关的实体时（如web文档），总会使用唯一的标识符。这些记录I &#x2F; O (除去重复)的功能在我们的应用程序共享的库代码中，并适用于Google的其他文件接口实现。通过这些库，带有极少的重复的记录，总会被以相同顺序交付给reader。</p><h1 id="容错处理"><a href="#容错处理" class="headerlink" title="容错处理"></a>容错处理</h1><h2 id="chunk副本"><a href="#chunk副本" class="headerlink" title="chunk副本"></a>chunk副本</h2><p>每个chunk会在不同机架的多个chunkserver上存有副本。用户可以为不同命名空间的文件制定不同的副本级别。副本级别默认为3。当有chunkserver脱机或通过校验和检测到损坏的副本时，master根据需求克隆现有的副本以保证每个chunk的副本数都是饱和的。</p><h2 id="master副本"><a href="#master副本" class="headerlink" title="master副本"></a>master副本</h2><p>master的状态同样有副本，master的操作日志和检查点被<strong>在多台机器上复制</strong>。只有当变更在被日志记录并被写入，master本地和所有master副本的磁盘中后，这个变更才被认为是已提交的。为了简单起见，一个master进程既要负责处理所有变更又要负责处理后台活动，如垃圾回收等从内部改变系统的活动。当master故障时，其几乎可以立刻重启。如果运行master进程的机器故障或其磁盘故障，在GFS之外的负责监控的基础架构会在其它持有master的操作日志副本的机器上启动一个新的master进程。client仅通过一个规范的命名来访问master结点（例如gfs-test），这个规范的命名是一个DNS别名，其可以在master重新被分配到另一台机器时被修改为目标机器。</p><p>此外，“影子”master节点（“shadow” master）<strong>可以提供只读的文件系统访问</strong>，即使在主master结点脱机时它们也可以提供服务。因为这些服务器可能稍稍滞后于主master服务器（通常滞后几分之一秒），所以这些服务器是影子服务器而非镜像服务器。这些影子master服务器增强了那些非正在被变更的文件和不介意读到稍旧数据的应用程序的可用性。实际上，由于文件内容是从chunkserver上读取的，所以应用程序不会读取到陈旧的文件内容。能够在一个很短的时间窗口内被读取到的陈旧的数据只有文件元数据，如目录内容和访问控制信息。</p><p>为了让自己的元数据跟随主master变化，影子master服务器会持续读取不断增长的操作日志副本，并像主master一样按照相同的顺序对其数据结构应用变更。像主master一样，影子master服务器也会在启动时从chunkserver拉取数据来获取chunk副本的位置（启动后便很少拉取数据），并频繁地与chunkserver交换握手信息来监控它们的状态。<strong>只有因主master决定创建或删除副本时，影子master服务器上的副本位置才取决于主master服务器</strong>。</p><h2 id="数据完整性"><a href="#数据完整性" class="headerlink" title="数据完整性"></a>数据完整性</h2><p>每个chunkserver都<strong>使用校验和来检测存储的数据是否损坏</strong>。由于GFS集群通常在数百台机器上有数千chunk磁盘，所以集群中经常会出现磁盘故障，从而导致数据损坏或丢失。我们可以<strong>通过chunk的其他副本来修复损坏的chunk</strong>，但不能通过比较chunkserver间的副本来检测chunk是否损坏。除此之外，即使内容不同的副本中的数据也可能都是合法的：GFS中变更的语义（特别是前文中讨论过的record append）不会保证副本完全相同。因此，<strong>每个chunkserver必须能够通过维护校验和的方式独立的验证副本中数据的完整性</strong>。</p><p><strong>一个chunk被划分为64KB的block</strong>。<strong>每个block有其对应的32位校验和</strong>。就像其他元数据一样，校验和也在内存中保存且会被通过日志的方式<strong>持久化存储</strong>。校验和与用户数据是分开存储的。</p><p>对于读取操作，无论请求来自client还是其他chunkserver，<strong>chunkserver都会在返回任何数据前校验所有包含待读取数据的block的校验和</strong>。因此，chunkserver不会将损坏的数据传给其他机器。如果一个block中数据和记录中低的校验和不匹配，那么chunkserver会给请求者返回一个错误，<strong>并向master报告校验和不匹配</strong>。随后，请求者会从其他副本读取数据，<strong>而master会从该chunk的其他副本克隆这个chunk</strong>。当该chunk新的合法的副本被安置后，master会通知报告了校验和不匹配的chunkserver删除那份损坏的副本。</p><p>校验和对读取性能的影响很小。因为我们的大部分读操作至少会读跨几个block的内容，我们只需要读取并校验相对少量的额外数据。GFS客户端代码通过尝试将读取的数据与需要校验的block边界对其的方式，进一步地减小了校验开销。除此之外，chunkserver上校验和的查找与比较不需要I&#x2F;O操作，且校验和计算操作经常与其他操作在I&#x2F;O上重叠，因此几乎不存在额外的I&#x2F;O开销。</p><p>因为向chunk末尾append数据的操作在我们的工作负载中占主要地位，所以我们对这种写入场景的校验和计算做了大量优化。在<strong>append操作</strong>时，<strong>我们仅增量更新上一个block剩余部分的校验和，并为append的新block计算新校验和</strong>。即使最后一个block已经损坏且目前没被检测到，增量更新后的该block的新校验和也不会与block中存储的数据匹配。在下一次读取该block时，GFS会像往常一样检测到数据损坏。</p><p>相反，如果<strong>write操作</strong>覆盖了一个chunk已存在的范围，那么我们<strong>必须读取并验证这个范围的头一个和最后一个block</strong>，再执行write操作，最后计算并记录新的校验和。如果我们没有在写入前校验头一个和最后一个block，新的校验和可能会掩盖这两个block中没被覆写的区域中存在的数据损坏问题。因为写入会修改头一个和后一个block的部分内容，且会重新计算校验和，如果该内容以损坏，然后又重新计算了校验和，就会掩盖损坏内容。</p><p>chunkserver可以<strong>在空闲期间扫描并验证非活动的chunk的内容</strong>。这样可以让我们检测到很少被读取的chunk中的数据损坏。一旦检测到数据损坏，master可以创建一个新的未损坏的副本并删除损坏的副本。这样可以防止master将chunk的非活动的但是已损坏的副本识别成数据合法的副本。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>总体而言GFS提供了一个大规模分布式存储的一个良好的解决方案，也让我对分布式存储有了更深的影响，其中其数据流与控制流解耦，租约设计，弱一致性换取高性能，具体的分布式读写操作，分布式数据容错方案都给我留下了深刻的印象。</p><p>但是GFS也被提出具有一定的问题，其问题主要来自于master节点保存的内容过多，master节点的容错率不强等。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="http://research.google.com/archive/gfs.html">http://research.google.com/archive/gfs.html</a></li><li><a href="https://pdos.csail.mit.edu/6.824/schedule.html">https://pdos.csail.mit.edu/6.824/schedule.html</a></li><li><a href="https://blog.mrcroxx.com/posts/paper-reading/gfs-sosp2003/">https://blog.mrcroxx.com/posts/paper-reading/gfs-sosp2003/</a></li><li><a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/lecture-03-gfs/3.1">https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/lecture-03-gfs/3.1</a></li><li><a href="https://www.youtube.com/watch?v=WLad7CCexo8&ab_channel=BitTiger%E5%AE%98%E6%96%B9%E9%A2%91%E9%81%93BitTigerOfficialChannel">https://www.youtube.com/watch?v=WLad7CCexo8&ab_channel&#x3D;BitTiger%E5%AE%98%E6%96%B9%E9%A2%91%E9%81%93BitTigerOfficialChannel</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>IDEA远程开发选项丢失修复方法</title>
    <link href="/2023/12/01/IDEA%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91%E9%80%89%E9%A1%B9%E4%B8%A2%E5%A4%B1%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95/"/>
    <url>/2023/12/01/IDEA%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91%E9%80%89%E9%A1%B9%E4%B8%A2%E5%A4%B1%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p>今天打开IDEA发现远程开发选项没有了：</p><p><img src="/2023/12/01/IDEA%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91%E9%80%89%E9%A1%B9%E4%B8%A2%E5%A4%B1%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95/%E6%8D%9F%E5%9D%8F%E7%95%8C%E9%9D%A2.jpg" alt="损坏界面"></p><p>发现全网也没有什么提到过这个错误的，所有捣鼓了好久还进行了IDEA的重装也一直都没有解决，最后查看<a href="https://www.jetbrains.com/help/idea/2023.2/jetbrains-gateway.html#plugin_install">IDEA官方的介绍文档</a>才发现了问题所在：<strong>Remote Development Gateway插件被关闭了</strong></p><p>故而解决方法就是点击IDEA的设置选项卡，在插件(plugs)选项中重新勾选<code>Remote Development Gateway</code>来启用该插件即可</p><p><img src="/2023/12/01/IDEA%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91%E9%80%89%E9%A1%B9%E4%B8%A2%E5%A4%B1%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95.jpg" alt="解决方法"></p><p>点击启用后可以发现远程开发选项又回来了：</p><p><img src="/2023/12/01/IDEA%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91%E9%80%89%E9%A1%B9%E4%B8%A2%E5%A4%B1%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95/%E4%BF%AE%E5%A4%8D%E5%90%8E%E7%95%8C%E9%9D%A2.jpg" alt="修复后界面"></p><p>所以还是要多从官方的信息源找起啊</p>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【MIT6.824】lab 1 MapReduce实现总结</title>
    <link href="/2023/11/22/MIT6-824lab1/"/>
    <url>/2023/11/22/MIT6-824lab1/</url>
    
    <content type="html"><![CDATA[<p>MIT6.824是一门经典的分布式课程，课程链接：<a href="https://pdos.csail.mit.edu/6.824/labs/lab-mr.html">https://pdos.csail.mit.edu/6.824/labs/lab-mr.html</a>，对于lab 1我们需要在提供的代码框架的基础上补充coordinator和worker的代码，以实现分布式的MapReduce程序。</p><p>本人在借鉴了部分其他人的设计思想的基础上，独立完成了所有的代码，最后设计的实现能够通过所有的测试脚本。</p><p>实现的代码厂库：<a href="https://github.com/slipegg/MIT6.824/tree/main/6.5840">https://github.com/slipegg/MIT6.824/tree/main/6.5840</a></p><h1 id="实现目标"><a href="#实现目标" class="headerlink" title="实现目标"></a>实现目标</h1><p>在给定的代码框架中实现一个单词计数的MapReduce程序。原本的框架中已经给了一个在本地串行执行单词计数的独立程序，并提供了一个通过UNIX-domain sockets实现的RPC(<a href="https://slipegg.github.io/2023/11/14/RPC%E4%BB%8B%E7%BB%8D/">RPC介绍</a>)，我们需要完成的部分有：</p><ol><li>设计coordinator和worker之间交流的流程和格式，以方便worker向coordinator申请任务，coordinator将taks发送给worker，worker把task的完成情况返回给coordinator</li><li>coordinator对Map类型的task和Reduce类型的task进行管理，需要初始化这些任务，需要记录任务完成的情况，并生成新的任务，直到全部完成</li><li>worker如何完成Map类型以及Reduce类型task</li></ol><h1 id="总体设计"><a href="#总体设计" class="headerlink" title="总体设计"></a>总体设计</h1><p><strong>worker</strong>会不断向coordinator发送心跳，申请任务，拿到任务后进行map或者renduce类型的task的执行，在执行完毕后发送请求给coordinator以表示该任务完成了。当coordinator告诉其所有任务都完成时，他会结束运行</p><p><strong>coordinator</strong>只维护task的状态不维护各个worker的状态。worker向其发送心跳申请任务时，coordinator会去遍历任务，取出还没有发送的任务或者过了太长时间都没有完成的任务返回回去，如果没有，就返回一个等待任务。coordinator接收到worker的某个任务完成的请求时会改变这个任务的状态，如果当前阶段所有的任务都完成了就转向下一个阶段，知道转到了所有MapReduce任务都完成的阶段。</p><p>整体流程如下图所示：</p><p><img src="/./MIT6-824lab1/MapReduce.png" alt="MapReduce流程"></p><h1 id="rpc信息传递设计"><a href="#rpc信息传递设计" class="headerlink" title="rpc信息传递设计"></a>rpc信息传递设计</h1><h2 id="Heartbeat"><a href="#Heartbeat" class="headerlink" title="Heartbeat"></a>Heartbeat</h2><p>worker通过rpc向coordinator发送心跳（Heartbeat）来申请任务。如下：</p><ul><li><p>关键结构体定义如下，HeartbeatRequest是个空结构，HeartbeatResponse承载了coordinator返回给worker的信息，这里的信息实际上是运行map类型和reduce类型的task所必须的信息的集合。所有的返回都需要JobType来标明其类型，需要id来标明其是哪个作业，<strong>对于map类型作业</strong>，其额外需要FilePath来获取任务的输入，还需要NReduce来决定输出的数量，<strong>对于reduce类型作业</strong>，其额外需要NMap来辅助获取map类型的中间输出。</p>  <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> HeartbeatRequest <span class="hljs-keyword">struct</span> &#123;<br>&#125;<br><br><span class="hljs-keyword">type</span> HeartbeatResponse <span class="hljs-keyword">struct</span> &#123;<br>    FilePath <span class="hljs-type">string</span><br>    JobType  JobType<br>    NReduce  <span class="hljs-type">int</span><br>    NMap     <span class="hljs-type">int</span><br>    Id       <span class="hljs-type">int</span><br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>调用请求如下，它会调用coordinator的heartbeat函数来处理，并将任务返回到response中。</p>  <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go">call(<span class="hljs-string">&quot;Coordinator.Heartbeat&quot;</span>, &amp;HeartbeatRequest&#123;&#125;, &amp;response)<br></code></pre></td></tr></table></figure></li></ul><h2 id="Report"><a href="#Report" class="headerlink" title="Report"></a>Report</h2><p>worker完成任务后通过rpc向coordinator发送回复。如下：</p><ul><li><p>关键结构体设计如下。ReportRequest通过phase和id来联合表示是哪个任务完成了。</p>  <figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">type</span> <span class="hljs-type">ReportRequest</span> struct &#123;<br>    <span class="hljs-type">Id</span>    int<br>    <span class="hljs-type">Phase</span> <span class="hljs-type">SchedulePhase</span><br>&#125;<br><br><span class="hljs-keyword">type</span> <span class="hljs-type">ReportResponse</span> struct &#123;<br>&#125;<br><br></code></pre></td></tr></table></figure></li><li><p>调用请求如下,它会调用coordinator的Report函数来处理，来将该任务标记为运行结束。</p>  <figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs lisp">call(<span class="hljs-string">&quot;Coordinator.Report&quot;</span>, <span class="hljs-symbol">&amp;ReportRequest</span>&#123;Id: id, Phase: phase&#125;, <span class="hljs-symbol">&amp;ReportResponse</span>&#123;&#125;)<br></code></pre></td></tr></table></figure></li></ul><h1 id="coordinator设计"><a href="#coordinator设计" class="headerlink" title="coordinator设计"></a>coordinator设计</h1><p>coordinator会衍生出2个额外的协程，一个负责给rpc注册，并响应rpc传来的函数调用请求，一个负责给worker选择task生成resopnse</p><h2 id="rpc函数调用处理"><a href="#rpc函数调用处理" class="headerlink" title="rpc函数调用处理"></a>rpc函数调用处理</h2><p>给rpc注册的程序就是原本框架提供的代码，具体代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// start a thread that listens for RPCs from worker.go</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Coordinator)</span></span> server() &#123;<br>rpc.Register(c)<br>rpc.HandleHTTP()<br><span class="hljs-comment">//l, e := net.Listen(&quot;tcp&quot;, &quot;:1234&quot;)</span><br>sockname := coordinatorSock()<br>os.Remove(sockname)<br>l, e := net.Listen(<span class="hljs-string">&quot;unix&quot;</span>, sockname)<br><span class="hljs-keyword">if</span> e != <span class="hljs-literal">nil</span> &#123;<br>log.Fatal(<span class="hljs-string">&quot;listen error:&quot;</span>, e)<br>&#125;<br><span class="hljs-keyword">go</span> http.Serve(l, <span class="hljs-literal">nil</span>)<br>&#125;<br><br></code></pre></td></tr></table></figure><p>其相应的也是上面提到的hearbeat和report事件。比较有go特色的的地方在于如何等待另一个进程生成对应的回应，采用的是如下的代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> heartbeatMsg <span class="hljs-keyword">struct</span> &#123;<br>response *HeartbeatResponse<br>ok       <span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Coordinator)</span></span> Heartbeat(request *HeartbeatRequest, response *HeartbeatResponse) <span class="hljs-type">error</span> &#123;<br>msg := heartbeatMsg&#123;response, <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;)&#125;<br>c.heartbeatCh &lt;- msg<br>&lt;-msg.ok<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>构建msg将信息传递过去给c.heartbeach，然后等待msg.ok准备就绪，也就是response填好了数据，再返回。Report也是同理</p><h2 id="task管理"><a href="#task管理" class="headerlink" title="task管理"></a>task管理</h2><p>在coordinator初始化时会生成一个schedule协程来负责task生成和管理</p><ul><li>task有4种类型Map类型、Reduce类型、等待类型和完成类型，Map类型和Reduce类需要worker进行实际处理，等待类型只需要worker去sleep一段时间就好了，然后再去询问有没有新任务，完成类型的任务发送过来之后worker就可以结束运行了</li><li>task有3个状态，分别为等待、运行、完成，一开始初始化时为等待状态，交给worker运行后为运行状态，worker发送report回来说明自己运行完毕后为完成状态。</li><li>coordinator有三个阶段分别为Map阶段、Reduce阶段和Complete阶段，一开始为Map阶段，其需要处理Map类型的task，当Map类型的task全部完成后需要转变到Reduce阶段，处理Reduce类型的task，当Reduce类型的状态也全部完成后就转为Complete状态，可以结束运行了。</li></ul><p>schedule代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Coordinator)</span></span> schedule() &#123;<br>c.initMapPhase()<br><br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> msg := &lt;-c.heartbeatCh:<br>isAllTaskDoneInPhase := c.selectANewTask(msg.response)<br><span class="hljs-keyword">if</span> isAllTaskDoneInPhase &#123;<br>c.switchPhase()<br>c.selectTaskAfterSwitchPhase(msg.response)<br>&#125;<br>log.Printf(<span class="hljs-string">&quot;Coordinator: Heartbeat response: %v\n&quot;</span>, msg.response)<br>msg.ok &lt;- <span class="hljs-keyword">struct</span>&#123;&#125;&#123;&#125;<br><br><span class="hljs-keyword">case</span> msg := &lt;-c.reportCh:<br><span class="hljs-keyword">if</span> msg.request.Phase == c.phase &#123;<br>log.Printf(<span class="hljs-string">&quot;Coordinator: Worker has finished %v-task%d\n&quot;</span>, c.phase, msg.request.Id)<br>c.tasks[msg.request.Id].status = Finished<br>&#125;<br>msg.ok &lt;- <span class="hljs-keyword">struct</span>&#123;&#125;&#123;&#125;<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>生成一个新任务时需要去遍历查看是否有处于等待状态的任务或者是运行时间过久（说明worker可能已经挂掉了）的任务，然后将其分配出去，主要代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Coordinator)</span></span> selectANewTask(response *HeartbeatResponse) <span class="hljs-type">bool</span> &#123;<br>isAllTaskDone, isNewTaskScheduled := <span class="hljs-literal">true</span>, <span class="hljs-literal">false</span><br><br><span class="hljs-keyword">for</span> id, task := <span class="hljs-keyword">range</span> c.tasks &#123;<br><span class="hljs-keyword">switch</span> task.status &#123;<br><span class="hljs-keyword">case</span> Idle:<br>isAllTaskDone, isNewTaskScheduled = <span class="hljs-literal">false</span>, <span class="hljs-literal">true</span><br>c.tasks[id].status, c.tasks[id].startTime = Working, time.Now()<br>c.scheduleTaskToResponse(id, response)<br><br><span class="hljs-keyword">case</span> Working:<br>isAllTaskDone = <span class="hljs-literal">false</span><br><span class="hljs-keyword">if</span> time.Since(task.startTime) &gt; MaxTaskRunInterval &#123;<br>isNewTaskScheduled = <span class="hljs-literal">true</span><br>c.tasks[id].startTime = time.Now()<br>c.scheduleTaskToResponse(id, response)<br>&#125;<br><br><span class="hljs-keyword">case</span> Finished:<br>&#125;<br><br><span class="hljs-keyword">if</span> isNewTaskScheduled &#123;<br><span class="hljs-keyword">break</span><br>&#125;<br>&#125;<br><br><span class="hljs-keyword">if</span> !isNewTaskScheduled &amp;&amp; !isAllTaskDone &#123;<br>response.JobType = WaitJob<br>&#125;<br><br><span class="hljs-keyword">return</span> isAllTaskDone<br>&#125;<br></code></pre></td></tr></table></figure><p>当coordinator进行Complete阶段后其实并不会再去处理其他事情，比如给worker发送运行结束的指令，而是直接给doneCh赋值，然后以此退出运行</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Coordinator)</span></span> Done() <span class="hljs-type">bool</span> &#123;<br>&lt;-c.doneCh<br>log.Printf(<span class="hljs-string">&quot;Coordinator: Done\n&quot;</span>)<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span><br>&#125;<br></code></pre></td></tr></table></figure><h1 id="worker-设计"><a href="#worker-设计" class="headerlink" title="worker 设计"></a>worker 设计</h1><h2 id="运行流程"><a href="#运行流程" class="headerlink" title="运行流程"></a>运行流程</h2><p>worker就是不断地发送heartbeat命令然后获取任务进行运行，直到接收到了Complete任务或者发送heartbeat失败，就可以结束运行了。如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Worker</span><span class="hljs-params">(mapf <span class="hljs-keyword">func</span>(<span class="hljs-type">string</span>, <span class="hljs-type">string</span>)</span></span> []KeyValue,<br>reducef <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(<span class="hljs-type">string</span>, []<span class="hljs-type">string</span>)</span></span> <span class="hljs-type">string</span>) &#123;<br><br><span class="hljs-keyword">for</span> &#123;<br>response := doHeartbeat()<br>log.Printf(<span class="hljs-string">&quot;Worker: receive coordinator&#x27;s response, new job is %v \n&quot;</span>, response)<br><br><span class="hljs-keyword">switch</span> response.JobType &#123;<br><span class="hljs-keyword">case</span> MapJob:<br>doMapTask(mapf, response)<br><span class="hljs-keyword">case</span> ReduceJob:<br>doReduceTask(reducef, response)<br><span class="hljs-keyword">case</span> WaitJob:<br>time.Sleep(<span class="hljs-number">1</span> * time.Second)<br><span class="hljs-keyword">case</span> CompleteJob:<br><span class="hljs-keyword">return</span><br><span class="hljs-keyword">default</span>:<br><span class="hljs-built_in">panic</span>(fmt.Sprintf(<span class="hljs-string">&quot;worker get an unexpected jobType %v&quot;</span>, response.JobType))<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Map类型task"><a href="#Map类型task" class="headerlink" title="Map类型task"></a>Map类型task</h2><p>Map类型的task的处理如下所示，总体就是调用mapF统计文件中各个单词的数量，并记录到中间文件中，由于将中间结果写入到文件中是可以并行运行的，所以这里启动了多个协程来进行处理</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">doMapTask</span><span class="hljs-params">(mapF <span class="hljs-keyword">func</span>(<span class="hljs-type">string</span>, <span class="hljs-type">string</span>)</span></span> []KeyValue, response *HeartbeatResponse) &#123;<br>wordCountList := getWordCountListOfFile(mapF, response.FilePath)<br><br>intermediate := splitWordCountListToReduceNNum(wordCountList, response.NReduce)<br><br><span class="hljs-keyword">var</span> writeIntermediateFilewg sync.WaitGroup<br><span class="hljs-keyword">for</span> reduceNumber, splitedWordCountList := <span class="hljs-keyword">range</span> intermediate &#123;<br>writeIntermediateFilewg.Add(<span class="hljs-number">1</span>)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(reduceNumber <span class="hljs-type">int</span>, splitedWordCountList []KeyValue)</span></span> &#123;<br><span class="hljs-keyword">defer</span> writeIntermediateFilewg.Done()<br>writeIntermediateFile(response.Id, reduceNumber, splitedWordCountList)<br>&#125;(reduceNumber, splitedWordCountList)<br>&#125;<br>writeIntermediateFilewg.Wait()<br><br>doReport(response.Id, MapPhase)<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Reduce类型task"><a href="#Reduce类型task" class="headerlink" title="Reduce类型task"></a>Reduce类型task</h2><p>Reduce类型task的处理如下所示，总体就是把对应的中间文件读出来，将结果通过reduceF进行聚集，输出到最终的文件中</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">doReduceTask</span><span class="hljs-params">(reduceF <span class="hljs-keyword">func</span>(<span class="hljs-type">string</span>, []<span class="hljs-type">string</span>)</span></span> <span class="hljs-type">string</span>, response *HeartbeatResponse) &#123;<br>wordCountList := getWordCountListFromIntermediateFile(response.NMap, response.Id)<br><br>wordCountMap := gatherAndSortIntermediateWordCountList(wordCountList)<br><br><span class="hljs-keyword">var</span> buf bytes.Buffer<br>reducIntermediateWordCount(reduceF, wordCountMap, &amp;buf)<br><br>fileName := generateReduceResultFileName(response.Id)<br>atomicWriteFile(fileName, &amp;buf)<br><br>doReport(response.Id, ReducePhase)<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="原子写入文件"><a href="#原子写入文件" class="headerlink" title="原子写入文件"></a>原子写入文件</h2><p>这里采用了一种原子写入的方式，以防止多个worker都需要写入同一个文件名的文件时可能出现的问题。总体思想就是先写入到一个临时文件中，然后再将其改名为对应的文件名，如果临时文件没有写成功，就用defer命令将其删除。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">atomicWriteFile</span><span class="hljs-params">(filename <span class="hljs-type">string</span>, reader io.Reader)</span></span> (err <span class="hljs-type">error</span>) &#123;<br>tmpFileName, err := writeToTmpFile(filename, reader)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;cannot write to temp file: %v&quot;</span>, err)<br>&#125;<br><br><span class="hljs-keyword">if</span> err := os.Rename(tmpFileName, filename); err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;cannot rename temp file: %v&quot;</span>, err)<br>&#125;<br><br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">writeToTmpFile</span><span class="hljs-params">(filename <span class="hljs-type">string</span>, reader io.Reader)</span></span> (tmpFileName <span class="hljs-type">string</span>, err <span class="hljs-type">error</span>) &#123;<br>dir, file := filepath.Split(filename)<br><span class="hljs-keyword">if</span> dir == <span class="hljs-string">&quot;&quot;</span> &#123;<br>dir = <span class="hljs-string">&quot;.&quot;</span><br>&#125;<br><br>tmpFile, err := os.CreateTemp(dir, file)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>, fmt.Errorf(<span class="hljs-string">&quot;cannot create temp file: %v&quot;</span>, err)<br>&#125;<br><span class="hljs-keyword">defer</span> tmpFile.Close()<br><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>os.Remove(tmpFile.Name())<br>&#125;<br>&#125;()<br><br>_, err = io.Copy(tmpFile, reader)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>, fmt.Errorf(<span class="hljs-string">&quot;cannot write to temp file: %v&quot;</span>, err)<br>&#125;<br><span class="hljs-keyword">if</span> err := tmpFile.Close(); err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>, fmt.Errorf(<span class="hljs-string">&quot;cannot close temp file: %v&quot;</span>, err)<br>&#125;<br><br><span class="hljs-keyword">return</span> tmpFile.Name(), <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><h1 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h1><p>coordinator运行结果:</p><p><img src="/./MIT6-824lab1/coordinator%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C.jpg" alt="coordinator运行结果"></p><p>worker运行结果:</p><p><img src="/./MIT6-824lab1/worker%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C.jpg" alt="worker运行结果"></p><p>中间文件：</p><p><img src="/./MIT6-824lab1/%E4%B8%AD%E9%97%B4%E6%96%87%E4%BB%B6.jpg" alt="中间文件"></p><p>输出结果：</p><p><img src="/./MIT6-824lab1/%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C.jpg" alt="输出结果"></p><p>测试脚本结果：</p><p><img src="/./MIT6-824lab1/%E6%B5%8B%E8%AF%95%E8%84%9A%E6%9C%AC%E7%BB%93%E6%9E%9C.jpg" alt="测试脚本结果"></p><h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><p>最后进行脚本测试的时候发现early_exit这个点总是通不过，这个脚本会捕捉最早退出运行的进程，然后拷贝所有输出文件，然后再在所有进程都退出的时候拷贝所有输出文件，以此对比两个文件是否相同，来判断是否coordinator和所有的woker都在任务全部完成后再退出。</p><p>后面仔细查看不通过的原因发现是因为其依靠下面的部分来进行捕捉退出的进程,本机器上使用的是<code>wait -n</code>,但是实际查看发现其并没有正确地在相关进程退出时进行触发，而是一开始就触发了，其触发时coordinator和所有worker其实都还在前台运行了，后面讲这部分改成了if里面的测试，就可以正常捕捉退出的进程然后顺利通过了。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">jobs</span> &amp;&gt; /dev/null<br><span class="hljs-keyword">if</span> [[ <span class="hljs-string">&quot;<span class="hljs-variable">$OSTYPE</span>&quot;</span> = <span class="hljs-string">&quot;darwin&quot;</span>* ]]<br><span class="hljs-keyword">then</span><br>  <span class="hljs-comment"># bash on the Mac doesn&#x27;t have wait -n</span><br>  <span class="hljs-keyword">while</span> [ ! -e <span class="hljs-variable">$DF</span> ]<br>  <span class="hljs-keyword">do</span><br>    <span class="hljs-built_in">sleep</span> 0.2<br>  <span class="hljs-keyword">done</span><br><span class="hljs-keyword">else</span><br>  <span class="hljs-comment"># the -n causes wait to wait for just one child process,</span><br>  <span class="hljs-comment"># rather than waiting for all to finish.</span><br>  <span class="hljs-built_in">wait</span> -n<br><span class="hljs-keyword">fi</span><br></code></pre></td></tr></table></figure><p>从看MapReduce论文到学go再到能看懂作业要求，再到能看懂别人写的代码，再到能自己独立完成这部分代码总共断断续续持续了一个月，能够感受到自己在这之中的不断的精进，MapReduce的设计确实也很巧妙，go总体的设计确实很适合分布式，MIT6.824确实不愧是一名深受好评的课，学一下是很有必要的，希望自己后面也能都将其他部分啃下来了。</p><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ol><li><a href="https://github.com/OneSizeFitsQuorum/MIT6.824-2021">https://github.com/OneSizeFitsQuorum/MIT6.824-2021</a></li><li><a href="https://github.com/PKUFlyingPig/MIT6.824">https://github.com/PKUFlyingPig/MIT6.824</a></li><li><a href="https://github.com/szw2021/MIT6.824-2021/tree/practice/src">https://github.com/szw2021/MIT6.824-2021/tree/practice/src</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
      <category>go</category>
      
      <category>MIT6.824</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RPC介绍</title>
    <link href="/2023/11/14/RPC%E4%BB%8B%E7%BB%8D/"/>
    <url>/2023/11/14/RPC%E4%BB%8B%E7%BB%8D/</url>
    
    <content type="html"><![CDATA[<pre><code class="hljs">最近在学MIT6.824的lab1——MapReduce，发现其中使用到了RPC来让work和coordinator之间通信，故而乘机学习一下。</code></pre><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>RPC（Remote Procedure Call，远程过程调用）是一种在分布式系统中进行进程间通信的协议。它允许一个程序（客户端）调用另一个程序（服务器）上的函数或过程，就像调用本地函数一样，而不必关心底层网络细节。</p><p>在 RPC 中，客户端和服务器可以在不同的机器上，甚至在不同的网络上。RPC 提供了一种抽象，使得远程调用看起来就像是本地调用一样。通过 RPC，程序可以通过网络传输数据和调用远程函数，使得分布式系统中的组件可以协同工作。</p><p>其整体流程如下图所示：</p><p><img src="https://pic4.zhimg.com/45366c44f775abfd0ac3b43bccc1abc3_b" alt="RPC流程"></p><p>对于RPC需要关注的主要有三点：</p><ul><li><strong>通信协议：</strong> RPC可以基于TCP或者HTTP协议，一般而言TCP的协议更快</li><li><strong>寻址：</strong> 远程提供服务器需要提供服务所在地址，例如IP和端口</li><li><strong>数据序列化：</strong> 远程调用无法依据内存进行参数和结果传递，所以需要规定序列化的格式，例如Json格式</li></ul><p>常用的RPC框架有如下这些： </p><ul><li>Thrift：thrift是一个软件框架，用来进行可扩展且跨语言的服务的开发。它结合了功能强大的软件堆栈和代码生成引擎，以构建在 C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk, and OCaml 这些编程语言间无缝结合的、高效的服务。</li><li>gRPC：一开始由 google 开发，是一款语言中立、平台中立、开源的远程过程调用(RPC)系统。</li><li>Dubbo：Dubbo是一个分布式服务框架，以及SOA治理方案。其功能主要包括：高性能NIO通讯及多协议集成，服务动态寻址与路由，软负载均衡与容错，依赖分析与降级等。Dubbo是阿里巴巴内部的SOA服务化治理方案的核心框架，Dubbo自2011年开源后，已被许多非阿里系公司使用。</li><li>Spring Cloud：Spring Cloud由众多子项目组成，如Spring Cloud Config、Spring Cloud Netflix、Spring Cloud Consul 等，提供了搭建分布式系统及微服务常用的工具，如配置管理、服务发现、断路器、智能路由、微代理、控制总线、一次性token、全局锁、选主、分布式会话和集群状态等，满足了构建微服务所需的所有解决方案。Spring Cloud基于Spring Boot, 使得开发部署极其简单。</li></ul><h1 id="GO语言示例"><a href="#GO语言示例" class="headerlink" title="GO语言示例"></a>GO语言示例</h1><p>在 Go 语言中，标准库提供了一个 net&#x2F;rpc 包，用于实现 RPC。基本的使用流程包括注册对象、注册服务、处理请求等。以下是一个简单的 Go RPC 例子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;net&quot;</span><br><span class="hljs-string">&quot;net/rpc&quot;</span><br>)<br><br><span class="hljs-comment">// 定义一个用于 RPC 的对象</span><br><span class="hljs-keyword">type</span> MyService <span class="hljs-keyword">struct</span>&#123;&#125;<br><br><span class="hljs-comment">// 定义一个 RPC 方法</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *MyService)</span></span> Multiply(args *Args, reply *<span class="hljs-type">int</span>) <span class="hljs-type">error</span> &#123;<br>*reply = args.A * args.B<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-comment">// 定义传递给 RPC 方法的参数结构</span><br><span class="hljs-keyword">type</span> Args <span class="hljs-keyword">struct</span> &#123;<br>A, B <span class="hljs-type">int</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-comment">// 注册服务</span><br>rpc.Register(<span class="hljs-built_in">new</span>(MyService))<br><br><span class="hljs-comment">// 创建监听器</span><br>listener, err := net.Listen(<span class="hljs-string">&quot;tcp&quot;</span>, <span class="hljs-string">&quot;:1234&quot;</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-built_in">panic</span>(err)<br>&#125;<br><br><span class="hljs-comment">// 处理连接</span><br><span class="hljs-keyword">for</span> &#123;<br>conn, err := listener.Accept()<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">continue</span><br>&#125;<br><span class="hljs-keyword">go</span> rpc.ServeConn(conn)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>在该例子中，MyService 结构体中的 Multiply 方法被注册为 RPC 服务。通过监听端口 1234，该服务可以接收客户端的 RPC 调用请求。客户端可以通过 net&#x2F;rpc 包中的函数来发起远程调用。RPC 在分布式系统中广泛用于实现不同节点之间的通信和协作。</p><p>以下是一个简单的 Go RPC 客户端的调用代码示例,程序需要确保 RPC 客户端的网络协议和端口与服务器端一致，这样它们才能正确地进行通信。在这个例子中，服务器端监听的是 TCP 端口 1234。：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-string">&quot;net/rpc&quot;</span><br>)<br><br><span class="hljs-comment">// 定义传递给 RPC 方法的参数结构</span><br><span class="hljs-keyword">type</span> Args <span class="hljs-keyword">struct</span> &#123;<br>A, B <span class="hljs-type">int</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-comment">// 连接 RPC 服务器</span><br>client, err := rpc.Dial(<span class="hljs-string">&quot;tcp&quot;</span>, <span class="hljs-string">&quot;localhost:1234&quot;</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-built_in">panic</span>(err)<br>&#125;<br><span class="hljs-keyword">defer</span> client.Close()<br><br><span class="hljs-comment">// 准备 RPC 调用的参数</span><br>args := Args&#123;<span class="hljs-number">3</span>, <span class="hljs-number">4</span>&#125;<br><br><span class="hljs-comment">// 调用 Multiply 方法</span><br><span class="hljs-keyword">var</span> result <span class="hljs-type">int</span><br>err = client.Call(<span class="hljs-string">&quot;MyService.Multiply&quot;</span>, args, &amp;result)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-built_in">panic</span>(err)<br>&#125;<br><br><span class="hljs-comment">// 打印结果</span><br>fmt.Printf(<span class="hljs-string">&quot;Result of 3 * 4: %d\n&quot;</span>, result)<br>&#125;<br></code></pre></td></tr></table></figure><p>在这个例子中，rpc.Dial 函数用于连接到服务器，然后通过 client.Call 方法调用远程的 Multiply 方法。在调用过程中，需要传递参数结构 Args 和一个用于接收结果的变量。最后，打印出调用结果:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Result</span> of <span class="hljs-number">3</span> * <span class="hljs-number">4</span>: <span class="hljs-number">12</span><br></code></pre></td></tr></table></figure><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ul><li><a href="https://jaminzhang.github.io/architecture/RPC-Introduction/">https://jaminzhang.github.io/architecture/RPC-Introduction/</a></li><li><a href="https://zhuanlan.zhihu.com/p/187560185">https://zhuanlan.zhihu.com/p/187560185</a></li><li><a href="https://cloud.tencent.com/developer/article/2021745">https://cloud.tencent.com/developer/article/2021745</a></li><li><a href="https://chat.openai.com/">ChatGPT</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
      <category>go</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何写出优雅的代码</title>
    <link href="/2023/11/09/%E5%A6%82%E4%BD%95%E5%86%99%E5%87%BA%E4%BC%98%E9%9B%85%E7%9A%84%E4%BB%A3%E7%A0%81/"/>
    <url>/2023/11/09/%E5%A6%82%E4%BD%95%E5%86%99%E5%87%BA%E4%BC%98%E9%9B%85%E7%9A%84%E4%BB%A3%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>最近在写模拟器的代码，现在需要对整体的架构都进行一个大更改，而当我回过头去看时发现好多代码都写得很丑，越写越像屎山代码，需要对整体进行一轮迭代，故而正好趁此机会来学习一下如何写一个优雅的代码。写之前看了很多博客，这里记录一下对自己比较有启发的点。</p><h1 id="什么是优雅的代码"><a href="#什么是优雅的代码" class="headerlink" title="什么是优雅的代码"></a>什么是优雅的代码</h1><pre><code class="hljs">这一个衡量标准很直接：WTF min</code></pre><p><img src="https://camo.githubusercontent.com/ded622d3db4ad28f7b47098ae182c09dc1d629c90f487a885f683527825ecc94/687474703a2f2f692e737461636b2e696d6775722e636f6d2f65545a76572e6a7067" alt="优雅的代码"></p><p>代码最后还是需要给人读的，需要认识到：</p><pre><code class="hljs">任何一个傻瓜都能写出计算机可以理解的代码。唯有写出人类容易理解的代码，才是优秀的程序员。—— Martin Fowler</code></pre><p>好的代码最重要的特点：整洁</p><pre><code class="hljs">整洁的代码如同优美的散文。—— Grady Booch</code></pre><h1 id="如何保证代码整洁"><a href="#如何保证代码整洁" class="headerlink" title="如何保证代码整洁"></a>如何保证代码整洁</h1><h2 id="1-有意义的命名"><a href="#1-有意义的命名" class="headerlink" title="1. 有意义的命名"></a>1. 有意义的命名</h2><p>命名要尽可能地输出多的信息，让人能快速理解这个类、变量或者函数的含义、功能。<strong>花时间来取名是值得的</strong></p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 创建后的天数</span><br><span class="hljs-comment">**/</span><br><span class="hljs-built_in">int</span> d;<br></code></pre></td></tr></table></figure><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs abnf">int daysSinceCreation<span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure><p>后一种命名就能够更加凸显变量的含义了。</p><p>命名是越短越好的，但是为了能够清晰表达意思，取长名字也是值得的。</p><p>尽量不要取相似的名字以让人困惑。</p><h2 id="2-优雅的注释"><a href="#2-优雅的注释" class="headerlink" title="2. 优雅的注释"></a>2. 优雅的注释</h2><p>一份优雅的代码本身就应该具有足够的表达力，不需要注释就能看懂。<strong>注释的存在往往是弥补我们无法用代码清晰表达意图的情况</strong>。当发现自己需要对某处的代码写注释时就需要考虑是不是应该用更好的代码对其进行替代了。</p><pre><code class="hljs">好代码&gt;&gt;坏代码+注释</code></pre><p>注释应该只需要注重解释上层的东西，包括设计的意图、功能，而不需要解释执行的细节，这由代码来进行展示。</p><p>注释不要去写能由git记录的信息。</p><h2 id="3-简洁的函数"><a href="#3-简洁的函数" class="headerlink" title="3. 简洁的函数"></a>3. 简洁的函数</h2><p>控制函数的长度，一般不要长于一个屏幕的大小，也就是<strong>控制在30行以内</strong></p><p><strong>if语句、else语句、while语句等，其中的代码应该只有一行</strong>，该行通常是一个调用语句，这样不但能保持短小，还可以给调用方法命名一个有说明性的名字，进一步增加代码的可读性</p><p>函数的功能要单一，具有原子性，以方便函数复用。最简单的规则就是看看该方法是否能在拆出一个方法，且拆出去的方法是不同于该方法的诠释和实现。</p><p>需要保证函数中的抽象层级一致。</p><p>不要返回null或者特殊对象等，不要传入null。</p><p>函数参数不要超过3个，如果超过就需要考虑将其抽象为类。</p><h2 id="4-整齐的代码结构"><a href="#4-整齐的代码结构" class="headerlink" title="4. 整齐的代码结构"></a>4. 整齐的代码结构</h2><p>一个文件的代码数量需要<strong>控制在200行以内</strong>，最多不要超过500行。</p><p>关系紧密的代码放在一起</p><ul><li>变量声明放在其使用的位置</li><li>函数的调用者要放在被调用者上面，以从上到下展示调用依赖顺序</li></ul><p>对象暴露行为，隐藏数据，调用对象时不应该了解该对象的内部情况。</p><p>一组代码代表一个完整的思路，不同组的代码中间要用空行间隔。</p><h2 id="5-重构代码"><a href="#5-重构代码" class="headerlink" title="5. 重构代码"></a>5. 重构代码</h2><p>好代码不是一蹴而就的，重构代码是必要的。</p><p>重复的代码肯定是可以抽象出一个上层函数的。</p><ul><li>都同一个类中就考虑将其提炼出一个函数</li><li>不在同一个类中，就需要考虑创建一个共享的地方，可以是一个工具类，以便多个类都可以使用它</li><li>只是相似的话，可以重拍顺序，将相同的部分提料出来</li></ul><p>过长的函数可以通过提取函数的方式来缩短。</p><p>如果一个类不是单一职责的，则可能会导致一旦其变化就需要修改多个其他类，或者不同类的变化都需要修改这个类，这时就需要考虑对其重构，划定职责。</p><p>有时候会发现三四个相同的字段，在多个类和函数中均出现，这时候说明有必要给这一组字段建立一个类，将其封装起来。</p><p>以查询代替临时变量，也就是对于复杂的赋值表达式，使用函数来进行替代。</p><p>对于复杂过长的函数，可能将其转化为一个类进行重构。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>写一份优雅的代码远比写一份能跑的代码难，但是这是值得的。想如何写代码远比写代码来得更加重要，写代码时的角度需要变化，不要以自己的角度去看自己写的代码，而是要以一个代码阅读者的角度来审视自己的代码。</p><h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><ul><li><a href="https://mp.weixin.qq.com/s?__biz=MzAxNDEwNjk5OQ==&mid=2650403801&idx=1&sn=5dab2af09f753fd089fe0f1f56260b10&chksm=83953bc1b4e2b2d79f78028ed6e79651167d85bf67453af791d9304fa4003eed73d9f2957fc7&scene=21#wechat_redirect">阿里工程师谈，什么是好的代码？</a></li><li><a href="https://developer.aliyun.com/article/1117703">一文详解｜如何写出优雅的代码</a></li><li><a href="https://www.zhihu.com/question/28492982">如何写出优雅的代码？</a></li><li><a href="https://juejin.cn/post/7016992016521232421">如何写出优雅的代码？</a></li><li><a href="https://github.com/CodingDocs/advanced-programmer/blob/master/docs/%E5%85%AB%E7%82%B9%E5%BB%BA%E8%AE%AE%E5%8A%A9%E6%82%A8%E5%86%99%E5%87%BA%E4%BC%98%E9%9B%85%E7%9A%84Java%E4%BB%A3%E7%A0%81.md">八点建议助您写出优雅的Java代码</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>代码风格</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文阅读】MapReduce: Simplified Data Processing on Large Clusters</title>
    <link href="/2023/11/05/MapReducePaperRead/"/>
    <url>/2023/11/05/MapReducePaperRead/</url>
    
    <content type="html"><![CDATA[<p>原博客链接：<a href="https://tanxinyu.work/mapreduce-thesis/">https://tanxinyu.work/mapreduce-thesis/</a></p><h1 id="相关背景"><a href="#相关背景" class="headerlink" title="相关背景"></a>相关背景</h1><p>在 20 世纪初，包括本文作者在内的 Google 的很多程序员，为了处理海量的原始数据，已经实现了数以百计的、专用的计算方法。这些计算方法用来处理大量的原始数据，比如，文档抓取（类似网络爬虫的程序）、Web 请求日志等等；也为了计算处理各种类型的衍生数据，比如倒排索引、Web 文档的图结构的各种表示形势、每台主机上网络爬虫抓取的页面数量的汇总、每天被请求的最多的查询的集合等等。</p><h1 id="要解决的问题"><a href="#要解决的问题" class="headerlink" title="要解决的问题"></a>要解决的问题</h1><p>大多数以上提到的数据处理运算在概念上很容易理解。然而由于输入的数据量巨大，因此要想在可接受的时间内完成运算，只有将这些计算分布在成百上千的主机上。如何处理并行计算、如何分发数据、如何处理错误？所有这些问题综合在一起，需要大量的代码处理，因此也使得原本简单的运算变得难以处理。</p><h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>为了解决上述复杂的问题，本文设计一个新的抽象模型，使用这个抽象模型，用户只要表述想要执行的简单运算即可，而不必关心并行计算、容错、数据分布、负载均衡等复杂的细节，这些问题都被封装在了一个库里面：利用一个输入 key&#x2F;value pair 集合来产生一个输出的 key&#x2F;value pair 集合。</p><p>MapReduce 库的用户可以用两个函数表达这个计算：Map 和 Reduce。</p><ul><li>用户自定义的 Map 函数接受一个输入的 key&#x2F;value pair 值，然后产生一个中间 key&#x2F;value pair 值的集合。MapReduce 库把所有具有相同中间 key 值 I 的中间 value 值集合在一起后按照一定的规律传递给 reduce 函数。</li><li>用户自定义的 Reduce 函数接受一个中间 key 的值 I 和相关的一个 value 值的集合。Reduce 函数合并这些 value 值，形成一个较小的 value 值的集合。一般的，每次 Reduce 函数调用只产生 0 或 1 个输出 value 值。通常 Map 通过一个迭代器把中间 value 值提供给 Reduce 函数，这样 Reduce Worker 就可以处理无法全部放入内存中的大量的 value 值的集合。<br>在概念上，用户定义的 Map 和 Reduce 函数都有相关联的类型：</li></ul><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs livescript"><span class="hljs-keyword">map</span><span class="hljs-function"><span class="hljs-params">(k1,v1)</span> -&gt;</span><span class="hljs-keyword">list</span>(k2,v2)<br>reduce<span class="hljs-function"><span class="hljs-params">(k2,<span class="hljs-keyword">list</span>(v2))</span> -&gt;</span><span class="hljs-keyword">list</span>(v2)<br></code></pre></td></tr></table></figure><p>比如，输入的 key 和 value 值与输出的 key 和 value 值在类型上推导的域不同。此外，中间 key 和 value 值与输出 key 和 value 值在类型上推导的域相同。</p><h1 id="执行流程"><a href="#执行流程" class="headerlink" title="执行流程"></a>执行流程</h1><p>通过将 Map 调用的输入数据自动分割为 M 个数据片段的集合，Map 调用被分布到多台机器上执行。输入的数据片段能够在不同的机器上并行处理。使用分区函数将 Map 调用产生的中间 key 值分成 R 个不同分区（例如，hash(key) mod R），Reduce 调用也被分布到多台机器上执行。分区数量（R）和分区函数由用户来指定。</p><p><img src="https://tanxinyu.work/mapreduce-thesis/mapreduce.png" alt="执行流程"></p><p>上图展示了 MapReduce 实现中操作的全部流程。当用户调用 MapReduce 函数时，将发生下面的一系列动作：</p><ol><li>用户程序首先调用的 MapReduce 库将输入文件分成 M 个数据片度，每个数据片段的大小一般从 16MB 到 64MB（可以通过可选的参数来控制每个数据片段的大小）。然后用户程序在机群中创建大量的程序副本。</li><li>这些程序副本中的有一个特殊的程序–master。副本中其它的程序都是 worker 程序，由 master 分配任务。有 M 个 Map 任务和 R 个 Reduce 任务将被分配，master 将一个 Map 任务或 Reduce 任务分配给一个空闲的 worker。</li><li>被分配了 map 任务的 worker 程序读取相关的输入数据片段，从输入的数据片段中解析出 key&#x2F;value pair，然后把 key&#x2F;value pair 传递给用户自定义的 Map 函数，由 Map 函数生成并输出的中间 key&#x2F;value pair，并缓存在内存中。</li><li>缓存中的 key&#x2F;value pair 通过分区函数分成 R 个区域，之后周期性的写入到本地磁盘上。缓存的 key&#x2F;value pair 在本地磁盘上的存储位置将被回传给 master，由 master 负责把这些存储位置再传送给 Reduce worker</li><li>当 Reduce worker 程序接收到 master 程序发来的数据存储位置信息后，使用 RPC 从 Map worker 所在主机的磁盘上读取这些缓存数据。当 Reduce worker 读取了所有的中间数据后，通过对 key 进行排序后使得具有相同 key 值的数据聚合在一起。由于许多不同的 key 值会映射到相同的 Reduce 任务上，因此必须进行排序。如果中间数据太大无法在内存中完成排序，那么就要在外部进行排序。</li><li>Reduce worker 程序遍历排序后的中间数据，对于每一个唯一的中间 key 值，Reduce worker 程序将这个 key 值和它相关的中间 value 值的集合传递给用户自定义的 Reduce 函数。Reduce 函数的输出被追加到所属分区的输出文件。</li><li>当所有的 Map 和 Reduce 任务都完成之后，master 唤醒用户程序。在这个时候，在用户程序里的对 MapReduce 调用才返回。</li></ol><h1 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h1><h2 id="worker-故障"><a href="#worker-故障" class="headerlink" title="worker 故障"></a>worker 故障</h2><p>master 与 worker 之间同步心跳，对于失效的 worker，根据其类型来做进一步处理：</p><ul><li>Map worker 故障：由于 Map 任务将数据临时存储在本地，所以需要重新执行。</li><li>Reduce worker 故障：由于 Reduce 任务将数据存储在全局文件系统中 ，所以不需要重新执行。</li></ul><h2 id="master-故障"><a href="#master-故障" class="headerlink" title="master 故障"></a>master 故障</h2><p>MapReduce 任务重新执行</p><h2 id="故障语义保证"><a href="#故障语义保证" class="headerlink" title="故障语义保证"></a>故障语义保证</h2><p>当用户提供的 Map 和 Reduce 操作是输入确定性函数（即相同的输入产生相同的输出）时，MapReduce 的分布式实现在任何情况下的输出都和所有程序没有出现任何错误、顺序的执行产生的输出是一样的。</p><ul><li>Map worker 任务的原子提交：每个 Map 任务生成 R 个本地临时文件，当一个 Map 任务完成时，worker 发送一个包含 R 个临时文件名的完成消息给 master。如果 master 从一个已经完成的 Map 任务再次接收到一个完成消息，master 将忽略这个消息；</li><li>Reduce worker 任务的原子提交：当 Reduce 任务完成时，Reduce worker 进程以原子的方式把临时文件重命名为最终的输出文件。如果同一个 Reduce 任务在多台机器上执行，针对同一个最终的输出文件将有多个重命名操作执行。MapReduce 依赖底层文件系统提供的重命名操作的原子性来保证最终的文件系统状态仅仅包含一个 Reduce 任务产生的数据。</li></ul><h1 id="存储位置优化"><a href="#存储位置优化" class="headerlink" title="存储位置优化"></a>存储位置优化</h1><p>核心思想：本地读文件以减少流量消耗</p><p>MapReduce 的 master 在调度 Map 任务时会考虑输入文件的位置信息，尽量将一个 Map 任务调度在包含相关输入数据拷贝的机器上执行；如果上述努力失败了，master 将尝试在保存有输入数据拷贝的机器附近的机器上执行 Map 任务（例如，分配到一个和包含输入数据的机器在一个交换机里的 worker 机器上执行）。</p><h1 id="任务粒度"><a href="#任务粒度" class="headerlink" title="任务粒度"></a>任务粒度</h1><p>理想情况下，M 和 R 应当比集群中 worker 的机器数量要多得多。在每台 worker 机器都执行大量的不同任务能够提高集群的动态的负载均衡能力，并且能够加快故障恢复的速度：失效机器上执行的大量 Map 任务都可以分布到所有其他的 worker 机器上去执行。</p><p>实际使用时建议用户选择合适的 M 值，以使得每一个独立任务都是处理大约 16M 到 64M 的输入数据（这样，上面描写的输入数据本地存储优化策略才最有效），另外，也建议把 R 值设置使用的 worker 机器数量的小倍数。比如：M&#x3D;200000，R&#x3D;5000，使用 2000 台 worker 机器。</p><h1 id="备用任务"><a href="#备用任务" class="headerlink" title="备用任务"></a>备用任务</h1><p>影响一个 MapReduce 的总执行时间最通常的因素是“落伍者”：在运算过程中，如果有一台机器花了很长的时间才完成最后几个 Map 或 Reduce 任务，导致 MapReduce 操作总的执行时间超过预期。</p><p>为了解决落伍者的问题，当一个 MapReduce 操作接近完成的时候，master 调度备用（backup）任务进程来执行剩下的、处于处理中状态（in-progress）的任务。无论是最初的执行进程、还是备用（backup）任务进程完成了任务，MapReduce 都把这个任务标记成为已经完成。此个机制通常只会占用比正常操作多几个百分点的计算资源。但能减少近 50% 的任务完成总时间。</p><h1 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h1><h2 id="分区函数"><a href="#分区函数" class="headerlink" title="分区函数"></a>分区函数</h2><p>MapReduce 缺省的分区函数是使用 hash 方法(比如，hash(key) mod R) 进行分区。hash 方法能产生非常平衡的分区。然而，有的时候，其它的一些分区函数对 key 值进行的分区将非常有用。比如，输出的 key 值是 URLs，有的用户希望每个主机的所有条目保持在同一个输出文件中。为了支持类似的情况，MapReduce 库的用户需要提供专门的分区函数。例如，使用“hash(Hostname(urlkey))mod R”作为分区函数就可以把所有来自同一个主机的 URLs 保存在同一个输出文件中。</p><h2 id="顺序保证"><a href="#顺序保证" class="headerlink" title="顺序保证"></a>顺序保证</h2><p>MapReduce 确保在给定的分区中，中间 key&#x2F;value pair 数据的处理顺序是按照 key 值增量顺序处理的。这样的顺序保证对每个分成生成一个有序的输出文件，这对于需要对输出文件按 key 值随机存取的应用非常有意义，对在排序输出的数据集也很有帮助。</p><h2 id="Combiner-函数"><a href="#Combiner-函数" class="headerlink" title="Combiner 函数"></a>Combiner 函数</h2><p>在某些情况下，Map 函数产生的中间 key 值的重复数据会占很大的比重，并且，用户自定义的 Reduce 函数满足结合律和交换律。在 2.1 节的词数统计程序是个很好的例子。由于词频率倾向于一个 zipf 分布（齐夫分布），每个 Map 任务将产生成千上万个这样的记录。所有的这些记录将通过网络被发送到一个单独的 Reduce 任务，然后由这个 Reduce 任务把所有这些记录累加起来产生一个数字。MapReduce 允许用户指定一个可选的 combiner 函数，combiner 函数首先在本地将这些记录进行一次合并，然后将合并的结果再通过网络发送出去。</p><p>Combiner 函数在每台执行 Map 任务的机器上都会被执行一次。一般情况下，Combiner 和 Reduce 函数是一样的。Combiner 函数和 Reduce 函数之间唯一的区别是 MapReduce 库怎样控制函数的输出。Reduce 函数的输出被保存在最终的输出文件里，而 Combiner 函数的输出被写到中间文件里，然后被发送给 Reduce 任务。</p><p>部分的合并中间结果可以显著的提高一些 MapReduce 操作的速度。</p><h2 id="输入和输出的类型"><a href="#输入和输出的类型" class="headerlink" title="输入和输出的类型"></a>输入和输出的类型</h2><p>支持常用的类型，可以通过提供一个简单的 Reader 接口实现来支持一个新的输入类型。Reader 并非一定要从文件中读取数据，比如可以很容易的实现一个从数据库里读记录的 Reader，或者从内存中的数据结构读取数据的 Reader。</p><h2 id="副作用"><a href="#副作用" class="headerlink" title="副作用"></a>副作用</h2><p>在某些情况下，MapReduce 的使用者发现，如果在 Map 或 Reduce 操作过程中增加辅助的输出文件会比较省事。MapReduce 依靠程序 writer 把这种“副作用”变成原子的和幂等的。通常应用程序首先把输出结果写到一个临时文件中，在输出全部数据之后，在使用系统级的原子操作 rename 重新命名这个临时文件。</p><h2 id="跳过损坏的记录"><a href="#跳过损坏的记录" class="headerlink" title="跳过损坏的记录"></a>跳过损坏的记录</h2><p>每个 worker 进程都设置了信号处理函数捕获内存段异常（segmentation violation）和总线错误（bus error）。 在执行 Map 或者 Reduce 操作之前，MapReduce 库通过全局变量保存记录序号。如果用户程序触发了一个系统信号，消息处理函数将用“最后一口气”通过 UDP 包向 master 发送处理的最后一条记录的序号。当 master 看到在处理某条特定记录不止失败一次时，master 就标志着条记录需要被跳过，并且在下次重新执行相关的 Map 或者 Reduce 任务的时候跳过这条记录。</p><h2 id="本地执行"><a href="#本地执行" class="headerlink" title="本地执行"></a>本地执行</h2><p>支持本地串行执行以方便调试</p><h2 id="状态信息"><a href="#状态信息" class="headerlink" title="状态信息"></a>状态信息</h2><p>master 支持嵌入 HTTP 服务器以显示一组状态信息页面，用户可以监控各种执行状态。状态信息页面显示了包括计算执行的进度，比如已经完成了多少任务、有多少任务正在处理、输入的字节数、中间数据的字节数、输出的字节数、处理百分比等等</p><h2 id="计数器"><a href="#计数器" class="headerlink" title="计数器"></a>计数器</h2><p>MapReduce 库使用计数器统计不同事件发生次数。比如，用户可能想统计已经处理了多少个单词、已经索引的多少篇 German 文档等等。</p><p>这些计数器的值周期性的从各个单独的 worker 机器上传递给 master（附加在 ping 的应答包中传递）。master 把执行成功的 Map 和 Reduce 任务的计数器值进行累计，当 MapReduce 操作完成之后，返回给用户代码。</p><p>计数器当前的值也会显示在 master 的状态页面上，这样用户就可以看到当前计算的进度。当累加计数器的值的时候，master 要检查重复运行的 Map 或者 Reduce 任务，避免重复累加（之前提到的备用任务和失效后重新执行任务这两种情况会导致相同的任务被多次执行）。</p><h1 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h1><p>分布式的 Grep：Map 函数输出匹配某个模式的一行，Reduce 函数是一个恒等函数，即把中间数据复制到输出。</p><ul><li>计算 URL 访问频率：Map 函数处理日志中 web 页面请求的记录，然后输出 (URL,1)。Reduce 函数把相同 URL 的 value 值都累加起来，产生 (URL, 记录总数）结果。<br>网络链接倒排：Map 函数在源页面（source）中搜索所有的链接目标（target）并输出为 (target,source)。Reduce 函数把给定链接目标（target）的链接组合成一个列表，输出 (target,list(source))。</li><li>每个主机的检索词向量：检索词向量用一个（词，频率）列表来概述出现在文档或文档集中的最重要的一些词。Map 函数为每一个输入文档输出（主机名，检索词向量），其中主机名来自文档的 URL。Reduce 函数接收给定主机的所有文档的检索词向量，并把这些检索词向量加在一起，丢弃掉低频的检索词，输出一个最终的（主机名，检索词向量）。</li><li>倒排索引：Map 函数分析每个文档输出一个（词，文档号）的列表，Reduce 函数的输入是一个给定词的所有（词，文档号），排序所有的文档号，输出（词，list（文档号）)。所有的输出集合形成一个简单的倒排索引，它以一种简单的算法跟踪词在文档中的位置。<br>分布式排序：Map 函数从每个记录提取 key，输出 (key,record)。Reduce 函数不改变任何的值。这个运算依赖分区机制和排序属性。</li></ul><h1 id="经验分享"><a href="#经验分享" class="headerlink" title="经验分享"></a>经验分享</h1><ul><li>约束编程模式使得并行和分布式计算非常容易，也易于构造容错的计算环境；</li><li>网络带宽是稀有资源。大量的系统优化是针对减少网络传输量为目的的：本地优化策略使大量的数据从本地磁盘读取，中间文件写入本地磁盘、并且只写一份中间文件也节约了网络带宽。</li><li>多次执行相同的任务可以减少硬件配置不平衡带来的负面影响，同时解决了由于机器失效导致的数据丢失问题。</li></ul><h1 id="创新之处"><a href="#创新之处" class="headerlink" title="创新之处"></a>创新之处</h1><ul><li>通过简单的接口实现了自动的并行化和大规模的分布式计算，通过使用 MapReduce 模型接口实现了在大量普通 PC 机上的高性能计算。</li><li>向工业界证明了 MapReduce 模型在分布式计算上的可行性，拉开了分布式计算的序幕并影响了其后所有的计算框架，包括现在流行的批处理框架 Spark 和流处理框架 Flink 都很受其影响。</li></ul><h1 id="不足之处"><a href="#不足之处" class="headerlink" title="不足之处"></a>不足之处</h1><ul><li>基于历史局限性和当时的成本考虑，没有利用内存去更高效的处理数据，不过也为 Spark 提供了思路。</li><li>没有将资料调度和计算调度分离，使得 MapReduce 系统看起来较为冗杂。在开源的 Hadoop 生态中，MapReduce 现只关注于计算，具体的资源调度由 Yarn 管理。</li></ul><h1 id="相关系统"><a href="#相关系统" class="headerlink" title="相关系统"></a>相关系统</h1><ul><li>分布式存储系统：GFS&#x2F;Colossus&#x2F;HDFS</li><li>批处理框架：Spark</li><li>流处理框架：Flink</li><li>高可用机制：Chubby&#x2F;ZooKeeper</li></ul><h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><ul><li><a href="http://nil.csail.mit.edu/6.824/2020/notes/l01.txt">6.824 讲义</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/video/1.html">6.824 视频</a></li><li><a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/mapreduce-osdi04.pdf">论文</a></li><li><a href="https://github.com/Cxka/paper/blob/0a72fe0b354b65bac25e45163163eb2573f1faf2/map-reduce/map-reduce-cn.pdf">中文翻译</a></li><li><a href="https://blog.mrcroxx.com/posts/paper-reading/mapreduce-osdi04/">其他优质博客</a></li></ul><h1 id="补充MapReduce论文示例代码"><a href="#补充MapReduce论文示例代码" class="headerlink" title="补充MapReduce论文示例代码"></a>补充MapReduce论文示例代码</h1><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;mapreduce/mapreduce.h&quot;</span></span><br><br><span class="hljs-comment">// User’s map function</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">WordCounter</span> : <span class="hljs-keyword">public</span> Mapper &#123;<br>  <span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">Map</span><span class="hljs-params">(<span class="hljs-type">const</span> MapInput&amp; input)</span> </span>&#123;<br>      <span class="hljs-type">const</span> string&amp; text = input.<span class="hljs-built_in">value</span>();<br>      <span class="hljs-type">const</span> <span class="hljs-type">int</span> n = text.<span class="hljs-built_in">size</span>();<br>      <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; ) &#123;<br>        <span class="hljs-comment">// Skip past leading whitespace</span><br>        <span class="hljs-keyword">while</span> ((i &lt; n) &amp;&amp; <span class="hljs-built_in">isspace</span>(text[i]))<br>          i++;<br><br>        <span class="hljs-comment">// Find word end</span><br>        <span class="hljs-type">int</span> start = i;<br>        <span class="hljs-keyword">while</span> ((i &lt; n) &amp;&amp; !<span class="hljs-built_in">isspace</span>(text[i]))<br>          i++;<br>        <br>        <span class="hljs-keyword">if</span> (start &lt; i)<br>          <span class="hljs-built_in">Emit</span>(text.<span class="hljs-built_in">substr</span>(start,i-start),<span class="hljs-string">&quot;1&quot;</span>);<br>      &#125;<br>  &#125;<br>&#125;;<br><span class="hljs-built_in">REGISTER_MAPPER</span>(WordCounter);<br><br><span class="hljs-comment">// User’s reduce function</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Adder</span> : <span class="hljs-keyword">public</span> Reducer &#123;<br>  <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">Reduce</span><span class="hljs-params">(ReduceInput* input)</span> </span>&#123;<br>    <span class="hljs-comment">// Iterate over all entries with the</span><br>    <span class="hljs-comment">// same key and add the values</span><br>    int64 value = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">while</span> (!input-&gt;<span class="hljs-built_in">done</span>()) &#123;<br>      value += <span class="hljs-built_in">StringToInt</span>(input-&gt;<span class="hljs-built_in">value</span>());<br>      input-&gt;<span class="hljs-built_in">NextValue</span>();<br>    &#125;<br><br>    <span class="hljs-comment">// Emit sum for input-&gt;key()</span><br>    <span class="hljs-built_in">Emit</span>(<span class="hljs-built_in">IntToString</span>(value));<br>  &#125;<br>&#125;;<br><span class="hljs-built_in">REGISTER_REDUCER</span>(Adder);<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span>** argv)</span> </span>&#123;<br>  <span class="hljs-built_in">ParseCommandLineFlags</span>(argc, argv);<br><br>  MapReduceSpecification spec;<br><br>  <span class="hljs-comment">// Store list of input files into &quot;spec&quot;</span><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; argc; i++) &#123;<br>    MapReduceInput* input = spec.<span class="hljs-built_in">add_input</span>();<br>    input-&gt;<span class="hljs-built_in">set_format</span>(<span class="hljs-string">&quot;text&quot;</span>);<br>    input-&gt;<span class="hljs-built_in">set_filepattern</span>(argv[i]);<br>    input-&gt;<span class="hljs-built_in">set_mapper_class</span>(<span class="hljs-string">&quot;WordCounter&quot;</span>);<br>  &#125;<br><br>  <span class="hljs-comment">// Specify the output files:</span><br>  <span class="hljs-comment">// /gfs/test/freq-00000-of-00100</span><br>  <span class="hljs-comment">// /gfs/test/freq-00001-of-00100</span><br>  <span class="hljs-comment">// ...</span><br>  MapReduceOutput* out = spec.<span class="hljs-built_in">output</span>();<br>  out-&gt;<span class="hljs-built_in">set_filebase</span>(<span class="hljs-string">&quot;/gfs/test/freq&quot;</span>);<br>  out-&gt;<span class="hljs-built_in">set_num_tasks</span>(<span class="hljs-number">100</span>);<br>  out-&gt;<span class="hljs-built_in">set_format</span>(<span class="hljs-string">&quot;text&quot;</span>);<br>  out-&gt;<span class="hljs-built_in">set_reducer_class</span>(<span class="hljs-string">&quot;Adder&quot;</span>);<br><br>  <span class="hljs-comment">// Optional: do partial sums within map</span><br>  <span class="hljs-comment">// tasks to save network bandwidth</span><br>  out-&gt;<span class="hljs-built_in">set_combiner_class</span>(<span class="hljs-string">&quot;Adder&quot;</span>);<br><br>  <span class="hljs-comment">// Tuning parameters: use at most 2000</span><br>  <span class="hljs-comment">// machines and 100 MB of memory per task</span><br>  spec.<span class="hljs-built_in">set_machines</span>(<span class="hljs-number">2000</span>);<br>  spec.<span class="hljs-built_in">set_map_megabytes</span>(<span class="hljs-number">100</span>);<br>  spec.<span class="hljs-built_in">set_reduce_megabytes</span>(<span class="hljs-number">100</span>);<br><br>  <span class="hljs-comment">// Now run it</span><br>  MapReduceResult result;<br>  <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">MapReduce</span>(spec, &amp;result)) <span class="hljs-built_in">abort</span>();<br><br>  <span class="hljs-comment">// Done: ’result’ structure contains info</span><br>  <span class="hljs-comment">// about counters, time taken, number of</span><br>  <span class="hljs-comment">// machines used, etc.</span><br><br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>git学习记录</title>
    <link href="/2023/11/04/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"/>
    <url>/2023/11/04/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<p>网站学习链接：<a href="https://learngitbranching.js.org/?locale=zh_CN">https://learngitbranching.js.org/?locale=zh_CN</a></p><p>经验贴：<a href="https://zhuanlan.zhihu.com/p/383960650">https://zhuanlan.zhihu.com/p/383960650</a></p><ul><li><code>git brach -b &lt;branchName&gt;</code> 新建一个<code>branchName</code>分支，并切换到那个分支</li><li><code>git checkout branchName^</code> 使得HEAD指向<code>branchName</code>的前一个分支，有几个<code>^</code>就代表前移几个，如果<code>branchName</code> 有多个parent，那么<code>^num</code> 就是指选择跳到第几个parent</li><li><code>git checkout branchName~2</code> 使得HEAD指向<code>branchName</code> 的前2个分支，如果没有后面的数字就是默认1</li><li><code>git checkout HEAD~^2~2</code> ,<code>git branch -f bugWork HEAD~^2^</code>git的操作符还支持链式操作</li><li><code>git revert</code>用于撤销提交，生成一条新的提交来覆盖之前的修改，保留修改历史，语法：<code>git revert &lt;commit&gt;</code> ，其中，<code>&lt;commit&gt;</code>是<strong>要撤销的提交</strong>的哈希值或引用</li><li><code>git reset</code>用于重置分支的指针，可以选择保留或丢弃之前的修改，改变提交历史，语法：<code>git reset &lt;commit&gt;</code> ，其中，<code>&lt;commit&gt;</code>是<strong>要重置到的目标提交</strong>的哈希值或引用<ul><li><code>-soft</code>：重置分支的指针，但不改变工作区和暂存区的内容。之前的修改将被保留在暂存区中，你可以随时重新提交它们</li><li><code>-mixed</code>（默认选项）：重置分支的指针，并清除暂存区的内容。之前的修改将保留在工作区中，但不会自动提交</li><li><code>-hard</code>：重置分支的指针，并清除暂存区和工作区的内容。之前的修改将完全丢失，慎用该选项</li></ul></li><li>使用<code>git reset</code>会改变分支的提交历史。如果你在公共分支上使用<code>git reset</code>，并将其推送到远程仓库，可能会导致其他人的问题。因此，在公共分支上通常更推荐使用<code>git revert</code></li><li><code>git rebase &lt;branch&gt; &lt;based_branch&gt;</code> 可以指定将branch对based_branch进行rebase</li><li><code>git cherry-pick commit1 commit2</code> 可以将两个commit放到HEAD后面,注意commit的顺序就是这里排列的顺序</li><li><code>git rebase -i HEAD~4</code> 是一个 Git 命令，用于以<strong>交互方式</strong>进行历史提交的重新整理（rebase）。该命令允许你修改最近的 4 个提交，可以根据需要修改这些操作命令。常见的操作命令包括 “pick”（保留提交）、”edit”（修改提交）、”reword”（修改提交信息）、”squash”（合并提交）等</li><li><code>git rebase</code></li><li><code>git branch -f main caption</code> 用于将分支<code>main</code>的指针强制移动到指定的提交<code>caption</code>上</li><li><code>git commit --amend</code>是一个用于修改最近一次提交的Git命令</li><li><code>git tag tagName commitName</code> 给c1提交赋上v0标签</li><li><code>git push origin &lt;tagname&gt;</code> 将tag推送到远程</li><li><code>git describe &lt;commit&gt;</code> 如果不指定<code>&lt;commit&gt;</code>，则默认使用当前所在的提交。如果这个<code>&lt;commit&gt;</code> 有标签就输出相应的标签，如果没有就会去找最近的标签，生成一个描述，格式为<code>&lt;tag&gt;-&lt;num&gt;-g&lt;hash&gt;</code>，其中<code>&lt;tag&gt;</code>是最近的标签，<code>&lt;num&gt;</code>是指定提交与最近标签之间的提交数，<code>&lt;hash&gt;</code>是指定提交的简短哈希值</li><li><code>git fetch</code> 会获取远程厂库的所有分支的所有提交记录，并把<code>orgin/xxx</code> 指向对应的远程提交，但是它并不会更改本地的内容还有本地的分支</li><li><code>git pull</code> 实际上是<code>git fetch</code>和<code>git merge</code>的合集，它会获取远程更新并与当前对应分支合并</li><li><code>git pull --rebase</code> 是<code>git fetch</code> 和<code>git rebase</code> 的合集，它会获取远程更新并对其进行rebase</li><li><code>git push</code> 实际上会merge本地拷贝的<code>origin/xxxx</code>分支然后再提交</li><li><code>git checkout -b foo origin/main</code> 可以把<code>foo</code>和远程分支<code>origin/main</code>绑定起来</li><li><code>git branch -u o/main foo</code> 使得foo分支直接绑定远程分支main，如果当前分支就是foo，就可省略foo</li><li><code>git branch -m &lt;old_branch_name&gt; &lt;new_branch_name&gt;</code> 可以修改branch的名字</li><li><code>git push origin main</code> 将本地 <code>main</code> 分支的提交推送到远程仓库 <code>origin</code> 的 <code>main</code> 分支的命令</li><li><code>git push origin &lt;source&gt;:&lt;destination&gt;</code> 将本地 <code>&lt;source&gt;</code> 分支的提交推送到远程仓库 <code>origin</code> 的 <code>&lt;destination&gt;</code> 分支的命令。这样可以将本地的修改共享给其他协作者，并将本地分支映射到远程仓库的不同分支。<code>source</code>既可以是<code>branch</code>的名字也可以是某个指定的提交位置例如<code>HEAD~2</code></li><li><code>git fetch origin &lt;source&gt;:&lt;destination&gt;</code> 将远程的厂库<code>origin</code>的<code>source</code>分支更新到本地<code>destination</code>分支。注意<code>source</code>也是既可以是分支名也可以是某个指定的提交位置。注意这样子的<code>o/xxxx</code>分支不会进行变化</li><li><code>git push origin :side</code> 会删除远程的side分支</li><li><code>git fetch origin :bugFix</code> 会在本地创建一个bugFix分支</li><li><code>git pull origin foo</code> 相当于：<code>git fetch origin foo; git merge o/foo</code></li><li><code>git pull origin bar~1:bugFix</code> 相当于：<code>git fetch origin bar~1:bugFix; git merge bugFix</code></li></ul>]]></content>
    
    
    <categories>
      
      <category>git</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>博客基础使用指南</title>
    <link href="/2023/11/04/%E5%8D%9A%E5%AE%A2%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"/>
    <url>/2023/11/04/%E5%8D%9A%E5%AE%A2%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</url>
    
    <content type="html"><![CDATA[<h1 id="在本地写文章"><a href="#在本地写文章" class="headerlink" title="在本地写文章"></a>在本地写文章</h1><pre><code class="hljs">指令需要在根目录下的控制台中运行</code></pre><ul><li>直接创建新文章：<code>hexo new a</code></li><li>新建草稿：<code>hexo new draft b</code></li><li>将草稿变成发布文章：<code>hexo publish b</code></li><li>文章首部内容示例：  <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> <span class="hljs-string">我就是标题</span><br><span class="hljs-attr">date:</span> <span class="hljs-number">2021-09-25 23:32:04</span><br><span class="hljs-attr">comments:</span> <span class="hljs-literal">true</span> <span class="hljs-comment">#是否可评论 </span><br><span class="hljs-attr">layout:</span> <span class="hljs-string">post</span> <span class="hljs-comment"># 公开文章 </span><br><span class="hljs-attr">toc:</span> <span class="hljs-literal">true</span> <span class="hljs-comment">#是否显示文章目录 </span><br><span class="hljs-attr">tags:</span>   <span class="hljs-comment">#标签 </span><br><span class="hljs-bullet">-</span> <span class="hljs-string">我就是新的标签1</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">老子是新的标签2</span><br><span class="hljs-meta">---</span><br></code></pre></td></tr></table></figure></li></ul><h1 id="部署运行"><a href="#部署运行" class="headerlink" title="部署运行"></a>部署运行</h1><ul><li>清理缓存： <code>hexo clean</code></li><li>生成静态网页并部署到远程github厂库：<code>hexo g -d</code></li><li>启动服务：<code>hexo s</code></li><li>本地访问的链接：<code>http://localhost:4000/</code></li><li>远程访问链接：<code>https://slipegg.github.io/</code></li></ul><h1 id="备忘录"><a href="#备忘录" class="headerlink" title="备忘录"></a>备忘录</h1><p>站点访问统计:<a href="https://console.leancloud.app/apps">国际版LeanCloud</a></p><p>注意下面的部署文章没有提到要在LeadCloud里创建Comment数据库，以及设置权限，修改serverUrl配置，修改完成后评论功能才能正常使用。</p><p>github推送使用的是git，所以依赖的其实是本地的私钥</p><p>部署的参考文档：</p><ul><li><a href="https://blog.csdn.net/yaorongke/article/details/119089190">https://blog.csdn.net/yaorongke/article/details/119089190</a></li><li><a href="https://blog.csdn.net/PaperJack/article/details/120479912">https://blog.csdn.net/PaperJack/article/details/120479912</a></li><li><a href="https://iyichen.xyz/2022/01/hexo-leancloud-valine-access-fail/">https://iyichen.xyz/2022/01/hexo-leancloud-valine-access-fail/</a></li><li><a href="https://zhengyujie.github.io/2019/08/18/valine%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/">https://zhengyujie.github.io/2019/08/18/valine%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/</a></li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2023/11/04/hello-world/"/>
    <url>/2023/11/04/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>测试文章</title>
    <link href="/2021/06/10/test/"/>
    <url>/2021/06/10/test/</url>
    
    <content type="html"><![CDATA[<p>这是一篇测试文章</p><img src="/2021/06/10/test/test.jpg" class="" title="图片引用方法一"><p><img src="/2021/06/10/test/test.jpg" alt="图片引用方法二"></p><p><img src="/images/test.jpg" alt="图片引用方法三"></p>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
