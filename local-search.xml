<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>【K8s源码分析（六）】-K8s中Pod拓扑分布约束（Pod Topology Spread Constraints）插件介绍</title>
    <link href="/2024/05/12/k8sSource6/"/>
    <url>/2024/05/12/k8sSource6/</url>
    
    <content type="html"><![CDATA[<p>本次分析参考的K8s版本是<a href="https://github.com/kubernetes/kubernetes/tree/release-1.27">v1.27.0</a>。</p><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在 k8s 集群调度中，<strong>亲和性</strong>相关的概念本质上都是控制 Pod 如何被调度 – <strong>堆叠或打散</strong>。<code>podAffinity</code> 以及 <code>podAntiAffinity</code> 两个特性对 Pod 在不同拓扑域（拓扑键-拓扑值构成了一个拓扑域，例如region-east）的分布进行了一些控制，<code>podAffinity</code> 可以将无数个 Pod 调度到特定的某一个拓扑域，这是<strong>堆叠</strong>的体现；<code>podAntiAffinity</code> 则可以控制一个拓扑域只存在一个 Pod，这是<strong>打散</strong>的体现。前面已经进行了介绍，详见：<a href="https://slipegg.github.io/2024/05/11/k8sSource5/">K8s源码分析（五）-K8s中Pod亲和性调度插件介绍</a></p><p>但<code>podAffinity</code> 以及 <code>podAntiAffinity</code> 这两种情况都太极端了，在不少场景下都无法达到理想的效果，例如为了实现容灾和高可用，将业务 Pod 尽可能均匀的分布在不同可用区就很难实现。</p><p><code>PodTopologySpread</code>（Pod 拓扑分布约束） 特性的提出正是为了对 Pod 的调度分布提供更精细的控制，以提高服务可用性以及资源利用率，<code>PodTopologySpread</code> 由 <code>EvenPodsSpread</code> 特性门所控制，在 v1.16 版本第一次发布，并在 v1.18 版本进入 beta 阶段默认启用。</p><p>官方对其的介绍详见：<a href="https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/">Pod Topology Spread Constraints</a></p><h2 id="使用规范"><a href="#使用规范" class="headerlink" title="使用规范"></a>使用规范</h2><p>这一特性的定义在<code>spec.topologySpreadConstraints</code>下，一些可以定义的字段如下</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">example-pod</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-comment"># Configure a topology spread constraint</span><br>  <span class="hljs-attr">topologySpreadConstraints:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">maxSkew:</span> <span class="hljs-string">&lt;integer&gt;</span><br>      <span class="hljs-attr">minDomains:</span> <span class="hljs-string">&lt;integer&gt;</span> <span class="hljs-comment"># optional</span><br>      <span class="hljs-attr">topologyKey:</span> <span class="hljs-string">&lt;string&gt;</span><br>      <span class="hljs-attr">whenUnsatisfiable:</span> <span class="hljs-string">&lt;string&gt;</span><br>      <span class="hljs-attr">labelSelector:</span> <span class="hljs-string">&lt;object&gt;</span><br>      <span class="hljs-attr">matchLabelKeys:</span> <span class="hljs-string">&lt;list&gt;</span> <span class="hljs-comment"># optional; beta since v1.27</span><br>      <span class="hljs-attr">nodeAffinityPolicy:</span> [<span class="hljs-string">Honor|Ignore</span>] <span class="hljs-comment"># optional; beta since v1.26</span><br>      <span class="hljs-attr">nodeTaintsPolicy:</span> [<span class="hljs-string">Honor|Ignore</span>] <span class="hljs-comment"># optional; beta since v1.26</span><br>  <span class="hljs-comment">### other Pod fields go here</span><br></code></pre></td></tr></table></figure><ul><li><p><strong>topologyKey：</strong>这个拓扑约束所生效的目标拓扑键，计算分布不均匀程度时以其作为单位。例如region、zone、hostName等。</p></li><li><p><strong>maxSkew：</strong>描述了允许的最大pod的分布不均匀程度。不均匀程度由同一个拓扑键下各个拓扑值中包含的所有的node中匹配的pod的数量之和的<strong>最大值减去最小值</strong>得到。</p><p>  <img src="/2024/05/12/k8sSource6/region.png" alt="示例"></p><p>  例如现在的拓扑键是region，总共有3个不同的拓扑值，分别为A、B、C，就是有3个拓扑域它们中分别有2、2、1个相匹配的pod，那么其不均匀程度就是2-1&#x3D;1。如过设置maxSkew为1，那么要维持这个maxSkew，pod就得调度到Region C中的任意一个node上去。</p></li><li><p><strong>whenUnsatisfiable：</strong>当不满足maxSkew约束的node时如何处理。值可以为：</p><ul><li><code>DoNotSchedule</code>（默认）告诉调度器不要调度。</li><li><code>ScheduleAnyway</code> 告诉调度器仍然继续调度，只是根据如何能将偏差最小化来对节点进行排序。</li></ul></li><li><p><strong>labelSelector：</strong>筛选需要匹配的pod的规则。</p></li><li><p><strong>minDomains（可选项）：</strong>符合条件的拓扑域的最小值。如果小于这个值，那么就设置全局中匹配到的pod的数量的最小值为0，这时候各个拓扑域下的node相匹配的pod数量需要小于等于maxSkew。如果拓扑域的数量大于这个值，那么就不会有影响。默认值为1，设置的值必须大于0。</p><p>  <strong>注意：</strong>在 Kubernetes v1.30 之前，<code>minDomains</code> 字段只有在启用了 <code>MinDomainsInPodTopologySpread</code> <a href="https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/feature-gates/">特性门控</a>时才可用（自 v1.28 起默认启用） 在早期的 Kubernetes 集群中，此特性门控可能被显式禁用或此字段可能不可用。</p></li><li><p><strong>matchLabelKeys（可选项，beta，v1.27启用）：</strong>在labelSelector之外进行额外的pod筛选，即labelSelector筛选后的pod<strong>必须还得包含这些key</strong>。注意其要求如果没有labelSelector就不能使用这个项，并且不能和labelSelector有相同的key。默认是空，即不可能该项。</p></li><li><p><strong>nodeAffinityPolicy（可选项，beta，v1.26启用）：</strong>定义如何对待nodeAffinity和nodeSelector。</p><ul><li><strong>Honor：</strong>只有匹配nodeAffinity&#x2F;nodeSelector的节点才会包含在计算中。</li><li><strong>Ignore：</strong>nodeAffinity&#x2F;nodeSelector 操作被忽略，所有节点都包含在计算中。</li></ul></li><li><p><strong>nodeTaintsPolicy （可选项，beta，v1.26启用）：定义如何处理污点节点。</strong></p><ul><li><strong>Honor：</strong>只查看没有污点的节点，以及要调度的pod 具有容忍度的污点的节点。</li><li><strong>Ignore：</strong>所有节点都包含在计算中。</li></ul></li></ul><p>当一个 Pod 定义多个<code>topologySpreadConstraint</code>时，这些约束将使用<strong>逻辑 AND 运算进行组合</strong>。因为可以有多个约束，所以有可能会出现调度到任意节点都无法满足的情况。</p><h1 id="源代码分析"><a href="#源代码分析" class="headerlink" title="源代码分析"></a>源代码分析</h1><p>该组件的相关代码都在<code>pkg/scheduler/framework/plugins/podtopologyspread</code>文件夹下，其包含的文件如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs go">podtopologyspread/<br>├── common.<span class="hljs-keyword">go</span><br>├── filtering.<span class="hljs-keyword">go</span><br>├── filtering_test.<span class="hljs-keyword">go</span><br>├── plugin.<span class="hljs-keyword">go</span><br>├── plugin_test.<span class="hljs-keyword">go</span><br>├── scoring.<span class="hljs-keyword">go</span><br>└── scoring_test.<span class="hljs-keyword">go</span><br></code></pre></td></tr></table></figure><h2 id="plugin-go"><a href="#plugin-go" class="headerlink" title="plugin.go"></a>plugin.go</h2><p>查看其初始的部分，如下。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// PodTopologySpread is a plugin that ensures pod&#x27;s topologySpreadConstraints is satisfied.</span><br><span class="hljs-keyword">type</span> PodTopologySpread <span class="hljs-keyword">struct</span> &#123;<br>systemDefaulted                              <span class="hljs-type">bool</span><br>parallelizer                                 parallelize.Parallelizer<br>defaultConstraints                           []v1.TopologySpreadConstraint<br>sharedLister                                 framework.SharedLister<br>services                                     corelisters.ServiceLister<br>replicationCtrls                             corelisters.ReplicationControllerLister<br>replicaSets                                  appslisters.ReplicaSetLister<br>statefulSets                                 appslisters.StatefulSetLister<br>enableMinDomainsInPodTopologySpread          <span class="hljs-type">bool</span><br>enableNodeInclusionPolicyInPodTopologySpread <span class="hljs-type">bool</span><br>enableMatchLabelKeysInPodTopologySpread      <span class="hljs-type">bool</span><br>&#125;<br><br><span class="hljs-keyword">var</span> _ framework.PreFilterPlugin = &amp;PodTopologySpread&#123;&#125;<br><span class="hljs-keyword">var</span> _ framework.FilterPlugin = &amp;PodTopologySpread&#123;&#125;<br><span class="hljs-keyword">var</span> _ framework.PreScorePlugin = &amp;PodTopologySpread&#123;&#125;<br><span class="hljs-keyword">var</span> _ framework.ScorePlugin = &amp;PodTopologySpread&#123;&#125;<br><span class="hljs-keyword">var</span> _ framework.EnqueueExtensions = &amp;PodTopologySpread&#123;&#125;<br><br><span class="hljs-comment">// Name is the name of the plugin used in the plugin registry and configurations.</span><br><span class="hljs-keyword">const</span> Name = names.PodTopologySpread<br></code></pre></td></tr></table></figure><p>可以看到与上一次分析的亲和性调度插件类似，也是定义并实现了以下接口。</p><ul><li><strong>PreFilter</strong></li><li><strong>Filter</strong></li><li><strong>PreScore</strong></li><li><strong>Score</strong></li><li><strong>EnqueueExtensions</strong></li></ul><p>结构体中还有一些特别的额外变量，其含义如下：</p><ul><li><strong>systemDefaulted：</strong>是否使用了系统默认的拓扑约束</li><li><strong>parallelizer：</strong>一个并行处理工具</li><li><strong>defaultConstraints：</strong>默认的拓扑约束</li><li><strong>sharedLister：</strong>一个共享的列表器，它提供了对 Kubernetes 资源（如节点、Pods 等）的访问</li><li><strong>services：</strong>一个服务列表器，用于列出 Kubernetes 中的服务资源。</li><li><strong>replicationCtrls：</strong>一个副本控制器列表器，用于列出和访问 Kubernetes 中的副本控制器对象。</li><li><strong>replicaSets：</strong>一个副本集列表器，用于列出和访问 Kubernetes 中的副本集对象。</li><li><strong>statefulSets：</strong>一个有状态集列表器，用于列出和访问 Kubernetes 中的有状态集对象。</li><li><strong>enableMinDomainsInPodTopologySpread：</strong>控制是否启用 Pod 拓扑分布的最小域 <code>minDomains</code> 特性。</li><li><strong>enableNodeInclusionPolicyInPodTopologySpread：</strong>控制是否启用了节点包含策略特性，如果<strong>没有启用</strong>，那么就只考虑通过节点亲和性及node selector的node。但是<strong>如果启用了</strong>，就会根据各个拓扑约束的nodeAffinityPolicy和nodeTaintsPolicy 来考虑是否检查节点能否通过亲和性约束及node selector和节点污点特性。</li><li><strong>enableMatchLabelKeysInPodTopologySpread：</strong>控制是否启用在 Pod 拓扑分布中的<code>matchLabelKeys</code>特性。</li></ul><p>再查看其注册的事件，可以看到当<strong>pod有任何修改</strong>或者<strong>node有添加、删除、更新label的操作</strong>时，就会将调度失败的pod进行重新调度。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// EventsToRegister returns the possible events that may make a Pod</span><br><span class="hljs-comment">// failed by this plugin schedulable.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *PodTopologySpread)</span></span> EventsToRegister() []framework.ClusterEvent &#123;<br><span class="hljs-keyword">return</span> []framework.ClusterEvent&#123;<br><span class="hljs-comment">// All ActionType includes the following events:</span><br><span class="hljs-comment">// - Add. An unschedulable Pod may fail due to violating topology spread constraints,</span><br><span class="hljs-comment">// adding an assigned Pod may make it schedulable.</span><br><span class="hljs-comment">// - Update. Updating on an existing Pod&#x27;s labels (e.g., removal) may make</span><br><span class="hljs-comment">// an unschedulable Pod schedulable.</span><br><span class="hljs-comment">// - Delete. An unschedulable Pod may fail due to violating an existing Pod&#x27;s topology spread constraints,</span><br><span class="hljs-comment">// deleting an existing Pod may make it schedulable.</span><br>&#123;Resource: framework.Pod, ActionType: framework.All&#125;,<br><span class="hljs-comment">// Node add|delete|updateLabel maybe lead an topology key changed,</span><br><span class="hljs-comment">// and make these pod in scheduling schedulable or unschedulable.</span><br>&#123;Resource: framework.Node, ActionType: framework.Add | framework.Delete | framework.UpdateNodeLabel&#125;,<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>再看其初始化的构建函数<code>New</code>，如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// New initializes a new plugin and returns it.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">New</span><span class="hljs-params">(plArgs runtime.Object, h framework.Handle, fts feature.Features)</span></span> (framework.Plugin, <span class="hljs-type">error</span>) &#123;<br><span class="hljs-keyword">if</span> h.SnapshotSharedLister() == <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, fmt.Errorf(<span class="hljs-string">&quot;SnapshotSharedlister is nil&quot;</span>)<br>&#125;<br>args, err := getArgs(plArgs)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>&#125;<br><span class="hljs-keyword">if</span> err := validation.ValidatePodTopologySpreadArgs(<span class="hljs-literal">nil</span>, &amp;args); err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>&#125;<br>pl := &amp;PodTopologySpread&#123;<br>parallelizer:                        h.Parallelizer(),<br>sharedLister:                        h.SnapshotSharedLister(),<br>defaultConstraints:                  args.DefaultConstraints,<br>enableMinDomainsInPodTopologySpread: fts.EnableMinDomainsInPodTopologySpread,<br>enableNodeInclusionPolicyInPodTopologySpread: fts.EnableNodeInclusionPolicyInPodTopologySpread,<br>enableMatchLabelKeysInPodTopologySpread:      fts.EnableMatchLabelKeysInPodTopologySpread,<br>&#125;<br><span class="hljs-keyword">if</span> args.DefaultingType == config.SystemDefaulting &#123;<br>pl.defaultConstraints = systemDefaultConstraints<br>pl.systemDefaulted = <span class="hljs-literal">true</span><br>&#125;<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(pl.defaultConstraints) != <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">if</span> h.SharedInformerFactory() == <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, fmt.Errorf(<span class="hljs-string">&quot;SharedInformerFactory is nil&quot;</span>)<br>&#125;<br>pl.setListers(h.SharedInformerFactory())<br>&#125;<br><span class="hljs-keyword">return</span> pl, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><h2 id="filtering-go"><a href="#filtering-go" class="headerlink" title="filtering.go"></a>filtering.go</h2><h3 id="PreFilter"><a href="#PreFilter" class="headerlink" title="PreFilter"></a>PreFilter</h3><p>首先查看其<code>PreFilter</code>函数，如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// PreFilter invoked at the prefilter extension point.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *PodTopologySpread)</span></span> PreFilter(ctx context.Context, cycleState *framework.CycleState, pod *v1.Pod) (*framework.PreFilterResult, *framework.Status) &#123;<br>s, err := pl.calPreFilterState(ctx, pod)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, framework.AsStatus(err)<br>&#125;<br>cycleState.Write(preFilterStateKey, s)<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>再查看核心的<code>calPreFilterState</code>函数，如下，补充了部分注释。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// calPreFilterState computes preFilterState describing how pods are spread on topologies.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *PodTopologySpread)</span></span> calPreFilterState(ctx context.Context, pod *v1.Pod) (*preFilterState, <span class="hljs-type">error</span>) &#123;<br>    <span class="hljs-comment">// 获取所有节点信息的列表。</span><br>    allNodes, err := pl.sharedLister.NodeInfos().List()<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-comment">// 如果获取节点信息失败，返回错误。</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, fmt.Errorf(<span class="hljs-string">&quot;listing NodeInfos: %w&quot;</span>, err)<br>    &#125;<br><br>    <span class="hljs-keyword">var</span> constraints []topologySpreadConstraint<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(pod.Spec.TopologySpreadConstraints) &gt; <span class="hljs-number">0</span> &#123;<br>        <span class="hljs-comment">// 如果 Pod 规范中定义了拓扑分布约束，则使用这些约束。</span><br>        <span class="hljs-comment">// 由于 API 服务器中的特性门控会剥离规范，因此不需要再次检查特性门控，只需检查约束的长度。</span><br>        constraints, err = pl.filterTopologySpreadConstraints(<br>            pod.Spec.TopologySpreadConstraints, <span class="hljs-comment">// Pod 的拓扑分布约束。</span><br>            pod.Labels,                        <span class="hljs-comment">// Pod 的标签。</span><br>            v1.DoNotSchedule,                  <span class="hljs-comment">// Kubernetes 调度策略。</span><br>        )<br>        <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-comment">// 如果获取 Pod 的硬拓扑分布约束失败，返回错误。</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, fmt.Errorf(<span class="hljs-string">&quot;obtaining pod&#x27;s hard topology spread constraints: %w&quot;</span>, err)<br>        &#125;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-comment">// 如果 Pod 规范中没有定义拓扑分布约束，则构建默认的约束。</span><br>        constraints, err = pl.buildDefaultConstraints(pod, v1.DoNotSchedule)<br>        <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-comment">// 如果设置默认的硬拓扑分布约束失败，返回错误。</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, fmt.Errorf(<span class="hljs-string">&quot;setting default hard topology spread constraints: %w&quot;</span>, err)<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 如果没有拓扑分布约束，则返回一个空的 preFilterState。</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(constraints) == <span class="hljs-number">0</span> &#123;<br>        <span class="hljs-keyword">return</span> &amp;preFilterState&#123;&#125;, <span class="hljs-literal">nil</span><br>    &#125;<br><br>    <span class="hljs-comment">// 初始化 preFilterState 结构体。</span><br>    s := preFilterState&#123;<br>        Constraints:          constraints,<br>        TpKeyToCriticalPaths: <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]*criticalPaths, <span class="hljs-built_in">len</span>(constraints)),<br>        TpPairToMatchNum:     <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[topologyPair]<span class="hljs-type">int</span>, sizeHeuristic(<span class="hljs-built_in">len</span>(allNodes), constraints)),<br>    &#125;<br><br>    <span class="hljs-comment">// 创建一个切片来存储每个节点的拓扑对计数。</span><br>    tpCountsByNode := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">map</span>[topologyPair]<span class="hljs-type">int</span>, <span class="hljs-built_in">len</span>(allNodes))<br>    <span class="hljs-comment">// 获取 Pod 的必需节点亲和性。</span><br>    requiredNodeAffinity := nodeaffinity.GetRequiredNodeAffinity(pod)<br>    processNode := <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(i <span class="hljs-type">int</span>)</span></span> &#123;<br>        <span class="hljs-comment">// 对每个节点应用处理函数。</span><br>        nodeInfo := allNodes[i]<br>        node := nodeInfo.Node()<br>        <span class="hljs-keyword">if</span> node == <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-comment">// 如果节点信息为空，则记录错误并返回。</span><br>            klog.ErrorS(<span class="hljs-literal">nil</span>, <span class="hljs-string">&quot;Node not found&quot;</span>)<br>            <span class="hljs-keyword">return</span><br>        &#125;<br><br>        <span class="hljs-keyword">if</span> !pl.enableNodeInclusionPolicyInPodTopologySpread &#123;<br>            <span class="hljs-comment">// 如果没有启用节点包含策略，则只对通过选择的节点应用分布。</span><br>            <span class="hljs-comment">// 忽略解析错误以保持向后兼容性。</span><br>            <span class="hljs-keyword">if</span> match, _ := requiredNodeAffinity.Match(node); !match &#123;<br>                <span class="hljs-keyword">return</span><br>            &#125;<br>        &#125;<br><br>        <span class="hljs-comment">// 确保当前节点的标签包含所有 &#x27;Constraints&#x27; 中的拓扑键。</span><br>        <span class="hljs-keyword">if</span> !nodeLabelsMatchSpreadConstraints(node.Labels, constraints) &#123;<br>            <span class="hljs-keyword">return</span><br>        &#125;<br><br>        tpCounts := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[topologyPair]<span class="hljs-type">int</span>, <span class="hljs-built_in">len</span>(constraints))<br>        <span class="hljs-keyword">for</span> _, c := <span class="hljs-keyword">range</span> constraints &#123;<br>            <span class="hljs-comment">// 检查节点是否与包含策略匹配。</span><br>            <span class="hljs-keyword">if</span> pl.enableNodeInclusionPolicyInPodTopologySpread &amp;&amp;<br>                !c.matchNodeInclusionPolicies(pod, node, requiredNodeAffinity) &#123;<br>                <span class="hljs-keyword">continue</span><br>            &#125;<br><br>            <span class="hljs-comment">// 创建拓扑对并计算与选择器匹配的 Pod 数量。</span><br>            pair := topologyPair&#123;key: c.TopologyKey, value: node.Labels[c.TopologyKey]&#125;<br>            count := countPodsMatchSelector(nodeInfo.Pods, c.Selector, pod.Namespace)<br>            tpCounts[pair] = count<br>        &#125;<br>        <span class="hljs-comment">// 将当前节点的拓扑对计数存储到切片中。</span><br>        tpCountsByNode[i] = tpCounts<br>    &#125;<br>    <span class="hljs-comment">// 并行处理所有节点。</span><br>    pl.parallelizer.Until(ctx, <span class="hljs-built_in">len</span>(allNodes), processNode, pl.Name())<br><br>    <span class="hljs-comment">// 累加每个节点的拓扑对计数到 preFilterState。</span><br>    <span class="hljs-keyword">for</span> _, tpCounts := <span class="hljs-keyword">range</span> tpCountsByNode &#123;<br>        <span class="hljs-keyword">for</span> tp, count := <span class="hljs-keyword">range</span> tpCounts &#123;<br>            s.TpPairToMatchNum[tp] += count<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">if</span> pl.enableMinDomainsInPodTopologySpread &#123;<br>        <span class="hljs-comment">// 如果启用了最小域特性，则计算每个拓扑键的域数量。</span><br>        s.TpKeyToDomainsNum = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">int</span>, <span class="hljs-built_in">len</span>(constraints))<br>        <span class="hljs-keyword">for</span> tp := <span class="hljs-keyword">range</span> s.TpPairToMatchNum &#123;<br>            s.TpKeyToDomainsNum[tp.key]++<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 为每个拓扑键计算最小匹配数。</span><br>    <span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-built_in">len</span>(constraints); i++ &#123;<br>        key := constraints[i].TopologyKey<br>        s.TpKeyToCriticalPaths[key] = newCriticalPaths()<br>    &#125;<br>    <span class="hljs-keyword">for</span> pair, num := <span class="hljs-keyword">range</span> s.TpPairToMatchNum &#123;<br>        s.TpKeyToCriticalPaths[pair.key].update(pair.value, num)<br>    &#125;<br><br>    <span class="hljs-comment">// 返回计算出的 preFilterState。</span><br>    <span class="hljs-keyword">return</span> &amp;s, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到该函数的主要作用还是统计各个拓扑域上符合条件的pod的数量。其流程如下：</p><ol><li><p>获取所有的节点信息</p></li><li><p>查看pod是否有自定义的拓扑分布约束，如果没有就构建一个默认的约束。</p><p> 构建默认约束的函数<code>buildDefaultConstraints</code>如下，注意其输入为要调度的pod和<code>noSchedule</code>级别。</p> <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// buildDefaultConstraints builds the constraints for a pod using</span><br><span class="hljs-comment">// .DefaultConstraints and the selectors from the services, replication</span><br><span class="hljs-comment">// controllers, replica sets and stateful sets that match the pod.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *PodTopologySpread)</span></span> buildDefaultConstraints(p *v1.Pod, action v1.UnsatisfiableConstraintAction) ([]topologySpreadConstraint, <span class="hljs-type">error</span>) &#123;<br>constraints, err := pl.filterTopologySpreadConstraints(pl.defaultConstraints, p.Labels, action)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> || <span class="hljs-built_in">len</span>(constraints) == <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>&#125;<br>selector := helper.DefaultSelector(p, pl.services, pl.replicationCtrls, pl.replicaSets, pl.statefulSets)<br><span class="hljs-keyword">if</span> selector.Empty() &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, <span class="hljs-literal">nil</span><br>&#125;<br><span class="hljs-keyword">for</span> i := <span class="hljs-keyword">range</span> constraints &#123;<br>constraints[i].Selector = selector<br>&#125;<br><span class="hljs-keyword">return</span> constraints, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p> 其中主要的函数是<code>filterTopologySpreadConstraints</code>函数，其传入的是pl.defaultConstraints，如下，补充了部分注释。</p> <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// filterTopologySpreadConstraints 从 Pod 的拓扑分布约束中筛选出满足 whenUnsatisfiable 为指定 action 的约束。</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *PodTopologySpread)</span></span> filterTopologySpreadConstraints(<br>    constraints []v1.TopologySpreadConstraint,  <span class="hljs-comment">// Kubernetes v1 版本的拓扑分布约束列表。</span><br>    podLabels <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">string</span>,               <span class="hljs-comment">// Pod 的标签。</span><br>    action v1.UnsatisfiableConstraintAction,  <span class="hljs-comment">// 当约束不可满足时的动作。</span><br>) ([]topologySpreadConstraint, <span class="hljs-type">error</span>) &#123;  <span class="hljs-comment">// 返回筛选后的拓扑分布约束列表和错误（如果有的话）。</span><br><br>    <span class="hljs-keyword">var</span> result []topologySpreadConstraint  <span class="hljs-comment">// 初始化一个用于存放筛选结果的切片。</span><br>    <span class="hljs-keyword">for</span> _, c := <span class="hljs-keyword">range</span> constraints &#123;       <span class="hljs-comment">// 遍历所有的拓扑分布约束。</span><br>        <span class="hljs-keyword">if</span> c.WhenUnsatisfiable == action &#123;  <span class="hljs-comment">// 检查约束的 whenUnsatisfiable 字段是否与指定的 action 匹配。</span><br>            selector, err := metav1.LabelSelectorAsSelector(c.LabelSelector)  <span class="hljs-comment">// 将 LabelSelector 转换为 Selector。</span><br>            <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;  <span class="hljs-comment">// 如果转换出错，返回错误。</span><br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>            &#125;<br><br>            <span class="hljs-comment">// 如果启用了按标签键匹配，并且约束中定义了 MatchLabelKeys，则从 Pod 标签中提取相应的标签。</span><br>            <span class="hljs-keyword">if</span> pl.enableMatchLabelKeysInPodTopologySpread &amp;&amp; <span class="hljs-built_in">len</span>(c.MatchLabelKeys) &gt; <span class="hljs-number">0</span> &#123;<br>                matchLabels := <span class="hljs-built_in">make</span>(labels.Set)  <span class="hljs-comment">// 初始化一个标签集合。</span><br>                <span class="hljs-keyword">for</span> _, labelKey := <span class="hljs-keyword">range</span> c.MatchLabelKeys &#123;  <span class="hljs-comment">// 遍历 MatchLabelKeys。</span><br>                    <span class="hljs-keyword">if</span> value, ok := podLabels[labelKey]; ok &#123;  <span class="hljs-comment">// 如果 Pod 标签中包含该键，则添加到集合中。</span><br>                        matchLabels[labelKey] = value<br>                    &#125;<br>                &#125;<br>                <span class="hljs-comment">// 如果集合非空，则将标签集合与选择器合并。</span><br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(matchLabels) &gt; <span class="hljs-number">0</span> &#123;<br>                    selector = mergeLabelSetWithSelector(matchLabels, selector)<br>                &#125;<br>            &#125;<br><br>            <span class="hljs-comment">// 创建 topologySpreadConstraint 结构体实例，填充筛选出的约束的相关信息。</span><br>            tsc := topologySpreadConstraint&#123;<br>                MaxSkew:            c.MaxSkew,           <span class="hljs-comment">// 最大偏差数。</span><br>                TopologyKey:        c.TopologyKey,        <span class="hljs-comment">// 拓扑键。</span><br>                Selector:           selector,             <span class="hljs-comment">// 与标签匹配的选择器。</span><br>                <span class="hljs-comment">// 如果 MinDomains 为 nil，我们将其视为 1。</span><br>                MinDomains:         <span class="hljs-number">1</span>,<br>                <span class="hljs-comment">// 如果 NodeAffinityPolicy 为 nil，我们将其视为 &quot;Honor&quot;。</span><br>                NodeAffinityPolicy: v1.NodeInclusionPolicyHonor,<br>                <span class="hljs-comment">// 如果 NodeTaintsPolicy 为 nil，我们将其视为 &quot;Ignore&quot;。</span><br>                NodeTaintsPolicy:   v1.NodeInclusionPolicyIgnore,<br>            &#125;<br>            <span class="hljs-comment">// 如果启用了最小域特性，并且约束中定义了 MinDomains，则使用该值。</span><br>            <span class="hljs-keyword">if</span> pl.enableMinDomainsInPodTopologySpread &amp;&amp; c.MinDomains != <span class="hljs-literal">nil</span> &#123;<br>                tsc.MinDomains = *c.MinDomains<br>            &#125;<br>            <span class="hljs-comment">// 如果启用了节点包含策略特性，则根据约束中的设置更新 NodeAffinityPolicy 和 NodeTaintsPolicy。</span><br>            <span class="hljs-keyword">if</span> pl.enableNodeInclusionPolicyInPodTopologySpread &#123;<br>                <span class="hljs-keyword">if</span> c.NodeAffinityPolicy != <span class="hljs-literal">nil</span> &#123;<br>                    tsc.NodeAffinityPolicy = *c.NodeAffinityPolicy<br>                &#125;<br>                <span class="hljs-keyword">if</span> c.NodeTaintsPolicy != <span class="hljs-literal">nil</span> &#123;<br>                    tsc.NodeTaintsPolicy = *c.NodeTaintsPolicy<br>                &#125;<br>            &#125;<br>            <span class="hljs-comment">// 将筛选出的拓扑分布约束添加到结果切片中。</span><br>            result = <span class="hljs-built_in">append</span>(result, tsc)<br>        &#125;<br>    &#125;<br>    <span class="hljs-comment">// 返回筛选后的拓扑分布约束列表，如果没有错误发生，则返回 nil。</span><br>    <span class="hljs-keyword">return</span> result, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p> 其会遍历所有的constrain，只有满足默认的action，即v1.DoNotSchedule才会继续往下执行：</p><ol><li><p>处理pod的selector，注意到这里如果LabelKeys是enable的，会将LabelKeys中定义的label转化成selector，其方法是查看pod中该key对应的value，组成一个selector，然后调用<code>mergeLabelSetWithSelector</code>函数合并进原来的selector。如下</p> <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">mergeLabelSetWithSelector</span><span class="hljs-params">(matchLabels labels.Set, s labels.Selector)</span></span> labels.Selector &#123;<br>mergedSelector := labels.SelectorFromSet(matchLabels)<br><br>requirements, ok := s.Requirements()<br><span class="hljs-keyword">if</span> !ok &#123;<br><span class="hljs-keyword">return</span> s<br>&#125;<br><br><span class="hljs-keyword">for</span> _, r := <span class="hljs-keyword">range</span> requirements &#123;<br>mergedSelector = mergedSelector.Add(r)<br>&#125;<br><br><span class="hljs-keyword">return</span> mergedSelector<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>查看是否默认配置启用了MinDomains特性，如果是就需改MinDomains为设定值。</p></li><li><p>查看是否默认配置了节点包含策略特性，如果没有就将Pod的节点亲和性约束和节点污点特性添加进来。</p></li></ol></li><li><p>如果拓扑约束为空就直接返回，否则初始化一个preFilterState结构体。该结构体的定义如下</p></li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// preFilterState computed at PreFilter and used at Filter.</span><br><span class="hljs-comment">// It combines TpKeyToCriticalPaths and TpPairToMatchNum to represent:</span><br><span class="hljs-comment">// (1) critical paths where the least pods are matched on each spread constraint.</span><br><span class="hljs-comment">// (2) number of pods matched on each spread constraint.</span><br><span class="hljs-comment">// A nil preFilterState denotes it&#x27;s not set at all (in PreFilter phase);</span><br><span class="hljs-comment">// An empty preFilterState object denotes it&#x27;s a legit state and is set in PreFilter phase.</span><br><span class="hljs-comment">// Fields are exported for comparison during testing.</span><br><span class="hljs-keyword">type</span> preFilterState <span class="hljs-keyword">struct</span> &#123;<br>Constraints []topologySpreadConstraint<br><span class="hljs-comment">// We record 2 critical paths instead of all critical paths here.</span><br><span class="hljs-comment">// criticalPaths[0].MatchNum always holds the minimum matching number.</span><br><span class="hljs-comment">// criticalPaths[1].MatchNum is always greater or equal to criticalPaths[0].MatchNum, but</span><br><span class="hljs-comment">// it&#x27;s not guaranteed to be the 2nd minimum match number.</span><br>TpKeyToCriticalPaths <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]*criticalPaths<br><span class="hljs-comment">// TpKeyToDomainsNum is keyed with topologyKey, and valued with the number of domains.</span><br>TpKeyToDomainsNum <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">int</span><br><span class="hljs-comment">// TpPairToMatchNum is keyed with topologyPair, and valued with the number of matching pods.</span><br>TpPairToMatchNum <span class="hljs-keyword">map</span>[topologyPair]<span class="hljs-type">int</span><br>&#125;<br></code></pre></td></tr></table></figure><p>各个变量的含义参考注释如下：</p><ul><li><p><strong>Constraints：</strong>拓扑约束</p></li><li><p><strong>TpKeyToCriticalPaths：</strong>是一个map，key是拓扑键，例如Region、hostName。注意再看一下<code>criticalPaths</code>的定义，如下</p>  <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// CAVEAT: the reason that `[2]criticalPath` can work is based on the implementation of current</span><br><span class="hljs-comment">// preemption algorithm, in particular the following 2 facts:</span><br><span class="hljs-comment">// Fact 1: we only preempt pods on the same node, instead of pods on multiple nodes.</span><br><span class="hljs-comment">// Fact 2: each node is evaluated on a separate copy of the preFilterState during its preemption cycle.</span><br><span class="hljs-comment">// If we plan to turn to a more complex algorithm like &quot;arbitrary pods on multiple nodes&quot;, this</span><br><span class="hljs-comment">// structure needs to be revisited.</span><br><span class="hljs-comment">// Fields are exported for comparison during testing.</span><br><span class="hljs-comment">// 翻译：</span><br><span class="hljs-comment">// [2]criticalPath 之所以能够工作，是基于当前的抢占算法实现，特别是以下两个事实：</span><br><span class="hljs-comment">// 事实 1：我们只在同一个节点上抢占 pods，而不是在多个节点上的 pods。</span><br><span class="hljs-comment">// 事实 2：在每个节点的抢占周期中，对其评估时使用的是 preFilterState 的一个独立副本。 </span><br><span class="hljs-comment">// 如果我们计划转向更复杂的算法，如“多个节点上的任意 pods”，则需要重新审视这种结构。 </span><br><span class="hljs-comment">// 字段在测试期间被导出以供比较。</span><br><span class="hljs-keyword">type</span> criticalPaths [<span class="hljs-number">2</span>]<span class="hljs-keyword">struct</span> &#123;<br><span class="hljs-comment">// TopologyValue denotes the topology value mapping to topology key.</span><br>TopologyValue <span class="hljs-type">string</span><br><span class="hljs-comment">// MatchNum denotes the number of matching pods.</span><br>MatchNum <span class="hljs-type">int</span><br>&#125;<br></code></pre></td></tr></table></figure><p>  可以看到<code>criticalPaths</code>定义了这个拓扑键下的拓扑域中匹配的pod数量。</p><p>  而看注释可以得知<code>TpKeyToCriticalPaths[0]</code> 定义了这个域中最少匹配的pod的数量及相应的value，而<code>TpKeyToCriticalPaths[1]</code> 记录了另一个value的情况，它匹配的数量肯定不会比<code>TpKeyToCriticalPaths[0]</code> 小。</p></li><li><p><strong>TpKeyToDomainsNum：</strong>各个拓扑键下的拓扑域的数量。</p></li><li><p><strong>TpPairToMatchNum：</strong>各个拓扑域匹配的pod的数量。可以注意一下topologyPair的定义，如下：</p>  <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> topologyPair <span class="hljs-keyword">struct</span> &#123;<br>key   <span class="hljs-type">string</span><br>value <span class="hljs-type">string</span><br>&#125;<br></code></pre></td></tr></table></figure></li></ul><ol><li><p>并行遍历各个node，统计各个node上各个拓扑域中匹配到的pod的数量。其流程如下</p><ol><li><p>得到node的信息。</p></li><li><p>如果没有启用节点包含策略特性，那么就检查节点是否符合pod的节点亲和性及node selector的要求，如果不符合就直接返回，如下</p> <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Match checks whether the pod is schedulable onto nodes according to</span><br><span class="hljs-comment">// the requirements in both nodeSelector and nodeAffinity.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s RequiredNodeAffinity)</span></span> Match(node *v1.Node) (<span class="hljs-type">bool</span>, <span class="hljs-type">error</span>) &#123;<br><span class="hljs-keyword">if</span> s.labelSelector != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">if</span> !s.labelSelector.Matches(labels.Set(node.Labels)) &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>, <span class="hljs-literal">nil</span><br>&#125;<br>&#125;<br><span class="hljs-keyword">if</span> s.nodeSelector != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> s.nodeSelector.Match(node)<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>, <span class="hljs-literal">nil</span><br>&#125;<br><br></code></pre></td></tr></table></figure></li><li><p>检查当前node是否包含了约束需要的拓扑键，即是否有类似于约束要求的region的定义，如果没有就直接返回。</p></li><li><p>遍历每个拓扑约束：</p><ol><li><p>如果启用了节点包含策略特性，那么就根据配置有选择性地检查当前节点是否符合pod的节点亲和性及node selector的要求，以及是否符合节点污点及容忍的要求。如果不符合，就跳过这个拓扑约束。<code>matchNodeInclusionPolicies</code>函数如下</p> <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(tsc *topologySpreadConstraint)</span></span> matchNodeInclusionPolicies(pod *v1.Pod, node *v1.Node, require nodeaffinity.RequiredNodeAffinity) <span class="hljs-type">bool</span> &#123;<br><span class="hljs-keyword">if</span> tsc.NodeAffinityPolicy == v1.NodeInclusionPolicyHonor &#123;<br><span class="hljs-comment">// We ignore parsing errors here for backwards compatibility.</span><br><span class="hljs-keyword">if</span> match, _ := require.Match(node); !match &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>&#125;<br>&#125;<br><br><span class="hljs-keyword">if</span> tsc.NodeTaintsPolicy == v1.NodeInclusionPolicyHonor &#123;<br><span class="hljs-keyword">if</span> _, untolerated := v1helper.FindMatchingUntoleratedTaint(node.Spec.Taints, pod.Spec.Tolerations, helper.DoNotScheduleTaintsFilterFunc()); untolerated &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span><br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>计算这个node上满足selector要求的pod的数量，<code>countPodsMatchSelector</code>函数如下：</p> <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">countPodsMatchSelector</span><span class="hljs-params">(podInfos []*framework.PodInfo, selector labels.Selector, ns <span class="hljs-type">string</span>)</span></span> <span class="hljs-type">int</span> &#123;<br><span class="hljs-keyword">if</span> selector.Empty() &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>&#125;<br>count := <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> _, p := <span class="hljs-keyword">range</span> podInfos &#123;<br><span class="hljs-comment">// Bypass terminating Pod (see #87621).</span><br><span class="hljs-keyword">if</span> p.Pod.DeletionTimestamp != <span class="hljs-literal">nil</span> || p.Pod.Namespace != ns &#123;<br><span class="hljs-keyword">continue</span><br>&#125;<br><span class="hljs-keyword">if</span> selector.Matches(labels.Set(p.Pod.Labels)) &#123;<br>count++<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> count<br>&#125;<br></code></pre></td></tr></table></figure><p> 注意这里专门过来了已经删除的pod以及不和要调度的pod在同一namespace的pod。【或许未来可以考虑跨namespace的pod的拓扑约束】</p></li></ol></li><li><p>对各个拓扑域匹配的pod的数量进行记录。</p></li></ol></li><li><p>汇总统计结果，转化为记录各个拓扑域匹配的pod数量。</p></li><li><p>如果启用了<code>MinDomains</code>特性就统计各个拓扑键下拓扑值的数量。</p></li><li><p>统计各个拓扑域的最小匹配的pod数到TpKeyToCriticalPaths中，具体的更新方法如下，补充了部分注释：</p> <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p *criticalPaths)</span></span> update(tpVal <span class="hljs-type">string</span>, num <span class="hljs-type">int</span>) &#123;<br>    <span class="hljs-comment">// 首先验证 tpVal 是否已经存在于 criticalPaths 中</span><br>    i := <span class="hljs-number">-1</span> <span class="hljs-comment">// 初始化索引 i 为 -1，表示尚未找到匹配的拓扑值</span><br>    <span class="hljs-keyword">if</span> tpVal == p[<span class="hljs-number">0</span>].TopologyValue &#123;<br>        i = <span class="hljs-number">0</span> <span class="hljs-comment">// 如果 tpVal 与第一个元素的拓扑值匹配，则索引 i 设为 0</span><br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> tpVal == p[<span class="hljs-number">1</span>].TopologyValue &#123;<br>        i = <span class="hljs-number">1</span> <span class="hljs-comment">// 如果 tpVal 与第二个元素的拓扑值匹配，则索引 i 设为 1</span><br>    &#125;<br><br>    <span class="hljs-keyword">if</span> i &gt;= <span class="hljs-number">0</span> &#123;<br>        <span class="hljs-comment">// 如果索引 i 是非负的，表示找到了 tpVal</span><br>        p[i].MatchNum = num <span class="hljs-comment">// 更新找到的拓扑值对应的匹配 pods 数量</span><br>        <span class="hljs-keyword">if</span> p[<span class="hljs-number">0</span>].MatchNum &gt; p[<span class="hljs-number">1</span>].MatchNum &#123;<br>            <span class="hljs-comment">// 如果第一个路径的匹配 pods 数量大于第二个路径，</span><br>            <span class="hljs-comment">// 则交换两个路径的拓扑值和匹配数量</span><br>            p[<span class="hljs-number">0</span>], p[<span class="hljs-number">1</span>] = p[<span class="hljs-number">1</span>], p[<span class="hljs-number">0</span>]<br>        &#125;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-comment">// 如果索引 i 是 -1，表示 tpVal 在 criticalPaths 中不存在</span><br>        <span class="hljs-keyword">if</span> num &lt; p[<span class="hljs-number">0</span>].MatchNum &#123;<br>            <span class="hljs-comment">// 如果新的数量 num 小于第一个路径的匹配 pods 数量，</span><br>            <span class="hljs-comment">// 则用第一个路径的信息更新第二个路径</span><br>            p[<span class="hljs-number">1</span>] = p[<span class="hljs-number">0</span>]<br>            <span class="hljs-comment">// 然后更新第一个路径的拓扑值和匹配数量</span><br>            p[<span class="hljs-number">0</span>].TopologyValue, p[<span class="hljs-number">0</span>].MatchNum = tpVal, num<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> num &lt; p[<span class="hljs-number">1</span>].MatchNum &#123;<br>            <span class="hljs-comment">// 如果新的数量 num 小于第二个路径的匹配 pods 数量，</span><br>            <span class="hljs-comment">// 则只更新第二个路径的拓扑值和匹配数量</span><br>            p[<span class="hljs-number">1</span>].TopologyValue, p[<span class="hljs-number">1</span>].MatchNum = tpVal, num<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p> 这个方法的逻辑是，首先检查传入的拓扑键 <code>tpVal</code> 是否已经存在于 <code>criticalPaths</code> 中。如果存在，就更新对应的 <code>MatchNum</code>。如果不存在，并且新的数量 <code>num</code> 小于已有的最小数量<code>p[0].MatchNum</code>，则进行相应的更新或替换，同时把原本p[0]的内容转移到p[1]。如果num介于<code>p[0].MatchNum</code>与<code>p[1].MatchNum</code>之间就更新<code>p[1].MatchNum</code>。如此保证一般情况下p[0]是最小的，p[1]是第二小的，除非出现了传入的拓扑值 <code>tpVal</code> 是已经存在于 <code>criticalPaths</code> 中的特殊情况。</p></li></ol><h3 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h3><p><code>Filter</code>函数，如下，补充了部分注释。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Filter invoked at the filter extension point.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *PodTopologySpread)</span></span> Filter(ctx context.Context, cycleState *framework.CycleState, pod *v1.Pod, nodeInfo *framework.NodeInfo) *framework.Status &#123;<br>    node := nodeInfo.Node()<br>    <span class="hljs-keyword">if</span> node == <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-comment">// 如果节点信息为空，则返回错误状态</span><br>        <span class="hljs-keyword">return</span> framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;node not found&quot;</span>))<br>    &#125;<br><br>    s, err := getPreFilterState(cycleState)<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-comment">// 如果获取预过滤状态失败，则返回错误状态</span><br>        <span class="hljs-keyword">return</span> framework.AsStatus(err)<br>    &#125;<br><br>    <span class="hljs-comment">// 如果 preFilterState 为空，这是合法的，表示所有待调度的 Pods 都可以容忍</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(s.Constraints) == <span class="hljs-number">0</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>    &#125;<br><br>    podLabelSet := labels.Set(pod.Labels)<br>    <span class="hljs-keyword">for</span> _, c := <span class="hljs-keyword">range</span> s.Constraints &#123;<br>        tpKey := c.TopologyKey<br>        tpVal, ok := node.Labels[c.TopologyKey]<br>        <span class="hljs-keyword">if</span> !ok &#123;<br>            <span class="hljs-comment">// 如果节点缺少所需的标签，则记录日志并返回不可调度且不可解决的状态</span><br>            klog.V(<span class="hljs-number">5</span>).InfoS(<span class="hljs-string">&quot;Node doesn&#x27;t have required label&quot;</span>, <span class="hljs-string">&quot;node&quot;</span>, klog.KObj(node), <span class="hljs-string">&quot;label&quot;</span>, tpKey)<br>            <span class="hljs-keyword">return</span> framework.NewStatus(framework.UnschedulableAndUnresolvable, ErrReasonNodeLabelNotMatch)<br>        &#125;<br><br>        <span class="hljs-comment">// 得到全局最小匹配的pod数量</span><br>        minMatchNum, err := s.minMatchNum(tpKey, c.MinDomains, pl.enableMinDomainsInPodTopologySpread)<br>        <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-comment">// 如果在获取预过滤阶段预先计算的值时发生内部错误，则记录日志并继续</span><br>            klog.ErrorS(err, <span class="hljs-string">&quot;Internal error occurred while retrieving value precalculated in PreFilter&quot;</span>, <span class="hljs-string">&quot;topologyKey&quot;</span>, tpKey, <span class="hljs-string">&quot;paths&quot;</span>, s.TpKeyToCriticalPaths)<br>            <span class="hljs-keyword">continue</span><br>        &#125;<br><br>        selfMatchNum := <span class="hljs-number">0</span><br>        <span class="hljs-keyword">if</span> c.Selector.Matches(podLabelSet) &#123;<br>            <span class="hljs-comment">// 如果选择器与 Pod 的标签匹配，则自身匹配数量为 1</span><br>            selfMatchNum = <span class="hljs-number">1</span><br>        &#125;<br><br>        pair := topologyPair&#123;key: tpKey, value: tpVal&#125;<br>        matchNum := <span class="hljs-number">0</span><br>        <span class="hljs-keyword">if</span> tpCount, ok := s.TpPairToMatchNum[pair]; ok &#123;<br>            <span class="hljs-comment">// 如果找到拓扑对匹配的数量，则使用该数量</span><br>            matchNum = tpCount<br>        &#125;<br>        skew := matchNum + selfMatchNum - minMatchNum<br>        <span class="hljs-keyword">if</span> skew &gt; <span class="hljs-type">int</span>(c.MaxSkew) &#123;<br>            <span class="hljs-comment">// 如果偏差超过最大偏差，则记录日志并返回不可调度的状态</span><br>            klog.V(<span class="hljs-number">5</span>).InfoS(<span class="hljs-string">&quot;Node failed spreadConstraint: matchNum + selfMatchNum - minMatchNum &gt; maxSkew&quot;</span>, <span class="hljs-string">&quot;node&quot;</span>, klog.KObj(node), <span class="hljs-string">&quot;topologyKey&quot;</span>, tpKey, <span class="hljs-string">&quot;matchNum&quot;</span>, matchNum, <span class="hljs-string">&quot;selfMatchNum&quot;</span>, selfMatchNum, <span class="hljs-string">&quot;minMatchNum&quot;</span>, minMatchNum, <span class="hljs-string">&quot;maxSkew&quot;</span>, c.MaxSkew)<br>            <span class="hljs-keyword">return</span> framework.NewStatus(framework.Unschedulable, ErrReasonConstraintsNotMatch)<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 如果所有约束都满足，则返回 nil，表示节点通过过滤</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>这里的逻辑就比较简单了，整体流程如下。</p><ol><li>获取node信息及PreFilter的结果。</li><li>遍历处理每个拓扑约束constrain，注意这里的约束经过PreFilter筛选后都是没通过就不可以调度的硬约束。<ol><li><p>如果node没有这个约束需要查看的拓扑键就返回不通过筛选。</p></li><li><p>统计域中各个value全局最小的匹配到的node的数量<code>minMatchNum</code>，函数<code>minMatchNum</code>如下</p> <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// minMatchNum returns the global minimum for the calculation of skew while taking MinDomains into account.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *preFilterState)</span></span> minMatchNum(tpKey <span class="hljs-type">string</span>, minDomains <span class="hljs-type">int32</span>, enableMinDomainsInPodTopologySpread <span class="hljs-type">bool</span>) (<span class="hljs-type">int</span>, <span class="hljs-type">error</span>) &#123;<br>paths, ok := s.TpKeyToCriticalPaths[tpKey]<br><span class="hljs-keyword">if</span> !ok &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>, fmt.Errorf(<span class="hljs-string">&quot;failed to retrieve path by topology key&quot;</span>)<br>&#125;<br><br>minMatchNum := paths[<span class="hljs-number">0</span>].MatchNum<br><span class="hljs-keyword">if</span> !enableMinDomainsInPodTopologySpread &#123;<br><span class="hljs-keyword">return</span> minMatchNum, <span class="hljs-literal">nil</span><br>&#125;<br><br>domainsNum, ok := s.TpKeyToDomainsNum[tpKey]<br><span class="hljs-keyword">if</span> !ok &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>, fmt.Errorf(<span class="hljs-string">&quot;failed to retrieve the number of domains by topology key&quot;</span>)<br>&#125;<br><br><span class="hljs-keyword">if</span> domainsNum &lt; <span class="hljs-type">int</span>(minDomains) &#123;<br><span class="hljs-comment">// When the number of eligible domains with matching topology keys is less than `minDomains`,</span><br><span class="hljs-comment">// it treats &quot;global minimum&quot; as 0.</span><br>minMatchNum = <span class="hljs-number">0</span><br>&#125;<br><br><span class="hljs-keyword">return</span> minMatchNum, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p> 可以看到如果没有启用MinDomains特性，就直接返回最小值，如果启用了就查看这个拓扑键下拓扑值的数量，如果小于minDomains，就返回0，否则返回最小值。</p></li><li><p>如果自身也符合这个约束的label筛选要求，那么就设置<code>selfMatchNum</code>为1，否则设置为0。</p></li><li><p>得到node所在的这个拓扑域的匹配的node的数量<code>matchNum</code> </p></li><li><p>计算偏差度，即<code>skew=matchNum + selfMatchNum - minMatchNum</code></p></li><li><p>如果偏差度<code>skew</code>大于可以容忍的最大偏差MaxSkew，那么就返回不通过筛选</p></li></ol></li><li>通过了所有的约束检查，返回nil</li></ol><h2 id="Scoring-go"><a href="#Scoring-go" class="headerlink" title="Scoring.go"></a>Scoring.go</h2><h3 id="PreScore"><a href="#PreScore" class="headerlink" title="PreScore"></a>PreScore</h3><p><code>PreScore</code>函数如下，补充了部分注释</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// PreScore 在打分阶段之前构建并写入周期状态，这些状态将被 Score 和 NormalizeScore 使用。</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *PodTopologySpread)</span></span> PreScore(<br>    ctx context.Context,<br>    cycleState *framework.CycleState,<br>    pod *v1.Pod,<br>    filteredNodes []*v1.Node,<br>) *framework.Status &#123;<br>    allNodes, err := pl.sharedLister.NodeInfos().List()<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-comment">// 如果获取所有节点信息失败，则返回错误状态</span><br>        <span class="hljs-keyword">return</span> framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;getting all nodes: %w&quot;</span>, err))<br>    &#125;<br><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(filteredNodes) == <span class="hljs-number">0</span> || <span class="hljs-built_in">len</span>(allNodes) == <span class="hljs-number">0</span> &#123;<br>        <span class="hljs-comment">// 如果没有过滤后的节点或所有节点，则无需打分</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>    &#125;<br><br>    state := &amp;preScoreState&#123;<br>        IgnoredNodes:           sets.NewString(),<br>        TopologyPairToPodCounts: <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[topologyPair]*<span class="hljs-type">int64</span>),<br>    &#125;<br>    <span class="hljs-comment">// 仅在使用非系统默认的分布规则时，才要求节点拥有所有拓扑标签。</span><br>    <span class="hljs-comment">// 这允许没有区域标签的节点仍然可以进行主机名分布。</span><br>    requireAllTopologies := <span class="hljs-built_in">len</span>(pod.Spec.TopologySpreadConstraints) &gt; <span class="hljs-number">0</span> || !pl.systemDefaulted<br>    err = pl.initPreScoreState(state, pod, filteredNodes, requireAllTopologies)<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-comment">// 如果计算 preScoreState 失败，则返回错误状态</span><br>        <span class="hljs-keyword">return</span> framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;calculating preScoreState: %w&quot;</span>, err))<br>    &#125;<br><br>    <span class="hljs-comment">// 如果传入的 Pod 没有软拓扑分布约束，则返回</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(state.Constraints) == <span class="hljs-number">0</span> &#123;<br>        cycleState.Write(preScoreStateKey, state)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>    &#125;<br><br>    <span class="hljs-comment">// 为了向后兼容性，忽略解析错误。</span><br>    requiredNodeAffinity := nodeaffinity.GetRequiredNodeAffinity(pod)<br>    processAllNode := <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(i <span class="hljs-type">int</span>)</span></span> &#123;<br>        nodeInfo := allNodes[i]<br>        node := nodeInfo.Node()<br>        <span class="hljs-keyword">if</span> node == <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-keyword">return</span><br>        &#125;<br><br>        <span class="hljs-keyword">if</span> !pl.enableNodeInclusionPolicyInPodTopologySpread &#123;<br>            <span class="hljs-comment">// `node` 应该满足传入 Pod 的 NodeSelector/NodeAffinity</span><br>            <span class="hljs-keyword">if</span> match, _ := requiredNodeAffinity.Match(node); !match &#123;<br>                <span class="hljs-keyword">return</span><br>            &#125;<br>        &#125;<br><br>        <span class="hljs-comment">// 如果 requireAllTopologies 为 true，并且 `node` 缺少拓扑标签，则跳过该节点</span><br>        <span class="hljs-keyword">if</span> requireAllTopologies &amp;&amp; !nodeLabelsMatchSpreadConstraints(node.Labels, state.Constraints) &#123;<br>            <span class="hljs-keyword">return</span><br>        &#125;<br><br>        <span class="hljs-keyword">for</span> _, c := <span class="hljs-keyword">range</span> state.Constraints &#123;<br>            <span class="hljs-keyword">if</span> pl.enableNodeInclusionPolicyInPodTopologySpread &amp;&amp;<br>               !c.matchNodeInclusionPolicies(pod, node, requiredNodeAffinity) &#123;<br>                <span class="hljs-keyword">continue</span><br>            &#125;<br><br>            pair := topologyPair&#123;key: c.TopologyKey, value: node.Labels[c.TopologyKey]&#125;<br>            <span class="hljs-comment">// 如果当前拓扑对没有与任何候选节点关联，则继续以避免不必要的计算。</span><br>            <span class="hljs-comment">// 每个节点的计数也跳过，因为它们在 Score 阶段完成。</span><br>            tpCount := state.TopologyPairToPodCounts[pair]<br>            <span class="hljs-keyword">if</span> tpCount == <span class="hljs-literal">nil</span> &#123;<br>                <span class="hljs-keyword">continue</span><br>            &#125;<br>            count := countPodsMatchSelector(nodeInfo.Pods, c.Selector, pod.Namespace)<br>            <span class="hljs-comment">// 对于匹配选择器的 Pod 数量，增加拓扑对计数</span><br>            atomic.AddInt64(tpCount, <span class="hljs-type">int64</span>(count))<br>        &#125;<br>    &#125;<br>    pl.parallelizer.Until(ctx, <span class="hljs-built_in">len</span>(allNodes), processAllNode, pl.Name())<br><br>    <span class="hljs-comment">// 将 preScoreState 写入周期状态，以便后续的 Score 或 NormalizeScore 使用</span><br>    cycleState.Write(preScoreStateKey, state)<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>其流程如下：</p><ol><li><p>获取所有节点信息，检查是否有通过筛选的node，如果没有就直接返回</p></li><li><p>检查是否需要node有所有的拓扑键，如果采取的是自定义的约束或者不是系统默认的约束，就设置为必须得满足</p></li><li><p>初始化<code>preScoreState</code>变量，关键的<code>initPreScoreState</code>函数如下：</p> <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// initPreScoreState 遍历 &quot;filteredNodes&quot; 以筛选出没有所需拓扑键的节点，并初始化：</span><br><span class="hljs-comment">// 1) s.TopologyPairToPodCounts: 以合格的拓扑对和节点名称为键。</span><br><span class="hljs-comment">// 2) s.IgnoredNodes: 不应被打分的节点集合。</span><br><span class="hljs-comment">// 3) s.TopologyNormalizingWeight: 基于拓扑中值的数量，给予每个约束的权重。</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *PodTopologySpread)</span></span> initPreScoreState(s *preScoreState, pod *v1.Pod, filteredNodes []*v1.Node, requireAllTopologies <span class="hljs-type">bool</span>) <span class="hljs-type">error</span> &#123;<br>    <span class="hljs-keyword">var</span> err <span class="hljs-type">error</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(pod.Spec.TopologySpreadConstraints) &gt; <span class="hljs-number">0</span> &#123;<br>        <span class="hljs-comment">// 如果 Pod 规范中定义了拓扑分布约束，则过滤这些约束</span><br>        s.Constraints, err = pl.filterTopologySpreadConstraints(<br>            pod.Spec.TopologySpreadConstraints, <span class="hljs-comment">// Pod 的拓扑分布约束</span><br>            pod.Labels,                       <span class="hljs-comment">// Pod 的标签</span><br>            v1.ScheduleAnyway,                <span class="hljs-comment">// 调度策略</span><br>        )<br>        <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-comment">// 如果获取 Pod 的软拓扑分布约束时出错，则返回错误</span><br>            <span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;obtaining pod&#x27;s soft topology spread constraints: %w&quot;</span>, err)<br>        &#125;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-comment">// 如果 Pod 规范中没有定义拓扑分布约束，则构建默认约束</span><br>        s.Constraints, err = pl.buildDefaultConstraints(pod, v1.ScheduleAnyway)<br>        <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-comment">// 如果设置默认软拓扑分布约束时出错，则返回错误</span><br>            <span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;setting default soft topology spread constraints: %w&quot;</span>, err)<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(s.Constraints) == <span class="hljs-number">0</span> &#123;<br>        <span class="hljs-comment">// 如果没有拓扑分布约束，则不需要进一步处理，直接返回 nil</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>    &#125;<br>    topoSize := <span class="hljs-built_in">make</span>([]<span class="hljs-type">int</span>, <span class="hljs-built_in">len</span>(s.Constraints)) <span class="hljs-comment">// 为每个约束维护一个拓扑大小的切片</span><br>    <span class="hljs-keyword">for</span> _, node := <span class="hljs-keyword">range</span> filteredNodes &#123;<br>        <span class="hljs-comment">// 如果要求所有拓扑键并且节点标签不匹配分布约束，则将节点添加到忽略集合中</span><br>        <span class="hljs-keyword">if</span> requireAllTopologies &amp;&amp; !nodeLabelsMatchSpreadConstraints(node.Labels, s.Constraints) &#123;<br>            s.IgnoredNodes.Insert(node.Name)<br>            <span class="hljs-keyword">continue</span><br>        &#125;<br>        <span class="hljs-keyword">for</span> i, constraint := <span class="hljs-keyword">range</span> s.Constraints &#123;<br>            <span class="hljs-comment">// 对于每个约束，检查节点是否有相应的拓扑键</span><br>            <span class="hljs-comment">// 如果是主机名标签，则跳过，因为主机名分布独立处理</span><br>            <span class="hljs-keyword">if</span> constraint.TopologyKey == v1.LabelHostname &#123;<br>                <span class="hljs-keyword">continue</span><br>            &#125;<br>            pair := topologyPair&#123;key: constraint.TopologyKey, value: node.Labels[constraint.TopologyKey]&#125;<br>            <span class="hljs-comment">// 如果拓扑对在计数映射中不存在，则初始化它并增加相应约束的拓扑大小</span><br>            <span class="hljs-keyword">if</span> s.TopologyPairToPodCounts[pair] == <span class="hljs-literal">nil</span> &#123;<br>                s.TopologyPairToPodCounts[pair] = <span class="hljs-built_in">new</span>(<span class="hljs-type">int64</span>)<br>                topoSize[i]++<br>            &#125;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 为每个约束初始化拓扑归一化权重，基于拓扑中值的数量</span><br>    s.TopologyNormalizingWeight = <span class="hljs-built_in">make</span>([]<span class="hljs-type">float64</span>, <span class="hljs-built_in">len</span>(s.Constraints))<br>    <span class="hljs-keyword">for</span> i, c := <span class="hljs-keyword">range</span> s.Constraints &#123;<br>        sz := topoSize[i]<br>        <span class="hljs-comment">// 如果拓扑键是主机名，则使用过滤后的节点数减去忽略的节点数作为大小</span><br>        <span class="hljs-keyword">if</span> c.TopologyKey == v1.LabelHostname &#123;<br>            sz = <span class="hljs-built_in">len</span>(filteredNodes) - <span class="hljs-built_in">len</span>(s.IgnoredNodes)<br>        &#125;<br>        <span class="hljs-comment">// 计算并设置拓扑归一化权重</span><br>        s.TopologyNormalizingWeight[i] = topologyNormalizingWeight(sz)<br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p> 其运行流程如下</p><ol><li>查看pod是否有拓扑约束，如果有就读取，如果没有就创建一个系统默认的的拓扑约束，与PreFilter类似。</li><li>如果拓扑约束为空直接返回nil</li><li>开始遍历筛选过后的node<ol><li><p>如果需要检查是否包含所有的拓扑键，但是node没有全部的拓扑键，那么就将这个node加入到<code>IgnoredNodes</code>中，然后跳过这个node</p></li><li><p>遍历所有的拓扑约束：</p><ol><li>如果拓扑约束的拓扑键是<code>hostName</code>那么就跳过，因为其后面会特殊处理</li><li>查看是否在之前统计了这个node上对应的拓扑键-拓扑值，如果没有就加入，然后这个拓扑约束的<code>topoSize+1</code> 。故最后<code>topoSize</code>会记录各个拓扑约束中拓扑键对应的拓扑值的个数。</li></ol></li><li><p>计算各个拓扑约束的权重，也需要遍历所有的拓扑约束</p><ol><li>得到这个拓扑约束中<code>topoSize</code> 的值</li><li>如果拓扑约束的拓扑键是<code>hostName</code>，那么就将<code>topoSize</code> 设置为<code>len(filteredNodes) - len(s.IgnoredNodes)</code> ，即不能被忽略的node的个数</li><li>计算这个拓扑约束的权重，计算函数<code>topologyNormalizingWeight</code>如下</li></ol> <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// topologyNormalizingWeight calculates the weight for the topology, based on</span><br><span class="hljs-comment">// the number of values that exist for a topology.</span><br><span class="hljs-comment">// Since &lt;size&gt; is at least 1 (all nodes that passed the Filters are in the</span><br><span class="hljs-comment">// same topology), and k8s supports 5k nodes, the result is in the interval</span><br><span class="hljs-comment">// &lt;1.09, 8.52&gt;.</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">// Note: &lt;size&gt; could also be zero when no nodes have the required topologies,</span><br><span class="hljs-comment">// however we don&#x27;t care about topology weight in this case as we return a 0</span><br><span class="hljs-comment">// score for all nodes.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">topologyNormalizingWeight</span><span class="hljs-params">(size <span class="hljs-type">int</span>)</span></span> <span class="hljs-type">float64</span> &#123;<br><span class="hljs-keyword">return</span> math.Log(<span class="hljs-type">float64</span>(size + <span class="hljs-number">2</span>))<br>&#125;<br></code></pre></td></tr></table></figure><p> 权重即为<code>ln(topoSize+2)</code> ，即拓扑键对应的拓扑值种类越多，权重就越大，一般而言肯定是<code>hostName</code>这种拓扑键的约束权重最大了。</p></li></ol></li></ol></li><li><p>如果权重不为空就将权重写入到<code>cycleState</code>中</p></li><li><p>得到要调度的pod的node亲和性</p></li><li><p>并行遍历各个node，流程如下</p><ol><li>得到node的信息</li><li>与PreFilter类似，如果没有启用节点包含策略，就检查是否通过了node亲和性及node selector的约束，如果没有直接返回</li><li>如果需要node有所有的拓扑键，但是node没有，那么也会直接返回</li><li>遍历每个拓扑约束，流程如下<ol><li><p>如果启用了节点包含策略特性，那么就根据配置有选择性地检查当前节点是否符合pod的节点亲和性及node selector的要求，以及是否符合节点污点及容忍的要求。如果不符合，就跳过这个拓扑约束。</p></li><li><p>如果拓扑键是hostName，也直接跳过（后面在<code>Score</code>时再计算）</p></li><li><p>计算这个拓扑约束的拓扑键对应的拓扑域上相匹配的pod的个数</p> <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">countPodsMatchSelector</span><span class="hljs-params">(podInfos []*framework.PodInfo, selector labels.Selector, ns <span class="hljs-type">string</span>)</span></span> <span class="hljs-type">int</span> &#123;<br><span class="hljs-keyword">if</span> selector.Empty() &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>&#125;<br>count := <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> _, p := <span class="hljs-keyword">range</span> podInfos &#123;<br><span class="hljs-comment">// Bypass terminating Pod (see #87621).</span><br><span class="hljs-keyword">if</span> p.Pod.DeletionTimestamp != <span class="hljs-literal">nil</span> || p.Pod.Namespace != ns &#123;<br><span class="hljs-keyword">continue</span><br>&#125;<br><span class="hljs-keyword">if</span> selector.Matches(labels.Set(p.Pod.Labels)) &#123;<br>count++<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> count<br>&#125;<br><br></code></pre></td></tr></table></figure></li></ol></li></ol></li><li><p>将结果写入到<code>cycleState</code>中，与PreFilter基本是一样的操作，最后得到是各个各个拓扑域对应的匹配的pod的数量</p></li></ol><h3 id="Score"><a href="#Score" class="headerlink" title="Score"></a>Score</h3><p>代码如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Score invoked at the Score extension point.</span><br><span class="hljs-comment">// The &quot;score&quot; returned in this function is the matching number of pods on the `nodeName`,</span><br><span class="hljs-comment">// it is normalized later.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *PodTopologySpread)</span></span> Score(ctx context.Context, cycleState *framework.CycleState, pod *v1.Pod, nodeName <span class="hljs-type">string</span>) (<span class="hljs-type">int64</span>, *framework.Status) &#123;<br>nodeInfo, err := pl.sharedLister.NodeInfos().Get(nodeName)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>, framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;getting node %q from Snapshot: %w&quot;</span>, nodeName, err))<br>&#125;<br><br>node := nodeInfo.Node()<br>s, err := getPreScoreState(cycleState)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>, framework.AsStatus(err)<br>&#125;<br><br><span class="hljs-comment">// Return if the node is not qualified.</span><br><span class="hljs-keyword">if</span> s.IgnoredNodes.Has(node.Name) &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>, <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-comment">// For each present &lt;pair&gt;, current node gets a credit of &lt;matchSum&gt;.</span><br><span class="hljs-comment">// And we sum up &lt;matchSum&gt; and return it as this node&#x27;s score.</span><br><span class="hljs-keyword">var</span> score <span class="hljs-type">float64</span><br><span class="hljs-keyword">for</span> i, c := <span class="hljs-keyword">range</span> s.Constraints &#123;<br><span class="hljs-keyword">if</span> tpVal, ok := node.Labels[c.TopologyKey]; ok &#123;<br><span class="hljs-keyword">var</span> cnt <span class="hljs-type">int64</span><br><span class="hljs-keyword">if</span> c.TopologyKey == v1.LabelHostname &#123;<br>cnt = <span class="hljs-type">int64</span>(countPodsMatchSelector(nodeInfo.Pods, c.Selector, pod.Namespace))<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>pair := topologyPair&#123;key: c.TopologyKey, value: tpVal&#125;<br>cnt = *s.TopologyPairToPodCounts[pair]<br>&#125;<br>score += scoreForCount(cnt, c.MaxSkew, s.TopologyNormalizingWeight[i])<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-type">int64</span>(math.Round(score)), <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>其流程比较简明，如下</p><ol><li><p>得到node的信息即PreScore的结果</p></li><li><p>如果node在没通过筛选需要被忽略的node，即<code>IgnoredNodes</code>中，那么返回分数为0</p></li><li><p>遍历各个拓扑约束，计算分数</p><ol><li><p>得到这个node对应在这个拓扑约束的拓扑键中的拓扑域</p></li><li><p>如果这个拓扑约束的拓扑键是hostName是hostName，那么就调用<code>countPodsMatchSelector</code>计算这个node上匹配的pod数量<code>cnt</code>，不然就从PreScore的结果中得到对应的拓扑域上匹配的pod数量<code>cnt</code></p></li><li><p>调用scoreForCount对当前的拓扑约束进行分数计算</p> <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// scoreForCount calculates the score based on number of matching pods in a</span><br><span class="hljs-comment">// topology domain, the constraint&#x27;s maxSkew and the topology weight.</span><br><span class="hljs-comment">// `maxSkew-1` is added to the score so that differences between topology</span><br><span class="hljs-comment">// domains get watered down, controlling the tolerance of the score to skews.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">scoreForCount</span><span class="hljs-params">(cnt <span class="hljs-type">int64</span>, maxSkew <span class="hljs-type">int32</span>, tpWeight <span class="hljs-type">float64</span>)</span></span> <span class="hljs-type">float64</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-type">float64</span>(cnt)*tpWeight + <span class="hljs-type">float64</span>(maxSkew<span class="hljs-number">-1</span>)<br>&#125;<br></code></pre></td></tr></table></figure><p> 计算方式为<code>cnt*拓扑约束的权重+maxSkew-1</code> 。【至于为什么要这样打分暂时也没想清楚】</p></li></ol></li><li><p>最终得到了各个拓扑约束下的总分，并返回</p></li></ol><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><a href="https://docs.youdianzhishi.com/k8s/scheduler/topology/">Pod 拓扑分布约束</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>k8s</category>
      
      <category>源码分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>k8s</tag>
      
      <tag>源码分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【K8s源码分析（五）】-K8s中Pod亲和性调度插件介绍</title>
    <link href="/2024/05/11/k8sSource5/"/>
    <url>/2024/05/11/k8sSource5/</url>
    
    <content type="html"><![CDATA[<p>本次分析参考的K8s版本是<a href="https://github.com/kubernetes/kubernetes/tree/release-1.27">v1.27.0</a>。</p><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>K8s调度器v1版的的默认的插件都在<code>pkg/scheduler/apis/config/v1/default_plugins.go:30</code> 中，如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// getDefaultPlugins returns the default set of plugins.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">getDefaultPlugins</span><span class="hljs-params">()</span></span> *v1.Plugins &#123;<br>plugins := &amp;v1.Plugins&#123;<br>MultiPoint: v1.PluginSet&#123;<br>Enabled: []v1.Plugin&#123;<br>&#123;Name: names.PrioritySort&#125;,<br>&#123;Name: names.NodeUnschedulable&#125;,<br>&#123;Name: names.NodeName&#125;,<br>&#123;Name: names.TaintToleration, Weight: pointer.Int32(<span class="hljs-number">3</span>)&#125;,<br>&#123;Name: names.NodeAffinity, Weight: pointer.Int32(<span class="hljs-number">2</span>)&#125;,<br>&#123;Name: names.NodePorts&#125;,<br>&#123;Name: names.NodeResourcesFit, Weight: pointer.Int32(<span class="hljs-number">1</span>)&#125;,<br>&#123;Name: names.VolumeRestrictions&#125;,<br>&#123;Name: names.EBSLimits&#125;,<br>&#123;Name: names.GCEPDLimits&#125;,<br>&#123;Name: names.NodeVolumeLimits&#125;,<br>&#123;Name: names.AzureDiskLimits&#125;,<br>&#123;Name: names.VolumeBinding&#125;,<br>&#123;Name: names.VolumeZone&#125;,<br>&#123;Name: names.PodTopologySpread, Weight: pointer.Int32(<span class="hljs-number">2</span>)&#125;,<br>&#123;Name: names.InterPodAffinity, Weight: pointer.Int32(<span class="hljs-number">2</span>)&#125;,<br>&#123;Name: names.DefaultPreemption&#125;,<br>&#123;Name: names.NodeResourcesBalancedAllocation, Weight: pointer.Int32(<span class="hljs-number">1</span>)&#125;,<br>&#123;Name: names.ImageLocality, Weight: pointer.Int32(<span class="hljs-number">1</span>)&#125;,<br>&#123;Name: names.DefaultBinder&#125;,<br>&#125;,<br>&#125;,<br>&#125;<br>applyFeatureGates(plugins)<br><br><span class="hljs-keyword">return</span> plugins<br>&#125;<br></code></pre></td></tr></table></figure><p>而本次我们主要关注的是<code>InterPodAffinity</code>插件，也就是pod的亲和性调度插件，此处是官方对其的介绍：<a href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity">Pod 间亲和性和反亲和性</a></p><p>在 Kubernetes 中，Pod 亲和性（Pod Affinity）是一种特性，它允许根据特定的规则来约束 Pod 可以调度的节点。使用 Pod 亲和性就可以控制 Pod 应该（或不应该）与某些其他 Pod 在同一个域内运行。这在需要一组 Pod 彼此靠近以优化网络通信或共享资源时非常有用。</p><p>Pod 亲和性分为两种类型：</p><ol><li><strong>Pod 亲和性（Pod Affinity）</strong>：定义了 Pod 应该与具有某些特定标签的 Pod 调度在同一域内。</li><li><strong>Pod 反亲和性（Pod Anti-Affinity）</strong>：定义了 Pod 不应该与具有某些特定标签的 Pod 调度在同一域内。</li></ol><p>注意如果当前正在调度的 Pod 是与其自身具有亲和性的系列中的第一个，则在通过所有其他亲和性检查后允许对其进行调度。这是通过验证集群中没有其他 pod 与该 pod 的命名空间和选择器匹配、该 pod 与其自己的术语匹配以及所选节点与所有请求的拓扑匹配来确定的。这可以确保即使所有 Pod 都指定了 Pod 间关联性，也不会出现死锁。</p><h2 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a>使用示例</h2><p>我们现在首先定义一个基准Pod，名为<code>pod-podaffinity-target</code>，定义了它的label为<code>&#123;podenv: pro&#125;</code>并指定它必须放在node1上。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">pod-podaffinity-target</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">dev</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">podenv:</span> <span class="hljs-string">pro</span> <span class="hljs-comment">#设置标签</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">containers:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">nginx</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">nginx:1.17.1</span><br>  <span class="hljs-attr">nodeName:</span> <span class="hljs-string">node1</span> <span class="hljs-comment"># 将目标pod名确指定到node1上</span><br></code></pre></td></tr></table></figure><p>创建完这个Pod之后，我们再定义一个pod，名为<code>pod-podaffinity-target</code>，这个pod与<code>pod-podaffinity-target</code>具有亲和性要求，定义的域为<code>kubernetes.io/hostname</code>，即需要在同一个node上，配置文件如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">pod-podaffinity-required</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">dev</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">containers:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">nginx</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">nginx:1.17.1</span><br>  <span class="hljs-attr">affinity:</span>  <span class="hljs-comment">#亲和性设置</span><br>    <span class="hljs-attr">podAffinity:</span> <span class="hljs-comment">#设置pod亲和性</span><br>      <span class="hljs-attr">requiredDuringSchedulingIgnoredDuringExecution:</span> <span class="hljs-comment"># 硬限制</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">labelSelector:</span><br>          <span class="hljs-attr">matchExpressions:</span> <span class="hljs-comment"># 匹配env的值在[&quot;xxx&quot;]中的标签</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">podenv</span><br>            <span class="hljs-attr">operator:</span> <span class="hljs-string">In</span><br>            <span class="hljs-attr">values:</span> [<span class="hljs-string">&quot;pro&quot;</span>]<br>        <span class="hljs-attr">namespaces:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-string">dev</span><br>        <span class="hljs-attr">namespaceSelector:</span><br>          <span class="hljs-attr">matchLabels:</span><br>            <span class="hljs-attr">environment:</span> <span class="hljs-string">production</span><br>        <span class="hljs-attr">topologyKey:</span> <span class="hljs-string">kubernetes.io/hostname</span><br></code></pre></td></tr></table></figure><p>然后我们再定义一个pod，名为<code>pod-podantiaffinity-required</code>，这个pod与<code>pod-podaffinity-target</code>具有反亲和性要求，定义的域为<code>kubernetes.io/hostname</code>，即不能在同一个node上运行，配置文件如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">pod-podantiaffinity-required</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">dev</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">containers:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">nginx</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">nginx:1.17.1</span><br>  <span class="hljs-attr">affinity:</span>  <span class="hljs-comment">#亲和性设置</span><br>    <span class="hljs-attr">podAntiAffinity:</span> <span class="hljs-comment">#设置pod亲和性</span><br>      <span class="hljs-attr">requiredDuringSchedulingIgnoredDuringExecution:</span> <span class="hljs-comment"># 硬限制</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">labelSelector:</span><br>          <span class="hljs-attr">matchExpressions:</span> <span class="hljs-comment"># 匹配podenv的值在[&quot;pro&quot;]中的标签</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">podenv</span><br>            <span class="hljs-attr">operator:</span> <span class="hljs-string">In</span><br>            <span class="hljs-attr">values:</span> [<span class="hljs-string">&quot;pro&quot;</span>]<br>        <span class="hljs-attr">namespaces:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-string">dev</span><br>        <span class="hljs-attr">namespaceSelector:</span><br>          <span class="hljs-attr">matchLabels:</span><br>            <span class="hljs-attr">environment:</span> <span class="hljs-string">production</span><br>        <span class="hljs-attr">topologyKey:</span> <span class="hljs-string">kubernetes.io/hostname</span><br></code></pre></td></tr></table></figure><p>全部运行后，得到的所有pod如下，可以看到pod-podaffinity-required 与pod-podaffinity-target 都部署到了node1上，而pod-podantiaffinity-required没有与pod-podaffinity-target 部署在同一个节点上，而是部署在了master节点上。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># kubectl get po -n dev -o wide</span><br>NAME                           READY   STATUS    RESTARTS   AGE    IP                NODE     NOMINATED NODE   READINESS GATES<br>pod-podaffinity-required       1/1     Running   0          98s    192.168.166.169   node1    &lt;none&gt;           &lt;none&gt;<br>pod-podaffinity-target         1/1     Running   0          2m6s   192.168.166.166   node1    &lt;none&gt;           &lt;none&gt;<br>pod-podantiaffinity-required   1/1     Running   0          87s    192.168.219.106   master   &lt;none&gt;           &lt;none&gt;<br></code></pre></td></tr></table></figure><h2 id="亲和性细节介绍"><a href="#亲和性细节介绍" class="headerlink" title="亲和性细节介绍"></a>亲和性细节介绍</h2><p>下面整体介绍一下配置亲和性关系时的一些细节。</p><p>在<code>affinity</code>字段下面需要设置亲和性类型，类型有<code>nodeAffinity</code>、<code>nodeAntiAffinity</code>和<code>podAffinity</code> 、<code>podAntiAffinity</code>，而此次介绍的是<code>podAffinity</code>和<code>podAntiAffinity</code> 。</p><p>在<code>podAffinity</code> 和<code>podAntiAffinity</code>下面就需要指定各个级别限制的内容，限制的级别有：</p><ul><li><code>requiredDuringSchedulingIgnoredDuringExecution</code> :在调度时必须要满足亲和性要求，但是在运行过程中可以无视亲和性要求</li><li><code>preferredDuringSchedulingIgnoredDuringExecution</code> :其配置的亲和性要求是优选的，但不一定必须满足。在运行过程中也是可以无视。</li></ul><p><em>看名字K8s应该有准备在后面加入在运行过程中有变化时也得遵循的亲和性要求，但是目前还没有支持，可以后续期待一下。</em></p><p>每个限制级别下面就有各个选择器，用来选择检查和哪些pod的亲和性关系，亲和性粒度怎么样。主要有：</p><ul><li><strong>labelSelector</strong>：根据label来筛选的pod进行亲和性检查。</li><li><strong>namespaces：</strong>直接规定亲和性要求所适用的namespace名字，不标注或值为[] 则表示只在此pod所对应的namespace中生效。</li><li><strong>namespaceSelector：</strong>根据标签查询来规定亲和性要求所适用的namespace，和namespaces是或的关系，namespace只需要满足两者其一就可以了。值为{}表示适用于所有namespace ，值为null或不标注着表示只在此pod所对应的namespace中生效。</li><li><strong>topologyKey</strong>：确定亲和性处理的范围，<code>kubernetes.io/hostname</code>就代表不能在同一个主机上，还有其他的key，例如：<code>topology.kubernetes.io/zone</code>、<code>topology.kubernetes.io/region</code>、<code>topology.kubernetes.io/os</code>、<code>topology.kubernetes.io/architecture</code>等，也可以自行定义。</li><li><strong>matchLabelKeys、mismatchLabelKeys（在v1.29均为alpha阶段，高于本次讨论版本）：</strong>主要就是通过label的key值来确定要（或不要）使用的pod</li></ul><h1 id="亲和性调度插件代码分析"><a href="#亲和性调度插件代码分析" class="headerlink" title="亲和性调度插件代码分析"></a>亲和性调度插件代码分析</h1><p>亲和性调度插件的代码在<code>pkg/scheduler/framework/plugins/interpodaffinity</code> 文件夹下面，其文件包含如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">interpodaffinity/<br>├── filtering.go<br>├── filtering_test.go<br>├── plugin.go<br>├── plugin_test.go<br>├── scoring.go<br>└── scoring_test.go<br></code></pre></td></tr></table></figure><h2 id="plugin-go文件"><a href="#plugin-go文件" class="headerlink" title="plugin.go文件"></a>plugin.go文件</h2><p>首先查看其一开始部分的代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Name is the name of the plugin used in the plugin registry and configurations.</span><br><span class="hljs-keyword">const</span> Name = names.InterPodAffinity<br><br><span class="hljs-keyword">var</span> _ framework.PreFilterPlugin = &amp;InterPodAffinity&#123;&#125;<br><span class="hljs-keyword">var</span> _ framework.FilterPlugin = &amp;InterPodAffinity&#123;&#125;<br><span class="hljs-keyword">var</span> _ framework.PreScorePlugin = &amp;InterPodAffinity&#123;&#125;<br><span class="hljs-keyword">var</span> _ framework.ScorePlugin = &amp;InterPodAffinity&#123;&#125;<br><span class="hljs-keyword">var</span> _ framework.EnqueueExtensions = &amp;InterPodAffinity&#123;&#125;<br><br><span class="hljs-comment">// InterPodAffinity is a plugin that checks inter pod affinity</span><br><span class="hljs-keyword">type</span> InterPodAffinity <span class="hljs-keyword">struct</span> &#123;<br>parallelizer parallelize.Parallelizer<br>args         config.InterPodAffinityArgs<br>sharedLister framework.SharedLister<br>nsLister     listersv1.NamespaceLister<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到它定义了自己的名字，然后检查了自己是否实现了以下插件的接口：</p><ul><li><strong>PreFilter</strong></li><li><strong>Filter</strong></li><li><strong>PreScore</strong></li><li><strong>Score</strong></li><li><strong>EnqueueExtensions</strong></li></ul><p>然后看到其自身额外需要的变量也不多，各个需要的变量的含义如下：</p><ol><li><strong>parallelizer</strong>:<ul><li>类型：<code>parallelize.Parallelizer</code></li><li>用途：<code>Parallelizer</code> 是一个并行处理工具，它允许调度框架并行地执行某些操作，例如并行地对多个节点进行过滤或打分。这样可以提高调度的效率。</li></ul></li><li><strong>args</strong>:<ul><li>类型：<code>config.InterPodAffinityArgs</code></li><li>用途：<code>args</code> 存储了初始化插件时所需的参数。在 <code>InterPodAffinity</code> 的上下文中，<code>config.InterPodAffinityArgs</code> 可能包含与 Pod 亲和性相关的配置，如默认的命名空间选择行为或其他与亲和性规则相关的设置。</li></ul></li><li><strong>sharedLister</strong>:<ul><li>类型：<code>framework.SharedLister</code></li><li>用途：<code>sharedLister</code> 是一个共享的列表器（Lister），它提供了对 Kubernetes 资源的访问，如 Pods、Nodes 等。这个列表器允许插件在调度决策过程中获取当前集群状态的视图。</li></ul></li><li><strong>nsLister</strong>:<ul><li>类型：<code>listersv1.NamespaceLister</code></li><li>用途：<code>nsLister</code> 是一个专门用于命名空间（Namespace）的列表器。它允许插件获取关于 Kubernetes 命名空间的信息，这在处理跨命名空间的亲和性规则时非常有用。</li></ul></li></ol><p>注意到<code>EnqueueExtensions</code>的接口定义如下，即希望对于所有会让pod失败的插件都定义一个<code>EventsToRegister</code>函数，来让系统知道何时可以产生一个事件让失败的pod重新调度。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// EnqueueExtensions is an optional interface that plugins can implement to efficiently</span><br><span class="hljs-comment">// move unschedulable Pods in internal scheduling queues. Plugins</span><br><span class="hljs-comment">// that fail pod scheduling (e.g., Filter plugins) are expected to implement this interface.</span><br><span class="hljs-keyword">type</span> EnqueueExtensions <span class="hljs-keyword">interface</span> &#123;<br><span class="hljs-comment">// EventsToRegister returns a series of possible events that may cause a Pod</span><br><span class="hljs-comment">// failed by this plugin schedulable.</span><br><span class="hljs-comment">// The events will be registered when instantiating the internal scheduling queue,</span><br><span class="hljs-comment">// and leveraged to build event handlers dynamically.</span><br><span class="hljs-comment">// Note: the returned list needs to be static (not depend on configuration parameters);</span><br><span class="hljs-comment">// otherwise it would lead to undefined behavior.</span><br>EventsToRegister() []ClusterEvent<br>&#125;<br></code></pre></td></tr></table></figure><p>再查看该插件定义的<code>EventsToRegister</code>函数，可以看到如果使用这个插件，那么如果pod或者Node有添加、删除、label更新等操作都会触发事件，使得将失败的pod进行移入到activeQ或backOffQ中，详见之前的对调度队列的介绍：<a href="https://slipegg.github.io/2024/05/10/k8sSource2/">K8s源码分析（二）-K8s调度队列介绍</a></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// EventsToRegister returns the possible events that may make a failed Pod</span><br><span class="hljs-comment">// schedulable</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *InterPodAffinity)</span></span> EventsToRegister() []framework.ClusterEvent &#123;<br><span class="hljs-keyword">return</span> []framework.ClusterEvent&#123;<br><span class="hljs-comment">// All ActionType includes the following events:</span><br><span class="hljs-comment">// - Delete. An unschedulable Pod may fail due to violating an existing Pod&#x27;s anti-affinity constraints,</span><br><span class="hljs-comment">// deleting an existing Pod may make it schedulable.</span><br><span class="hljs-comment">// - Update. Updating on an existing Pod&#x27;s labels (e.g., removal) may make</span><br><span class="hljs-comment">// an unschedulable Pod schedulable.</span><br><span class="hljs-comment">// - Add. An unschedulable Pod may fail due to violating pod-affinity constraints,</span><br><span class="hljs-comment">// adding an assigned Pod may make it schedulable.</span><br>&#123;Resource: framework.Pod, ActionType: framework.All&#125;,<br>&#123;Resource: framework.Node, ActionType: framework.Add | framework.UpdateNodeLabel&#125;,<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>再查看其定义的初始化代码New，如下。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// New initializes a new plugin and returns it.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">New</span><span class="hljs-params">(plArgs runtime.Object, h framework.Handle)</span></span> (framework.Plugin, <span class="hljs-type">error</span>) &#123;<br><span class="hljs-keyword">if</span> h.SnapshotSharedLister() == <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, fmt.Errorf(<span class="hljs-string">&quot;SnapshotSharedlister is nil&quot;</span>)<br>&#125;<br>args, err := getArgs(plArgs)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>&#125;<br><span class="hljs-keyword">if</span> err := validation.ValidateInterPodAffinityArgs(<span class="hljs-literal">nil</span>, &amp;args); err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>&#125;<br>pl := &amp;InterPodAffinity&#123;<br>parallelizer: h.Parallelizer(),<br>args:         args,<br>sharedLister: h.SnapshotSharedLister(),<br>nsLister:     h.SharedInformerFactory().Core().V1().Namespaces().Lister(),<br>&#125;<br><br><span class="hljs-keyword">return</span> pl, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><h2 id="filtering-go"><a href="#filtering-go" class="headerlink" title="filtering.go"></a>filtering.go</h2><p>filter筛选时都是根据硬约束，即<code>requiredDuringSchedulingIgnoredDuringExecution</code> 的要求来进行筛选。其代码在<code>pkg/scheduler/framework/plugins/interpodaffinity/filtering.go</code>中。</p><h3 id="PreFilter"><a href="#PreFilter" class="headerlink" title="PreFilter"></a>PreFilter</h3><p>其代码如下，补充了部分注释。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// PreFilter invoked at the prefilter extension point.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *InterPodAffinity)</span></span> PreFilter(ctx context.Context, cycleState *framework.CycleState, pod *v1.Pod) (*framework.PreFilterResult, *framework.Status) &#123;<br>    <span class="hljs-comment">// 定义几个变量，用于存储所有节点信息和具有必需的反亲和性 Pod 的节点信息</span><br>    <span class="hljs-keyword">var</span> allNodes []*framework.NodeInfo<br>    <span class="hljs-keyword">var</span> nodesWithRequiredAntiAffinityPods []*framework.NodeInfo<br>    <span class="hljs-keyword">var</span> err <span class="hljs-type">error</span><br>    <br>    <span class="hljs-comment">// 获取所有节点信息</span><br>    <span class="hljs-keyword">if</span> allNodes, err = pl.sharedLister.NodeInfos().List(); err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;failed to list NodeInfos: %w&quot;</span>, err))<br>    &#125;<br>    <span class="hljs-comment">// 获取具有必需的反亲和性 Pod 的节点列表</span><br>    <span class="hljs-keyword">if</span> nodesWithRequiredAntiAffinityPods, err = pl.sharedLister.NodeInfos().HavePodsWithRequiredAntiAffinityList(); err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;failed to list NodeInfos with pods with affinity: %w&quot;</span>, err))<br>    &#125;<br><br>    <span class="hljs-comment">// 初始化预过滤状态</span><br>    s := &amp;preFilterState&#123;&#125;<br><br>    <span class="hljs-comment">// 从 Pod 中解析 Pod 信息</span><br>    <span class="hljs-keyword">if</span> s.podInfo, err = framework.NewPodInfo(pod); err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, framework.NewStatus(framework.UnschedulableAndUnresolvable, fmt.Sprintf(<span class="hljs-string">&quot;parsing pod: %+v&quot;</span>, err))<br>    &#125;<br><br>    <span class="hljs-comment">// 处理 Pod 亲和性项的命名空间</span><br>    <span class="hljs-keyword">for</span> i := <span class="hljs-keyword">range</span> s.podInfo.RequiredAffinityTerms &#123;<br>        <span class="hljs-keyword">if</span> err := pl.mergeAffinityTermNamespacesIfNotEmpty(&amp;s.podInfo.RequiredAffinityTerms[i]); err != <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, framework.AsStatus(err)<br>        &#125;<br>    &#125;<br>    <span class="hljs-comment">// 处理 Pod 反亲和性项的命名空间</span><br>    <span class="hljs-keyword">for</span> i := <span class="hljs-keyword">range</span> s.podInfo.RequiredAntiAffinityTerms &#123;<br>        <span class="hljs-keyword">if</span> err := pl.mergeAffinityTermNamespacesIfNotEmpty(&amp;s.podInfo.RequiredAntiAffinityTerms[i]); err != <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, framework.AsStatus(err)<br>        &#125;<br>    &#125;<br>    <span class="hljs-comment">// 获取命名空间标签的快照</span><br>    s.namespaceLabels = GetNamespaceLabelsSnapshot(pod.Namespace, pl.nsLister)<br><br>    <span class="hljs-comment">// 获取现有反亲和性计数</span><br>    s.existingAntiAffinityCounts = pl.getExistingAntiAffinityCounts(ctx, pod, s.namespaceLabels, nodesWithRequiredAntiAffinityPods)<br>    <span class="hljs-comment">// 获取即将到来的亲和性和反亲和性计数</span><br>    s.affinityCounts, s.antiAffinityCounts = pl.getIncomingAffinityAntiAffinityCounts(ctx, s.podInfo, allNodes)<br><br>    <span class="hljs-comment">// 如果没有现有的反亲和性计数，并且 Pod 没有必需的亲和性或反亲和性项，则跳过</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(s.existingAntiAffinityCounts) == <span class="hljs-number">0</span> &amp;&amp; <span class="hljs-built_in">len</span>(s.podInfo.RequiredAffinityTerms) == <span class="hljs-number">0</span> &amp;&amp; <span class="hljs-built_in">len</span>(s.podInfo.RequiredAntiAffinityTerms) == <span class="hljs-number">0</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, framework.NewStatus(framework.Skip)<br>    &#125;<br><br>    <span class="hljs-comment">// 将预过滤状态写入周期状态</span><br>    cycleState.Write(preFilterStateKey, s)<br>    <span class="hljs-comment">// 函数返回 nil，表示不需要进一步处理</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>下面具体来分析一下这部分代码。</p><ol><li><p>获取了所有节点信息</p></li><li><p>获取了所有拥有反亲和性 Pod 的节点列表</p></li><li><p>合并亲和性生效的namespace，函数<code>mergeAffinityTermNamespacesIfNotEmpty</code>如下。其做法是将NamespaceSelector中筛选的所有namespace插入到直接规定的namespaces中，从这里也可以看出来上面提到的namespaceSelector和namespaces是或的关系。</p> <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Updates Namespaces with the set of namespaces identified by NamespaceSelector.</span><br><span class="hljs-comment">// If successful, NamespaceSelector is set to nil.</span><br><span class="hljs-comment">// The assumption is that the term is for an incoming pod, in which case</span><br><span class="hljs-comment">// namespaceSelector is either unrolled into Namespaces (and so the selector</span><br><span class="hljs-comment">// is set to Nothing()) or is Empty(), which means match everything. Therefore,</span><br><span class="hljs-comment">// there when matching against this term, there is no need to lookup the existing</span><br><span class="hljs-comment">// pod&#x27;s namespace labels to match them against term&#x27;s namespaceSelector explicitly.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *InterPodAffinity)</span></span> mergeAffinityTermNamespacesIfNotEmpty(at *framework.AffinityTerm) <span class="hljs-type">error</span> &#123;<br><span class="hljs-keyword">if</span> at.NamespaceSelector.Empty() &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br>ns, err := pl.nsLister.List(at.NamespaceSelector)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> err<br>&#125;<br><span class="hljs-keyword">for</span> _, n := <span class="hljs-keyword">range</span> ns &#123;<br>at.Namespaces.Insert(n.Name)<br>&#125;<br>at.NamespaceSelector = labels.Nothing()<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>合并反亲和性生效的namespace，与合并亲和性类似。</p></li><li><p>得到namespace的label的快照，并保存起来。</p></li><li><p>查看已经部署运行具有反亲和性约束的pod，查看这些已有的反亲和性约束与要调度的pod之间的约束结果，函数<code>getExistingAntiAffinityCounts</code>如下。</p> <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// calculates the following for each existing pod on each node:</span><br><span class="hljs-comment">//  1. Whether it has PodAntiAffinity</span><br><span class="hljs-comment">//  2. Whether any AntiAffinityTerm matches the incoming pod</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *InterPodAffinity)</span></span> getExistingAntiAffinityCounts(ctx context.Context, pod *v1.Pod, nsLabels labels.Set, nodes []*framework.NodeInfo) topologyToMatchedTermCount &#123;<br>topoMaps := <span class="hljs-built_in">make</span>([]topologyToMatchedTermCount, <span class="hljs-built_in">len</span>(nodes))<br>index := <span class="hljs-type">int32</span>(<span class="hljs-number">-1</span>)<br>processNode := <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(i <span class="hljs-type">int</span>)</span></span> &#123;<br>nodeInfo := nodes[i]<br>node := nodeInfo.Node()<br><span class="hljs-keyword">if</span> node == <span class="hljs-literal">nil</span> &#123;<br>klog.ErrorS(<span class="hljs-literal">nil</span>, <span class="hljs-string">&quot;Node not found&quot;</span>)<br><span class="hljs-keyword">return</span><br>&#125;<br>topoMap := <span class="hljs-built_in">make</span>(topologyToMatchedTermCount)<br><span class="hljs-keyword">for</span> _, existingPod := <span class="hljs-keyword">range</span> nodeInfo.PodsWithRequiredAntiAffinity &#123;<br>topoMap.updateWithAntiAffinityTerms(existingPod.RequiredAntiAffinityTerms, pod, nsLabels, node, <span class="hljs-number">1</span>)<br>&#125;<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(topoMap) != <span class="hljs-number">0</span> &#123;<br>topoMaps[atomic.AddInt32(&amp;index, <span class="hljs-number">1</span>)] = topoMap<br>&#125;<br>&#125;<br>pl.parallelizer.Until(ctx, <span class="hljs-built_in">len</span>(nodes), processNode, pl.Name())<br><br>result := <span class="hljs-built_in">make</span>(topologyToMatchedTermCount)<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt;= <span class="hljs-type">int</span>(index); i++ &#123;<br>result.<span class="hljs-built_in">append</span>(topoMaps[i])<br>&#125;<br><br><span class="hljs-keyword">return</span> result<br>&#125;<br></code></pre></td></tr></table></figure><p> 首先看一下这个函数的中的topologyToMatchedTermCount的定义，如下</p> <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> topologyPair <span class="hljs-keyword">struct</span> &#123;<br>key   <span class="hljs-type">string</span><br>value <span class="hljs-type">string</span><br>&#125;<br><span class="hljs-keyword">type</span> topologyToMatchedTermCount <span class="hljs-keyword">map</span>[topologyPair]<span class="hljs-type">int64</span><br><br><span class="hljs-comment">// ...</span><br><br><span class="hljs-comment">// updates the topologyToMatchedTermCount map with the specified value</span><br><span class="hljs-comment">// for each anti-affinity term matched the target pod.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(m topologyToMatchedTermCount)</span></span> updateWithAntiAffinityTerms(terms []framework.AffinityTerm, pod *v1.Pod, nsLabels labels.Set, node *v1.Node, value <span class="hljs-type">int64</span>) &#123;<br><span class="hljs-comment">// Check anti-affinity terms.</span><br><span class="hljs-keyword">for</span> _, t := <span class="hljs-keyword">range</span> terms &#123;<br><span class="hljs-keyword">if</span> t.Matches(pod, nsLabels) &#123;<br>m.update(node, t.TopologyKey, value)<br>&#125;<br>&#125;<br>&#125;<br><br><span class="hljs-comment">// ...</span><br><br><span class="hljs-comment">// Matches returns true if the pod matches the label selector and namespaces or namespace selector.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(at *AffinityTerm)</span></span> Matches(pod *v1.Pod, nsLabels labels.Set) <span class="hljs-type">bool</span> &#123;<br><span class="hljs-keyword">if</span> at.Namespaces.Has(pod.Namespace) || at.NamespaceSelector.Matches(nsLabels) &#123;<br><span class="hljs-keyword">return</span> at.Selector.Matches(labels.Set(pod.Labels))<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(m topologyToMatchedTermCount)</span></span> update(node *v1.Node, tk <span class="hljs-type">string</span>, value <span class="hljs-type">int64</span>) &#123;<br><span class="hljs-keyword">if</span> tv, ok := node.Labels[tk]; ok &#123;<br>pair := topologyPair&#123;key: tk, value: tv&#125;<br>m[pair] += value<br><span class="hljs-comment">// value could be negative, hence we delete the entry if it is down to zero.</span><br><span class="hljs-keyword">if</span> m[pair] == <span class="hljs-number">0</span> &#123;<br><span class="hljs-built_in">delete</span>(m, pair)<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p> 可以看到是一个topologyToMatchedTermCount是一个map，不过这里其value一直为1.函数<code>getExistingAntiAffinityCounts</code>这里会遍历有反亲和性约束的pod，然后看其该pod反亲和性约束所生效的namespace和所生效的label的范围是不是包含了要调度的pod，如果是就将作用域及作用域的具体值所对应的值加上value（也就是1），然后返回回去。最后得到的结果就例如：对于hostname域为node1的具有反亲和性约束的pod的数量为2，对于region域为east1的具有反亲和性约束的pod的数量为1。<strong>如此就将对于pod的反亲和性约束转变为了对于各个域的反亲和性约束。</strong></p></li><li><p>然后查看要调度的pod的亲和性与反亲和性约束，查看已有的pod与该pod的约束结果，函数<code>getIncomingAffinityAntiAffinityCounts</code>如下。</p> <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// finds existing Pods that match affinity terms of the incoming pod&#x27;s (anti)affinity terms.</span><br><span class="hljs-comment">// It returns a topologyToMatchedTermCount that are checked later by the affinity</span><br><span class="hljs-comment">// predicate. With this topologyToMatchedTermCount available, the affinity predicate does not</span><br><span class="hljs-comment">// need to check all the pods in the cluster.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *InterPodAffinity)</span></span> getIncomingAffinityAntiAffinityCounts(ctx context.Context, podInfo *framework.PodInfo, allNodes []*framework.NodeInfo) (topologyToMatchedTermCount, topologyToMatchedTermCount) &#123;<br>affinityCounts := <span class="hljs-built_in">make</span>(topologyToMatchedTermCount)<br>antiAffinityCounts := <span class="hljs-built_in">make</span>(topologyToMatchedTermCount)<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(podInfo.RequiredAffinityTerms) == <span class="hljs-number">0</span> &amp;&amp; <span class="hljs-built_in">len</span>(podInfo.RequiredAntiAffinityTerms) == <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">return</span> affinityCounts, antiAffinityCounts<br>&#125;<br><br>affinityCountsList := <span class="hljs-built_in">make</span>([]topologyToMatchedTermCount, <span class="hljs-built_in">len</span>(allNodes))<br>antiAffinityCountsList := <span class="hljs-built_in">make</span>([]topologyToMatchedTermCount, <span class="hljs-built_in">len</span>(allNodes))<br>index := <span class="hljs-type">int32</span>(<span class="hljs-number">-1</span>)<br>processNode := <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(i <span class="hljs-type">int</span>)</span></span> &#123;<br>nodeInfo := allNodes[i]<br>node := nodeInfo.Node()<br><span class="hljs-keyword">if</span> node == <span class="hljs-literal">nil</span> &#123;<br>klog.ErrorS(<span class="hljs-literal">nil</span>, <span class="hljs-string">&quot;Node not found&quot;</span>)<br><span class="hljs-keyword">return</span><br>&#125;<br>affinity := <span class="hljs-built_in">make</span>(topologyToMatchedTermCount)<br>antiAffinity := <span class="hljs-built_in">make</span>(topologyToMatchedTermCount)<br><span class="hljs-keyword">for</span> _, existingPod := <span class="hljs-keyword">range</span> nodeInfo.Pods &#123;<br>affinity.updateWithAffinityTerms(podInfo.RequiredAffinityTerms, existingPod.Pod, node, <span class="hljs-number">1</span>)<br><span class="hljs-comment">// The incoming pod&#x27;s terms have the namespaceSelector merged into the namespaces, and so</span><br><span class="hljs-comment">// here we don&#x27;t lookup the existing pod&#x27;s namespace labels, hence passing nil for nsLabels.</span><br>antiAffinity.updateWithAntiAffinityTerms(podInfo.RequiredAntiAffinityTerms, existingPod.Pod, <span class="hljs-literal">nil</span>, node, <span class="hljs-number">1</span>)<br>&#125;<br><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(affinity) &gt; <span class="hljs-number">0</span> || <span class="hljs-built_in">len</span>(antiAffinity) &gt; <span class="hljs-number">0</span> &#123;<br>k := atomic.AddInt32(&amp;index, <span class="hljs-number">1</span>)<br>affinityCountsList[k] = affinity<br>antiAffinityCountsList[k] = antiAffinity<br>&#125;<br>&#125;<br>pl.parallelizer.Until(ctx, <span class="hljs-built_in">len</span>(allNodes), processNode, pl.Name())<br><br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt;= <span class="hljs-type">int</span>(index); i++ &#123;<br>affinityCounts.<span class="hljs-built_in">append</span>(affinityCountsList[i])<br>antiAffinityCounts.<span class="hljs-built_in">append</span>(antiAffinityCountsList[i])<br>&#125;<br><br><span class="hljs-keyword">return</span> affinityCounts, antiAffinityCounts<br>&#125;<br></code></pre></td></tr></table></figure><p> 操作的一些细节与6类似，主要就是并行遍历所有的node，然后运行检查每个node时，逐个检查node上的每个pod，然后检查与要调度的pod存在的亲和性、反亲和性约束的结果，并转化为了对各个域的亲和性、反亲和性约束结果，最终汇总返回。</p></li><li><p>如果与现存的具有反亲和性约束的pod没有约束关系，或者本身也没有亲和性、反亲和性约束，那么就更新状态为可跳过，并返回。不然就写入这个预筛选结果到<code>cycleState</code>中</p></li></ol><h3 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h3><p>其代码如下，补充了部分注释。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Filter invoked at the filter extension point.</span><br><span class="hljs-comment">// It checks if a pod can be scheduled on the specified node with pod affinity/anti-affinity configuration.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *InterPodAffinity)</span></span> Filter(ctx context.Context, cycleState *framework.CycleState, pod *v1.Pod, nodeInfo *framework.NodeInfo) *framework.Status &#123;<br>    <span class="hljs-comment">// 检查给定的节点信息是否有效，如果节点为空，则返回错误状态</span><br>    <span class="hljs-keyword">if</span> nodeInfo.Node() == <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> framework.NewStatus(framework.Error, <span class="hljs-string">&quot;node not found&quot;</span>)<br>    &#125;<br><br>    <span class="hljs-comment">// 获取调度前的过滤状态信息，如果获取失败，则返回错误状态</span><br>    state, err := getPreFilterState(cycleState)<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> framework.AsStatus(err)<br>    &#125;<br><br>    <span class="hljs-comment">// 检查是否满足 Pod 的亲和性规则，如果不满足，则返回不可调度且不可解决的状态</span><br>    <span class="hljs-keyword">if</span> !satisfyPodAffinity(state, nodeInfo) &#123;<br>        <span class="hljs-keyword">return</span> framework.NewStatus(framework.UnschedulableAndUnresolvable, ErrReasonAffinityRulesNotMatch)<br>    &#125;<br><br>    <span class="hljs-comment">// 检查是否满足 Pod 的反亲和性规则，如果不满足，则返回不可调度的状态</span><br>    <span class="hljs-keyword">if</span> !satisfyPodAntiAffinity(state, nodeInfo) &#123;<br>        <span class="hljs-keyword">return</span> framework.NewStatus(framework.Unschedulable, ErrReasonAntiAffinityRulesNotMatch)<br>    &#125;<br><br>    <span class="hljs-comment">// 检查是否满足现有 Pod 的反亲和性规则，如果不满足，则返回不可调度的状态</span><br>    <span class="hljs-keyword">if</span> !satisfyExistingPodsAntiAffinity(state, nodeInfo) &#123;<br>        <span class="hljs-keyword">return</span> framework.NewStatus(framework.Unschedulable, ErrReasonExistingAntiAffinityRulesNotMatch)<br>    &#125;<br><br>    <span class="hljs-comment">// 如果所有检查都通过，则返回 nil，表示 Pod 可以被调度到该节点</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>整体的逻辑很简明，首先是得到预筛选的结果，然后检查该node是否满足要调度的pod的亲和性、反亲和性约束，已经是否满足已运行的pod的反亲和性约束。</p><p>查看<code>satisfyPodAffinity</code>函数，如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Checks if the node satisfies the incoming pod&#x27;s affinity rules.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">satisfyPodAffinity</span><span class="hljs-params">(state *preFilterState, nodeInfo *framework.NodeInfo)</span></span> <span class="hljs-type">bool</span> &#123;<br>podsExist := <span class="hljs-literal">true</span><br><span class="hljs-keyword">for</span> _, term := <span class="hljs-keyword">range</span> state.podInfo.RequiredAffinityTerms &#123;<br><span class="hljs-keyword">if</span> topologyValue, ok := nodeInfo.Node().Labels[term.TopologyKey]; ok &#123;<br>tp := topologyPair&#123;key: term.TopologyKey, value: topologyValue&#125;<br><span class="hljs-keyword">if</span> state.affinityCounts[tp] &lt;= <span class="hljs-number">0</span> &#123;<br>podsExist = <span class="hljs-literal">false</span><br>&#125;<br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-comment">// All topology labels must exist on the node.</span><br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>&#125;<br>&#125;<br><br><span class="hljs-keyword">if</span> !podsExist &#123;<br><span class="hljs-comment">// This pod may be the first pod in a series that have affinity to themselves. In order</span><br><span class="hljs-comment">// to not leave such pods in pending state forever, we check that if no other pod</span><br><span class="hljs-comment">// in the cluster matches the namespace and selector of this pod, the pod matches</span><br><span class="hljs-comment">// its own terms, and the node has all the requested topologies, then we allow the pod</span><br><span class="hljs-comment">// to pass the affinity check.</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(state.affinityCounts) == <span class="hljs-number">0</span> &amp;&amp; podMatchesAllAffinityTerms(state.podInfo.RequiredAffinityTerms, state.podInfo.Pod) &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span><br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span><br>&#125;<br></code></pre></td></tr></table></figure><p>在函数中首先遍历了要调度的pod的亲和性约束项，PreFilter转换的亲和性约束的结果查看node所在的域是否包含有亲和性pod，如果没有就不通过。例如要调度的pod的亲和性约束约束了region域，假设这个node的region的值为west（如果没有region域那么也不通过），然后根据PreFilter的结果来看，值为west的region中统计的与其具有亲和性的pod的数量是否大于0，如果是，那么这一项检查就通过了，如果不是就不通过。</p><p>然后这里也专门统计了是否存在与其具有亲和性约束的pod，如果完全不存在，那么这个pod可能就是所有亲和性约束的第一个，那么就检查一下当前的pod是否满足自己的亲和性要求，如下，如果通过了也能让其通过这部分的筛选。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// returns true IFF the given pod matches all the given terms.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">podMatchesAllAffinityTerms</span><span class="hljs-params">(terms []framework.AffinityTerm, pod *v1.Pod)</span></span> <span class="hljs-type">bool</span> &#123;<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(terms) == <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>&#125;<br><span class="hljs-keyword">for</span> _, t := <span class="hljs-keyword">range</span> terms &#123;<br><span class="hljs-comment">// The incoming pod NamespaceSelector was merged into the Namespaces set, and so</span><br><span class="hljs-comment">// we are not explicitly passing in namespace labels.</span><br><span class="hljs-keyword">if</span> !t.Matches(pod, <span class="hljs-literal">nil</span>) &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span><br>&#125;<br></code></pre></td></tr></table></figure><p>再查看<code>satisfyPodAntiAffinity</code>函数，如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Checks if the node satisfies the incoming pod&#x27;s anti-affinity rules.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">satisfyPodAntiAffinity</span><span class="hljs-params">(state *preFilterState, nodeInfo *framework.NodeInfo)</span></span> <span class="hljs-type">bool</span> &#123;<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(state.antiAffinityCounts) &gt; <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">for</span> _, term := <span class="hljs-keyword">range</span> state.podInfo.RequiredAntiAffinityTerms &#123;<br><span class="hljs-keyword">if</span> topologyValue, ok := nodeInfo.Node().Labels[term.TopologyKey]; ok &#123;<br>tp := topologyPair&#123;key: term.TopologyKey, value: topologyValue&#125;<br><span class="hljs-keyword">if</span> state.antiAffinityCounts[tp] &gt; <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>&#125;<br>&#125;<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span><br>&#125;<br></code></pre></td></tr></table></figure><p>也是类似，检查node所在的域是否有与该要调度的pod具有反亲和性约束的pod，如果有，就不通过筛选。</p><p>在查看<code>satisfyExistingPodsAntiAffinity</code>函数，如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Checks if scheduling the pod onto this node would break any anti-affinity</span><br><span class="hljs-comment">// terms indicated by the existing pods.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">satisfyExistingPodsAntiAffinity</span><span class="hljs-params">(state *preFilterState, nodeInfo *framework.NodeInfo)</span></span> <span class="hljs-type">bool</span> &#123;<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(state.existingAntiAffinityCounts) &gt; <span class="hljs-number">0</span> &#123;<br><span class="hljs-comment">// Iterate over topology pairs to get any of the pods being affected by</span><br><span class="hljs-comment">// the scheduled pod anti-affinity terms</span><br><span class="hljs-keyword">for</span> topologyKey, topologyValue := <span class="hljs-keyword">range</span> nodeInfo.Node().Labels &#123;<br>tp := topologyPair&#123;key: topologyKey, value: topologyValue&#125;<br><span class="hljs-keyword">if</span> state.existingAntiAffinityCounts[tp] &gt; <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>&#125;<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span><br>&#125;<br></code></pre></td></tr></table></figure><p>也是类似，检查node所在的域是否有与该要调度的pod具有反亲和性约束的pod，如果有，就不通过筛选。</p><h2 id="scoring-go"><a href="#scoring-go" class="headerlink" title="scoring.go"></a>scoring.go</h2><p>打分时则依靠<code>preferredDuringSchedulingIgnoredDuringExecution</code> 来进行倾向性的打分。其代码在<code>pkg/scheduler/framework/plugins/interpodaffinity/scoring.go</code>中。</p><h3 id="PreScore"><a href="#PreScore" class="headerlink" title="PreScore"></a>PreScore</h3><p><code>PreScore</code>函数的代码如下，添加了部分注释。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// PreScore builds and writes cycle state used by Score and NormalizeScore.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *InterPodAffinity)</span></span> PreScore(<br>pCtx context.Context,<br>cycleState *framework.CycleState,<br>pod *v1.Pod,<br>nodes []*v1.Node,<br>) *framework.Status &#123;<br>    <span class="hljs-comment">// 如果没有节点可供打分，则直接返回 nil。</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(nodes) == <span class="hljs-number">0</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>    &#125;<br><br>    <span class="hljs-comment">// 检查 sharedLister 是否为空，如果是，则返回错误状态。</span><br>    <span class="hljs-keyword">if</span> pl.sharedLister == <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> framework.NewStatus(framework.Error, <span class="hljs-string">&quot;empty shared lister in InterPodAffinity PreScore&quot;</span>)<br>    &#125;<br><br>    <span class="hljs-comment">// 获取 Pod 的亲和性配置。</span><br>    affinity := pod.Spec.Affinity<br>    <span class="hljs-comment">// 检查是否存在亲和性约束。</span><br>    hasPreferredAffinityConstraints := affinity != <span class="hljs-literal">nil</span> &amp;&amp; affinity.PodAffinity != <span class="hljs-literal">nil</span> &amp;&amp; <span class="hljs-built_in">len</span>(affinity.PodAffinity.PreferredDuringSchedulingIgnoredDuringExecution) &gt; <span class="hljs-number">0</span><br>    <span class="hljs-comment">// 检查是否存在反亲和性约束。</span><br>    hasPreferredAntiAffinityConstraints := affinity != <span class="hljs-literal">nil</span> &amp;&amp; affinity.PodAntiAffinity != <span class="hljs-literal">nil</span> &amp;&amp; <span class="hljs-built_in">len</span>(affinity.PodAntiAffinity.PreferredDuringSchedulingIgnoredDuringExecution) &gt; <span class="hljs-number">0</span><br><br>    <span class="hljs-comment">// 如果没有首选的亲和性或反亲和性约束，并且配置指示忽略现有 Pod 的首选术语，</span><br>    <span class="hljs-comment">// 则写入一个空的 topologyScore 映射并返回 nil。</span><br>    <span class="hljs-keyword">if</span> pl.args.IgnorePreferredTermsOfExistingPods &amp;&amp; !hasPreferredAffinityConstraints &amp;&amp; !hasPreferredAntiAffinityConstraints &#123;<br>        cycleState.Write(preScoreStateKey, &amp;preScoreState&#123;<br>            topologyScore: <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">int64</span>),<br>        &#125;)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>    &#125;<br><br>    <span class="hljs-keyword">var</span> allNodes []*framework.NodeInfo<br>    <span class="hljs-keyword">var</span> err <span class="hljs-type">error</span><br>    <span class="hljs-comment">// 如果有亲和性或者反亲和性约束</span><br>    <span class="hljs-keyword">if</span> hasPreferredAffinityConstraints || hasPreferredAntiAffinityConstraints &#123;<br>        <span class="hljs-comment">// 获取所有节点的信息</span><br>        allNodes, err = pl.sharedLister.NodeInfos().List()<br>        <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-comment">// 如果从 sharedLister 获取所有节点失败，则返回错误状态。</span><br>            <span class="hljs-keyword">return</span> framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;failed to get all nodes from shared lister: %w&quot;</span>, err))<br>        &#125;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-comment">// 如果没有亲和性也没用反亲和性约束，则只获取有亲和性pod的node</span><br>        allNodes, err = pl.sharedLister.NodeInfos().HavePodsWithAffinityList()<br>        <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-comment">// 如果从 sharedLister 获取有亲和性 Pod 的节点列表失败，则返回错误状态。</span><br>            <span class="hljs-keyword">return</span> framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;failed to get pods with affinity list: %w&quot;</span>, err))<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 初始化 preScoreState 结构体，用于存储拓扑打分信息。</span><br>    state := &amp;preScoreState&#123;<br>        topologyScore: <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">int64</span>),<br>    &#125;<br><br>    <span class="hljs-comment">// 尝试为 Pod 创建 PodInfo，如果失败，则返回错误状态。</span><br>    <span class="hljs-keyword">if</span> state.podInfo, err = framework.NewPodInfo(pod); err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-comment">// 理论上我们不会到这里，因为错误会在 PreFilter 中被捕获。</span><br>        <span class="hljs-keyword">return</span> framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;failed to parse pod: %w&quot;</span>, err))<br>    &#125;<br><br>    <span class="hljs-comment">// 处理 Pod 的首选亲和性术语，如果合并命名空间失败，则返回错误状态。</span><br>    <span class="hljs-keyword">for</span> i := <span class="hljs-keyword">range</span> state.podInfo.PreferredAffinityTerms &#123;<br>        <span class="hljs-keyword">if</span> err := pl.mergeAffinityTermNamespacesIfNotEmpty(&amp;state.podInfo.PreferredAffinityTerms[i].AffinityTerm); err != <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-keyword">return</span> framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;updating PreferredAffinityTerms: %w&quot;</span>, err))<br>        &#125;<br>    &#125;<br>    <span class="hljs-comment">// 处理 Pod 的首选反亲和性术语，如果合并命名空间失败，则返回错误状态。</span><br>    <span class="hljs-keyword">for</span> i := <span class="hljs-keyword">range</span> state.podInfo.PreferredAntiAffinityTerms &#123;<br>        <span class="hljs-keyword">if</span> err := pl.mergeAffinityTermNamespacesIfNotEmpty(&amp;state.podInfo.PreferredAntiAffinityTerms[i].AffinityTerm); err != <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-keyword">return</span> framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;updating PreferredAntiAffinityTerms: %w&quot;</span>, err))<br>        &#125;<br>    &#125;<br>    <span class="hljs-comment">// 获取命名空间标签的快照。</span><br>    state.namespaceLabels = GetNamespaceLabelsSnapshot(pod.Namespace, pl.nsLister)<br><br>    <span class="hljs-comment">// 初始化一个列表来存储每个节点的拓扑打分信息。</span><br>    topoScores := <span class="hljs-built_in">make</span>([]scoreMap, <span class="hljs-built_in">len</span>(allNodes))<br>    index := <span class="hljs-type">int32</span>(<span class="hljs-number">-1</span>)<br>    processNode := <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(i <span class="hljs-type">int</span>)</span></span> &#123;<br>        nodeInfo := allNodes[i]<br>        <span class="hljs-keyword">if</span> nodeInfo.Node() == <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-keyword">return</span><br>        &#125;<br>        <span class="hljs-comment">// 如果 Pod 没有首选的亲和性术语，我们只需要处理节点上的有亲和性 Pod。</span><br>        podsToProcess := nodeInfo.PodsWithAffinity<br>        <span class="hljs-keyword">if</span> hasPreferredAffinityConstraints || hasPreferredAntiAffinityConstraints &#123;<br>            <span class="hljs-comment">// 如果 Pod 有首选的亲和性或反亲和性术语，我们需要处理节点上的所有 Pod。</span><br>            podsToProcess = nodeInfo.Pods<br>        &#125;<br><br>        <span class="hljs-comment">// 初始化当前节点的拓扑打分映射。</span><br>        topoScore := <span class="hljs-built_in">make</span>(scoreMap)<br>        <span class="hljs-comment">// 遍历当前节点上的 Pod，处理现有 Pod 并计算拓扑打分。</span><br>        <span class="hljs-keyword">for</span> _, existingPod := <span class="hljs-keyword">range</span> podsToProcess &#123;<br>            pl.processExistingPod(state, existingPod, nodeInfo, pod, topoScore)<br>        &#125;<br>        <span class="hljs-comment">// 如果当前节点有拓扑打分，则将其添加到 topoScores 列表中。</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(topoScore) &gt; <span class="hljs-number">0</span> &#123;<br>            topoScores[atomic.AddInt32(&amp;index, <span class="hljs-number">1</span>)] = topoScore<br>        &#125;<br>    &#125;<br>    <span class="hljs-comment">// 并行处理所有节点。</span><br>    pl.parallelizer.Until(pCtx, <span class="hljs-built_in">len</span>(allNodes), processNode, pl.Name())<br><br>    <span class="hljs-comment">// 将所有节点的拓扑打分信息累加到 state 中。</span><br>    <span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt;= <span class="hljs-type">int</span>(index); i++ &#123;<br>        state.topologyScore.<span class="hljs-built_in">append</span>(topoScores[i])<br>    &#125;<br><br>    <span class="hljs-comment">// 将构建好的周期状态写入 cycleState。</span><br>    cycleState.Write(preScoreStateKey, state)<br>    <span class="hljs-comment">// 返回 nil 表示成功。</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>整体的流程如下：</p><ol><li>获取pod的亲和性即反亲和性优选约束</li><li>如果pod没有相关的优选约束且系统也指明了要忽略优选约束，那么就直接返回。（如果没有忽略，我们就还需要考虑其他pod的优选倾向）</li><li>如果pod有亲和性优选或者反亲和性优选约束，那么考虑的node就是所有的node，如果都没有，那么就只考虑带有亲和性约束的pod的node。</li><li>与PreFilter类似，分别合并亲和性、反亲和性优选约束生效的namespace。</li><li>获取命名空间快照。</li><li>通过并行的方式给2中得到的每个node进行打分。<ol><li><p>在打分时首先查看要调度的pod是否有亲和性优选或者反亲和性优选约束，如果有要处理的pod就是node上的所有pod，否则就是带有亲和性约束的pod。</p></li><li><p>通过<code>processExistingPod</code>函数给每个要处理的pod进行打分，该函数如下</p> <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *InterPodAffinity)</span></span> processExistingPod(<br>state *preScoreState,<br>existingPod *framework.PodInfo,<br>existingPodNodeInfo *framework.NodeInfo,<br>incomingPod *v1.Pod,<br>topoScore scoreMap,<br>) &#123;<br>existingPodNode := existingPodNodeInfo.Node()<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(existingPodNode.Labels) == <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">return</span><br>&#125;<br><br><span class="hljs-comment">// For every soft pod affinity term of &lt;pod&gt;, if &lt;existingPod&gt; matches the term,</span><br><span class="hljs-comment">// increment &lt;p.counts&gt; for every node in the cluster with the same &lt;term.TopologyKey&gt;</span><br><span class="hljs-comment">// value as that of &lt;existingPods&gt;`s node by the term`s weight.</span><br><span class="hljs-comment">// Note that the incoming pod&#x27;s terms have the namespaceSelector merged into the namespaces, and so</span><br><span class="hljs-comment">// here we don&#x27;t lookup the existing pod&#x27;s namespace labels, hence passing nil for nsLabels.</span><br>topoScore.processTerms(state.podInfo.PreferredAffinityTerms, existingPod.Pod, <span class="hljs-literal">nil</span>, existingPodNode, <span class="hljs-number">1</span>)<br><br><span class="hljs-comment">// For every soft pod anti-affinity term of &lt;pod&gt;, if &lt;existingPod&gt; matches the term,</span><br><span class="hljs-comment">// decrement &lt;p.counts&gt; for every node in the cluster with the same &lt;term.TopologyKey&gt;</span><br><span class="hljs-comment">// value as that of &lt;existingPod&gt;`s node by the term`s weight.</span><br><span class="hljs-comment">// Note that the incoming pod&#x27;s terms have the namespaceSelector merged into the namespaces, and so</span><br><span class="hljs-comment">// here we don&#x27;t lookup the existing pod&#x27;s namespace labels, hence passing nil for nsLabels.</span><br>topoScore.processTerms(state.podInfo.PreferredAntiAffinityTerms, existingPod.Pod, <span class="hljs-literal">nil</span>, existingPodNode, <span class="hljs-number">-1</span>)<br><br><span class="hljs-comment">// For every hard pod affinity term of &lt;existingPod&gt;, if &lt;pod&gt; matches the term,</span><br><span class="hljs-comment">// increment &lt;p.counts&gt; for every node in the cluster with the same &lt;term.TopologyKey&gt;</span><br><span class="hljs-comment">// value as that of &lt;existingPod&gt;&#x27;s node by the constant &lt;args.hardPodAffinityWeight&gt;</span><br><span class="hljs-keyword">if</span> pl.args.HardPodAffinityWeight &gt; <span class="hljs-number">0</span> &amp;&amp; <span class="hljs-built_in">len</span>(existingPodNode.Labels) != <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">for</span> _, t := <span class="hljs-keyword">range</span> existingPod.RequiredAffinityTerms &#123;<br>topoScore.processTerm(&amp;t, pl.args.HardPodAffinityWeight, incomingPod, state.namespaceLabels, existingPodNode, <span class="hljs-number">1</span>)<br>&#125;<br>&#125;<br><br><span class="hljs-comment">// For every soft pod affinity term of &lt;existingPod&gt;, if &lt;pod&gt; matches the term,</span><br><span class="hljs-comment">// increment &lt;p.counts&gt; for every node in the cluster with the same &lt;term.TopologyKey&gt;</span><br><span class="hljs-comment">// value as that of &lt;existingPod&gt;&#x27;s node by the term&#x27;s weight.</span><br>topoScore.processTerms(existingPod.PreferredAffinityTerms, incomingPod, state.namespaceLabels, existingPodNode, <span class="hljs-number">1</span>)<br><br><span class="hljs-comment">// For every soft pod anti-affinity term of &lt;existingPod&gt;, if &lt;pod&gt; matches the term,</span><br><span class="hljs-comment">// decrement &lt;pm.counts&gt; for every node in the cluster with the same &lt;term.TopologyKey&gt;</span><br><span class="hljs-comment">// value as that of &lt;existingPod&gt;&#x27;s node by the term&#x27;s weight.</span><br>topoScore.processTerms(existingPod.PreferredAntiAffinityTerms, incomingPod, state.namespaceLabels, existingPodNode, <span class="hljs-number">-1</span>)<br>&#125;<br></code></pre></td></tr></table></figure><p> 如注释所述，首先是查看这个已经存在的pod是否满足要调度的pod的亲和性优选约束，这会遍历各个亲和性优选约束，如果满足某个约束，那么就在这个node所属域的值上加上对应亲和性优选约束的weight。其主要的<code>processTerms</code>函数如下。例如亲和性优选约束是值为west的region，weight为10，那么如果当前pod也为west的region，那么值为west的region的分数就会加10.</p> <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(m scoreMap)</span></span> processTerms(terms []framework.WeightedAffinityTerm, pod *v1.Pod, nsLabels labels.Set, node *v1.Node, multiplier <span class="hljs-type">int32</span>) &#123;<br><span class="hljs-keyword">for</span> _, term := <span class="hljs-keyword">range</span> terms &#123;<br>m.processTerm(&amp;term.AffinityTerm, term.Weight, pod, nsLabels, node, multiplier)<br>&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(m scoreMap)</span></span> processTerm(term *framework.AffinityTerm, weight <span class="hljs-type">int32</span>, pod *v1.Pod, nsLabels labels.Set, node *v1.Node, multiplier <span class="hljs-type">int32</span>) &#123;<br><span class="hljs-keyword">if</span> term.Matches(pod, nsLabels) &#123;<br><span class="hljs-keyword">if</span> tpValue, tpValueExist := node.Labels[term.TopologyKey]; tpValueExist &#123;<br><span class="hljs-keyword">if</span> m[term.TopologyKey] == <span class="hljs-literal">nil</span> &#123;<br>m[term.TopologyKey] = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">int64</span>)<br>&#125;<br>m[term.TopologyKey][tpValue] += <span class="hljs-type">int64</span>(weight * multiplier)<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p> 然后也会查看各个反亲和性优选约束，这里就是减去对应的比重，都是通过multiplier控制。</p><p> 然后如果<code>HardPodAffinityWeight&gt;0</code>还会去查看已经运行的pod的硬亲和性约束，如果匹配其具体的约束，那么该正在运行的pod对应的域的分数就会加上<code>HardPodAffinityWeight</code> 。</p><p> 然后还会统计以运行的pod的亲和性优选约束及反亲和性优选约束，如果匹配分数也会加上或者减去对应的权重值。</p></li><li><p>如果有统计到分数，那么就加入结果中。</p></li></ol></li><li>最后就能得到各类型的域及对应值的分数，并放入到cycleState中。</li></ol><h3 id="Score"><a href="#Score" class="headerlink" title="Score"></a>Score</h3><p><code>Score</code>函数的代码如下。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Score invoked at the Score extension point.</span><br><span class="hljs-comment">// The &quot;score&quot; returned in this function is the sum of weights got from cycleState which have its topologyKey matching with the node&#x27;s labels.</span><br><span class="hljs-comment">// it is normalized later.</span><br><span class="hljs-comment">// Note: the returned &quot;score&quot; is positive for pod-affinity, and negative for pod-antiaffinity.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *InterPodAffinity)</span></span> Score(ctx context.Context, cycleState *framework.CycleState, pod *v1.Pod, nodeName <span class="hljs-type">string</span>) (<span class="hljs-type">int64</span>, *framework.Status) &#123;<br>nodeInfo, err := pl.sharedLister.NodeInfos().Get(nodeName)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>, framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;failed to get node %q from Snapshot: %w&quot;</span>, nodeName, err))<br>&#125;<br>node := nodeInfo.Node()<br><br>s, err := getPreScoreState(cycleState)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>, framework.AsStatus(err)<br>&#125;<br><span class="hljs-keyword">var</span> score <span class="hljs-type">int64</span><br><span class="hljs-keyword">for</span> tpKey, tpValues := <span class="hljs-keyword">range</span> s.topologyScore &#123;<br><span class="hljs-keyword">if</span> v, exist := node.Labels[tpKey]; exist &#123;<br>score += tpValues[v]<br>&#125;<br>&#125;<br><br><span class="hljs-keyword">return</span> score, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>首先是获取PreScore的打分结果，然后匹配当前node的域与打分的域，如果匹配上了，就加上对应的分数。例如PreScore的结果是：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs txt">&#123;&#123;&#123;region,east&#125;:-5&#125;, &#123;&#123;region,west&#125;:10&#125;, &#123;&#123;hostname,node1&#125;:-10&#125;, &#123;&#123;hostname,node2&#125;:8&#125;&#125;<br></code></pre></td></tr></table></figure><p>而node在值为east的region，所在的host为node2，那么它的分数就是-5+8&#x3D;3分。</p><h3 id="NormalizeScore"><a href="#NormalizeScore" class="headerlink" title="NormalizeScore"></a>NormalizeScore</h3><p>这里再关注一下<code>NormalizeScore</code>函数，如下，它的作用是规范化每个过滤后的节点的分数。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// NormalizeScore normalizes the score for each filteredNode.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *InterPodAffinity)</span></span> NormalizeScore(ctx context.Context, cycleState *framework.CycleState, pod *v1.Pod, scores framework.NodeScoreList) *framework.Status &#123;<br>    <span class="hljs-comment">// 从调度周期状态中获取预打分状态，如果获取失败，则返回错误状态。</span><br>    s, err := getPreScoreState(cycleState)<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> framework.AsStatus(err)<br>    &#125;<br>    <span class="hljs-comment">// 如果拓扑打分映射为空，则直接返回 nil，表示没有分数需要规范化。</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(s.topologyScore) == <span class="hljs-number">0</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>    &#125;<br><br>    <span class="hljs-comment">// 初始化最小和最大计数变量为 int64 类型的最大和最小值。</span><br>    <span class="hljs-keyword">var</span> minCount <span class="hljs-type">int64</span> = math.MaxInt64<br>    <span class="hljs-keyword">var</span> maxCount <span class="hljs-type">int64</span> = math.MinInt64<br><br>    <span class="hljs-comment">// 遍历所有节点的分数，找出最大和最小分数。</span><br>    <span class="hljs-keyword">for</span> i := <span class="hljs-keyword">range</span> scores &#123;<br>        score := scores[i].Score<br>        <span class="hljs-comment">// 如果当前分数大于已知的最大分数，则更新最大分数。</span><br>        <span class="hljs-keyword">if</span> score &gt; maxCount &#123;<br>            maxCount = score<br>        &#125;<br>        <span class="hljs-comment">// 如果当前分数小于已知的最小分数，则更新最小分数。</span><br>        <span class="hljs-keyword">if</span> score &lt; minCount &#123;<br>            minCount = score<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 计算最大分数和最小分数之间的差异。</span><br>    maxMinDiff := maxCount - minCount<br><br>    <span class="hljs-comment">// 遍历所有节点的分数，进行规范化处理。</span><br>    <span class="hljs-keyword">for</span> i := <span class="hljs-keyword">range</span> scores &#123;<br>        fScore := <span class="hljs-type">float64</span>(<span class="hljs-number">0</span>) <span class="hljs-comment">// 初始化浮点分数为 0。</span><br><br>        <span class="hljs-comment">// 如果最大分数和最小分数之间的差异大于 0，则计算规范化后的分数。</span><br>        <span class="hljs-keyword">if</span> maxMinDiff &gt; <span class="hljs-number">0</span> &#123;<br>            <span class="hljs-comment">// 使用规范化公式计算浮点分数：系统规定最大分值 * (当前分数 - 最小分数) / (最大分数 - 最小分数)。</span><br>            fScore = <span class="hljs-type">float64</span>(framework.MaxNodeScore) * (<span class="hljs-type">float64</span>(scores[i].Score-minCount) / <span class="hljs-type">float64</span>(maxMinDiff))<br>        &#125;<br><br>        <span class="hljs-comment">// 将计算出的浮点分数转换为 int64 类型，并更新节点的分数。</span><br>        scores[i].Score = <span class="hljs-type">int64</span>(fScore)<br>    &#125;<br><br>    <span class="hljs-comment">// 返回 nil，表示分数规范化成功完成。</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>首先是检查了一下PreScore的结果是不是null，如果是就直接返回nil了。然后就是统计分数列别的最大值和最小值，然后使用规范化公式计算浮点分数：系统规定最大分值 * (当前分数 - 最小分数) &#x2F; (最大分数 - 最小分数) ，并将计算出的浮点分数转换为 int64 类型，并更新节点的分数。</p>]]></content>
    
    
    <categories>
      
      <category>k8s</category>
      
      <category>源码分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>k8s</tag>
      
      <tag>源码分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【K8s源码分析（四）】-K8s调度器绑定周期介绍</title>
    <link href="/2024/05/10/k8sSource4/"/>
    <url>/2024/05/10/k8sSource4/</url>
    
    <content type="html"><![CDATA[<p>本次分析参考的K8s版本是<a href="https://github.com/kubernetes/kubernetes/tree/release-1.27">v1.27.0</a>。</p><p>K8s的整体调度框架如下图所示。</p><p><img src="/2024/05/10/k8sSource4/scheduling-framework-extensions.png" alt="Scheduling framework extension points"></p><h1 id="bindeCycle顶层函数"><a href="#bindeCycle顶层函数" class="headerlink" title="bindeCycle顶层函数"></a>bindeCycle顶层函数</h1><p>K8s调度器中绑定周期的函数<code>bindingCycle</code>在<code>pkg/scheduler/schedule_one.go:225</code>中，如下，补充了一些注释。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// bindingCycle tries to bind an assumed Pod.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(sched *Scheduler)</span></span> bindingCycle(<br>    ctx context.Context, <span class="hljs-comment">// 调度上下文</span><br>    state *framework.CycleState, <span class="hljs-comment">// 调度周期状态</span><br>    fwk framework.Framework, <span class="hljs-comment">// 调度框架</span><br>    scheduleResult ScheduleResult, <span class="hljs-comment">// 调度结果</span><br>    assumedPodInfo *framework.QueuedPodInfo, <span class="hljs-comment">// 假定的 Pod 信息</span><br>    start time.Time, <span class="hljs-comment">// 绑定周期开始时间</span><br>    podsToActivate *framework.PodsToActivate) *framework.Status &#123; <span class="hljs-comment">// 待激活的 Pods</span><br><br>    assumedPod := assumedPodInfo.Pod <span class="hljs-comment">// 获取假定的 Pod</span><br><br>    <span class="hljs-comment">// 运行 &quot;permit&quot; 插件，检查是否允许绑定操作</span><br>    <span class="hljs-keyword">if</span> status := fwk.WaitOnPermit(ctx, assumedPod); !status.IsSuccess() &#123;<br>        <span class="hljs-keyword">return</span> status<br>    &#125;<br><br>    <span class="hljs-comment">// 运行 &quot;prebind&quot; 插件，执行绑定前的检查和操作</span><br>    <span class="hljs-keyword">if</span> status := fwk.RunPreBindPlugins(ctx, state, assumedPod, scheduleResult.SuggestedHost); !status.IsSuccess() &#123;<br>        <span class="hljs-keyword">return</span> status<br>    &#125;<br><br>    <span class="hljs-comment">// 运行 &quot;bind&quot; 插件，实际执行 Pod 到节点的绑定操作</span><br>    <span class="hljs-keyword">if</span> status := sched.bind(ctx, fwk, assumedPod, scheduleResult.SuggestedHost, state); !status.IsSuccess() &#123;<br>        <span class="hljs-keyword">return</span> status<br>    &#125;<br><br>    <span class="hljs-comment">// 日志记录 Pod 绑定成功的信息</span><br>    klog.V(<span class="hljs-number">2</span>).InfoS(<span class="hljs-string">&quot;Successfully bound pod to node&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(assumedPod), <span class="hljs-string">&quot;node&quot;</span>, scheduleResult.SuggestedHost, <span class="hljs-string">&quot;evaluatedNodes&quot;</span>, scheduleResult.EvaluatedNodes, <span class="hljs-string">&quot;feasibleNodes&quot;</span>, scheduleResult.FeasibleNodes)<br><br>    <span class="hljs-comment">// 更新 Pod 调度的指标</span><br>    metrics.PodScheduled(fwk.ProfileName(), metrics.SinceInSeconds(start))<br>    metrics.PodSchedulingAttempts.Observe(<span class="hljs-type">float64</span>(assumedPodInfo.Attempts))<br>    metrics.PodSchedulingDuration.WithLabelValues(getAttemptsLabel(assumedPodInfo)).Observe(metrics.SinceInSeconds(assumedPodInfo.InitialAttemptTimestamp))<br><br>    <span class="hljs-comment">// 运行 &quot;postbind&quot; 插件，执行绑定后的检查和操作</span><br>    fwk.RunPostBindPlugins(ctx, state, assumedPod, scheduleResult.SuggestedHost)<br><br>    <span class="hljs-comment">// 成功绑定周期结束后，如果有必要，将一些 Pods 移动到activeQ队列中</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(podsToActivate.Map) != <span class="hljs-number">0</span> &#123;<br>        sched.SchedulingQueue.Activate(podsToActivate.Map)<br>        <span class="hljs-comment">// 与 schedulingCycle() 中的逻辑不同，我们不删除条目，</span><br>        <span class="hljs-comment">// 因为 podsToActivate.Map 不再被消费</span><br>    &#125;<br><br>    <span class="hljs-comment">// 返回 nil 表示没有错误</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到我们这里运行了permit、prebind、bind、postbind插件。下面具体来看这几个插件是如何运行的。</p><h1 id="Permit插件"><a href="#Permit插件" class="headerlink" title="Permit插件"></a>Permit插件</h1><p>其运行函数<code>WaitOnPermit</code>在<code>pkg/scheduler/framework/runtime/framework.go:1250</code>中，如下，补充了部分注释</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// WaitOnPermit will block, if the pod is a waiting pod, until the waiting pod is rejected or allowed.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *frameworkImpl)</span></span> WaitOnPermit(ctx context.Context, pod *v1.Pod) *framework.Status &#123;<br>    waitingPod := f.waitingPods.get(pod.UID) <span class="hljs-comment">// 根据pod的id来查看其是否在等待队列中</span><br>    <span class="hljs-keyword">if</span> waitingPod == <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span> <span class="hljs-comment">// 如果不在等待队列中，直接返回</span><br>    &#125;<br>    <span class="hljs-keyword">defer</span> f.waitingPods.remove(pod.UID) <span class="hljs-comment">// 无论函数如何结束，都从等待列表中移除该 Pod</span><br>    <br>    klog.V(<span class="hljs-number">4</span>).InfoS(<span class="hljs-string">&quot;Pod waiting on permit&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod)) <span class="hljs-comment">// 日志记录 Pod 正在等待许可</span><br><br>    startTime := time.Now() <span class="hljs-comment">// 记录开始等待的时间</span><br>    s := &lt;-waitingPod.s <span class="hljs-comment">// 从pod的通道中接收状态</span><br>    metrics.PermitWaitDuration.WithLabelValues(s.Code().String()).Observe(metrics.SinceInSeconds(startTime)) <span class="hljs-comment">// 记录许可等待的持续时间</span><br><br>    <span class="hljs-keyword">if</span> !s.IsSuccess() &#123;<br>        <span class="hljs-keyword">if</span> s.IsUnschedulable() &#123;<br>            klog.V(<span class="hljs-number">4</span>).InfoS(<span class="hljs-string">&quot;Pod rejected while waiting on permit&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="hljs-string">&quot;status&quot;</span>, s.Message()) <span class="hljs-comment">// 日志记录 Pod 在等待许可时被拒绝</span><br>            <span class="hljs-keyword">return</span> s <span class="hljs-comment">// 返回拒绝状态</span><br>        &#125;<br>        err := s.AsError() <span class="hljs-comment">// 将状态转换为错误</span><br>        klog.ErrorS(err, <span class="hljs-string">&quot;Failed waiting on permit for pod&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod)) <span class="hljs-comment">// 日志记录等待许可失败</span><br>        <span class="hljs-keyword">return</span> framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;waiting on permit for pod: %w&quot;</span>, err)).WithFailedPlugin(s.FailedPlugin()) <span class="hljs-comment">// 返回错误状态</span><br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span> <span class="hljs-comment">// 如果状态成功，则返回 nil 表示没有错误</span><br>&#125;<br></code></pre></td></tr></table></figure><p>主要流程包括：</p><ol><li>查看等待队列是否包含该pod，如果不包含直接返回</li><li>如果包含，就记录开始等待的时间，并通过通道来进行阻塞等待</li><li>记录许可等待的持续时间。</li><li>检查接收到的状态。如果状态不成功：<ul><li>如果状态是不可调度的（Unschedulable），记录日志并返回拒绝状态。</li><li>如果状态不是成功的，记录错误日志，并返回错误状态。</li></ul></li><li>如果成功就直接返回。</li></ol><h1 id="PreBind插件"><a href="#PreBind插件" class="headerlink" title="PreBind插件"></a>PreBind插件</h1><p>该插件对应的执行函数<code>RunPreBindPlugins</code>在<code>pkg/scheduler/framework/runtime/framework.go:1048</code>中，如下，补充了部分注释。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// RunPreBindPlugins runs the set of configured prebind plugins. It returns a</span><br><span class="hljs-comment">// failure (bool) if any of the plugins returns an error. It also returns an</span><br><span class="hljs-comment">// error containing the rejection message or the error occurred in the plugin.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *frameworkImpl)</span></span> RunPreBindPlugins(ctx context.Context, state *framework.CycleState, pod *v1.Pod, nodeName <span class="hljs-type">string</span>) (status *framework.Status) &#123;<br>    startTime := time.Now() <span class="hljs-comment">// 记录 PreBind 插件开始运行的时间</span><br>    <span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>        <span class="hljs-comment">// 记录 PreBind 插件的运行时间和最终状态</span><br>        metrics.FrameworkExtensionPointDuration.WithLabelValues(metrics.PreBind, status.Code().String(), f.profileName).Observe(metrics.SinceInSeconds(startTime))<br>    &#125;()<br>    <span class="hljs-keyword">for</span> _, pl := <span class="hljs-keyword">range</span> f.preBindPlugins &#123;<br>        <span class="hljs-comment">// 遍历所有的 PreBind 插件</span><br>        status = f.runPreBindPlugin(ctx, pl, state, pod, nodeName)<br>        <span class="hljs-keyword">if</span> !status.IsSuccess() &#123;<br>            <span class="hljs-keyword">if</span> status.IsUnschedulable() &#123;<br>                <span class="hljs-comment">// 如果插件返回的状态是不可调度的，则记录日志并返回该状态</span><br>                klog.V(<span class="hljs-number">4</span>).InfoS(<span class="hljs-string">&quot;Pod rejected by PreBind plugin&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="hljs-string">&quot;node&quot;</span>, nodeName, <span class="hljs-string">&quot;plugin&quot;</span>, pl.Name(), <span class="hljs-string">&quot;status&quot;</span>, status.Message())<br>                status.SetFailedPlugin(pl.Name()) <span class="hljs-comment">// 设置失败的插件名称</span><br>                <span class="hljs-keyword">return</span> status<br>            &#125;<br>            err := status.AsError() <span class="hljs-comment">// 将状态转换为错误</span><br>            klog.ErrorS(err, <span class="hljs-string">&quot;Failed running PreBind plugin&quot;</span>, <span class="hljs-string">&quot;plugin&quot;</span>, pl.Name(), <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="hljs-string">&quot;node&quot;</span>, nodeName)<br>            <span class="hljs-comment">// 如果插件运行失败，记录错误日志并返回错误状态</span><br>            <span class="hljs-keyword">return</span> framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;running PreBind plugin %q: %w&quot;</span>, pl.Name(), err))<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span> <span class="hljs-comment">// 如果所有插件都成功运行，则返回 nil 表示没有错误</span><br>&#125;<br></code></pre></td></tr></table></figure><p>主要还是遍历所有的PreBind插件，并通过<code>runPreBindPlugin</code>函数进行运行，如果不成功就需要进行相关记录。<code>runPreBindPlugin</code> 函数在<code>pkg/scheduler/framework/runtime/framework.go:1069</code>中</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *frameworkImpl)</span></span> runPreBindPlugin(ctx context.Context, pl framework.PreBindPlugin, state *framework.CycleState, pod *v1.Pod, nodeName <span class="hljs-type">string</span>) *framework.Status &#123;<br><span class="hljs-keyword">if</span> !state.ShouldRecordPluginMetrics() &#123;<br><span class="hljs-keyword">return</span> pl.PreBind(ctx, state, pod, nodeName)<br>&#125;<br>startTime := time.Now()<br>status := pl.PreBind(ctx, state, pod, nodeName)<br>f.metricsRecorder.ObservePluginDurationAsync(metrics.PreBind, pl.Name(), status.Code().String(), metrics.SinceInSeconds(startTime))<br><span class="hljs-keyword">return</span> status<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到主要是调用插件的PreBind函数进行检查。</p><h1 id="Bind插件"><a href="#Bind插件" class="headerlink" title="Bind插件"></a>Bind插件</h1><p>该插件对应的执行函数<code>Bind</code>在<code>pkg/scheduler/schedule_one.go:796</code>中，如下。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// bind binds a pod to a given node defined in a binding object.</span><br><span class="hljs-comment">// The precedence for binding is: (1) extenders and (2) framework plugins.</span><br><span class="hljs-comment">// We expect this to run asynchronously, so we handle binding metrics internally.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(sched *Scheduler)</span></span> bind(ctx context.Context, fwk framework.Framework, assumed *v1.Pod, targetNode <span class="hljs-type">string</span>, state *framework.CycleState) (status *framework.Status) &#123;<br><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>sched.finishBinding(fwk, assumed, targetNode, status)<br>&#125;()<br><br>bound, err := sched.extendersBinding(assumed, targetNode)<br><span class="hljs-keyword">if</span> bound &#123;<br><span class="hljs-keyword">return</span> framework.AsStatus(err)<br>&#125;<br><span class="hljs-keyword">return</span> fwk.RunBindPlugins(ctx, state, assumed, targetNode)<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到首先会调用<code>extendersBinding</code>这个拓展插件进行运行，其代码在<code>pkg/scheduler/schedule_one.go:809</code>中，如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// TODO(#87159): Move this to a Plugin.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(sched *Scheduler)</span></span> extendersBinding(pod *v1.Pod, node <span class="hljs-type">string</span>) (<span class="hljs-type">bool</span>, <span class="hljs-type">error</span>) &#123;<br><span class="hljs-keyword">for</span> _, extender := <span class="hljs-keyword">range</span> sched.Extenders &#123;<br><span class="hljs-keyword">if</span> !extender.IsBinder() || !extender.IsInterested(pod) &#123;<br><span class="hljs-keyword">continue</span><br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>, extender.Bind(&amp;v1.Binding&#123;<br>ObjectMeta: metav1.ObjectMeta&#123;Namespace: pod.Namespace, Name: pod.Name, UID: pod.UID&#125;,<br>Target:     v1.ObjectReference&#123;Kind: <span class="hljs-string">&quot;Node&quot;</span>, Name: node&#125;,<br>&#125;)<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>从TODO中可以看到这部分代码在后面可能也变成插件的形式。这里遍历每个拓展，检查看是不是拓展是不是对该pod感兴趣，需要去主动的bind。</p><p>如果这些拓展都不处理pod，就会调用<code>RunBindPlugins</code>来进行bind，代码在中。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// RunBindPlugins runs the set of configured bind plugins until one returns a non `Skip` status.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *frameworkImpl)</span></span> RunBindPlugins(ctx context.Context, state *framework.CycleState, pod *v1.Pod, nodeName <span class="hljs-type">string</span>) (status *framework.Status) &#123;<br>startTime := time.Now()<br><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>metrics.FrameworkExtensionPointDuration.WithLabelValues(metrics.Bind, status.Code().String(), f.profileName).Observe(metrics.SinceInSeconds(startTime))<br>&#125;()<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(f.bindPlugins) == <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">return</span> framework.NewStatus(framework.Skip, <span class="hljs-string">&quot;&quot;</span>)<br>&#125;<br><span class="hljs-keyword">for</span> _, pl := <span class="hljs-keyword">range</span> f.bindPlugins &#123;<br>status = f.runBindPlugin(ctx, pl, state, pod, nodeName)<br><span class="hljs-keyword">if</span> status.IsSkip() &#123;<br><span class="hljs-keyword">continue</span><br>&#125;<br><span class="hljs-keyword">if</span> !status.IsSuccess() &#123;<br><span class="hljs-keyword">if</span> status.IsUnschedulable() &#123;<br>klog.V(<span class="hljs-number">4</span>).InfoS(<span class="hljs-string">&quot;Pod rejected by Bind plugin&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="hljs-string">&quot;node&quot;</span>, nodeName, <span class="hljs-string">&quot;plugin&quot;</span>, pl.Name(), <span class="hljs-string">&quot;status&quot;</span>, status.Message())<br>status.SetFailedPlugin(pl.Name())<br><span class="hljs-keyword">return</span> status<br>&#125;<br>err := status.AsError()<br>klog.ErrorS(err, <span class="hljs-string">&quot;Failed running Bind plugin&quot;</span>, <span class="hljs-string">&quot;plugin&quot;</span>, pl.Name(), <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="hljs-string">&quot;node&quot;</span>, nodeName)<br><span class="hljs-keyword">return</span> framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;running Bind plugin %q: %w&quot;</span>, pl.Name(), err))<br>&#125;<br><span class="hljs-keyword">return</span> status<br>&#125;<br><span class="hljs-keyword">return</span> status<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到他会遍历每一个bindPlug，看这些插件然后去对他进行相关的绑定处理，如果有一个不成功，就会被视为失败，然后进行相关的记录。</p><p>每一个binPlug的绑定操作<code>runBindPlugin</code>在<code>pkg/scheduler/framework/runtime/framework.go:1108</code>中。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *frameworkImpl)</span></span> runBindPlugin(ctx context.Context, bp framework.BindPlugin, state *framework.CycleState, pod *v1.Pod, nodeName <span class="hljs-type">string</span>) *framework.Status &#123;<br><span class="hljs-keyword">if</span> !state.ShouldRecordPluginMetrics() &#123;<br><span class="hljs-keyword">return</span> bp.Bind(ctx, state, pod, nodeName)<br>&#125;<br>startTime := time.Now()<br>status := bp.Bind(ctx, state, pod, nodeName)<br>f.metricsRecorder.ObservePluginDurationAsync(metrics.Bind, bp.Name(), status.Code().String(), metrics.SinceInSeconds(startTime))<br><span class="hljs-keyword">return</span> status<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到是调用每个插件的Bind函数。</p><h1 id="PostBind插件"><a href="#PostBind插件" class="headerlink" title="PostBind插件"></a>PostBind插件</h1><p>该插件对应的执行函数<code>RunPostBindPlugins</code>在<code>pkg/scheduler/framework/runtime/framework.go:1119</code>中，如下。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// RunPostBindPlugins runs the set of configured postbind plugins.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *frameworkImpl)</span></span> RunPostBindPlugins(ctx context.Context, state *framework.CycleState, pod *v1.Pod, nodeName <span class="hljs-type">string</span>) &#123;<br>startTime := time.Now()<br><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>metrics.FrameworkExtensionPointDuration.WithLabelValues(metrics.PostBind, framework.Success.String(), f.profileName).Observe(metrics.SinceInSeconds(startTime))<br>&#125;()<br><span class="hljs-keyword">for</span> _, pl := <span class="hljs-keyword">range</span> f.postBindPlugins &#123;<br>f.runPostBindPlugin(ctx, pl, state, pod, nodeName)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到其会运行每一个<code>postBindPlugins</code>插件。</p><p>具体运行的函数<code>runPostBindPlugin</code>在<code>pkg/scheduler/framework/runtime/framework.go:1129</code>中，如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *frameworkImpl)</span></span> runPostBindPlugin(ctx context.Context, pl framework.PostBindPlugin, state *framework.CycleState, pod *v1.Pod, nodeName <span class="hljs-type">string</span>) &#123;<br><span class="hljs-keyword">if</span> !state.ShouldRecordPluginMetrics() &#123;<br>pl.PostBind(ctx, state, pod, nodeName)<br><span class="hljs-keyword">return</span><br>&#125;<br>startTime := time.Now()<br>pl.PostBind(ctx, state, pod, nodeName)<br>f.metricsRecorder.ObservePluginDurationAsync(metrics.PostBind, pl.Name(), framework.Success.String(), metrics.SinceInSeconds(startTime))<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到是调用了每个插件的PostBind函数。</p>]]></content>
    
    
    <categories>
      
      <category>k8s</category>
      
      <category>源码分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>k8s</tag>
      
      <tag>源码分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【K8s源码分析（三）】-K8s调度器调度周期介绍</title>
    <link href="/2024/05/10/k8sSource3/"/>
    <url>/2024/05/10/k8sSource3/</url>
    
    <content type="html"><![CDATA[<p>本次分析参考的K8s版本是<a href="https://github.com/kubernetes/kubernetes/tree/release-1.27">v1.27.0</a>。</p><p>K8s的整体调度框架如下图所示。</p><p><img src="/2024/05/10/k8sSource3/scheduling-framework-extensions.png" alt="Scheduling framework extension points"></p><h1 id="调度框架顶层函数"><a href="#调度框架顶层函数" class="headerlink" title="调度框架顶层函数"></a>调度框架顶层函数</h1><p>K8s调度器调度的核心函数<code>schedulerone</code>在<code>pkg/scheduler/schedule_one.go:62</code>，如下，这里将一些解释写在了注释里</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// scheduleOne does the entire scheduling workflow for a single pod. It is serialized on the scheduling algorithm&#x27;s host fitting.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(sched *Scheduler)</span></span> scheduleOne(ctx context.Context) &#123;<br>    <span class="hljs-comment">// 获取调度队列中的下一个 Pod 信息</span><br>    podInfo := sched.NextPod()<br>    <span class="hljs-comment">// 如果 podInfo 或者其包含的 Pod 为 nil，说明调度队列关闭或者没有 Pod 需要调度，直接返回</span><br>    <span class="hljs-keyword">if</span> podInfo == <span class="hljs-literal">nil</span> || podInfo.Pod == <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span><br>    &#125;<br>    <span class="hljs-comment">// 获取 Pod 对象</span><br>    pod := podInfo.Pod<br>    <span class="hljs-comment">// 为当前 Pod 选择一个调度框架（scheduler framework）</span><br>    fwk, err := sched.frameworkForPod(pod)<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-comment">// 这种情况不应该发生，因为我们只接受那些指定了匹配调度器名称的 Pod 进行调度</span><br>        klog.ErrorS(err, <span class="hljs-string">&quot;Error occurred&quot;</span>)<br>        <span class="hljs-keyword">return</span><br>    &#125;<br>    <span class="hljs-comment">// 如果跳过调度，则直接返回</span><br>    <span class="hljs-keyword">if</span> sched.skipPodSchedule(fwk, pod) &#123;<br>        <span class="hljs-keyword">return</span><br>    &#125;<br><br>    <span class="hljs-comment">// 记录尝试调度 Pod 的日志</span><br>    klog.V(<span class="hljs-number">3</span>).InfoS(<span class="hljs-string">&quot;Attempting to schedule pod&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod))<br><br>    <span class="hljs-comment">// 开始计时，尝试为 Pod 找到合适的宿主机</span><br>    start := time.Now()<br>    <span class="hljs-comment">// 初始化调度周期状态</span><br>    state := framework.NewCycleState()<br>    <span class="hljs-comment">// 设置是否记录插件指标的随机概率</span><br>    state.SetRecordPluginMetrics(rand.Intn(<span class="hljs-number">100</span>) &lt; pluginMetricsSamplePercent)<br><br>    <span class="hljs-comment">// 初始化一个空的 podsToActivate 结构，这个结构将由插件填充或者保持为空</span><br>    podsToActivate := framework.NewPodsToActivate()<br>    <span class="hljs-comment">// 将 podsToActivate 写入状态中</span><br>    state.Write(framework.PodsToActivateKey, podsToActivate)<br><br>    <span class="hljs-comment">// 创建一个新的带有取消功能的上下文，用于调度周期</span><br>    schedulingCycleCtx, cancel := context.WithCancel(ctx)<br>    <span class="hljs-keyword">defer</span> cancel()<br><br>    <span class="hljs-comment">// 执行调度周期，尝试为 Pod 找到合适的宿主机</span><br>    scheduleResult, assumedPodInfo, status := sched.schedulingCycle(schedulingCycleCtx, state, fwk, podInfo, start, podsToActivate)<br>    <span class="hljs-comment">// 如果调度失败，则调用失败处理器</span><br>    <span class="hljs-keyword">if</span> !status.IsSuccess() &#123;<br>        sched.FailureHandler(schedulingCycleCtx, fwk, assumedPodInfo, status, scheduleResult.nominatingInfo, start)<br>        <span class="hljs-keyword">return</span><br>    &#125;<br><br>    <span class="hljs-comment">// 异步绑定 Pod 到其宿主机（可以这样做是因为上面的假设步骤）</span><br>    <span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>        <span class="hljs-comment">// 创建一个新的带有取消功能的上下文，用于绑定周期</span><br>        bindingCycleCtx, cancel := context.WithCancel(ctx)<br>        <span class="hljs-keyword">defer</span> cancel()<br><br>        <span class="hljs-comment">// 增加绑定阶段的 goroutine 指标</span><br>        metrics.SchedulerGoroutines.WithLabelValues(metrics.Binding).Inc()<br>        <span class="hljs-keyword">defer</span> metrics.SchedulerGoroutines.WithLabelValues(metrics.Binding).Dec()<br>        metrics.Goroutines.WithLabelValues(metrics.Binding).Inc()<br>        <span class="hljs-keyword">defer</span> metrics.Goroutines.WithLabelValues(metrics.Binding).Dec()<br><br>        <span class="hljs-comment">// 执行绑定周期，尝试将 Pod 绑定到宿主机</span><br>        status := sched.bindingCycle(bindingCycleCtx, state, fwk, scheduleResult, assumedPodInfo, start, podsToActivate)<br>        <span class="hljs-comment">// 如果绑定失败，则处理绑定周期错误</span><br>        <span class="hljs-keyword">if</span> !status.IsSuccess() &#123;<br>            sched.handleBindingCycleError(bindingCycleCtx, state, fwk, assumedPodInfo, start, scheduleResult, status)<br>        &#125;<br>    &#125;()<br>&#125;<br></code></pre></td></tr></table></figure><p>这段代码的主要功能是：</p><ol><li>从调度队列中获取下一个要调度的 Pod。</li><li>为 Pod 选择一个调度框架。</li><li>如果配置允许，跳过调度。</li><li>记录日志并开始调度周期。</li><li>如果调度成功，异步地尝试将 Pod 绑定到选定的宿主机。</li><li>如果调度或绑定失败，执行相应的错误处理逻辑。</li></ol><p>此处也指明了两个周期，分别为调度周期<code>schedulingCycle</code>和绑定周期<code>bindingCycle</code>，绑定周期会在后面一节进行介绍，这里主要关注<code>schedulingCycle</code> 。</p><p>查看关键的<code>schedulingCycle</code>函数，在<code>pkg/scheduler/schedule_one.go:120</code>中,补充了部分注释。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// schedulingCycle tries to schedule a single Pod.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(sched *Scheduler)</span></span> schedulingCycle(<br>    ctx context.Context, <span class="hljs-comment">// 调度上下文</span><br>    state *framework.CycleState, <span class="hljs-comment">// 调度周期状态</span><br>    fwk framework.Framework, <span class="hljs-comment">// 调度框架</span><br>    podInfo *framework.QueuedPodInfo, <span class="hljs-comment">// 待调度的 Pod 信息</span><br>    start time.Time, <span class="hljs-comment">// 调度开始时间</span><br>    podsToActivate *framework.PodsToActivate, <span class="hljs-comment">// 待激活的 Pods</span><br>) (ScheduleResult, *framework.QueuedPodInfo, *framework.Status) &#123;<br>    <span class="hljs-comment">// 获取待调度的 Pod</span><br>    pod := podInfo.Pod<br>    <span class="hljs-comment">// 调用调度器的 SchedulePod 方法尝试调度 Pod</span><br>    scheduleResult, err := sched.SchedulePod(ctx, fwk, state, pod)<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-comment">// 如果没有可用节点，则返回错误状态</span><br>        <span class="hljs-keyword">if</span> err == ErrNoNodesAvailable &#123;<br>            status := framework.NewStatus(framework.UnschedulableAndUnresolvable).WithError(err)<br>            <span class="hljs-keyword">return</span> ScheduleResult&#123;nominatingInfo: clearNominatedNode&#125;, podInfo, status<br>        &#125;<br><br>        <span class="hljs-comment">// 如果错误是 FitError 类型，则说明 Pod 无法适应任何节点</span><br>        fitError, ok := err.(*framework.FitError)<br>        <span class="hljs-keyword">if</span> !ok &#123;<br>            klog.ErrorS(err, <span class="hljs-string">&quot;Error selecting node for pod&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod))<br>            <span class="hljs-keyword">return</span> ScheduleResult&#123;nominatingInfo: clearNominatedNode&#125;, podInfo, framework.AsStatus(err)<br>        &#125;<br><br>        <span class="hljs-comment">// 如果没有 PostFilter 插件，则不执行抢占</span><br>        <span class="hljs-keyword">if</span> !fwk.HasPostFilterPlugins() &#123;<br>            klog.V(<span class="hljs-number">3</span>).InfoS(<span class="hljs-string">&quot;No PostFilter plugins are registered, so no preemption will be performed&quot;</span>)<br>            <span class="hljs-keyword">return</span> ScheduleResult&#123;&#125;, podInfo, framework.NewStatus(framework.Unschedulable).WithError(err)<br>        &#125;<br><br>        <span class="hljs-comment">// 运行 PostFilter 插件，尝试使 Pod 在未来的调度周期中可调度</span><br>        result, status := fwk.RunPostFilterPlugins(ctx, state, pod, fitError.Diagnosis.NodeToStatusMap)<br>        msg := status.Message()<br>        fitError.Diagnosis.PostFilterMsg = msg<br>        <span class="hljs-keyword">if</span> status.Code() == framework.Error &#123;<br>            klog.ErrorS(<span class="hljs-literal">nil</span>, <span class="hljs-string">&quot;Status after running PostFilter plugins for pod&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="hljs-string">&quot;status&quot;</span>, msg)<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            klog.V(<span class="hljs-number">5</span>).InfoS(<span class="hljs-string">&quot;Status after running PostFilter plugins for pod&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="hljs-string">&quot;status&quot;</span>, msg)<br>        &#125;<br><br>        <span class="hljs-comment">// 获取 PostFilter 插件返回的 NominatingInfo</span><br>        <span class="hljs-keyword">var</span> nominatingInfo *framework.NominatingInfo<br>        <span class="hljs-keyword">if</span> result != <span class="hljs-literal">nil</span> &#123;<br>            nominatingInfo = result.NominatingInfo<br>        &#125;<br>        <span class="hljs-keyword">return</span> ScheduleResult&#123;nominatingInfo: nominatingInfo&#125;, podInfo, framework.NewStatus(framework.Unschedulable).WithError(err)<br>    &#125;<br><br>    <span class="hljs-comment">// 计算并记录调度算法的延迟</span><br>    metrics.SchedulingAlgorithmLatency.Observe(metrics.SinceInSeconds(start))<br>    <span class="hljs-comment">// 假设 Pod 已经在给定节点上运行，这样子就不用等它实际绑定就可以执行后续的操作了</span><br>    assumedPodInfo := podInfo.DeepCopy()<br>    assumedPod := assumedPodInfo.Pod<br>    <span class="hljs-comment">// 假设操作，设置 Pod 的 NodeName 为调度结果推荐的宿主机</span><br>    err = sched.assume(assumedPod, scheduleResult.SuggestedHost)<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-comment">// 如果假设操作失败，这可能是重试逻辑中的一个 BUG</span><br>        <span class="hljs-comment">// 报告错误以便重新调度 Pod</span><br>        <span class="hljs-keyword">return</span> ScheduleResult&#123;nominatingInfo: clearNominatedNode&#125;,<br>            assumedPodInfo,<br>            framework.AsStatus(err)<br>    &#125;<br><br>    <span class="hljs-comment">// 运行预留插件的 Reserve 方法</span><br>    <span class="hljs-keyword">if</span> sts := fwk.RunReservePluginsReserve(ctx, state, assumedPod, scheduleResult.SuggestedHost); !sts.IsSuccess() &#123;<br>        <span class="hljs-comment">// 如果预留失败，触发取消预留以清理与预留 Pod 相关的资源</span><br>        fwk.RunReservePluginsUnreserve(ctx, state, assumedPod, scheduleResult.SuggestedHost)<br>        <span class="hljs-keyword">if</span> forgetErr := sched.Cache.ForgetPod(assumedPod); forgetErr != <span class="hljs-literal">nil</span> &#123;<br>            klog.ErrorS(forgetErr, <span class="hljs-string">&quot;Scheduler cache ForgetPod failed&quot;</span>)<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> ScheduleResult&#123;nominatingInfo: clearNominatedNode&#125;,<br>            assumedPodInfo,<br>            sts<br>    &#125;<br><br>    <span class="hljs-comment">// 运行 &quot;permit&quot; 插件</span><br>    runPermitStatus := fwk.RunPermitPlugins(ctx, state, assumedPod, scheduleResult.SuggestedHost)<br>    <span class="hljs-keyword">if</span> !runPermitStatus.IsWait() &amp;&amp; !runPermitStatus.IsSuccess() &#123;<br>        <span class="hljs-comment">// 如果许可检查失败，触发取消预留以清理与预留 Pod 相关的资源</span><br>        fwk.RunReservePluginsUnreserve(ctx, state, assumedPod, scheduleResult.SuggestedHost)<br>        <span class="hljs-keyword">if</span> forgetErr := sched.Cache.ForgetPod(assumedPod); forgetErr != <span class="hljs-literal">nil</span> &#123;<br>            klog.ErrorS(forgetErr, <span class="hljs-string">&quot;Scheduler cache ForgetPod failed&quot;</span>)<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> ScheduleResult&#123;nominatingInfo: clearNominatedNode&#125;,<br>            assumedPodInfo,<br>            runPermitStatus<br>    &#125;<br><br>    <span class="hljs-comment">// 成功调度周期结束后，查看是否有必要设置一些pod为可调度的状态</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(podsToActivate.Map) != <span class="hljs-number">0</span> &#123;<br>        sched.SchedulingQueue.Activate(podsToActivate.Map)<br>        <span class="hljs-comment">// 激活后清空条目</span><br>        podsToActivate.Map = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]*v1.Pod)<br>    &#125;<br><br>    <span class="hljs-comment">// 返回调度结果</span><br>    <span class="hljs-keyword">return</span> scheduleResult, assumedPodInfo, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>主要流程包括：</p><ol><li>尝试调度 Pod，并处理可能出现的错误。</li><li>如果调度失败，根据错误类型执行不同的逻辑，如处理节点不可用或 Pod 不适应任何节点的情况。</li><li>如果调度成功，记录调度算法的延迟，并提前假设 Pod 已经在推荐的节点上运行。</li><li>运行预留插件的 Reserve 方法，并处理预留成功或失败的情况。</li><li>运行抢占插件，并根据结果进行相应的处理。</li><li>如果有待转为active的 Pods，执行激活操作。</li><li>返回调度结果。</li></ol><h1 id="一般调度"><a href="#一般调度" class="headerlink" title="一般调度"></a>一般调度</h1><p>这里最关键的是<code>SchedulePod</code>函数，在<code>pkg/scheduler/schedule_one.go:334</code>中</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// schedulePod tries to schedule the given pod to one of the nodes in the node list.</span><br><span class="hljs-comment">// If it succeeds, it will return the name of the node.</span><br><span class="hljs-comment">// If it fails, it will return a FitError with reasons.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(sched *Scheduler)</span></span> schedulePod(ctx context.Context, fwk framework.Framework, state *framework.CycleState, pod *v1.Pod) (result ScheduleResult, err <span class="hljs-type">error</span>) &#123;<br>trace := utiltrace.New(<span class="hljs-string">&quot;Scheduling&quot;</span>, utiltrace.Field&#123;Key: <span class="hljs-string">&quot;namespace&quot;</span>, Value: pod.Namespace&#125;, utiltrace.Field&#123;Key: <span class="hljs-string">&quot;name&quot;</span>, Value: pod.Name&#125;)<br><span class="hljs-keyword">defer</span> trace.LogIfLong(<span class="hljs-number">100</span> * time.Millisecond)<br><br><span class="hljs-keyword">if</span> err := sched.Cache.UpdateSnapshot(sched.nodeInfoSnapshot); err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> result, err<br>&#125;<br>trace.Step(<span class="hljs-string">&quot;Snapshotting scheduler cache and node infos done&quot;</span>)<br><br><span class="hljs-keyword">if</span> sched.nodeInfoSnapshot.NumNodes() == <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">return</span> result, ErrNoNodesAvailable<br>&#125;<br><br>feasibleNodes, diagnosis, err := sched.findNodesThatFitPod(ctx, fwk, state, pod)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> result, err<br>&#125;<br>trace.Step(<span class="hljs-string">&quot;Computing predicates done&quot;</span>)<br><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(feasibleNodes) == <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">return</span> result, &amp;framework.FitError&#123;<br>Pod:         pod,<br>NumAllNodes: sched.nodeInfoSnapshot.NumNodes(),<br>Diagnosis:   diagnosis,<br>&#125;<br>&#125;<br><br><span class="hljs-comment">// When only one node after predicate, just use it.</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(feasibleNodes) == <span class="hljs-number">1</span> &#123;<br><span class="hljs-keyword">return</span> ScheduleResult&#123;<br>SuggestedHost:  feasibleNodes[<span class="hljs-number">0</span>].Name,<br>EvaluatedNodes: <span class="hljs-number">1</span> + <span class="hljs-built_in">len</span>(diagnosis.NodeToStatusMap),<br>FeasibleNodes:  <span class="hljs-number">1</span>,<br>&#125;, <span class="hljs-literal">nil</span><br>&#125;<br><br>priorityList, err := prioritizeNodes(ctx, sched.Extenders, fwk, state, pod, feasibleNodes)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> result, err<br>&#125;<br><br>host, err := selectHost(priorityList)<br>trace.Step(<span class="hljs-string">&quot;Prioritizing done&quot;</span>)<br><br><span class="hljs-keyword">return</span> ScheduleResult&#123;<br>SuggestedHost:  host,<br>EvaluatedNodes: <span class="hljs-built_in">len</span>(feasibleNodes) + <span class="hljs-built_in">len</span>(diagnosis.NodeToStatusMap),<br>FeasibleNodes:  <span class="hljs-built_in">len</span>(feasibleNodes),<br>&#125;, err<br>&#125;<br></code></pre></td></tr></table></figure><p>在这里我们就能具体的看到predicates筛选过程和Prioritizing打分过程，整体的逻辑也比较简单，首先是筛选出合适的node，如果只有一个node了，那么就直接返回这个node，如果有多个就进行打分，然后选择评分最高的node返回回去。</p><h2 id="筛选过程"><a href="#筛选过程" class="headerlink" title="筛选过程"></a>筛选过程</h2><p>然后我们查看predicates筛选过程，其代码在<code>pkg/scheduler/schedule_one.go:387</code>中，如下，补充了一些注释</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Filters the nodes to find the ones that fit the pod based on the framework</span><br><span class="hljs-comment">// filter plugins and filter extenders.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(sched *Scheduler)</span></span> findNodesThatFitPod(ctx context.Context, fwk framework.Framework, state *framework.CycleState, pod *v1.Pod) ([]*v1.Node, framework.Diagnosis, <span class="hljs-type">error</span>) &#123;<br>    <span class="hljs-comment">// 初始化诊断信息，用于记录调度过程中的详细信息</span><br>    diagnosis := framework.Diagnosis&#123;<br>        NodeToStatusMap:      <span class="hljs-built_in">make</span>(framework.NodeToStatusMap),<br>        UnschedulablePlugins: sets.NewString(),<br>    &#125;<br><br>    <span class="hljs-comment">// 获取所有节点的信息</span><br>    allNodes, err := sched.nodeInfoSnapshot.NodeInfos().List()<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, diagnosis, err<br>    &#125;<br>    <span class="hljs-comment">// 运行 &quot;prefilter&quot; 插件</span><br>    preRes, s := fwk.RunPreFilterPlugins(ctx, state, pod)<br>    <span class="hljs-keyword">if</span> !s.IsSuccess() &#123;<br>        <span class="hljs-keyword">if</span> !s.IsUnschedulable() &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, diagnosis, s.AsError()<br>        &#125;<br>        <span class="hljs-comment">// 如果 PreFilter 插件返回的状态是不可调度的，记录相关信息</span><br>        msg := s.Message()<br>        diagnosis.PreFilterMsg = msg<br>        klog.V(<span class="hljs-number">5</span>).InfoS(<span class="hljs-string">&quot;Status after running PreFilter plugins for pod&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="hljs-string">&quot;status&quot;</span>, msg)<br>        <span class="hljs-comment">// 如果有插件失败，记录失败的插件名称</span><br>        <span class="hljs-keyword">if</span> s.FailedPlugin() != <span class="hljs-string">&quot;&quot;</span> &#123;<br>            diagnosis.UnschedulablePlugins.Insert(s.FailedPlugin())<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, diagnosis, <span class="hljs-literal">nil</span><br>    &#125;<br><br>    <span class="hljs-comment">// 如果 Pod 已经被提名到一个节点上（可能由于之前的抢占操作），</span><br>    <span class="hljs-comment">// 这个节点很可能是唯一一个合适的节点，所以首先评估这个节点</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(pod.Status.NominatedNodeName) &gt; <span class="hljs-number">0</span> &#123;<br>        feasibleNodes, err := sched.evaluateNominatedNode(ctx, pod, fwk, state, diagnosis)<br>        <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>            klog.ErrorS(err, <span class="hljs-string">&quot;Evaluation failed on nominated node&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="hljs-string">&quot;node&quot;</span>, pod.Status.NominatedNodeName)<br>        &#125;<br>        <span class="hljs-comment">// 如果提名的节点通过了所有的过滤，调度器可以决定将这个节点分配给 Pod</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(feasibleNodes) != <span class="hljs-number">0</span> &#123;<br>            <span class="hljs-keyword">return</span> feasibleNodes, diagnosis, <span class="hljs-literal">nil</span><br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 根据 PreFilter 插件的结果，可能需要过滤掉一些节点</span><br>    nodes := allNodes<br>    <span class="hljs-keyword">if</span> !preRes.AllNodes() &#123;<br>        nodes = <span class="hljs-built_in">make</span>([]*framework.NodeInfo, <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(preRes.NodeNames))<br>        <span class="hljs-keyword">for</span> n := <span class="hljs-keyword">range</span> preRes.NodeNames &#123;<br>            nInfo, err := sched.nodeInfoSnapshot.NodeInfos().Get(n)<br>            <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, diagnosis, err<br>            &#125;<br>            nodes = <span class="hljs-built_in">append</span>(nodes, nInfo)<br>        &#125;<br>    &#125;<br>    <span class="hljs-comment">// 寻找通过过滤的节点</span><br>    feasibleNodes, err := sched.findNodesThatPassFilters(ctx, fwk, state, pod, diagnosis, nodes)<br>    <span class="hljs-comment">// 无论是否发生错误，都尝试更新下一次开始搜索节点的索引</span><br>    processedNodes := <span class="hljs-built_in">len</span>(feasibleNodes) + <span class="hljs-built_in">len</span>(diagnosis.NodeToStatusMap)<br>    sched.nextStartNodeIndex = (sched.nextStartNodeIndex + processedNodes) % <span class="hljs-built_in">len</span>(nodes)<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, diagnosis, err<br>    &#125;<br><br>    <span class="hljs-comment">// 检查过滤扩展器以找到更多通过过滤的节点</span><br>    feasibleNodes, err = findNodesThatPassExtenders(sched.Extenders, pod, feasibleNodes, diagnosis.NodeToStatusMap)<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, diagnosis, err<br>    &#125;<br>    <span class="hljs-comment">// 返回所有通过过滤的节点</span><br>    <span class="hljs-keyword">return</span> feasibleNodes, diagnosis, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>这部分首先运行preFilter插件首先进行一些轻量级的检查，然后再运行filter插件进行正式筛选，然后在运行filter拓展插件。</p><p>这里我们主要关注filter插件的运行，查看其对应的findNodesThatPassFilters函数，在<code>pkg/scheduler/schedule_one.go:475</code>中，如下，补充了部分注释</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// findNodesThatPassFilters finds the nodes that fit the filter plugins.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(sched *Scheduler)</span></span> findNodesThatPassFilters(<br>    ctx context.Context, <span class="hljs-comment">// 调度上下文</span><br>    fwk framework.Framework, <span class="hljs-comment">// 调度框架</span><br>    state *framework.CycleState, <span class="hljs-comment">// 调度周期状态</span><br>    pod *v1.Pod, <span class="hljs-comment">// 待调度的 Pod</span><br>    diagnosis framework.Diagnosis, <span class="hljs-comment">// 调度诊断信息</span><br>    nodes []*framework.NodeInfo) ([]*v1.Node, <span class="hljs-type">error</span>) &#123; <span class="hljs-comment">// 所有节点信息</span><br>    numAllNodes := <span class="hljs-built_in">len</span>(nodes) <span class="hljs-comment">// 所有节点的数量</span><br>    <span class="hljs-comment">// 计算应该找到的可行节点数量</span><br>    numNodesToFind := sched.numFeasibleNodesToFind(fwk.PercentageOfNodesToScore(), <span class="hljs-type">int32</span>(numAllNodes))<br><br>    <span class="hljs-comment">// 创建一个足够大的列表来存储通过过滤的节点，以避免在运行时增长该列表</span><br>    feasibleNodes := <span class="hljs-built_in">make</span>([]*v1.Node, numNodesToFind)<br><br>    <span class="hljs-comment">// 如果框架没有过滤插件，直接使用所有节点</span><br>    <span class="hljs-keyword">if</span> !fwk.HasFilterPlugins() &#123;<br>        <span class="hljs-keyword">for</span> i := <span class="hljs-keyword">range</span> feasibleNodes &#123;<br>            <span class="hljs-comment">// 从上一个调度周期停止的地方开始检查节点</span><br>            feasibleNodes[i] = nodes[(sched.nextStartNodeIndex+i)%numAllNodes].Node()<br>        &#125;<br>        <span class="hljs-keyword">return</span> feasibleNodes, <span class="hljs-literal">nil</span><br>    &#125;<br><br>    <span class="hljs-comment">// 用于并行处理时的错误通道</span><br>    errCh := parallelize.NewErrorChannel()<br>    <span class="hljs-keyword">var</span> statusesLock sync.Mutex <span class="hljs-comment">// 用于保护对诊断信息的并发访问</span><br>    <span class="hljs-keyword">var</span> feasibleNodesLen <span class="hljs-type">int32</span> <span class="hljs-comment">// 通过过滤的节点数量</span><br>    ctx, cancel := context.WithCancel(ctx) <span class="hljs-comment">// 创建一个可取消的上下文</span><br>    <span class="hljs-keyword">defer</span> cancel()<br><br>    <span class="hljs-comment">// 检查每个节点是否通过过滤</span><br>    checkNode := <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(i <span class="hljs-type">int</span>)</span></span> &#123;<br>        nodeInfo := nodes[(sched.nextStartNodeIndex+i)%numAllNodes] <span class="hljs-comment">// 获取节点信息</span><br>        status := fwk.RunFilterPluginsWithNominatedPods(ctx, state, pod, nodeInfo) <span class="hljs-comment">// 运行过滤插件</span><br>        <span class="hljs-keyword">if</span> status.Code() == framework.Error &#123;<br>            errCh.SendErrorWithCancel(status.AsError(), cancel) <span class="hljs-comment">// 发送错误并可能取消整个操作</span><br>            <span class="hljs-keyword">return</span><br>        &#125;<br>        <span class="hljs-keyword">if</span> status.IsSuccess() &#123;<br>            <span class="hljs-comment">// 如果节点通过过滤，将其添加到可行节点列表中</span><br>            length := atomic.AddInt32(&amp;feasibleNodesLen, <span class="hljs-number">1</span>)<br>            <span class="hljs-keyword">if</span> length &gt; numNodesToFind &#123;<br>                cancel() <span class="hljs-comment">// 如果找到的节点超过了预定数量，取消剩余的检查</span><br>                atomic.AddInt32(&amp;feasibleNodesLen, <span class="hljs-number">-1</span>)<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                feasibleNodes[length<span class="hljs-number">-1</span>] = nodeInfo.Node()<br>            &#125;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-comment">// 如果节点没有通过过滤，记录其状态</span><br>            statusesLock.Lock()<br>            diagnosis.NodeToStatusMap[nodeInfo.Node().Name] = status<br>            diagnosis.UnschedulablePlugins.Insert(status.FailedPlugin())<br>            statusesLock.Unlock()<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 记录开始检查节点的时间</span><br>    beginCheckNode := time.Now()<br>    statusCode := framework.Success<br>    <span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>        <span class="hljs-comment">// 记录 Filter 扩展点的延迟</span><br>        metrics.FrameworkExtensionPointDuration.WithLabelValues(metrics.Filter, statusCode.String(), fwk.ProfileName()).Observe(metrics.SinceInSeconds(beginCheckNode))<br>    &#125;()<br><br>    <span class="hljs-comment">// 并行检查所有节点，直到找到预定数量的可行节点或检查完所有节点</span><br>    fwk.Parallelizer().Until(ctx, numAllNodes, checkNode, metrics.Filter)<br><br>    <span class="hljs-comment">// 截断可行节点列表到实际找到的节点数量</span><br>    feasibleNodes = feasibleNodes[:feasibleNodesLen]<br>    <span class="hljs-keyword">if</span> err := errCh.ReceiveError(); err != <span class="hljs-literal">nil</span> &#123;<br>        statusCode = framework.Error<br>        <span class="hljs-keyword">return</span> feasibleNodes, err<br>    &#125;<br>    <span class="hljs-keyword">return</span> feasibleNodes, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>注意到这里首先计算了需要筛选的node的数量，这主要是为了在大规模场景下降低筛选的数量，查看其对应的函数，在<code>pkg/scheduler/schedule_one.go:548</code>中，如下，补充了部分注释。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// numFeasibleNodesToFind returns the number of feasible nodes that once found, the scheduler stops</span><br><span class="hljs-comment">// its search for more feasible nodes.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(sched *Scheduler)</span></span> numFeasibleNodesToFind(percentageOfNodesToScore *<span class="hljs-type">int32</span>, numAllNodes <span class="hljs-type">int32</span>) (numNodes <span class="hljs-type">int32</span>) &#123;<br>    <span class="hljs-keyword">if</span> numAllNodes &lt; minFeasibleNodesToFind &#123;<br>        <span class="hljs-comment">// 如果所有节点的数量小于预设的最小可行节点数，则返回所有节点的数量</span><br>        <span class="hljs-keyword">return</span> numAllNodes<br>    &#125;<br><br>    <span class="hljs-comment">// 使用框架（profile）中设置的百分比，如果没有设置，则使用全局的百分比</span><br>    <span class="hljs-keyword">var</span> percentage <span class="hljs-type">int32</span><br>    <span class="hljs-keyword">if</span> percentageOfNodesToScore != <span class="hljs-literal">nil</span> &#123;<br>        percentage = *percentageOfNodesToScore<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        percentage = sched.percentageOfNodesToScore<br>    &#125;<br><br>    <span class="hljs-keyword">if</span> percentage == <span class="hljs-number">0</span> &#123;<br>        <span class="hljs-comment">// 如果没有提供百分比，则使用默认的计算方式</span><br>        percentage = <span class="hljs-type">int32</span>(<span class="hljs-number">50</span>) - numAllNodes/<span class="hljs-number">125</span><br>        <span class="hljs-keyword">if</span> percentage &lt; minFeasibleNodesPercentageToFind &#123;<br>            <span class="hljs-comment">// 确保百分比不低于预设的最小值</span><br>            percentage = minFeasibleNodesPercentageToFind<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 计算基于总节点数和百分比的节点数</span><br>    numNodes = numAllNodes * percentage / <span class="hljs-number">100</span><br>    <span class="hljs-keyword">if</span> numNodes &lt; minFeasibleNodesToFind &#123;<br>        <span class="hljs-comment">// 如果计算出的节点数小于最小可行节点数，则返回最小值</span><br>        <span class="hljs-keyword">return</span> minFeasibleNodesToFind<br>    &#125;<br><br>    <span class="hljs-comment">// 返回计算出的可行节点数</span><br>    <span class="hljs-keyword">return</span> numNodes<br>&#125;<br></code></pre></td></tr></table></figure><p>然后定义了内部的checkNode函数，其输入是要检查的node 的id相对于<code>sched.nextStartNodeIndex</code>的偏移。注意这里使用了k8s内部定义的并行函数fwk.Parallelizer().Until，其定义如下，在<code>pkg/scheduler/framework/parallelize/parallelism.go:56</code>和<code>staging/src/k8s.io/client-go/util/workqueue/parallelizer.go:46</code>中：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Until is a wrapper around workqueue.ParallelizeUntil to use in scheduling algorithms.</span><br><span class="hljs-comment">// A given operation will be a label that is recorded in the goroutine metric.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p Parallelizer)</span></span> Until(ctx context.Context, pieces <span class="hljs-type">int</span>, doWorkPiece workqueue.DoWorkPieceFunc, operation <span class="hljs-type">string</span>) &#123;<br>goroutinesMetric := metrics.Goroutines.WithLabelValues(operation)<br>withMetrics := <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(piece <span class="hljs-type">int</span>)</span></span> &#123;<br>goroutinesMetric.Inc()<br>doWorkPiece(piece)<br>goroutinesMetric.Dec()<br>&#125;<br><br>workqueue.ParallelizeUntil(ctx, p.parallelism, pieces, withMetrics, workqueue.WithChunkSize(chunkSizeFor(pieces, p.parallelism)))<br>&#125;<br><span class="hljs-comment">// ParallelizeUntil is a framework that allows for parallelizing N</span><br><span class="hljs-comment">// independent pieces of work until done or the context is canceled.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ParallelizeUntil</span><span class="hljs-params">(ctx context.Context, workers, pieces <span class="hljs-type">int</span>, doWorkPiece DoWorkPieceFunc, opts ...Options)</span></span> &#123;<br><span class="hljs-keyword">if</span> pieces == <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">return</span><br>&#125;<br>o := options&#123;&#125;<br><span class="hljs-keyword">for</span> _, opt := <span class="hljs-keyword">range</span> opts &#123;<br>opt(&amp;o)<br>&#125;<br>chunkSize := o.chunkSize<br><span class="hljs-keyword">if</span> chunkSize &lt; <span class="hljs-number">1</span> &#123;<br>chunkSize = <span class="hljs-number">1</span><br>&#125;<br><br>chunks := ceilDiv(pieces, chunkSize)<br>toProcess := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>, chunks)<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; chunks; i++ &#123;<br>toProcess &lt;- i<br>&#125;<br><span class="hljs-built_in">close</span>(toProcess)<br><br><span class="hljs-keyword">var</span> stop &lt;-<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;<br><span class="hljs-keyword">if</span> ctx != <span class="hljs-literal">nil</span> &#123;<br>stop = ctx.Done()<br>&#125;<br><span class="hljs-keyword">if</span> chunks &lt; workers &#123;<br>workers = chunks<br>&#125;<br>wg := sync.WaitGroup&#123;&#125;<br>wg.Add(workers)<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; workers; i++ &#123;<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">defer</span> utilruntime.HandleCrash()<br><span class="hljs-keyword">defer</span> wg.Done()<br><span class="hljs-keyword">for</span> chunk := <span class="hljs-keyword">range</span> toProcess &#123;<br>start := chunk * chunkSize<br>end := start + chunkSize<br><span class="hljs-keyword">if</span> end &gt; pieces &#123;<br>end = pieces<br>&#125;<br><span class="hljs-keyword">for</span> p := start; p &lt; end; p++ &#123;<br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> &lt;-stop:<br><span class="hljs-keyword">return</span><br><span class="hljs-keyword">default</span>:<br>doWorkPiece(p)<br>&#125;<br>&#125;<br>&#125;<br>&#125;()<br>&#125;<br>wg.Wait()<br>&#125;<br></code></pre></td></tr></table></figure><p>checkNode函数内部检查对应的node是否能通过所有filter插件的过滤(<code>RunFilterPluginsWithNominatedPods</code>)如果通过就将筛选过的node数量+1，并记录相关的值，同时还会检查是否已经筛选到了足够的node，如果足够了，那么就发送取消信号，停止并行进程，不再继续筛选。</p><p>对于每个node进行筛选的函数<code>RunFilterPluginsWithNominatedPods</code>在<code>pkg/scheduler/framework/runtime/framework.go:816</code>中，如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *frameworkImpl)</span></span> RunFilterPluginsWithNominatedPods(<br>    ctx context.Context, <span class="hljs-comment">// 调度上下文</span><br>    state *framework.CycleState, <span class="hljs-comment">// 当前周期状态</span><br>    pod *v1.Pod, <span class="hljs-comment">// 待调度的 Pod</span><br>    info *framework.NodeInfo, <span class="hljs-comment">// 节点信息</span><br>) *framework.Status &#123;<br>    <span class="hljs-keyword">var</span> status *framework.Status<br><br>    podsAdded := <span class="hljs-literal">false</span><br>  <span class="hljs-comment">// We run filters twice in some cases. If the node has greater or equal priority</span><br><span class="hljs-comment">// nominated pods, we run them when those pods are added to PreFilter state and nodeInfo.</span><br><span class="hljs-comment">// If all filters succeed in this pass, we run them again when these</span><br><span class="hljs-comment">// nominated pods are not added. This second pass is necessary because some</span><br><span class="hljs-comment">// filters such as inter-pod affinity may not pass without the nominated pods.</span><br><span class="hljs-comment">// If there are no nominated pods for the node or if the first run of the</span><br><span class="hljs-comment">// filters fail, we don&#x27;t run the second pass.</span><br><span class="hljs-comment">// We consider only equal or higher priority pods in the first pass, because</span><br><span class="hljs-comment">// those are the current &quot;pod&quot; must yield to them and not take a space opened</span><br><span class="hljs-comment">// for running them. It is ok if the current &quot;pod&quot; take resources freed for</span><br><span class="hljs-comment">// lower priority pods.</span><br><span class="hljs-comment">// Requiring that the new pod is schedulable in both circumstances ensures that</span><br><span class="hljs-comment">// we are making a conservative decision: filters like resources and inter-pod</span><br><span class="hljs-comment">// anti-affinity are more likely to fail when the nominated pods are treated</span><br><span class="hljs-comment">// as running, while filters like pod affinity are more likely to fail when</span><br><span class="hljs-comment">// the nominated pods are treated as not running. We can&#x27;t just assume the</span><br><span class="hljs-comment">// nominated pods are running because they are not running right now and in fact,</span><br><span class="hljs-comment">// they may end up getting scheduled to a different node.</span><br>    <span class="hljs-comment">// 我们可能需要两次运行过滤插件。如果节点上有优先级更高或相等的被提名的 Pods，</span><br>    <span class="hljs-comment">// 我们会在这些 Pods 被添加到 PreFilter 状态和 nodeInfo 时运行它们。</span><br>    <span class="hljs-comment">// 如果所有过滤插件在这一轮通过，我们会在这些被提名的 Pods 没有被添加的情况下再次运行它们。</span><br>    <span class="hljs-comment">// 第二轮运行是必要的，因为一些过滤插件（如 Pod 亲和性）可能在没有被提名的 Pods 的情况下无法通过。</span><br>    <span class="hljs-comment">// 如果节点没有被提名的 Pods 或者第一轮过滤插件失败，我们不会进行第二轮。</span><br>    <span class="hljs-comment">// 我们只考虑第一轮中优先级相等或更高的 Pods，因为当前的 &quot;pod&quot; 必须为它们让路，而不是占用为它们运行而开放的空间。</span><br>    <span class="hljs-comment">// 如果当前的 &quot;pod&quot; 占用了为低优先级 Pods 释放的资源，这是可以的。</span><br>    <span class="hljs-comment">// 要求新的 Pod 在这两种情况下都是可调度的，确保我们做出的是保守的决定：</span><br>    <span class="hljs-comment">// 像资源和 Pod 反亲和性这样的过滤器在将被提名的 Pods 视为运行时更有可能失败，</span><br>    <span class="hljs-comment">// 而像 Pod 亲和性这样的过滤器在将被提名的 Pods 视为未运行时更有可能失败。</span><br>    <span class="hljs-comment">// 我们不能仅仅假设被提名的 Pods 正在运行，因为它们现在并没有运行，事实上，</span><br>    <span class="hljs-comment">// 它们最终可能会被调度到一个不同的节点上。</span><br>    <span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">2</span>; i++ &#123;<br>        stateToUse := state<br>        nodeInfoToUse := info<br>        <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> &#123;<br>            <span class="hljs-comment">// 第一轮：添加被提名的 Pods 到周期状态和节点信息</span><br>            <span class="hljs-keyword">var</span> err <span class="hljs-type">error</span><br>            podsAdded, stateToUse, nodeInfoToUse, err = addNominatedPods(ctx, f, pod, state, info)<br>            <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>                <span class="hljs-keyword">return</span> framework.AsStatus(err)<br>            &#125;<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> !podsAdded || !status.IsSuccess() &#123;<br>            <span class="hljs-keyword">break</span><br>        &#125;<br><br>        <span class="hljs-comment">// 运行过滤插件</span><br>        status = f.RunFilterPlugins(ctx, stateToUse, pod, nodeInfoToUse)<br>        <span class="hljs-keyword">if</span> !status.IsSuccess() &amp;&amp; !status.IsUnschedulable() &#123;<br>            <span class="hljs-keyword">return</span> status<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> status<br>&#125;<br></code></pre></td></tr></table></figure><p>注意到这里执行了两遍筛选，主要是考虑到这个node上面可能存在一些预计要被调度过来的pod，在第一轮中会假设这些pod真的会被调度过来，然后查看是否满足pod筛选需求，在第二列会假设这些pod最后没有被调度过来，然后检查是否满足pod的筛选需求。因为在第一轮中可能会存在反亲和性要求，导致无法通过筛选，在第二轮中可能会存在亲和性要求，导致无法通过筛选，这是一种很保守的筛选方式。</p><p>利用各个插件进行筛选的函数（<code>RunFilterPlugins</code>）在<code>pkg/scheduler/framework/runtime/framework.go:725</code>中，如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// RunFilterPlugins runs the set of configured Filter plugins for pod on</span><br><span class="hljs-comment">// the given node. If any of these plugins doesn&#x27;t return &quot;Success&quot;, the</span><br><span class="hljs-comment">// given node is not suitable for running pod.</span><br><span class="hljs-comment">// Meanwhile, the failure message and status are set for the given node.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *frameworkImpl)</span></span> RunFilterPlugins(<br>ctx context.Context,<br>state *framework.CycleState,<br>pod *v1.Pod,<br>nodeInfo *framework.NodeInfo,<br>) *framework.Status &#123;<br><span class="hljs-keyword">for</span> _, pl := <span class="hljs-keyword">range</span> f.filterPlugins &#123;<br><span class="hljs-keyword">if</span> state.SkipFilterPlugins.Has(pl.Name()) &#123;<br><span class="hljs-keyword">continue</span><br>&#125;<br>metrics.PluginEvaluationTotal.WithLabelValues(pl.Name(), metrics.Filter, f.profileName).Inc()<br><span class="hljs-keyword">if</span> status := f.runFilterPlugin(ctx, pl, state, pod, nodeInfo); !status.IsSuccess() &#123;<br><span class="hljs-keyword">if</span> !status.IsUnschedulable() &#123;<br><span class="hljs-comment">// Filter plugins are not supposed to return any status other than</span><br><span class="hljs-comment">// Success or Unschedulable.</span><br>status = framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;running %q filter plugin: %w&quot;</span>, pl.Name(), status.AsError()))<br>&#125;<br>status.SetFailedPlugin(pl.Name())<br><span class="hljs-keyword">return</span> status<br>&#125;<br>&#125;<br><br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>这里的逻辑很简单，就是遍历各个筛选的插件，依次检查是否符合要求。</p><p>可以继续看<code>runFilterPlugin</code>这运行一个筛选插件进行检查的函数，在pkg&#x2F;scheduler&#x2F;framework&#x2F;runtime&#x2F;framework.go:750中。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *frameworkImpl)</span></span> runFilterPlugin(ctx context.Context, pl framework.FilterPlugin, state *framework.CycleState, pod *v1.Pod, nodeInfo *framework.NodeInfo) *framework.Status &#123;<br><span class="hljs-keyword">if</span> !state.ShouldRecordPluginMetrics() &#123;<br><span class="hljs-keyword">return</span> pl.Filter(ctx, state, pod, nodeInfo)<br>&#125;<br>startTime := time.Now()<br>status := pl.Filter(ctx, state, pod, nodeInfo)<br>f.metricsRecorder.ObservePluginDurationAsync(metrics.Filter, pl.Name(), status.Code().String(), metrics.SinceInSeconds(startTime))<br><span class="hljs-keyword">return</span> status<br>&#125;<br></code></pre></td></tr></table></figure><p>主要也就是调用插件的Filter函数，具体插件的介绍后面再补充。</p><h2 id="打分过程"><a href="#打分过程" class="headerlink" title="打分过程"></a>打分过程</h2><p>打分的函数<code>prioritizeNodes</code> 在<code>pkg/scheduler/schedule_one.go</code> 中，如下，补充了部分注释</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">prioritizeNodes</span><span class="hljs-params">(</span></span><br><span class="hljs-params"><span class="hljs-function">    ctx context.Context,</span></span><br><span class="hljs-params"><span class="hljs-function">    extenders []framework.Extender,</span></span><br><span class="hljs-params"><span class="hljs-function">    fwk framework.Framework,</span></span><br><span class="hljs-params"><span class="hljs-function">    state *framework.CycleState,</span></span><br><span class="hljs-params"><span class="hljs-function">    pod *v1.Pod,</span></span><br><span class="hljs-params"><span class="hljs-function">    nodes []*v1.Node,</span></span><br><span class="hljs-params"><span class="hljs-function">)</span></span> ([]framework.NodePluginScores, <span class="hljs-type">error</span>) &#123;<br>    <span class="hljs-comment">// 如果没有提供优先级配置，则所有节点的分数都设为 1。</span><br>    <span class="hljs-comment">// 这是为了在所需的格式中生成优先级列表</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(extenders) == <span class="hljs-number">0</span> &amp;&amp; !fwk.HasScorePlugins() &#123;<br>        result := <span class="hljs-built_in">make</span>([]framework.NodePluginScores, <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(nodes))<br>        <span class="hljs-keyword">for</span> i := <span class="hljs-keyword">range</span> nodes &#123;<br>            result = <span class="hljs-built_in">append</span>(result, framework.NodePluginScores&#123;<br>                Name:       nodes[i].Name,<br>                TotalScore: <span class="hljs-number">1</span>,<br>            &#125;)<br>        &#125;<br>        <span class="hljs-keyword">return</span> result, <span class="hljs-literal">nil</span><br>    &#125;<br><br>    <span class="hljs-comment">// 运行 PreScore 插件。</span><br>    preScoreStatus := fwk.RunPreScorePlugins(ctx, state, pod, nodes)<br>    <span class="hljs-keyword">if</span> !preScoreStatus.IsSuccess() &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, preScoreStatus.AsError()<br>    &#125;<br><br>    <span class="hljs-comment">// 运行 Score 插件。</span><br>    nodesScores, scoreStatus := fwk.RunScorePlugins(ctx, state, pod, nodes)<br>    <span class="hljs-keyword">if</span> !scoreStatus.IsSuccess() &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, scoreStatus.AsError()<br>    &#125;<br><br>    <span class="hljs-comment">// 如果启用了详细日志记录，记录每个插件对每个节点的打分</span><br>    klogV := klog.V(<span class="hljs-number">10</span>)<br>    <span class="hljs-keyword">if</span> klogV.Enabled() &#123;<br>        <span class="hljs-keyword">for</span> _, nodeScore := <span class="hljs-keyword">range</span> nodesScores &#123;<br>            <span class="hljs-keyword">for</span> _, pluginScore := <span class="hljs-keyword">range</span> nodeScore.Scores &#123;<br>                klogV.InfoS(<span class="hljs-string">&quot;Plugin scored node for pod&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="hljs-string">&quot;plugin&quot;</span>, pluginScore.Name, <span class="hljs-string">&quot;node&quot;</span>, nodeScore.Name, <span class="hljs-string">&quot;score&quot;</span>, pluginScore.Score)<br>            &#125;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 如果有扩展器并且有节点，运行扩展器</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(extenders) != <span class="hljs-number">0</span> &amp;&amp; nodes != <span class="hljs-literal">nil</span> &#123;<br>        allNodeExtendersScores := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]*framework.NodePluginScores, <span class="hljs-built_in">len</span>(nodes))<br>        <span class="hljs-keyword">var</span> mu sync.Mutex<br>        <span class="hljs-keyword">var</span> wg sync.WaitGroup<br>        <span class="hljs-comment">// 并发运行每个扩展器的优先级函数</span><br>        <span class="hljs-keyword">for</span> i := <span class="hljs-keyword">range</span> extenders &#123;<br>            <span class="hljs-keyword">if</span> !extenders[i].IsInterested(pod) &#123;<br>                <span class="hljs-keyword">continue</span><br>            &#125;<br>            wg.Add(<span class="hljs-number">1</span>)<br>            <span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(extIndex <span class="hljs-type">int</span>)</span></span> &#123;<br>                <span class="hljs-keyword">defer</span> wg.Done()<br>                metrics.SchedulerGoroutines.WithLabelValues(metrics.PrioritizingExtender).Inc()<br>                metrics.Goroutines.WithLabelValues(metrics.PrioritizingExtender).Inc()<br>                <span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>                    metrics.SchedulerGoroutines.WithLabelValues(metrics.PrioritizingExtender).Dec()<br>                    metrics.Goroutines.WithLabelValues(metrics.PrioritizingExtender).Dec()<br>                &#125;()<br>                prioritizedList, weight, err := extenders[extIndex].Prioritize(pod, nodes)<br>                <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>                    klog.V(<span class="hljs-number">5</span>).InfoS(<span class="hljs-string">&quot;Failed to run extender&#x27;s priority function. No score given by this extender.&quot;</span>, <span class="hljs-string">&quot;error&quot;</span>, err, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="hljs-string">&quot;extender&quot;</span>, extenders[extIndex].Name())<br>                    <span class="hljs-keyword">return</span><br>                &#125;<br>                mu.Lock()<br>                <span class="hljs-keyword">defer</span> mu.Unlock()<br>                <span class="hljs-keyword">for</span> i := <span class="hljs-keyword">range</span> *prioritizedList &#123;<br>                    nodename := (*prioritizedList)[i].Host<br>                    score := (*prioritizedList)[i].Score<br>                    klogV.InfoS(<span class="hljs-string">&quot;Extender scored node for pod&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="hljs-string">&quot;extender&quot;</span>, extenders[extIndex].Name(), <span class="hljs-string">&quot;node&quot;</span>, nodename, <span class="hljs-string">&quot;score&quot;</span>, score)<br>                    <span class="hljs-comment">// 将扩展器的分数转换为调度器使用的分数范围</span><br>                    finalscore := score * weight * (framework.MaxNodeScore / extenderv1.MaxExtenderPriority)<br>                    <span class="hljs-keyword">if</span> allNodeExtendersScores[nodename] == <span class="hljs-literal">nil</span> &#123;<br>                        allNodeExtendersScores[nodename] = &amp;framework.NodePluginScores&#123;<br>                            Name:   nodename,<br>                            Scores: <span class="hljs-built_in">make</span>([]framework.PluginScore, <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(extenders)),<br>                        &#125;<br>                    &#125;<br>                    allNodeExtendersScores[nodename].Scores = <span class="hljs-built_in">append</span>(allNodeExtendersScores[nodename].Scores, framework.PluginScore&#123;<br>                        Name:  extenders[extIndex].Name(),<br>                        Score: finalscore,<br>                    &#125;)<br>                    allNodeExtendersScores[nodename].TotalScore += finalscore<br>                &#125;<br>            &#125;(i)<br>        &#125;<br>        wg.Wait() <span class="hljs-comment">// 等待所有扩展器完成</span><br>        <span class="hljs-comment">// 将扩展器的分数添加到节点分数中</span><br>        <span class="hljs-keyword">for</span> i := <span class="hljs-keyword">range</span> nodesScores &#123;<br>            <span class="hljs-keyword">if</span> score, ok := allNodeExtendersScores[nodes[i].Name]; ok &#123;<br>                nodesScores[i].Scores = <span class="hljs-built_in">append</span>(nodesScores[i].Scores, score.Scores...)<br>                nodesScores[i].TotalScore += score.TotalScore<br>            &#125;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 记录每个节点的最终分数</span><br>    <span class="hljs-keyword">if</span> klogV.Enabled() &#123;<br>        <span class="hljs-keyword">for</span> i := <span class="hljs-keyword">range</span> nodesScores &#123;<br>            klogV.InfoS(<span class="hljs-string">&quot;Calculated node&#x27;s final score for pod&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="hljs-string">&quot;node&quot;</span>, nodesScores[i].Name, <span class="hljs-string">&quot;score&quot;</span>, nodesScores[i].TotalScore)<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">return</span> nodesScores, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>主要流程包括：</p><ol><li>如果没有提供任何扩展器或打分插件，则为所有节点设置默认分数，并返回。</li><li>运行 PreScore 插件，为打分阶段做准备。</li><li>运行 Score 插件，获取每个节点的分数。</li><li>如果有扩展器并且有节点，则并发运行每个扩展器的优先级函数，获取扩展器为节点分配的分数。</li><li>将扩展器的分数转换为调度器使用的分数范围，并添加到节点分数中。</li><li>记录每个节点的最终分数。</li></ol><p>这里补充一下其记录节点分数的结构体<code>NodePluginScores</code>，在文件<code>pkg/scheduler/framework/interface.go:55</code>中，其定义如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// NodePluginScores is a struct with node name and scores for that node.</span><br><span class="hljs-keyword">type</span> NodePluginScores <span class="hljs-keyword">struct</span> &#123;<br><span class="hljs-comment">// Name is node name.</span><br>Name <span class="hljs-type">string</span><br><span class="hljs-comment">// Scores is scores from plugins and extenders.</span><br>Scores []PluginScore<br><span class="hljs-comment">// TotalScore is the total score in Scores.</span><br>TotalScore <span class="hljs-type">int64</span><br>&#125;<br><br><span class="hljs-comment">// PluginScore is a struct with plugin/extender name and score.</span><br><span class="hljs-keyword">type</span> PluginScore <span class="hljs-keyword">struct</span> &#123;<br><span class="hljs-comment">// Name is the name of plugin or extender.</span><br>Name  <span class="hljs-type">string</span><br>Score <span class="hljs-type">int64</span><br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到每个插件给node打分都是一个int64的类型，一个节点可能会被多个插件进行打分，最后再汇总。</p><p>再回到插件打分，这里我们主要关注关键的打分插件<code>RunScorePlugins</code> ，在<code>pkg/scheduler/framework/runtime/framework.go:931</code>中，如下，补充了部分注释</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *frameworkImpl)</span></span> RunScorePlugins(ctx context.Context, state *framework.CycleState, pod *v1.Pod, nodes []*v1.Node) (ns []framework.NodePluginScores, status *framework.Status) &#123;<br>    startTime := time.Now()<br>    <span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>        <span class="hljs-comment">// 记录打分扩展点的持续时间</span><br>        metrics.FrameworkExtensionPointDuration.WithLabelValues(metrics.Score, status.Code().String(), f.profileName).Observe(metrics.SinceInSeconds(startTime))<br>    &#125;()<br>    allNodePluginScores := <span class="hljs-built_in">make</span>([]framework.NodePluginScores, <span class="hljs-built_in">len</span>(nodes))<br>    numPlugins := <span class="hljs-built_in">len</span>(f.scorePlugins) - state.SkipScorePlugins.Len()<br>    plugins := <span class="hljs-built_in">make</span>([]framework.ScorePlugin, <span class="hljs-number">0</span>, numPlugins)<br>    pluginToNodeScores := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]framework.NodeScoreList, numPlugins)<br>    <span class="hljs-comment">// 为每个插件创建一个节点分数列表</span><br>    <span class="hljs-keyword">for</span> _, pl := <span class="hljs-keyword">range</span> f.scorePlugins &#123;<br>        <span class="hljs-keyword">if</span> state.SkipScorePlugins.Has(pl.Name()) &#123;<br>            <span class="hljs-keyword">continue</span><br>        &#125;<br>        plugins = <span class="hljs-built_in">append</span>(plugins, pl)<br>        pluginToNodeScores[pl.Name()] = <span class="hljs-built_in">make</span>(framework.NodeScoreList, <span class="hljs-built_in">len</span>(nodes))<br>    &#125;<br>    ctx, cancel := context.WithCancel(ctx)<br>    <span class="hljs-keyword">defer</span> cancel()<br>    errCh := parallelize.NewErrorChannel()<br><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(plugins) &gt; <span class="hljs-number">0</span> &#123;<br>        <span class="hljs-comment">// 并行地为每个节点运行每个插件的 Score 方法</span><br>        f.Parallelizer().Until(ctx, <span class="hljs-built_in">len</span>(nodes), <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(index <span class="hljs-type">int</span>)</span></span> &#123;<br>            nodeName := nodes[index].Name<br>            <span class="hljs-keyword">for</span> _, pl := <span class="hljs-keyword">range</span> plugins &#123;<br>                s, status := f.runScorePlugin(ctx, pl, state, pod, nodeName)<br>                <span class="hljs-keyword">if</span> !status.IsSuccess() &#123;<br>                    err := fmt.Errorf(<span class="hljs-string">&quot;plugin %q failed with: %w&quot;</span>, pl.Name(), status.AsError())<br>                    errCh.SendErrorWithCancel(err, cancel)<br>                    <span class="hljs-keyword">return</span><br>                &#125;<br>                pluginToNodeScores[pl.Name()][index] = framework.NodeScore&#123;<br>                    Name:  nodeName,<br>                    Score: s,<br>                &#125;<br>            &#125;<br>        &#125;, metrics.Score)<br>        <span class="hljs-keyword">if</span> err := errCh.ReceiveError(); err != <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;running Score plugins: %w&quot;</span>, err))<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 并行地为每个打分插件运行 NormalizeScore 方法</span><br>    f.Parallelizer().Until(ctx, <span class="hljs-built_in">len</span>(plugins), <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(index <span class="hljs-type">int</span>)</span></span> &#123;<br>        pl := plugins[index]<br>        <span class="hljs-keyword">if</span> pl.ScoreExtensions() == <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-keyword">return</span><br>        &#125;<br>        nodeScoreList := pluginToNodeScores[pl.Name()]<br>        status := f.runScoreExtension(ctx, pl, state, pod, nodeScoreList)<br>        <span class="hljs-keyword">if</span> !status.IsSuccess() &#123;<br>            err := fmt.Errorf(<span class="hljs-string">&quot;plugin %q failed with: %w&quot;</span>, pl.Name(), status.AsError())<br>            errCh.SendErrorWithCancel(err, cancel)<br>            <span class="hljs-keyword">return</span><br>        &#125;<br>    &#125;, metrics.Score)<br>    <span class="hljs-keyword">if</span> err := errCh.ReceiveError(); err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;running Normalize on Score plugins: %w&quot;</span>, err))<br>    &#125;<br><br>    <span class="hljs-comment">// 并行地为每个打分插件应用分数权重，并构建 allNodePluginScores</span><br>    f.Parallelizer().Until(ctx, <span class="hljs-built_in">len</span>(nodes), <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(index <span class="hljs-type">int</span>)</span></span> &#123;<br>        nodePluginScores := framework.NodePluginScores&#123;<br>            Name:   nodes[index].Name,<br>            Scores: <span class="hljs-built_in">make</span>([]framework.PluginScore, <span class="hljs-built_in">len</span>(plugins)),<br>        &#125;<br><br>        <span class="hljs-keyword">for</span> i, pl := <span class="hljs-keyword">range</span> plugins &#123;<br>            weight := f.scorePluginWeight[pl.Name()]<br>            nodeScoreList := pluginToNodeScores[pl.Name()]<br>            score := nodeScoreList[index].Score<br><br>            <span class="hljs-keyword">if</span> score &gt; framework.MaxNodeScore || score &lt; framework.MinNodeScore &#123;<br>                err := fmt.Errorf(<span class="hljs-string">&quot;plugin %q returns an invalid score %v, it should in the range of [%v, %v] after normalizing&quot;</span>, pl.Name(), score, framework.MinNodeScore, framework.MaxNodeScore)<br>                errCh.SendErrorWithCancel(err, cancel)<br>                <span class="hljs-keyword">return</span><br>            &#125;<br>            weightedScore := score * <span class="hljs-type">int64</span>(weight)<br>            nodePluginScores.Scores[i] = framework.PluginScore&#123;<br>                Name:  pl.Name(),<br>                Score: weightedScore,<br>            &#125;<br>            nodePluginScores.TotalScore += weightedScore<br>        &#125;<br>        allNodePluginScores[index] = nodePluginScores<br>    &#125;, metrics.Score)<br>    <span class="hljs-keyword">if</span> err := errCh.ReceiveError(); err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;applying score defaultWeights on Score plugins: %w&quot;</span>, err))<br>    &#125;<br><br>    <span class="hljs-comment">// 返回所有节点的插件分数</span><br>    <span class="hljs-keyword">return</span> allNodePluginScores, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>主要流程包括：</p><ol><li>为每个插件创建一个节点分数列表。</li><li>使用并行处理为每个节点运行每个插件的 <code>Score</code> 方法。</li><li>为每个插件运行 <code>NormalizeScore</code> 方法，以标准化分数。</li><li>应用每个插件的分数权重，构建最终的节点分数。</li><li>返回各个节点的分数</li></ol><p>查看插件打分的函数runScorePlugin，在<code>pkg/scheduler/framework/runtime/framework.go:1025</code> 中，如下。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *frameworkImpl)</span></span> runScorePlugin(ctx context.Context, pl framework.ScorePlugin, state *framework.CycleState, pod *v1.Pod, nodeName <span class="hljs-type">string</span>) (<span class="hljs-type">int64</span>, *framework.Status) &#123;<br><span class="hljs-keyword">if</span> !state.ShouldRecordPluginMetrics() &#123;<br><span class="hljs-keyword">return</span> pl.Score(ctx, state, pod, nodeName)<br>&#125;<br>startTime := time.Now()<br>s, status := pl.Score(ctx, state, pod, nodeName)<br>f.metricsRecorder.ObservePluginDurationAsync(metrics.Score, pl.Name(), status.Code().String(), metrics.SinceInSeconds(startTime))<br><span class="hljs-keyword">return</span> s, status<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到主要是调用插件的Score方法。</p><h1 id="一般调度的后期处理"><a href="#一般调度的后期处理" class="headerlink" title="一般调度的后期处理"></a>一般调度的后期处理</h1><h2 id="PostFilter插件"><a href="#PostFilter插件" class="headerlink" title="PostFilter插件"></a>PostFilter插件</h2><p>在<code>schedulingCycle</code>中可以看到如果上述的一般调度没有为Pod找到合适的node，并且错误不是没有合适的node，即<code>ErrNoNodesAvailable</code> 的话，就会检查是否存在有PostFilterPlugins，如果有就运行，即运行<code>RunPostFilterPlugins</code>函数，来进行相关的处理，例如释放一些资源，从而希望使得该pod在下一次调度时有机会成功调度，当然这被释放的资源也可能被其他不同的pod给占用了，但是这对系统是无害的，所以也不管。</p><p>该<code>RunPostFilterPlugins</code>函数在<code>pkg/scheduler/framework/runtime/framework.go:762</code>中，如下所示</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// RunPostFilterPlugins runs the set of configured PostFilter plugins until the first</span><br><span class="hljs-comment">// Success, Error or UnschedulableAndUnresolvable is met; otherwise continues to execute all plugins.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *frameworkImpl)</span></span> RunPostFilterPlugins(ctx context.Context, state *framework.CycleState, pod *v1.Pod, filteredNodeStatusMap framework.NodeToStatusMap) (_ *framework.PostFilterResult, status *framework.Status) &#123;<br>startTime := time.Now()<br><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>metrics.FrameworkExtensionPointDuration.WithLabelValues(metrics.PostFilter, status.Code().String(), f.profileName).Observe(metrics.SinceInSeconds(startTime))<br>&#125;()<br><br><span class="hljs-comment">// `result` records the last meaningful(non-noop) PostFilterResult.</span><br><span class="hljs-keyword">var</span> result *framework.PostFilterResult<br><span class="hljs-keyword">var</span> reasons []<span class="hljs-type">string</span><br><span class="hljs-keyword">var</span> failedPlugin <span class="hljs-type">string</span><br><span class="hljs-keyword">for</span> _, pl := <span class="hljs-keyword">range</span> f.postFilterPlugins &#123;<br>r, s := f.runPostFilterPlugin(ctx, pl, state, pod, filteredNodeStatusMap)<br><span class="hljs-keyword">if</span> s.IsSuccess() &#123;<br><span class="hljs-keyword">return</span> r, s<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> s.Code() == framework.UnschedulableAndUnresolvable &#123;<br><span class="hljs-keyword">return</span> r, s.WithFailedPlugin(pl.Name())<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> !s.IsUnschedulable() &#123;<br><span class="hljs-comment">// Any status other than Success, Unschedulable or UnschedulableAndUnresolvable is Error.</span><br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, framework.AsStatus(s.AsError()).WithFailedPlugin(pl.Name())<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> r != <span class="hljs-literal">nil</span> &amp;&amp; r.Mode() != framework.ModeNoop &#123;<br>result = r<br>&#125;<br><br>reasons = <span class="hljs-built_in">append</span>(reasons, s.Reasons()...)<br><span class="hljs-comment">// Record the first failed plugin unless we proved that</span><br><span class="hljs-comment">// the latter is more relevant.</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(failedPlugin) == <span class="hljs-number">0</span> &#123;<br>failedPlugin = pl.Name()<br>&#125;<br>&#125;<br><br><span class="hljs-keyword">return</span> result, framework.NewStatus(framework.Unschedulable, reasons...).WithFailedPlugin(failedPlugin)<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到他就是遍历了所有的postFilter插件，然后使用函数<code>runPostFilterPlugin</code>运行这些插件，其在<code>pkg/scheduler/framework/runtime/framework.go:796</code>中</p><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs pf">func (f *frameworkImpl) runPostFilterPlugin(ctx context.Context, pl framework.PostFilterPlugin, <span class="hljs-keyword">state</span> *framework.CycleState, pod *v1.Pod, filteredNodeStatusMap framework.NodeToStatusMap) (*framework.PostFilterResult, *framework.Status) &#123;<br>if !<span class="hljs-keyword">state</span>.ShouldRecordPluginMetrics() &#123;<br>return pl.PostFilter(ctx, <span class="hljs-keyword">state</span>, pod, filteredNodeStatusMap)<br>&#125;<br>startTime := time.Now()<br>r, s := pl.PostFilter(ctx, <span class="hljs-keyword">state</span>, pod, filteredNodeStatusMap)<br>f.metricsRecorder.ObservePluginDurationAsync(metrics.PostFilter, pl.Name(), s.Code().String(), metrics.SinceInSeconds(startTime))<br>return r, s<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Reserve插件"><a href="#Reserve插件" class="headerlink" title="Reserve插件"></a>Reserve插件</h2><p>得到想要调度到的pod后，可能需要执行一些资源预留的操作，就需要定义在reserve插件中，该插件对应的调用函数为RunReservePluginsReserve，在<code>pkg/scheduler/framework/runtime/framework.go:1144</code> 中</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// RunReservePluginsReserve runs the Reserve method in the set of configured</span><br><span class="hljs-comment">// reserve plugins. If any of these plugins returns an error, it does not</span><br><span class="hljs-comment">// continue running the remaining ones and returns the error. In such a case,</span><br><span class="hljs-comment">// the pod will not be scheduled and the caller will be expected to call</span><br><span class="hljs-comment">// RunReservePluginsUnreserve.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *frameworkImpl)</span></span> RunReservePluginsReserve(ctx context.Context, state *framework.CycleState, pod *v1.Pod, nodeName <span class="hljs-type">string</span>) (status *framework.Status) &#123;<br>startTime := time.Now()<br><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>metrics.FrameworkExtensionPointDuration.WithLabelValues(metrics.Reserve, status.Code().String(), f.profileName).Observe(metrics.SinceInSeconds(startTime))<br>&#125;()<br><span class="hljs-keyword">for</span> _, pl := <span class="hljs-keyword">range</span> f.reservePlugins &#123;<br>status = f.runReservePluginReserve(ctx, pl, state, pod, nodeName)<br><span class="hljs-keyword">if</span> !status.IsSuccess() &#123;<br>err := status.AsError()<br>klog.ErrorS(err, <span class="hljs-string">&quot;Failed running Reserve plugin&quot;</span>, <span class="hljs-string">&quot;plugin&quot;</span>, pl.Name(), <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod))<br><span class="hljs-keyword">return</span> framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;running Reserve plugin %q: %w&quot;</span>, pl.Name(), err))<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>这里也是遍历所有的reserve插件，如果有任意一个插件失败了那么就失败了。单个插件的调用函数在<code>pkg/scheduler/framework/runtime/framework.go:1160</code>中，如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *frameworkImpl)</span></span> runReservePluginReserve(ctx context.Context, pl framework.ReservePlugin, state *framework.CycleState, pod *v1.Pod, nodeName <span class="hljs-type">string</span>) *framework.Status &#123;<br><span class="hljs-keyword">if</span> !state.ShouldRecordPluginMetrics() &#123;<br><span class="hljs-keyword">return</span> pl.Reserve(ctx, state, pod, nodeName)<br>&#125;<br>startTime := time.Now()<br>status := pl.Reserve(ctx, state, pod, nodeName)<br>f.metricsRecorder.ObservePluginDurationAsync(metrics.Reserve, pl.Name(), status.Code().String(), metrics.SinceInSeconds(startTime))<br><span class="hljs-keyword">return</span> status<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Permit插件"><a href="#Permit插件" class="headerlink" title="Permit插件"></a>Permit插件</h2><p>找到了要调度的pod后还需要运行permit插件，该插件主要用来查看记录是否还需要等待一下其他操作，例如抢占某个pod的资源，那么就需要等待被抢占pod的资源释放掉。</p><p>该插件对应的函数<code>RunPermitPlugins</code> 在<code>pkg/scheduler/framework/runtime/framework.go:1200</code>中，如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// RunPermitPlugins runs the set of configured permit plugins. If any of these</span><br><span class="hljs-comment">// plugins returns a status other than &quot;Success&quot; or &quot;Wait&quot;, it does not continue</span><br><span class="hljs-comment">// running the remaining plugins and returns an error. Otherwise, if any of the</span><br><span class="hljs-comment">// plugins returns &quot;Wait&quot;, then this function will create and add waiting pod</span><br><span class="hljs-comment">// to a map of currently waiting pods and return status with &quot;Wait&quot; code.</span><br><span class="hljs-comment">// Pod will remain waiting pod for the minimum duration returned by the permit plugins.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *frameworkImpl)</span></span> RunPermitPlugins(ctx context.Context, state *framework.CycleState, pod *v1.Pod, nodeName <span class="hljs-type">string</span>) (status *framework.Status) &#123;<br>    startTime := time.Now() <span class="hljs-comment">// 记录permit插件开始运行的时间</span><br>    <span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>        <span class="hljs-comment">// 记录permit插件的运行时间和最终状态</span><br>        metrics.FrameworkExtensionPointDuration.WithLabelValues(metrics.Permit, status.Code().String(), f.profileName).Observe(metrics.SinceInSeconds(startTime))<br>    &#125;()<br>    pluginsWaitTime := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]time.Duration) <span class="hljs-comment">// 存储每个插件的等待时间</span><br>    statusCode := framework.Success <span class="hljs-comment">// 初始化状态码为成功</span><br>    <span class="hljs-keyword">for</span> _, pl := <span class="hljs-keyword">range</span> f.permitPlugins &#123;<br>        <span class="hljs-comment">// 运行当前permit插件</span><br>        status, timeout := f.runPermitPlugin(ctx, pl, state, pod, nodeName)<br>        <span class="hljs-keyword">if</span> !status.IsSuccess() &#123;<br>            <span class="hljs-keyword">if</span> status.IsUnschedulable() &#123;<br>                <span class="hljs-comment">// 如果插件返回不可调度的状态，则记录日志并返回该状态</span><br>                klog.V(<span class="hljs-number">4</span>).InfoS(<span class="hljs-string">&quot;Pod rejected by permit plugin&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="hljs-string">&quot;plugin&quot;</span>, pl.Name(), <span class="hljs-string">&quot;status&quot;</span>, status.Message())<br>                status.SetFailedPlugin(pl.Name()) <span class="hljs-comment">// 设置失败的插件名称</span><br>                <span class="hljs-keyword">return</span> status<br>            &#125;<br>            <span class="hljs-keyword">if</span> status.IsWait() &#123;<br>                <span class="hljs-comment">// 如果插件返回等待的状态，则记录等待时间，但不立即返回</span><br>                <span class="hljs-comment">// 允许的最长等待时间由 maxTimeout 限制</span><br>                <span class="hljs-keyword">if</span> timeout &gt; maxTimeout &#123;<br>                    timeout = maxTimeout<br>                &#125;<br>                pluginsWaitTime[pl.Name()] = timeout<br>                statusCode = framework.Wait <span class="hljs-comment">// 更新状态码为等待</span><br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-comment">// 如果插件返回错误状态，则记录错误日志并返回错误状态</span><br>                err := status.AsError()<br>                klog.ErrorS(err, <span class="hljs-string">&quot;Failed running Permit plugin&quot;</span>, <span class="hljs-string">&quot;plugin&quot;</span>, pl.Name(), <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod))<br>                <span class="hljs-keyword">return</span> framework.AsStatus(fmt.Errorf(<span class="hljs-string">&quot;running Permit plugin %q: %w&quot;</span>, pl.Name(), err)).WithFailedPlugin(pl.Name())<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">if</span> statusCode == framework.Wait &#123;<br>        <span class="hljs-comment">// 如果任何插件返回等待状态，则创建并添加等待中的 Pod 到映射中，并返回等待状态</span><br>        waitingPod := newWaitingPod(pod, pluginsWaitTime)<br>        f.waitingPods.add(waitingPod)<br>        msg := fmt.Sprintf(<span class="hljs-string">&quot;one or more plugins asked to wait and no plugin rejected pod %q&quot;</span>, pod.Name)<br>        klog.V(<span class="hljs-number">4</span>).InfoS(<span class="hljs-string">&quot;One or more plugins asked to wait and no plugin rejected pod&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod))<br>        <span class="hljs-keyword">return</span> framework.NewStatus(framework.Wait, msg)<br>    &#125;<br>    <span class="hljs-comment">// 如果所有插件都成功或返回等待，且没有插件拒绝 Pod，则返回 nil 表示没有错误</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>主要流程包括：</p><ol><li>记录开始运行许可插件的时间。</li><li>使用 <code>defer</code> 语句确保无论函数如何结束，都记录许可插件的运行时间和状态。</li><li>遍历所有的permit插件。</li><li>运行当前插件，并将结果状态保存到 <code>status</code>。</li><li>检查状态：<ul><li>如果状态是成功的，则继续运行下一个插件。</li><li>如果状态是不可调度的，则记录日志并返回该状态。</li><li>如果状态是等待的，则记录等待时间，并更新状态码为等待，然后继续运行下一个插件。</li><li>如果状态是错误，则记录错误日志，并返回错误状态。</li></ul></li><li>如果任何插件返回等待状态，则创建等待中的 Pod 并添加到映射中，然后返回等待状态。</li><li>如果所有插件都成功或返回等待，且没有插件拒绝 Pod，则返回 <code>nil</code>。</li></ol>]]></content>
    
    
    <categories>
      
      <category>k8s</category>
      
      <category>源码分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>k8s</tag>
      
      <tag>源码分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【K8s源码分析（二）】-K8s调度队列介绍</title>
    <link href="/2024/05/10/k8sSource2/"/>
    <url>/2024/05/10/k8sSource2/</url>
    
    <content type="html"><![CDATA[<p>本次分析参考的K8s版本是<a href="https://github.com/kubernetes/kubernetes/tree/release-1.27">v1.27.0</a>。</p><h1 id="调度队列简介"><a href="#调度队列简介" class="headerlink" title="调度队列简介"></a>调度队列简介</h1><p>这里是官方对于K8s中调度队列的介绍，很值得一看：<a href="https://github.com/kubernetes/community/blob/f03b6d5692bd979f07dd472e7b6836b2dad0fd9b/contributors/devel/sig-scheduling/scheduler_queues.md">Scheduling queue in kube-scheduler</a>。整体的架构如下图所示。</p><p><img src="/2024/05/10/k8sSource2/scheduling_queues.png" alt="调度队列"></p><p>简单来说K8s中的调度队列主要有3种：</p><ul><li><strong>ActiveQ</strong>（heap结构）：在每个调度周期开始时都会从这里取出一个Pod尝试调度。一开始提交的所有没有指定<code>.spec.nodeName</code>的Pod都会发送到这里，也会接收来自unschedulableQ和BackoffQ刷新来的pod。默认的排序规则是按照优先级进行排列，高优先级的Pod在前面。</li><li><strong>UnschedulableQ</strong>（Map结构）：存储调度失败的Pod，以等待资源更新、其他相关Pod调度成功等事件，从而将其的Pod其进行重调度。</li><li><strong>BackoffQ</strong>（heap结构）：用来暂时退避的队列，默认的排列规则是按退避时间的长度进行排序，需要退避的时间短的Pod在前面。为了防止Pod频繁的重调度，每个Pod都会记录自己的重调度次数，退避时间随着每次失败的调度尝试呈指数增长，直到达到最大值，例如尝试失败 3 次的 Pod 的目标退避超时设置为 curTime + 2s^3 (8s)。注意有两种情况下Pod会进入到BackoffQ队列中：<ul><li>unscheduleableQ会定时对其中的所有pod进行重调度，那么就需要计算各个pod是否退避了足够的时间，如果没有就放入到BackoffQ中再退避一段时间。</li><li>如果一个Pod调度失败时，正好这时又异步地发生了资源变更事件（<code>p.moveRequestCycle **&gt;=** podSchedulingCycle</code> ）(<code>schedulingCycle</code> 是当前调度的周期，ActiveQ队列每pop一个pod，就加1，<code>moveRequestCycle</code>是事件发生时<code>schedulingCycle</code> 的值），那么就不会放入UnschedulableQ中，而是会直接放入到BackoffQ中。</li></ul></li></ul><p>调度队列机制有两个在后台运行的定期刷新 go协程，负责将 pod 移动到活动队列，后续也将详细介绍相关代码：</p><ul><li><strong>flushUnschedulablePodsLeftover：</strong>每 30 秒运行一次，将 Pod 从UnschedulableQ中移动，以允许未由任何事件移动的不可调度的 Pod 再次重试。</li><li><strong>flushBackoffQCompleted：</strong>每1秒运行一次，将BackoffQ中已经回避了足够久的Pod移动到ActiveQ队列中</li></ul><p>移动请求（move request）会触发一个事件，该事件负责将 Pod 从UnschedulableQ移动到ActiveQ或BackoffQ。集群中许多事件可以触发移动请求的发生，包括了 Pod、节点、服务、PV、PVC、存储类和 CSI 节点的更改。例如当某些pod被调度时，UnschedulableQ中与其具有亲和性要求而导致之前无法调度的pod就会被移动出去，或者当某个新node加入时，原本因为资源不够导致无法调度的Pod也会被移动出去。</p><h1 id="调度队列源代码分析"><a href="#调度队列源代码分析" class="headerlink" title="调度队列源代码分析"></a>调度队列源代码分析</h1><h2 id="队列初始化"><a href="#队列初始化" class="headerlink" title="队列初始化"></a>队列初始化</h2><p>Scheduler中的调度队列<code>SchedulingQueue</code>为<code>internalqueue.SchedulingQueue</code>类型，该类型的实现在pkg&#x2F;scheduler&#x2F;internal&#x2F;queue&#x2F;scheduling_queue.go:92，如下。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// SchedulingQueue is an interface for a queue to store pods waiting to be scheduled.</span><br><span class="hljs-comment">// The interface follows a pattern similar to cache.FIFO and cache.Heap and</span><br><span class="hljs-comment">// makes it easy to use those data structures as a SchedulingQueue.</span><br><span class="hljs-keyword">type</span> SchedulingQueue <span class="hljs-keyword">interface</span> &#123;<br>framework.PodNominator<br>Add(pod *v1.Pod) <span class="hljs-type">error</span><br><span class="hljs-comment">// Activate moves the given pods to activeQ iff they&#x27;re in unschedulablePods or backoffQ.</span><br><span class="hljs-comment">// The passed-in pods are originally compiled from plugins that want to activate Pods,</span><br><span class="hljs-comment">// by injecting the pods through a reserved CycleState struct (PodsToActivate).</span><br>Activate(pods <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]*v1.Pod)<br><span class="hljs-comment">// AddUnschedulableIfNotPresent adds an unschedulable pod back to scheduling queue.</span><br><span class="hljs-comment">// The podSchedulingCycle represents the current scheduling cycle number which can be</span><br><span class="hljs-comment">// returned by calling SchedulingCycle().</span><br>AddUnschedulableIfNotPresent(pod *framework.QueuedPodInfo, podSchedulingCycle <span class="hljs-type">int64</span>) <span class="hljs-type">error</span><br><span class="hljs-comment">// SchedulingCycle returns the current number of scheduling cycle which is</span><br><span class="hljs-comment">// cached by scheduling queue. Normally, incrementing this number whenever</span><br><span class="hljs-comment">// a pod is popped (e.g. called Pop()) is enough.</span><br>SchedulingCycle() <span class="hljs-type">int64</span><br><span class="hljs-comment">// Pop removes the head of the queue and returns it. It blocks if the</span><br><span class="hljs-comment">// queue is empty and waits until a new item is added to the queue.</span><br>Pop() (*framework.QueuedPodInfo, <span class="hljs-type">error</span>)<br>Update(oldPod, newPod *v1.Pod) <span class="hljs-type">error</span><br>Delete(pod *v1.Pod) <span class="hljs-type">error</span><br>MoveAllToActiveOrBackoffQueue(event framework.ClusterEvent, preCheck PreEnqueueCheck)<br>AssignedPodAdded(pod *v1.Pod)<br>AssignedPodUpdated(pod *v1.Pod)<br>PendingPods() ([]*v1.Pod, <span class="hljs-type">string</span>)<br><span class="hljs-comment">// Close closes the SchedulingQueue so that the goroutine which is</span><br><span class="hljs-comment">// waiting to pop items can exit gracefully.</span><br>Close()<br><span class="hljs-comment">// Run starts the goroutines managing the queue.</span><br>Run()<br>&#125;<br></code></pre></td></tr></table></figure><p>上述代码定义了其需要的对队列中的元素添加、删除、更新、获取、运行等方法。而其标准实现<code>PriorityQueue</code> 在</p><p> <code>pkg/scheduler/internal/queue/scheduling_queue.go:145</code> 中，首先查看其需要的变量：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// PriorityQueue implements a scheduling queue.</span><br><span class="hljs-comment">// The head of PriorityQueue is the highest priority pending pod. This structure</span><br><span class="hljs-comment">// has two sub queues and a additional data structure, namely: activeQ,</span><br><span class="hljs-comment">// backoffQ and unschedulablePods.</span><br><span class="hljs-comment">//   - activeQ holds pods that are being considered for scheduling.</span><br><span class="hljs-comment">//   - backoffQ holds pods that moved from unschedulablePods and will move to</span><br><span class="hljs-comment">//     activeQ when their backoff periods complete.</span><br><span class="hljs-comment">//   - unschedulablePods holds pods that were already attempted for scheduling and</span><br><span class="hljs-comment">//     are currently determined to be unschedulable.</span><br><span class="hljs-keyword">type</span> PriorityQueue <span class="hljs-keyword">struct</span> &#123;<br>*nominator<br><br>stop  <span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;<br>clock clock.Clock<br><br><span class="hljs-comment">// pod initial backoff duration.</span><br>podInitialBackoffDuration time.Duration<br><span class="hljs-comment">// pod maximum backoff duration.</span><br>podMaxBackoffDuration time.Duration<br><span class="hljs-comment">// the maximum time a pod can stay in the unschedulablePods.</span><br>podMaxInUnschedulablePodsDuration time.Duration<br><br>cond sync.Cond<br><br><span class="hljs-comment">// activeQ is heap structure that scheduler actively looks at to find pods to</span><br><span class="hljs-comment">// schedule. Head of heap is the highest priority pod.</span><br>activeQ *heap.Heap<br><span class="hljs-comment">// podBackoffQ is a heap ordered by backoff expiry. Pods which have completed backoff</span><br><span class="hljs-comment">// are popped from this heap before the scheduler looks at activeQ</span><br>podBackoffQ *heap.Heap<br><span class="hljs-comment">// unschedulablePods holds pods that have been tried and determined unschedulable.</span><br>unschedulablePods *UnschedulablePods<br><span class="hljs-comment">// schedulingCycle represents sequence number of scheduling cycle and is incremented</span><br><span class="hljs-comment">// when a pod is popped.</span><br>schedulingCycle <span class="hljs-type">int64</span><br><span class="hljs-comment">// moveRequestCycle caches the sequence number of scheduling cycle when we</span><br><span class="hljs-comment">// received a move request. Unschedulable pods in and before this scheduling</span><br><span class="hljs-comment">// cycle will be put back to activeQueue if we were trying to schedule them</span><br><span class="hljs-comment">// when we received move request.</span><br>moveRequestCycle <span class="hljs-type">int64</span><br><br>clusterEventMap <span class="hljs-keyword">map</span>[framework.ClusterEvent]sets.String<br><span class="hljs-comment">// preEnqueuePluginMap is keyed with profile name, valued with registered preEnqueue plugins.</span><br>preEnqueuePluginMap <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>][]framework.PreEnqueuePlugin<br><br><span class="hljs-comment">// closed indicates that the queue is closed.</span><br><span class="hljs-comment">// It is mainly used to let Pop() exit its control loop while waiting for an item.</span><br>closed <span class="hljs-type">bool</span><br><br>nsLister listersv1.NamespaceLister<br><br>metricsRecorder metrics.MetricAsyncRecorder<br><span class="hljs-comment">// pluginMetricsSamplePercent is the percentage of plugin metrics to be sampled.</span><br>pluginMetricsSamplePercent <span class="hljs-type">int</span><br>&#125;<br></code></pre></td></tr></table></figure><p>在<code>pkg/scheduler/internal/queue/scheduling_queue.go:291</code>  中给出了生成了该队列的初始化方法</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// NewPriorityQueue creates a PriorityQueue object.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewPriorityQueue</span><span class="hljs-params">(</span></span><br><span class="hljs-params"><span class="hljs-function">lessFn framework.LessFunc,</span></span><br><span class="hljs-params"><span class="hljs-function">informerFactory informers.SharedInformerFactory,</span></span><br><span class="hljs-params"><span class="hljs-function">opts ...Option,</span></span><br><span class="hljs-params"><span class="hljs-function">)</span></span> *PriorityQueue &#123;<br>options := defaultPriorityQueueOptions<br><span class="hljs-keyword">if</span> options.podLister == <span class="hljs-literal">nil</span> &#123;<br>options.podLister = informerFactory.Core().V1().Pods().Lister()<br>&#125;<br><span class="hljs-keyword">for</span> _, opt := <span class="hljs-keyword">range</span> opts &#123;<br>opt(&amp;options)<br>&#125;<br><br>comp := <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(podInfo1, podInfo2 <span class="hljs-keyword">interface</span>&#123;&#125;)</span></span> <span class="hljs-type">bool</span> &#123;<br>pInfo1 := podInfo1.(*framework.QueuedPodInfo)<br>pInfo2 := podInfo2.(*framework.QueuedPodInfo)<br><span class="hljs-keyword">return</span> lessFn(pInfo1, pInfo2)<br>&#125;<br><br>pq := &amp;PriorityQueue&#123;<br>nominator:                         newPodNominator(options.podLister),<br>clock:                             options.clock,<br>stop:                              <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;),<br>podInitialBackoffDuration:         options.podInitialBackoffDuration,<br>podMaxBackoffDuration:             options.podMaxBackoffDuration,<br>podMaxInUnschedulablePodsDuration: options.podMaxInUnschedulablePodsDuration,<br>activeQ:                           heap.NewWithRecorder(podInfoKeyFunc, comp, metrics.NewActivePodsRecorder()),<br>unschedulablePods:                 newUnschedulablePods(metrics.NewUnschedulablePodsRecorder(), metrics.NewGatedPodsRecorder()),<br>moveRequestCycle:                  <span class="hljs-number">-1</span>,<br>clusterEventMap:                   options.clusterEventMap,<br>preEnqueuePluginMap:               options.preEnqueuePluginMap,<br>metricsRecorder:                   options.metricsRecorder,<br>pluginMetricsSamplePercent:        options.pluginMetricsSamplePercent,<br>&#125;<br>pq.cond.L = &amp;pq.lock<br>pq.podBackoffQ = heap.NewWithRecorder(podInfoKeyFunc, pq.podsCompareBackoffCompleted, metrics.NewBackoffPodsRecorder())<br>pq.nsLister = informerFactory.Core().V1().Namespaces().Lister()<br><br><span class="hljs-keyword">return</span> pq<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到其包含了许多我们上面介绍的概念，包括<code>activeQ</code> 、<code>unschedulablePods</code> 、<code>podBackoffQ</code> 、<code>schedulingCycle</code> 、<code>moveRequestCycle</code>  。</p><h2 id="QueuedPodInfo元素介绍"><a href="#QueuedPodInfo元素介绍" class="headerlink" title="QueuedPodInfo元素介绍"></a>QueuedPodInfo元素介绍</h2><p>这里也多次出现了<code>QueuedPodInfo</code>这个关键的数据结构，它是Pod中的基础元素，在此进行介绍，其定义在<code>pkg/scheduler/framework/types.go:98</code> 中，包括了PodInfo、添加时间、尝试次数等</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// QueuedPodInfo is a Pod wrapper with additional information related to</span><br><span class="hljs-comment">// the pod&#x27;s status in the scheduling queue, such as the timestamp when</span><br><span class="hljs-comment">// it&#x27;s added to the queue.</span><br><span class="hljs-keyword">type</span> QueuedPodInfo <span class="hljs-keyword">struct</span> &#123;<br>*PodInfo<br><span class="hljs-comment">// The time pod added to the scheduling queue.</span><br>Timestamp time.Time<br><span class="hljs-comment">// Number of schedule attempts before successfully scheduled.</span><br><span class="hljs-comment">// It&#x27;s used to record the # attempts metric.</span><br>Attempts <span class="hljs-type">int</span><br><span class="hljs-comment">// The time when the pod is added to the queue for the first time. The pod may be added</span><br><span class="hljs-comment">// back to the queue multiple times before it&#x27;s successfully scheduled.</span><br><span class="hljs-comment">// It shouldn&#x27;t be updated once initialized. It&#x27;s used to record the e2e scheduling</span><br><span class="hljs-comment">// latency for a pod.</span><br>InitialAttemptTimestamp time.Time<br><span class="hljs-comment">// If a Pod failed in a scheduling cycle, record the plugin names it failed by.</span><br>UnschedulablePlugins sets.String<br><span class="hljs-comment">// Whether the Pod is scheduling gated (by PreEnqueuePlugins) or not.</span><br>Gated <span class="hljs-type">bool</span><br>&#125;<br></code></pre></td></tr></table></figure><p>PodInfo的定义在<code>pkg/scheduler/framework/types.go:131</code></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// PodInfo is a wrapper to a Pod with additional pre-computed information to</span><br><span class="hljs-comment">// accelerate processing. This information is typically immutable (e.g., pre-processed</span><br><span class="hljs-comment">// inter-pod affinity selectors).</span><br><span class="hljs-keyword">type</span> PodInfo <span class="hljs-keyword">struct</span> &#123;<br>Pod                        *v1.Pod<br>RequiredAffinityTerms      []AffinityTerm<br>RequiredAntiAffinityTerms  []AffinityTerm<br>PreferredAffinityTerms     []WeightedAffinityTerm<br>PreferredAntiAffinityTerms []WeightedAffinityTerm<br>&#125;<br></code></pre></td></tr></table></figure><p>Pod的定义在<code>staging/src/k8s.io/api/core/v1/types.go:4202</code>中</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Pod is a collection of containers that can run on a host. This resource is created</span><br><span class="hljs-comment">// by clients and scheduled onto hosts.</span><br><span class="hljs-keyword">type</span> Pod <span class="hljs-keyword">struct</span> &#123;<br>metav1.TypeMeta <span class="hljs-string">`json:&quot;,inline&quot;`</span><br><span class="hljs-comment">// Standard object&#x27;s metadata.</span><br><span class="hljs-comment">// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata</span><br><span class="hljs-comment">// +optional</span><br>metav1.ObjectMeta <span class="hljs-string">`json:&quot;metadata,omitempty&quot; protobuf:&quot;bytes,1,opt,name=metadata&quot;`</span><br><br><span class="hljs-comment">// Specification of the desired behavior of the pod.</span><br><span class="hljs-comment">// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status</span><br><span class="hljs-comment">// +optional</span><br>Spec PodSpec <span class="hljs-string">`json:&quot;spec,omitempty&quot; protobuf:&quot;bytes,2,opt,name=spec&quot;`</span><br><br><span class="hljs-comment">// Most recently observed status of the pod.</span><br><span class="hljs-comment">// This data may not be up to date.</span><br><span class="hljs-comment">// Populated by the system.</span><br><span class="hljs-comment">// Read-only.</span><br><span class="hljs-comment">// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status</span><br><span class="hljs-comment">// +optional</span><br>Status PodStatus <span class="hljs-string">`json:&quot;status,omitempty&quot; protobuf:&quot;bytes,3,opt,name=status&quot;`</span><br>&#125;<br></code></pre></td></tr></table></figure><h2 id="ActiveQ源代码介绍"><a href="#ActiveQ源代码介绍" class="headerlink" title="ActiveQ源代码介绍"></a>ActiveQ源代码介绍</h2><p>从初始化代码中可以看到ActiveQ是一个heap，其相关定义在<code>pkg/scheduler/internal/heap/heap.go</code> 中</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Heap is a producer/consumer queue that implements a heap data structure.</span><br><span class="hljs-comment">// It can be used to implement priority queues and similar data structures.</span><br><span class="hljs-keyword">type</span> Heap <span class="hljs-keyword">struct</span> &#123;<br><span class="hljs-comment">// data stores objects and has a queue that keeps their ordering according</span><br><span class="hljs-comment">// to the heap invariant.</span><br>data *data<br><span class="hljs-comment">// metricRecorder updates the counter when elements of a heap get added or</span><br><span class="hljs-comment">// removed, and it does nothing if it&#x27;s nil</span><br>metricRecorder metrics.MetricRecorder<br>&#125;<br><span class="hljs-comment">// data is an internal struct that implements the standard heap interface</span><br><span class="hljs-comment">// and keeps the data stored in the heap.</span><br><span class="hljs-keyword">type</span> data <span class="hljs-keyword">struct</span> &#123;<br><span class="hljs-comment">// items is a map from key of the objects to the objects and their index.</span><br><span class="hljs-comment">// We depend on the property that items in the map are in the queue and vice versa.</span><br>items <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]*heapItem<br><span class="hljs-comment">// queue implements a heap data structure and keeps the order of elements</span><br><span class="hljs-comment">// according to the heap invariant. The queue keeps the keys of objects stored</span><br><span class="hljs-comment">// in &quot;items&quot;.</span><br>queue []<span class="hljs-type">string</span><br><br><span class="hljs-comment">// keyFunc is used to make the key used for queued item insertion and retrieval, and</span><br><span class="hljs-comment">// should be deterministic.</span><br>keyFunc KeyFunc<br><span class="hljs-comment">// lessFunc is used to compare two objects in the heap.</span><br>lessFunc lessFunc<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到他是用queue实现了一个heap。</p><p>ActiveQ的默认排序代码在<code>pkg/scheduler/framework/plugins/queuesort/priority_sort.go:42</code>中,即按优先级进行排序，如果优先级相同就提交时间的早晚进行排序。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Less is the function used by the activeQ heap algorithm to sort pods.</span><br><span class="hljs-comment">// It sorts pods based on their priority. When priorities are equal, it uses</span><br><span class="hljs-comment">// PodQueueInfo.timestamp.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pl *PrioritySort)</span></span> Less(pInfo1, pInfo2 *framework.QueuedPodInfo) <span class="hljs-type">bool</span> &#123;<br>p1 := corev1helpers.PodPriority(pInfo1.Pod)<br>p2 := corev1helpers.PodPriority(pInfo2.Pod)<br><span class="hljs-keyword">return</span> (p1 &gt; p2) || (p1 == p2 &amp;&amp; pInfo1.Timestamp.Before(pInfo2.Timestamp))<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="UnschedulableQ源代码介绍"><a href="#UnschedulableQ源代码介绍" class="headerlink" title="UnschedulableQ源代码介绍"></a>UnschedulableQ源代码介绍</h2><p>UnschedulableQ进行初始化的具体代码在<code>pkg/scheduler/internal/queue/scheduling_queue.go:998</code></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// newUnschedulablePods initializes a new object of UnschedulablePods.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">newUnschedulablePods</span><span class="hljs-params">(unschedulableRecorder, gatedRecorder metrics.MetricRecorder)</span></span> *UnschedulablePods &#123;<br><span class="hljs-keyword">return</span> &amp;UnschedulablePods&#123;<br>podInfoMap:            <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]*framework.QueuedPodInfo),<br>keyFunc:               util.GetPodFullName,<br>unschedulableRecorder: unschedulableRecorder,<br>gatedRecorder:         gatedRecorder,<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>其具体的定义代码在<code>pkg/scheduler/internal/queue/scheduling_queue.go:939</code> ,</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// UnschedulablePods holds pods that cannot be scheduled. This data structure</span><br><span class="hljs-comment">// is used to implement unschedulablePods.</span><br><span class="hljs-keyword">type</span> UnschedulablePods <span class="hljs-keyword">struct</span> &#123;<br><span class="hljs-comment">// podInfoMap is a map key by a pod&#x27;s full-name and the value is a pointer to the QueuedPodInfo.</span><br>podInfoMap <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]*framework.QueuedPodInfo<br>keyFunc    <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(*v1.Pod)</span></span> <span class="hljs-type">string</span><br><span class="hljs-comment">// unschedulableRecorder/gatedRecorder updates the counter when elements of an unschedulablePodsMap</span><br><span class="hljs-comment">// get added or removed, and it does nothing if it&#x27;s nil.</span><br>unschedulableRecorder, gatedRecorder metrics.MetricRecorder<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到他没有进行heap的包装，而是直接采用Map结构进行保存。</p><h2 id="BackoffQ源代码介绍"><a href="#BackoffQ源代码介绍" class="headerlink" title="BackoffQ源代码介绍"></a><strong>BackoffQ</strong>源代码介绍</h2><p>BackoffQ也是一个heap，与ActiveQ不同的一点在于排序函数不同，其排序函数的定义在<code>pkg/scheduler/internal/queue/scheduling_queue.go:888</code> </p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p *PriorityQueue)</span></span> podsCompareBackoffCompleted(podInfo1, podInfo2 <span class="hljs-keyword">interface</span>&#123;&#125;) <span class="hljs-type">bool</span> &#123;<br>pInfo1 := podInfo1.(*framework.QueuedPodInfo)<br>pInfo2 := podInfo2.(*framework.QueuedPodInfo)<br>bo1 := p.getBackoffTime(pInfo1)<br>bo2 := p.getBackoffTime(pInfo2)<br><span class="hljs-keyword">return</span> bo1.Before(bo2)<br>&#125;<br></code></pre></td></tr></table></figure><p><code>getBackoffTime</code>的定义在<code>pkg/scheduler/internal/queue/scheduling_queue.go:911</code>中，即计算完成避让的时间</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// getBackoffTime returns the time that podInfo completes backoff</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p *PriorityQueue)</span></span> getBackoffTime(podInfo *framework.QueuedPodInfo) time.Time &#123;<br>duration := p.calculateBackoffDuration(podInfo)<br>backoffTime := podInfo.Timestamp.Add(duration)<br><span class="hljs-keyword">return</span> backoffTime<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到队列排序时会将完成避让最早的pod放在前面。</p><p>然后再看其是如何计算避让时间的，在<code>pkg/scheduler/internal/queue/scheduling_queue.go</code> 中</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// calculateBackoffDuration is a helper function for calculating the backoffDuration</span><br><span class="hljs-comment">// based on the number of attempts the pod has made.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p *PriorityQueue)</span></span> calculateBackoffDuration(podInfo *framework.QueuedPodInfo) time.Duration &#123;<br>duration := p.podInitialBackoffDuration<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">1</span>; i &lt; podInfo.Attempts; i++ &#123;<br><span class="hljs-comment">// Use subtraction instead of addition or multiplication to avoid overflow.</span><br><span class="hljs-keyword">if</span> duration &gt; p.podMaxBackoffDuration-duration &#123;<br><span class="hljs-keyword">return</span> p.podMaxBackoffDuration<br>&#125;<br>duration += duration<br>&#125;<br><span class="hljs-keyword">return</span> duration<br>&#125;<br></code></pre></td></tr></table></figure><p>其计算可以理解为初次为<code>p.podInitialBackoffDuration</code>，每次需要的避让时间都是前一次的两倍，如果计算得到的避让时间大于<code>p.podMaxBackoffDuration/2</code> ，就将避让时间设置为<code>p.podMaxBackoffDuration</code> 。</p><h2 id="队列弹出待调度的Pod"><a href="#队列弹出待调度的Pod" class="headerlink" title="队列弹出待调度的Pod"></a>队列弹出待调度的Pod</h2><p>其代码在<code>pkg/scheduler/internal/queue/scheduling_queue.go:593</code> 中</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Pop removes the head of the active queue and returns it. It blocks if the</span><br><span class="hljs-comment">// activeQ is empty and waits until a new item is added to the queue. It</span><br><span class="hljs-comment">// increments scheduling cycle when a pod is popped.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p *PriorityQueue)</span></span> Pop() (*framework.QueuedPodInfo, <span class="hljs-type">error</span>) &#123;<br>p.lock.Lock()<br><span class="hljs-keyword">defer</span> p.lock.Unlock()<br><span class="hljs-keyword">for</span> p.activeQ.Len() == <span class="hljs-number">0</span> &#123;<br><span class="hljs-comment">// When the queue is empty, invocation of Pop() is blocked until new item is enqueued.</span><br><span class="hljs-comment">// When Close() is called, the p.closed is set and the condition is broadcast,</span><br><span class="hljs-comment">// which causes this loop to continue and return from the Pop().</span><br><span class="hljs-keyword">if</span> p.closed &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, fmt.Errorf(queueClosed)<br>&#125;<br>p.cond.Wait()<br>&#125;<br>obj, err := p.activeQ.Pop()<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>&#125;<br>pInfo := obj.(*framework.QueuedPodInfo)<br>pInfo.Attempts++<br>p.schedulingCycle++<br><span class="hljs-keyword">return</span> pInfo, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到如果activeQ中没有需要调度的Pod了那么就会使用<code>p.cond.Wait</code>来进行等待，否则就冲<code>activeQ</code>中Pop一个元素<code>QueuedPodInfo</code>，同时这个<code>QueuedPodInfo</code> 的Attempts会+1，整个队列中的schedulingCycle也会增加。</p><h2 id="队列增加新的待调度的Pod"><a href="#队列增加新的待调度的Pod" class="headerlink" title="队列增加新的待调度的Pod"></a>队列增加新的待调度的Pod</h2><p>其代码在<code>pkg/scheduler/internal/queue/scheduling_queue.go:398</code>中</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Add adds a pod to the active queue. It should be called only when a new pod</span><br><span class="hljs-comment">// is added so there is no chance the pod is already in active/unschedulable/backoff queues</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p *PriorityQueue)</span></span> Add(pod *v1.Pod) <span class="hljs-type">error</span> &#123;<br>p.lock.Lock()<br><span class="hljs-keyword">defer</span> p.lock.Unlock()<br><br>pInfo := p.newQueuedPodInfo(pod)<br>gated := pInfo.Gated<br><span class="hljs-keyword">if</span> added, err := p.addToActiveQ(pInfo); !added &#123;<br><span class="hljs-keyword">return</span> err<br>&#125;<br><span class="hljs-keyword">if</span> p.unschedulablePods.get(pod) != <span class="hljs-literal">nil</span> &#123;<br>klog.ErrorS(<span class="hljs-literal">nil</span>, <span class="hljs-string">&quot;Error: pod is already in the unschedulable queue&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod))<br>p.unschedulablePods.<span class="hljs-built_in">delete</span>(pod, gated)<br>&#125;<br><span class="hljs-comment">// Delete pod from backoffQ if it is backing off</span><br><span class="hljs-keyword">if</span> err := p.podBackoffQ.Delete(pInfo); err == <span class="hljs-literal">nil</span> &#123;<br>klog.ErrorS(<span class="hljs-literal">nil</span>, <span class="hljs-string">&quot;Error: pod is already in the podBackoff queue&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod))<br>&#125;<br>klog.V(<span class="hljs-number">5</span>).InfoS(<span class="hljs-string">&quot;Pod moved to an internal scheduling queue&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="hljs-string">&quot;event&quot;</span>, PodAdd, <span class="hljs-string">&quot;queue&quot;</span>, activeQName)<br>metrics.SchedulerQueueIncomingPods.WithLabelValues(<span class="hljs-string">&quot;active&quot;</span>, PodAdd).Inc()<br>p.addNominatedPodUnlocked(pInfo.PodInfo, <span class="hljs-literal">nil</span>)<br>p.cond.Broadcast()<br><br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>主要是将要加入的<code>pod</code>转化为<code>QueuedPodInfo</code>类型，然后添加到<code>activeQ</code>队列中，还需要检查其他队列中是否有这个pod，如果有就删除，同时做一些日志相关记录，然后还会调用<code>p.cond.Broadcast()</code>来解除上述提到的<code>p.cond.Wait</code> 的等待。</p><h2 id="pod调度失败返回队列的处理"><a href="#pod调度失败返回队列的处理" class="headerlink" title="pod调度失败返回队列的处理"></a>pod调度失败返回队列的处理</h2><p>当Pod调度失败后，会调用来<code>AddUnschedulableIfNotPresent</code>函数来进行处理，其代码位置在<code>pkg/scheduler/internal/queue/scheduling_queue.go</code> 中。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// AddUnschedulableIfNotPresent inserts a pod that cannot be scheduled into</span><br><span class="hljs-comment">// the queue, unless it is already in the queue. Normally, PriorityQueue puts</span><br><span class="hljs-comment">// unschedulable pods in `unschedulablePods`. But if there has been a recent move</span><br><span class="hljs-comment">// request, then the pod is put in `podBackoffQ`.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p *PriorityQueue)</span></span> AddUnschedulableIfNotPresent(pInfo *framework.QueuedPodInfo, podSchedulingCycle <span class="hljs-type">int64</span>) <span class="hljs-type">error</span> &#123;<br>p.lock.Lock()<br><span class="hljs-keyword">defer</span> p.lock.Unlock()<br>pod := pInfo.Pod<br><span class="hljs-keyword">if</span> p.unschedulablePods.get(pod) != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;Pod %v is already present in unschedulable queue&quot;</span>, klog.KObj(pod))<br>&#125;<br><br><span class="hljs-keyword">if</span> _, exists, _ := p.activeQ.Get(pInfo); exists &#123;<br><span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;Pod %v is already present in the active queue&quot;</span>, klog.KObj(pod))<br>&#125;<br><span class="hljs-keyword">if</span> _, exists, _ := p.podBackoffQ.Get(pInfo); exists &#123;<br><span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;Pod %v is already present in the backoff queue&quot;</span>, klog.KObj(pod))<br>&#125;<br><br><span class="hljs-comment">// Refresh the timestamp since the pod is re-added.</span><br>pInfo.Timestamp = p.clock.Now()<br><br><span class="hljs-comment">// If a move request has been received, move it to the BackoffQ, otherwise move</span><br><span class="hljs-comment">// it to unschedulablePods.</span><br><span class="hljs-keyword">for</span> plugin := <span class="hljs-keyword">range</span> pInfo.UnschedulablePlugins &#123;<br>metrics.UnschedulableReason(plugin, pInfo.Pod.Spec.SchedulerName).Inc()<br>&#125;<br><span class="hljs-keyword">if</span> p.moveRequestCycle &gt;= podSchedulingCycle &#123;<br><span class="hljs-keyword">if</span> err := p.podBackoffQ.Add(pInfo); err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;error adding pod %v to the backoff queue: %v&quot;</span>, klog.KObj(pod), err)<br>&#125;<br>klog.V(<span class="hljs-number">5</span>).InfoS(<span class="hljs-string">&quot;Pod moved to an internal scheduling queue&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="hljs-string">&quot;event&quot;</span>, ScheduleAttemptFailure, <span class="hljs-string">&quot;queue&quot;</span>, backoffQName)<br>metrics.SchedulerQueueIncomingPods.WithLabelValues(<span class="hljs-string">&quot;backoff&quot;</span>, ScheduleAttemptFailure).Inc()<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>p.unschedulablePods.addOrUpdate(pInfo)<br>klog.V(<span class="hljs-number">5</span>).InfoS(<span class="hljs-string">&quot;Pod moved to an internal scheduling queue&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="hljs-string">&quot;event&quot;</span>, ScheduleAttemptFailure, <span class="hljs-string">&quot;queue&quot;</span>, unschedulablePods)<br>metrics.SchedulerQueueIncomingPods.WithLabelValues(<span class="hljs-string">&quot;unschedulable&quot;</span>, ScheduleAttemptFailure).Inc()<br><br>&#125;<br><br>p.addNominatedPodUnlocked(pInfo.PodInfo, <span class="hljs-literal">nil</span>)<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>这里首先检查了其他队列中是否含有该pod，如果有就返回错误，然后比较<code>moveRequestCycle</code> 和<code>podSchedulingCycle</code> ，如果<code>p.moveRequestCycle &gt;= podSchedulingCycle</code>  那就说明在刚刚调度这个pod的时候集群发生了变化，可能现在可以成功调度这个pod了，将其转入backoffQ中，不然就正常加入unschedulableQ中。</p><h2 id="flushBackoffQCompleted"><a href="#flushBackoffQCompleted" class="headerlink" title="flushBackoffQCompleted"></a>flushBackoffQCompleted</h2><p>在队列运行时会初始化两个go协程，来分别不停检查<code>backoffQ</code>和<code>unschedulableQ</code>，以及时将相关的Pod移出。代码在<code>pkg/scheduler/internal/queue/scheduling_queue.go:333</code> 中</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Run starts the goroutine to pump from podBackoffQ to activeQ</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p *PriorityQueue)</span></span> Run() &#123;<br><span class="hljs-keyword">go</span> wait.Until(p.flushBackoffQCompleted, <span class="hljs-number">1.0</span>*time.Second, p.stop)<br><span class="hljs-keyword">go</span> wait.Until(p.flushUnschedulablePodsLeftover, <span class="hljs-number">30</span>*time.Second, p.stop)<br>&#125;<br></code></pre></td></tr></table></figure><p>对于<code>flushBackoffQCompleted</code>即是每1s运行一次，直到接收到<code>p.stop</code>信息。对<code>flushBackoffQCompleted</code> 函数的具体定义在<code>pkg/scheduler/internal/queue/scheduling_queue.go:537</code>中，如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// flushBackoffQCompleted Moves all pods from backoffQ which have completed backoff in to activeQ</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p *PriorityQueue)</span></span> flushBackoffQCompleted() &#123;<br>p.lock.Lock()<br><span class="hljs-keyword">defer</span> p.lock.Unlock()<br>activated := <span class="hljs-literal">false</span><br><span class="hljs-keyword">for</span> &#123;<br>rawPodInfo := p.podBackoffQ.Peek()<br><span class="hljs-keyword">if</span> rawPodInfo == <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">break</span><br>&#125;<br>pInfo := rawPodInfo.(*framework.QueuedPodInfo)<br>pod := pInfo.Pod<br><span class="hljs-keyword">if</span> p.isPodBackingoff(pInfo) &#123;<br><span class="hljs-keyword">break</span><br>&#125;<br>_, err := p.podBackoffQ.Pop()<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>klog.ErrorS(err, <span class="hljs-string">&quot;Unable to pop pod from backoff queue despite backoff completion&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod))<br><span class="hljs-keyword">break</span><br>&#125;<br><span class="hljs-keyword">if</span> err := p.activeQ.Add(pInfo); err != <span class="hljs-literal">nil</span> &#123;<br>klog.ErrorS(err, <span class="hljs-string">&quot;Error adding pod to the active queue&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pInfo.Pod))<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>klog.V(<span class="hljs-number">5</span>).InfoS(<span class="hljs-string">&quot;Pod moved to an internal scheduling queue&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="hljs-string">&quot;event&quot;</span>, BackoffComplete, <span class="hljs-string">&quot;queue&quot;</span>, activeQName)<br>metrics.SchedulerQueueIncomingPods.WithLabelValues(<span class="hljs-string">&quot;active&quot;</span>, BackoffComplete).Inc()<br>activated = <span class="hljs-literal">true</span><br>&#125;<br>&#125;<br><br><span class="hljs-keyword">if</span> activated &#123;<br>p.cond.Broadcast()<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>其主要内容就是从<code>backOffQ</code>的首个元素开始查看，检查器是否已经过了避让时间，如果过了就将其放入到<code>activeQ</code>队列中，直到首个元素没有达到避让时间或者队列为空。</p><h2 id="flushUnschedulablePodsLeftover"><a href="#flushUnschedulablePodsLeftover" class="headerlink" title="flushUnschedulablePodsLeftover"></a>flushUnschedulablePodsLeftover</h2><p><code>flushUnschedulablePodsLeftover</code>每30s运行一次，这部分的代码在<code>pkg/scheduler/internal/queue/scheduling_queue.go:572</code>中，如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// flushUnschedulablePodsLeftover moves pods which stay in unschedulablePods</span><br><span class="hljs-comment">// longer than podMaxInUnschedulablePodsDuration to backoffQ or activeQ.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p *PriorityQueue)</span></span> flushUnschedulablePodsLeftover() &#123;<br>p.lock.Lock()<br><span class="hljs-keyword">defer</span> p.lock.Unlock()<br><br><span class="hljs-keyword">var</span> podsToMove []*framework.QueuedPodInfo<br>currentTime := p.clock.Now()<br><span class="hljs-keyword">for</span> _, pInfo := <span class="hljs-keyword">range</span> p.unschedulablePods.podInfoMap &#123;<br>lastScheduleTime := pInfo.Timestamp<br><span class="hljs-keyword">if</span> currentTime.Sub(lastScheduleTime) &gt; p.podMaxInUnschedulablePodsDuration &#123;<br>podsToMove = <span class="hljs-built_in">append</span>(podsToMove, pInfo)<br>&#125;<br>&#125;<br><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(podsToMove) &gt; <span class="hljs-number">0</span> &#123;<br>p.movePodsToActiveOrBackoffQueue(podsToMove, UnschedulableTimeout)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到其主要作用是遍历所有的pod，如果其在unschedulableQ中呆的时间如果超过了最大的p.podMaxInUnschedulablePodsDuration时间，就会将其移出去，至于是移动到activeQ中还是移动到backoffQ中，取决于movePodsToActiveOrBackoffQueue函数，在<code>pkg/scheduler/internal/queue/scheduling_queue.go:771</code>中，如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// <span class="hljs-doctag">NOTE:</span> this function assumes lock has been acquired in caller</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p *PriorityQueue)</span></span> movePodsToActiveOrBackoffQueue(podInfoList []*framework.QueuedPodInfo, event framework.ClusterEvent) &#123;<br>activated := <span class="hljs-literal">false</span><br><span class="hljs-keyword">for</span> _, pInfo := <span class="hljs-keyword">range</span> podInfoList &#123;<br><span class="hljs-comment">// If the event doesn&#x27;t help making the Pod schedulable, continue.</span><br><span class="hljs-comment">// Note: we don&#x27;t run the check if pInfo.UnschedulablePlugins is nil, which denotes</span><br><span class="hljs-comment">// either there is some abnormal error, or scheduling the pod failed by plugins other than PreFilter, Filter and Permit.</span><br><span class="hljs-comment">// In that case, it&#x27;s desired to move it anyways.</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(pInfo.UnschedulablePlugins) != <span class="hljs-number">0</span> &amp;&amp; !p.podMatchesEvent(pInfo, event) &#123;<br><span class="hljs-keyword">continue</span><br>&#125;<br>pod := pInfo.Pod<br><span class="hljs-keyword">if</span> p.isPodBackingoff(pInfo) &#123;<br><span class="hljs-keyword">if</span> err := p.podBackoffQ.Add(pInfo); err != <span class="hljs-literal">nil</span> &#123;<br>klog.ErrorS(err, <span class="hljs-string">&quot;Error adding pod to the backoff queue&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pod))<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>klog.V(<span class="hljs-number">5</span>).InfoS(<span class="hljs-string">&quot;Pod moved to an internal scheduling queue&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pInfo.Pod), <span class="hljs-string">&quot;event&quot;</span>, event, <span class="hljs-string">&quot;queue&quot;</span>, backoffQName)<br>metrics.SchedulerQueueIncomingPods.WithLabelValues(<span class="hljs-string">&quot;backoff&quot;</span>, event.Label).Inc()<br>p.unschedulablePods.<span class="hljs-built_in">delete</span>(pod, pInfo.Gated)<br>&#125;<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>gated := pInfo.Gated<br><span class="hljs-keyword">if</span> added, _ := p.addToActiveQ(pInfo); added &#123;<br>klog.V(<span class="hljs-number">5</span>).InfoS(<span class="hljs-string">&quot;Pod moved to an internal scheduling queue&quot;</span>, <span class="hljs-string">&quot;pod&quot;</span>, klog.KObj(pInfo.Pod), <span class="hljs-string">&quot;event&quot;</span>, event, <span class="hljs-string">&quot;queue&quot;</span>, activeQName)<br>activated = <span class="hljs-literal">true</span><br>metrics.SchedulerQueueIncomingPods.WithLabelValues(<span class="hljs-string">&quot;active&quot;</span>, event.Label).Inc()<br>p.unschedulablePods.<span class="hljs-built_in">delete</span>(pod, gated)<br>&#125;<br>&#125;<br>&#125;<br>p.moveRequestCycle = p.schedulingCycle<br><span class="hljs-keyword">if</span> activated &#123;<br>p.cond.Broadcast()<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>注意这个函数不仅仅是在<code>flushUnschedulablePodsLeftover</code>中被调用，还会在处理其他移动请求时触发，只不过这里的移动请求是<code>UnschedulableTimeout</code> ，判断到底是如何移动也很容易从代码中看出，如果已经到达了避让时间，就加入到<code>activeQ</code>中，如果没有就加入到<code>backoffQ</code>中，注意到如果有移动进<code>activeQ</code>中，也是需要执行<code>p.cond.Broadcast()</code>，同时注意到这里更新了<code>moveRequestCycle</code>为<code>schedulingCycle</code>，这也是其统一更新<code>moveRequestCycle</code> 的地方。</p><h1 id="调度队列总结"><a href="#调度队列总结" class="headerlink" title="调度队列总结"></a>调度队列总结</h1><p>考虑到调度队列的细节，我们可以用下图来对其进行归纳回顾。</p><p><img src="/2024/05/10/k8sSource2/summary.png" alt="调度队列总结"></p>]]></content>
    
    
    <categories>
      
      <category>k8s</category>
      
      <category>源码分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>k8s</tag>
      
      <tag>源码分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【K8s源码分析（一）】-K8s调度框架及调度器初始化介绍</title>
    <link href="/2024/05/10/k8sSource1/"/>
    <url>/2024/05/10/k8sSource1/</url>
    
    <content type="html"><![CDATA[<p>本次分析参考的K8s版本是<a href="https://github.com/kubernetes/kubernetes/tree/release-1.27">v1.27.0</a>。</p><h1 id="调度框架介绍"><a href="#调度框架介绍" class="headerlink" title="调度框架介绍"></a>调度框架介绍</h1><p>这是官方对于<strong>v1.27</strong>调度框架的介绍文档：<a href="https://v1-27.docs.kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework/">https://v1-27.docs.kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework/</a></p><p>将调度器的实现转化为插件的形式有助于加强调度器的拓展性、灵活性，同时也使得调度核心的实现更加的轻量、可维护。</p><p>下图展示了Pod的调度上下文以及调度框架暴露的扩展点。图中“Filter”相当于“Predicate”，“Scoring”相当于“Priority function”。</p><p><img src="/2024/05/10/k8sSource1/scheduling-framework-extensions.png" alt="Scheduling framework extension points"></p><p>总体而言，首先新创建的Pod或还没有调度的Pod会存在队列中，然后经过调度周期的筛选得到符合条件的Node，然后在调度周期内再对各个符合条件的Node进行打分，最高分的Node就是需要调度到的Node，然后经过绑定周期将Pod放置到Node上。</p><p>各个拓展点的具体介绍建议参考上面提到的官方介绍文档，这里不再赘述。</p><h1 id="K8s-scheduler-介绍"><a href="#K8s-scheduler-介绍" class="headerlink" title="K8s scheduler 介绍"></a>K8s scheduler 介绍</h1><p>首先需要明确的一个点，K8s中的scheduler是以pod的形式运行在系统中的，通过如下的命令能找到其对应的pod。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># kubectl get pod -n kube-system</span><br>NAME                                       READY   STATUS             RESTARTS         AGE<br>...<br>kube-scheduler-master                      1/1     Running            0                2d4h<br>...<br></code></pre></td></tr></table></figure><p>Pod中的容器会存在一个scheduler程序并一直在前台运行，接收要调度的pod并给出调度结果。本文主要分析的也就是这个scheduler程序所对应的源代码。</p><p>这是官方对K8s scheduler代码层次结构的介绍文档：<a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-scheduling/scheduling_code_hierarchy_overview.md">Scheduler code hierarchy overview</a>。也很推荐观看！</p><p>整体的关键代码的结构如下所示：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">.<br>├── cmd<br>│   └── kube-<span class="hljs-keyword">scheduler</span><br><span class="hljs-keyword"></span>│       └── app - 控制器代码位置以及命令行接口参数定义（遵循所有Kubernetes控制器的标准设置）<br>├── pkg<br>│   └── <span class="hljs-keyword">scheduler </span>- 默认调度器代码库的根目录<br>│       ├── core - 默认调度算法的位置<br>│       ├── framework - 调度框架及其插件<br>│       └── internal - 缓存、队列和其他内部元素的实现<br>├── staging<br>│   └── src<br>│       └── k8s.io<br>│           └── kube-<span class="hljs-keyword">scheduler </span>- ComponentConfig API类型的所在位置<br>└── test<br>    ├── e2e<br>    │   └── <span class="hljs-keyword">scheduling </span>- 端到端调度测试<br>    │<br>    ├── integration<br>        ├── <span class="hljs-keyword">scheduler </span>- 调度器集成测试<br>        └── <span class="hljs-keyword">scheduler_perf </span>- 调度性能基准测试<br></code></pre></td></tr></table></figure><h1 id="K8s-scheduler的初始化"><a href="#K8s-scheduler的初始化" class="headerlink" title="K8s scheduler的初始化"></a>K8s scheduler的初始化</h1><h2 id="Cobra介绍"><a href="#Cobra介绍" class="headerlink" title="Cobra介绍"></a>Cobra介绍</h2><p>K8s中大部分组件其实都采用的是<a href="https://github.com/spf13/cobra">Cobra</a>结构。Cobra是一个用于创建现代命令行应用程序的库，云原生中很多项目都采用了它，包括<a href="https://kubernetes.io/">Kubernetes</a>、<a href="https://gohugo.io/">Hugo、</a><a href="https://github.com/cli/cli">GitHub CLI</a>等，目前都有36.2k个start了。而K8s中的scheduler实际上也是通过Cobra构建的。</p><p>Cobra的具体介绍可以参见<a href="https://xie.infoq.cn/article/915006cf3760c99ad0028d895">万字长文——Go 语言现代命令行框架 Cobra 详解</a>。</p><p>这边以一个小demo为例进行简单介绍。一个demo项目定义了一个名为hugo的命令行工具，代码如下所示：</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs maxima">.<br>├── cmd<br>│   ├── root.<span class="hljs-built_in">go</span><br>│   └── version.<span class="hljs-built_in">go</span><br>├── <span class="hljs-built_in">go</span>.<span class="hljs-built_in">mod</span><br>├── <span class="hljs-built_in">go</span>.<span class="hljs-built_in">sum</span><br>└── main.<span class="hljs-built_in">go</span><br></code></pre></td></tr></table></figure><p><code>main.go</code>的内容如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;hugo/cmd&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>cmd.Execute()<br>&#125;<br></code></pre></td></tr></table></figure><p><code>root.go</code>的内容如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> cmd<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-string">&quot;os&quot;</span><br><br><span class="hljs-string">&quot;github.com/spf13/cobra&quot;</span><br>)<br><br><span class="hljs-keyword">var</span> rootCmd = &amp;cobra.Command&#123;<br>Use:   <span class="hljs-string">&quot;hugo&quot;</span>,<br>Short: <span class="hljs-string">&quot;Hugo is a very fast static site generator&quot;</span>,<br>Long: <span class="hljs-string">`A Fast and Flexible Static Site Generator built with</span><br><span class="hljs-string">  love by spf13 and friends in Go.</span><br><span class="hljs-string">  Complete documentation is available at https://gohugo.io`</span>,<br>RunE: <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(cmd *cobra.Command, args []<span class="hljs-type">string</span>)</span></span> <span class="hljs-type">error</span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;run hugo...&quot;</span>)<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;,<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Execute</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">if</span> err := rootCmd.Execute(); err != <span class="hljs-literal">nil</span> &#123;<br>fmt.Println(err)<br>os.Exit(<span class="hljs-number">1</span>)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>version.go</code>的内容如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> cmd<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;fmt&quot;</span><br><br><span class="hljs-string">&quot;github.com/spf13/cobra&quot;</span><br>)<br><br><span class="hljs-keyword">var</span> versionCmd = &amp;cobra.Command&#123;<br>Use:   <span class="hljs-string">&quot;version&quot;</span>,<br>Short: <span class="hljs-string">&quot;Print the version number of Hugo&quot;</span>,<br>Long:  <span class="hljs-string">`All software has versions. This is Hugo&#x27;s`</span>,<br>RunE: <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(cmd *cobra.Command, args []<span class="hljs-type">string</span>)</span></span> <span class="hljs-type">error</span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;Hugo Static Site Generator v0.9 -- HEAD&quot;</span>)<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;,<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">init</span><span class="hljs-params">()</span></span> &#123;<br>rootCmd.AddCommand(versionCmd)<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到<code>main.go</code>的主要内容就是调用<code>root.go</code>中的<code>Execute()</code>函数，然后这个函数又是调用cobra定义的<code>rootCmd</code>对其进行执行。<code>rootCmd</code>是一个<code>cobra.Command</code>类，它定义时写了自己的说明文本，然后Run函数是最关键的，定义了自己的运行内容，也就是打印一句字符，这就是单独在命令行中输入hugo后需要执行的程序。如果想要进行命令嵌套，那么就得像<code>version.go</code>文件中的处理方法一样再定义另一个cobra的cmd变量<code>versionCmd</code> ，然后通过<code>AddCommand</code>函数就可以加入进去，如此之后就可以通过<code>hugo version</code>来运行<code>versionCmd</code> 中的<code>Run</code>对应的函数。</p><p>项目build之后得到执行文件<code>hugo</code>，运行结果如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># ./hugo </span><br>run hugo..<br><span class="hljs-comment"># ./hugo -h</span><br>A Fast and Flexible Static Site Generator built with<br>                                  love by spf13 and friends <span class="hljs-keyword">in</span> Go.<br>                                  Complete documentation is available at https://gohugo.io<br><br>Usage:<br>  hugo [flags]<br>  hugo [<span class="hljs-built_in">command</span>]<br><br>Available Commands:<br>  completion  Generate the autocompletion script <span class="hljs-keyword">for</span> the specified shell<br>  <span class="hljs-built_in">help</span>        Help about any <span class="hljs-built_in">command</span><br>  version     Print the version number of Hugo<br><br>Flags:<br>  -h, --<span class="hljs-built_in">help</span>   <span class="hljs-built_in">help</span> <span class="hljs-keyword">for</span> hugo<br><br>Use <span class="hljs-string">&quot;hugo [command] --help&quot;</span> <span class="hljs-keyword">for</span> more information about a <span class="hljs-built_in">command</span>.<br><span class="hljs-comment"># ./hugo version</span><br>Hugo Static Site Generator v0.9 -- HEAD<br></code></pre></td></tr></table></figure><h2 id="K8s-scheduler中初始化的源代码解析"><a href="#K8s-scheduler中初始化的源代码解析" class="headerlink" title="K8s scheduler中初始化的源代码解析"></a>K8s scheduler中初始化的源代码解析</h2><p>K8s的scheduler也是类似于上面的hugo程序，只不过更加复杂。</p><p>首先在<code>cmd/kube-scheduler/scheduler.go:29</code>中我们能看见scheduler的入口函数：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>command := app.NewSchedulerCommand()<br>code := cli.Run(command)<br>os.Exit(code)<br>&#125;<br></code></pre></td></tr></table></figure><p>这里也是通过<code>app.NewSchedulerCommand</code>得到了一个<code>cobra.Command</code> 类，然后让这个类运行起来。</p><p>具体看<code>cmd/kube-scheduler/app/server.go:76</code> </p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// NewSchedulerCommand creates a *cobra.Command object with default parameters and registryOptions</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewSchedulerCommand</span><span class="hljs-params">(registryOptions ...Option)</span></span> *cobra.Command &#123;<br>opts := options.NewOptions()<br><br>cmd := &amp;cobra.Command&#123;<br>Use: <span class="hljs-string">&quot;kube-scheduler&quot;</span>,<br>Long: <span class="hljs-string">`The Kubernetes scheduler is a control plane process which assigns</span><br><span class="hljs-string">Pods to Nodes. The scheduler determines which Nodes are valid placements for</span><br><span class="hljs-string">each Pod in the scheduling queue according to constraints and available</span><br><span class="hljs-string">resources. The scheduler then ranks each valid Node and binds the Pod to a</span><br><span class="hljs-string">suitable Node. Multiple different schedulers may be used within a cluster;</span><br><span class="hljs-string">kube-scheduler is the reference implementation.</span><br><span class="hljs-string">See [scheduling](https://kubernetes.io/docs/concepts/scheduling-eviction/)</span><br><span class="hljs-string">for more information about scheduling and the kube-scheduler component.`</span>,<br>RunE: <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(cmd *cobra.Command, args []<span class="hljs-type">string</span>)</span></span> <span class="hljs-type">error</span> &#123;<br><span class="hljs-keyword">return</span> runCommand(cmd, opts, registryOptions...)<br>&#125;,<br>Args: <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(cmd *cobra.Command, args []<span class="hljs-type">string</span>)</span></span> <span class="hljs-type">error</span> &#123;<br><span class="hljs-keyword">for</span> _, arg := <span class="hljs-keyword">range</span> args &#123;<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(arg) &gt; <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;%q does not take any arguments, got %q&quot;</span>, cmd.CommandPath(), args)<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;,<br>&#125;<br><br><span class="hljs-comment">//...</span><br><br><span class="hljs-keyword">return</span> cmd<br>&#125;<br></code></pre></td></tr></table></figure><p>这里定义了一个<code>cobra.Command</code>，与之前的示例类似，主要的内容还是在<code>runCommand</code>中。</p><p>查看其对应的内容，<code>cmd/kube-scheduler/app/server.go:121</code> </p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// runCommand runs the scheduler.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">runCommand</span><span class="hljs-params">(cmd *cobra.Command, opts *options.Options, registryOptions ...Option)</span></span> <span class="hljs-type">error</span> &#123;<br>verflag.PrintAndExitIfRequested()<br><br><span class="hljs-comment">// Activate logging as soon as possible, after that</span><br><span class="hljs-comment">// show flags with the final logging configuration.</span><br><span class="hljs-keyword">if</span> err := logsapi.ValidateAndApply(opts.Logs, utilfeature.DefaultFeatureGate); err != <span class="hljs-literal">nil</span> &#123;<br>fmt.Fprintf(os.Stderr, <span class="hljs-string">&quot;%v\n&quot;</span>, err)<br>os.Exit(<span class="hljs-number">1</span>)<br>&#125;<br>cliflag.PrintFlags(cmd.Flags())<br><br>ctx, cancel := context.WithCancel(context.Background())<br><span class="hljs-keyword">defer</span> cancel()<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>stopCh := server.SetupSignalHandler()<br>&lt;-stopCh<br>cancel()<br>&#125;()<br><br>cc, sched, err := Setup(ctx, opts, registryOptions...)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> err<br>&#125;<br><span class="hljs-comment">// add feature enablement metrics</span><br>utilfeature.DefaultMutableFeatureGate.AddMetrics()<br><span class="hljs-keyword">return</span> Run(ctx, cc, sched)<br>&#125;<br></code></pre></td></tr></table></figure><p>前面的内容主要是一些配置文件，其中最主要的初始化配置函数是<code>Setup(ctx, opts, registryOptions...)</code> ，初始化完毕后就会返回一个scheduler。</p><p>具体的内容在<code>cmd/kube-scheduler/app/server.go:309</code> ，对这部分代码的一些解释放在了注释里。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Setup creates a completed config and a scheduler based on the command args and options</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Setup</span><span class="hljs-params">(ctx context.Context, opts *options.Options, outOfTreeRegistryOptions ...Option)</span></span> (*schedulerserverconfig.CompletedConfig, *scheduler.Scheduler, <span class="hljs-type">error</span>) &#123;<br>    <span class="hljs-comment">// 尝试获取默认的调度器配置</span><br>    <span class="hljs-keyword">if</span> cfg, err := latest.Default(); err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, <span class="hljs-literal">nil</span>, err<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        opts.ComponentConfig = cfg <span class="hljs-comment">// 如果没有错误，将配置赋值给opts</span><br>    &#125;<br><br>    <span class="hljs-comment">// 验证opts中的选项是否有效</span><br>    <span class="hljs-keyword">if</span> errs := opts.Validate(); <span class="hljs-built_in">len</span>(errs) &gt; <span class="hljs-number">0</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, <span class="hljs-literal">nil</span>, utilerrors.NewAggregate(errs) <span class="hljs-comment">// 如果有验证错误，返回它们</span><br>    &#125;<br><br>    <span class="hljs-comment">// 从opts创建一个调度器的配置对象</span><br>    c, err := opts.Config(ctx)<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, <span class="hljs-literal">nil</span>, err<br>    &#125;<br><br>    <span class="hljs-comment">// 从调度器配置对象中获取完整的配置</span><br>    cc := c.Complete()<br><br>    <span class="hljs-comment">// 创建一个用于存放外部插件的注册表</span><br>    outOfTreeRegistry := <span class="hljs-built_in">make</span>(runtime.Registry)<br>    <span class="hljs-keyword">for</span> _, option := <span class="hljs-keyword">range</span> outOfTreeRegistryOptions &#123;<br>        <span class="hljs-keyword">if</span> err := option(outOfTreeRegistry); err != <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, <span class="hljs-literal">nil</span>, err<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 获取事件记录器工厂</span><br>    recorderFactory := getRecorderFactory(&amp;cc)<br><br>    <span class="hljs-comment">// 创建一个空的调度器配置概要切片</span><br>    completedProfiles := <span class="hljs-built_in">make</span>([]kubeschedulerconfig.KubeSchedulerProfile, <span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment">// 使用一系列参数和配置选项创建一个新的调度器实例</span><br>    sched, err := scheduler.New(<br>        cc.Client,                                 <span class="hljs-comment">// 客户端对象</span><br>        cc.InformerFactory,                       <span class="hljs-comment">// Informer工厂</span><br>        cc.DynInformerFactory,                    <span class="hljs-comment">// 动态Informer工厂</span><br>        recorderFactory,                          <span class="hljs-comment">// 事件记录器工厂</span><br>        ctx.Done(),                               <span class="hljs-comment">// 上下文取消通道</span><br>        scheduler.WithComponentConfigVersion(cc.ComponentConfig.TypeMeta.APIVersion),  <span class="hljs-comment">// 组件配置版本</span><br>        scheduler.WithKubeConfig(cc.KubeConfig),                                      <span class="hljs-comment">// Kube配置</span><br>        scheduler.WithProfiles(cc.ComponentConfig.Profiles...),                       <span class="hljs-comment">// 调度器配置概要</span><br>        scheduler.WithPercentageOfNodesToScore(cc.ComponentConfig.PercentageOfNodesToScore), <span class="hljs-comment">// 节点评分百分比</span><br>        scheduler.WithFrameworkOutOfTreeRegistry(outOfTreeRegistry),                <span class="hljs-comment">// 外部插件注册表</span><br>        scheduler.WithPodMaxBackoffSeconds(cc.ComponentConfig.PodMaxBackoffSeconds),  <span class="hljs-comment">// Pod最大退避秒数</span><br>        scheduler.WithPodInitialBackoffSeconds(cc.ComponentConfig.PodInitialBackoffSeconds),  <span class="hljs-comment">// Pod初始退避秒数</span><br>        scheduler.WithPodMaxInUnschedulablePodsDuration(cc.PodMaxInUnschedulablePodsDuration), <span class="hljs-comment">// Pod在不可调度Pod列表中的最大持续时间</span><br>        scheduler.WithExtenders(cc.ComponentConfig.Extenders...),  <span class="hljs-comment">// 扩展器</span><br>        scheduler.WithParallelism(cc.ComponentConfig.Parallelism),  <span class="hljs-comment">// 并行度</span><br>        scheduler.WithBuildFrameworkCapturer(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(profile kubeschedulerconfig.KubeSchedulerProfile)</span></span> &#123;<br>            <span class="hljs-comment">// 在框架实例化期间处理概要以设置默认插件和配置，并捕获它们以记录日志</span><br>            completedProfiles = <span class="hljs-built_in">append</span>(completedProfiles, profile)<br>        &#125;),<br>    )<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, <span class="hljs-literal">nil</span>, err<br>    &#125;<br><br>    <span class="hljs-comment">// 记录或写入配置和概要信息</span><br>    <span class="hljs-keyword">if</span> err := options.LogOrWriteConfig(klog.FromContext(ctx), opts.WriteConfigTo, &amp;cc.ComponentConfig, completedProfiles); err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, <span class="hljs-literal">nil</span>, err<br>    &#125;<br><br>    <span class="hljs-comment">// 返回完整的配置和调度器实例</span><br>    <span class="hljs-keyword">return</span> &amp;cc, sched, <span class="hljs-literal">nil</span><br>&#125;<br><br></code></pre></td></tr></table></figure><p>得到scheduler后运行的函数还是在后面的<code>Run(ctx, cc, sched)</code>里。</p><p>查看其对应的内容，<code>cmd/kube-scheduler/app/server.go:150</code> ，补充了一部分解释放在代码的注释里。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Run executes the scheduler based on the given configuration. It only returns on error or when context is done.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Run</span><span class="hljs-params">(ctx context.Context, cc *schedulerserverconfig.CompletedConfig, sched *scheduler.Scheduler)</span></span> <span class="hljs-type">error</span> &#123;<br>    logger := klog.FromContext(ctx) <span class="hljs-comment">// 从上下文中获取日志记录器</span><br><br>    <span class="hljs-comment">// 为了帮助调试，立即记录版本信息</span><br>    logger.Info(<span class="hljs-string">&quot;Starting Kubernetes Scheduler&quot;</span>, <span class="hljs-string">&quot;version&quot;</span>, version.Get())<br><br>    <span class="hljs-comment">// 记录 Golang 的设置，这些环境变量会影响 Go 运行时的行为</span><br>    logger.Info(<span class="hljs-string">&quot;Golang settings&quot;</span>, <span class="hljs-string">&quot;GOGC&quot;</span>, os.Getenv(<span class="hljs-string">&quot;GOGC&quot;</span>), <span class="hljs-string">&quot;GOMAXPROCS&quot;</span>, os.Getenv(<span class="hljs-string">&quot;GOMAXPROCS&quot;</span>), <span class="hljs-string">&quot;GOTRACEBACK&quot;</span>, os.Getenv(<span class="hljs-string">&quot;GOTRACEBACK&quot;</span>))<br><br>    <span class="hljs-comment">// Configz 注册，Configz 允许通过 HTTP 端点公开当前的配置</span><br>    <span class="hljs-keyword">if</span> cz, err := configz.New(<span class="hljs-string">&quot;componentconfig&quot;</span>); err == <span class="hljs-literal">nil</span> &#123;<br>        cz.Set(cc.ComponentConfig) <span class="hljs-comment">// 设置调度器的组件配置</span><br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;unable to register configz: %s&quot;</span>, err) <span class="hljs-comment">// 如果注册失败，返回错误</span><br>    &#125;<br><br>    <span class="hljs-comment">// 启动事件处理流水线</span><br>    cc.EventBroadcaster.StartRecordingToSink(ctx.Done()) <span class="hljs-comment">// 开始录制事件</span><br>    <span class="hljs-keyword">defer</span> cc.EventBroadcaster.Shutdown()                   <span class="hljs-comment">// 延后关闭事件广播</span><br><br>    <span class="hljs-comment">// 设置健康检查</span><br>    <span class="hljs-keyword">var</span> checks []healthz.HealthChecker<br>    <span class="hljs-keyword">if</span> cc.ComponentConfig.LeaderElection.LeaderElect &#123;<br>        checks = <span class="hljs-built_in">append</span>(checks, cc.LeaderElection.WatchDog) <span class="hljs-comment">// 如果启用了领导者选举，添加 WatchDog 健康检查</span><br>    &#125;<br><br>    <span class="hljs-comment">// 等待领导者选举的通道</span><br>    waitingForLeader := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;)<br>    isLeader := <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> <span class="hljs-type">bool</span> &#123;<br>        <span class="hljs-keyword">select</span> &#123;<br>        <span class="hljs-keyword">case</span> _, ok := &lt;-waitingForLeader:<br>            <span class="hljs-comment">// 如果通道关闭，我们是领导者</span><br>            <span class="hljs-keyword">return</span> !ok<br>        <span class="hljs-keyword">default</span>:<br>            <span class="hljs-comment">// 通道是打开的，我们正在等待领导者</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 启动健康检查服务器</span><br>    <span class="hljs-keyword">if</span> cc.SecureServing != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-comment">// 构建处理函数链</span><br>        handler := buildHandlerChain(newHealthzAndMetricsHandler(&amp;cc.ComponentConfig, cc.InformerFactory, isLeader, checks...), cc.Authentication.Authenticator, cc.Authorization.Authorizer)<br>        <span class="hljs-comment">// 启动安全服务器，注意处理返回的 stoppedCh 和 listenerStoppedCh</span><br>        <span class="hljs-keyword">if</span> _, _, err := cc.SecureServing.Serve(handler, <span class="hljs-number">0</span>, ctx.Done()); err != <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;failed to start secure server: %v&quot;</span>, err) <span class="hljs-comment">// 如果启动失败，返回错误</span><br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 启动所有的 informer</span><br>    cc.InformerFactory.Start(ctx.Done()) <span class="hljs-comment">// 启动 informer 工厂</span><br>    <span class="hljs-comment">// DynInformerFactory 可以在测试中为 nil</span><br>    <span class="hljs-keyword">if</span> cc.DynInformerFactory != <span class="hljs-literal">nil</span> &#123;<br>        cc.DynInformerFactory.Start(ctx.Done()) <span class="hljs-comment">// 启动动态 informer 工厂</span><br>    &#125;<br><br>    <span class="hljs-comment">// 等待所有缓存同步后再进行调度</span><br>    cc.InformerFactory.WaitForCacheSync(ctx.Done()) <span class="hljs-comment">// 等待 informer 工厂的缓存同步</span><br>    <span class="hljs-keyword">if</span> cc.DynInformerFactory != <span class="hljs-literal">nil</span> &#123;<br>        cc.DynInformerFactory.WaitForCacheSync(ctx.Done()) <span class="hljs-comment">// 等待动态 informer 工厂的缓存同步</span><br>    &#125;<br><br>    <span class="hljs-comment">// 如果启用了领导者选举，通过 LeaderElector 运行直到完成并退出</span><br>    <span class="hljs-keyword">if</span> cc.LeaderElection != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-comment">// 设置领导者选举的回调</span><br>        cc.LeaderElection.Callbacks = leaderelection.LeaderCallbacks&#123;<br>            OnStartedLeading: <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(ctx context.Context)</span></span> &#123;<br>                <span class="hljs-built_in">close</span>(waitingForLeader) <span class="hljs-comment">// 关闭等待领导者的通道，表示我们现在是领导者</span><br>                sched.Run(ctx)           <span class="hljs-comment">// 运行调度器</span><br>            &#125;,<br>            OnStoppedLeading: <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>                <span class="hljs-keyword">select</span> &#123;<br>                <span class="hljs-keyword">case</span> &lt;-ctx.Done():<br>                    <span class="hljs-comment">// 我们被请求终止。退出 0。</span><br>                    logger.Info(<span class="hljs-string">&quot;Requested to terminate, exiting&quot;</span>)<br>                    os.Exit(<span class="hljs-number">0</span>)<br>                <span class="hljs-keyword">default</span>:<br>                    <span class="hljs-comment">// 我们失去了锁。</span><br>                    logger.Error(<span class="hljs-literal">nil</span>, <span class="hljs-string">&quot;Leaderelection lost&quot;</span>)<br>                    klog.FlushAndExit(klog.ExitFlushTimeout, <span class="hljs-number">1</span>)<br>                &#125;<br>            &#125;,<br>        &#125;<br>        <span class="hljs-comment">// 创建新的领导者选举</span><br>        leaderElector, err := leaderelection.NewLeaderElector(*cc.LeaderElection)<br>        <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;couldn&#x27;t create leader elector: %v&quot;</span>, err) <span class="hljs-comment">// 如果创建失败，返回错误</span><br>        &#125;<br><br>        leaderElector.Run(ctx) <span class="hljs-comment">// 运行领导者选举</span><br><br>        <span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;lost lease&quot;</span>) <span class="hljs-comment">// 如果失去租约，返回错误</span><br>    &#125;<br><br>    <span class="hljs-comment">// 领导者选举被禁用，因此内联运行直到完成</span><br>    <span class="hljs-built_in">close</span>(waitingForLeader) <span class="hljs-comment">// 关闭等待领导者的通道</span><br>    sched.Run(ctx)           <span class="hljs-comment">// 运行调度器</span><br>    <span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;finished without leader&quot;</span>) <span class="hljs-comment">// 如果没有领导者，返回错误</span><br>&#125;<br></code></pre></td></tr></table></figure><p>这个函数首先设置日志记录器，记录版本和 Golang 环境设置，然后注册配置以供调试使用。接着，它启动事件处理流水线，并设置健康检查和健康检查服务器。之后，函数启动 informer 并等待缓存同步。如果配置了领导者选举，它会通过领导者选举器运行调度器，否则直接运行调度器。如果在任何步骤中出现错误，函数会返回该错误。</p><p>查看<code>sched.Run(ctx)</code> 这部分调度器实际运行的内容，<code>pkg/scheduler/scheduler.go:355</code> ，补充了一部分解释放在代码的注释里。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Run begins watching and scheduling. It starts scheduling and blocked until the context is done.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(sched *Scheduler)</span></span> Run(ctx context.Context) &#123;<br>    <span class="hljs-comment">// 启动调度队列，这将允许调度器观察新的、需要调度的 Pods</span><br>    sched.SchedulingQueue.Run()<br><br>  <span class="hljs-comment">// We need to start scheduleOne loop in a dedicated goroutine,</span><br>  <span class="hljs-comment">// because scheduleOne function hangs on getting the next item</span><br>  <span class="hljs-comment">// from the SchedulingQueue.</span><br>  <span class="hljs-comment">// If there are no new pods to schedule, it will be hanging there</span><br>  <span class="hljs-comment">// and if done in this goroutine it will be blocking closing</span><br>  <span class="hljs-comment">// SchedulingQueue, in effect causing a deadlock on shutdown.</span><br>    <span class="hljs-comment">// 翻译：</span><br>    <span class="hljs-comment">// 我们需要在一个独立的 goroutine 中启动 scheduleOne 循环，</span><br>    <span class="hljs-comment">// 因为 scheduleOne 函数在从 SchedulingQueue 获取下一个项目时会挂起。</span><br>    <span class="hljs-comment">// 如果没有新的 Pods 需要调度，它会在那里挂起，</span><br>    <span class="hljs-comment">// 如果在这个 goroutine 中执行，它将阻止关闭 SchedulingQueue，</span><br>    <span class="hljs-comment">// 从而在关闭时造成死锁。</span><br>    <span class="hljs-keyword">go</span> wait.UntilWithContext(ctx, sched.scheduleOne, <span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment">// 当上下文完成（即 ctx.Done() 通道关闭）时，阻塞直到收到信号</span><br>    &lt;-ctx.Done()<br><br>    <span class="hljs-comment">// 关闭调度队列，这将停止调度器的事件循环</span><br>    sched.SchedulingQueue.Close()<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到到了这里就剩下了两个主要的实体：调度队列和调度算法。</p><ul><li><p>调度队列收集需要调度的Pod，然后提交给scheduler调度，具体将在后面进行介绍。</p></li><li><p><code>go wait.UntilWithContext(ctx, sched.scheduleOne, 0)</code>启用了一个go协程，然后负责一个一个调度pod。注意一下<code>go wait.UntilWithContext</code> ，它 是 Kubernetes 项目中用于周期性运行函数的工具。它是一个包装了 <code>time.Ticker</code> 和 <code>context.Context</code> 的机制，允许在给定的时间间隔内重复执行某个函数，直到提供的上下文被取消。函数的基本签名如下：</p>  <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">UntilWithContext</span><span class="hljs-params">(ctx context.Context, f <span class="hljs-keyword">func</span>(context.Context)</span></span>, period time.Duration)<br></code></pre></td></tr></table></figure><p>  当 <code>ctx.Done()</code> 通道关闭时，<code>wait.UntilWithContext</code> 将停止执行其周期性的任务<code>sched.scheduleOne</code>，<code>0</code> 表示两次迭代之间没有间隔，<code>sched.scheduleOne</code> 将尽可能快地被调用。具体<code>sched.scheduleOne</code>的介绍将在后面进行。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>k8s</category>
      
      <category>源码分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>k8s</tag>
      
      <tag>源码分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文阅读】Gödel:Unified Large-Scale Resource Management and Scheduling at ByteDance</title>
    <link href="/2024/05/01/godelPaperRead/"/>
    <url>/2024/05/01/godelPaperRead/</url>
    
    <content type="html"><![CDATA[<h1 id="论文基础信息"><a href="#论文基础信息" class="headerlink" title="论文基础信息"></a>论文基础信息</h1><p><strong>论文地址：</strong> <a href="https://dl.acm.org/doi/10.1145/3620678.3624663">Gödel: Unified Large-Scale Resource Management and Scheduling at ByteDance</a></p><p><strong>收录会议：</strong> 云计算顶会-ACM Symposium on Cloud Computing(SoCC2023)</p><p><strong>作者：</strong> 字节跳动基础架构团队</p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p><strong>大规模：</strong> 字节跳动在全球范围内运营着数十个大规模集群，每个集群包含有数十万台机器。<br><strong>高异构：</strong> 数据中心内的机器也是异构的。包括不同型号的GPU、不同架构的CPU等。<br><strong>资源利用率低，弹性差：</strong> 之前的做法是每个业务组都有一个独立的集群，这会导致集群的资源利用率低，出现资源碎片。同时也导致在集群之间进行资源移动时需要的运营开销高，即弹性差。</p><h2 id="请求"><a href="#请求" class="headerlink" title="请求"></a>请求</h2><ul><li><p><strong>高并发：</strong> 请求的并发是数千个容器每秒，每天运行着数千万到数亿个容器。</p></li><li><p><strong>高异构：</strong> 在生成环境中包含着不同资源需求、不同服务级别协议（SLA）的异构任务，如下图所示。例如，1) 微服务​​、在线推理和数据库等关键业务服务，它们也可以抢占非关键业务的资源，2) 广泛的数据分析或机器学习 (ML) 模型训练等低优先级作业。</p><p>  注意这里提到了NUMA节点。在多CPU处理器架构中，NUMA节点中CPU有自己的内存，可以非常快速地访问自己的内存。例如对于推荐系统，推荐系统中的模型就需要存在内存中以降低获取延迟，这类任务就通常必须独占NUMA节点或者与其他非内存密集型任务共享 NUMA 节点。</p></li></ul><p><img src="/2024/05/01/godelPaperRead/workloads.jpg" alt="字节跳动集群中不同类型的任务"></p><h2 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h2><p>生产调度系统的主要要求是在异构机器上调度不同的任务，提高资源利用率，跟上每个计算集群不断增长的机器规模并实现高吞吐量。</p><p>现有的开源调度程序不能满足所有的需求。</p><ul><li><strong>Kubernetes：</strong> <ul><li>可以为微服务提供灵活的资源分配，但是面临可拓展性问题。一方面他的调度吞吐量差，另一方面他最多也只能支持5000个节点。</li><li>它也缺乏工作负载感知能力，无法很好地调度批处理作业。例如将机器学习任务放在一组共享相同网络前缀的节点上或在具有同质设备（例如相同的 GPU 型号）的特定节点上运行。虽然存在一些社区解决方案，但它们也存在一些问题，无法用于生产环境。</li><li>它也缺乏拓扑感知能力，即在调度Pod时遵守Pod的资源拓扑约束。传统的k8s做法是在调度到节点后再进行资源约束的检查，更合适的做法是在调度时就考虑资源拓扑约束。</li></ul></li><li><strong>YARN：</strong> <ul><li>适合复杂的批处理作业调度，但是不适用于微服务。</li><li>在将作业彼此隔离以及处理依赖性控制方面存在不足。</li><li>还缺乏资源碎片优化，导致资源利用率低。</li></ul></li></ul><p>学术界也有很多调度架构的研究，但是在该场景下也都存在一些问题。</p><ul><li><strong>单体式：</strong> 拓展性受限，无法解决高吞吐问题，且不够灵活，难以添加定制的调度策略。</li><li><strong>两级式：</strong> 悲观的资源分配策略会损坏资源的弹性，同时存在资源碎片问题，资源利用率低。</li><li><strong>状态共享式：</strong> 使用乐观并发控制来解决全局调度带来的冲突问题，其典型实现Kubernetes在调度到节点时进行冲突解决，但是这种解决方式在整个调度流程中都太晚了，降低了吞吐量和集群规模。</li><li><strong>分布式&#x2F;混合式：</strong> 分布式缺乏集中式调度器会限制调度的灵活性。</li></ul><p>字节跳动在早期参考过往经验将Kubernetes和YARN组合使用，经历了如下3个阶段：</p><ol><li>分别使用 Kubernetes 和 YARN 在<strong>单独的资源池</strong>中运行在线（即微服务）和离线（即批处理）工作负载。</li><li>通过一个协调器持续监控 Kubernetes 和 YARN 的资源供应和需求，然后根据流量模式<strong>在两个系统之间移动资源</strong>。它还利用历史数据来做出资源分配决策。移动资源依赖的是Kubernetes的<strong>污点机制</strong>。</li><li>进一步完善协调器等机制，使Kubernetes和YARN代理能够不断地进行通信。<strong>共享实时资源信息</strong>，以便离线工作负载可以利用同一节点上在线工作负载未使用的<strong>机会资源</strong>。</li></ol><p>但是这种组合做法仍然存在一些问题：</p><ul><li>组合<strong>无助于放置具有特殊要求的工作负载</strong>，例如更高的网络带宽、GPU 或 NUMA 关联性。</li><li>交换节点与节点上运行的任务无关。通过这种粗粒度的方法，选择驱逐的节点可<strong>能会造成级联故障</strong>（例如，驱逐运行参数服务器的节点会使训练工作人员失去所有进度）。</li><li>这种方法会产生<strong>大量的运营开销</strong>。例如，为了准备春节等特殊活动的高峰使用，运营团队必须提前几周开始与多个团队协调以预测扩大资源池的估计需求，这非常耗时且无法适应我们不断增长的需求基础设施。</li></ul><p>考虑到Kubernetes良好的社区生态，字节跳动决定在Kubernetes上构建一个新的调度系统Gödel，以解决上述问题。</p><h1 id="创新与贡献"><a href="#创新与贡献" class="headerlink" title="创新与贡献"></a>创新与贡献</h1><ol><li><p>引入了一种<strong>面向在线和离线任务调度的新范式</strong>，从而提供更好的拓扑亲和性（topology affinity），更高的资源弹性度，以及在非常大规模情况下更低的运营开销。</p></li><li><p>基于Kubernetes<strong>设计并实现了新的资源管理和调度系统Gödel</strong>，并提出了对普通 Kubernetes 的一些优化和增强的方法，以提高调度性能。 </p></li><li><p>在字节跳动的多个数据中心实际部署了Gödel，拥有数万台机器，并在真实工作负载下进行了<strong>评估</strong>，并在模拟环境中进行了<strong>测试</strong>。结果表明了它的优越的实用性和性能。</p><p>实践表明Gödel可以实现高达 5000 个 Pod&#x2F;秒的吞吐量，同时在单个 Gödel 集群上保持约 60% 的总体资源利用率。对于内存敏感的工作负载，借助 Gödel 支持的拓扑感知调度，数据获取延迟可减少 20% 以上。此外，与字节跳动的传统部署模式相比，Gödel 可以在几分钟内（而不是几小时或几天）在关键业务服务和低优先级作业之间转移计算资源，以响应紧急流量变化，而无需人工干预。</p></li></ol><p>调度系统已开源：<a href="https://github.com/kubewharf/godel-scheduler">https://github.com/kubewharf/godel-scheduler</a></p><h1 id="Godel系统架构"><a href="#Godel系统架构" class="headerlink" title="Gödel系统架构"></a>Gödel系统架构</h1><p><img src="/2024/05/01/godelPaperRead/overview.jpg" alt="Gödel系统架构"></p><p>Gödel系统整体的设计思想与Kubernetes类似，整体架构如上图所示。由于发现Etcd可能是调度的瓶颈，故Gödel默认使用字节跳动自研的开源KubeBrain作为高性能后背存储。为了提高调度的吞吐量，Gödel调度器被设计为分布式的状态共享式调度器。Gödel的关键组件包括：</p><ol><li><strong>Dispatcher</strong> </li><li><strong>Scheduler</strong></li><li><strong>Binder</strong></li><li><strong>CustomNodeResource(CNR)</strong></li></ol><h2 id="Dispatcher"><a href="#Dispatcher" class="headerlink" title="Dispatcher"></a>Dispatcher</h2><p>Dispatcher是Gödel的调度<strong>逻辑入口</strong>，它验证所有收到的作业请求，并根据资源请求和 QoS 优先级将它们存储在基于<strong>优先级的队列</strong>中，并最终将每个有效请求转发到所需的调度程序实例。</p><p>在Dispatcher中，我们使用逻辑队列来表示分配给不同业务组的<strong>资源配额</strong>，每当一个业务组提交一个部署Pod的任务请求时，就将该Pod放入到逻辑队列中，然后扣除逻辑队列的对应的可用资源。队列的排序策略支持多种。</p><p>Dispatcher还有一大功能是<strong>分区</strong>以控制调度器的冲突。初始只有一个分区，但是，在集群分配超过 90% 或吞吐量超过 2000 个 Pod&#x2F;秒且多个调度器之间的调度冲突高于 1%（所有阈值均可配置）的场景下，Dispatcher 会动态对集群进行分区并分配每个调度器实例相应的一组分区。</p><h2 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h2><p>Scheduler接收Dispatcher转发的作业请求，并做出调度决策（支持抢占）。Scheduler的调度单元不是单个Pod而是一个<strong>Scheduling Unit</strong>。Scheduler可以存在多个，采用状态共享式，如前所述，会受到分区调控，既可以调度到本分区也可以调度到整个集群。调度到本分区可以避免冲突，降低节点扫描开销，但是代价是调度质量的降低，还会资源碎片的存在，导致无法在本地找到所有需要的资源。系统会自动调节调度器的调度模式，例如当资源不足冲突上升时调节到只能在分区中调度。</p><p>系统还支持添加、删除调度器，但是经过实验验证，更多调度器会导致更高的调度冲突，从而导致调度器并不是越多越好。</p><h2 id="Binder"><a href="#Binder" class="headerlink" title="Binder"></a>Binder</h2><p>Binder使用乐观并发控制来解决调度冲突，支持抢占、协同调度，最终将pod绑定到Scheduler选择的特定节点上。它的工作原理与 Kubernetes 默认调度程序的绑定周期类似，但处理地更快。</p><p>Binder 使用优先级队列来执行多个调度程序发送的调度决策，并按顺序处理 Pod 绑定。被拒绝的 Pod 将返回给 Dispatcher 以进行调度重试。其冲突处理的细节如下：</p><ol><li>检查节点是否有足够的资源，是否满足 Pod 的拓扑约束。</li><li>对于抢占调度，如果多个Scheduler试图抢占同一个Pod，那么只满足第一个</li><li>对于Gang调度，会尝试解决所有Pod的冲突，通过了就绑定所有的Pod，否则不绑定任何Pod。</li></ol><h2 id="CustomNodeResource-CNR"><a href="#CustomNodeResource-CNR" class="headerlink" title="CustomNodeResource(CNR)"></a>CustomNodeResource(CNR)</h2><p>CNR代表自定义节点资源，用以支持拓扑感知调度，集群中的每台服务器都会有一个CNR对象。每个 CNR 对象代表特定节点的拓扑和资源使用情况以及该节点上每个 pod 的拓扑。依赖这些信息，Gödel 调度器就可以在调度阶段就考虑资源拓扑约束。</p><h2 id="Scheduling-Unit"><a href="#Scheduling-Unit" class="headerlink" title="Scheduling Unit"></a>Scheduling Unit</h2><p>Scheduling Unit是Gödel的基本调度单元，每个Scheduling Unit包含一个或多个Running Unit。整体采取的是一个两级结构，Job是一个Scheduling Unit，Job中的pod或者subtasks是Running Unit，只有当调度器为Scheduling Unit至少Min Member个Running Units找到可用资源时，Scheduling Unit才会被标记为可调度的，否则不会有pod运行。</p><p>Min Member是一个为了应对不同类型作业所提出的一个巧妙的设计，对于需要gang调度的作业，可以将Min Member设置为所有的Running Unit数量，如果运行的是微服务作业，可以将Min Member设置为1。</p><p>目前，我们在字节跳动生产集群中一般部署三种或更多类型的应用：微服务（线上）、批处理作业（线下）和机器学习（线下）。Scheduling Unit帮助其在调度程序级别上填补在线和离线作业之间的语义差距。</p><p>此外为了平滑地将原本的YARN任务迁移到Gödel，其还创建了多种自定义资源定义（CRD）来模仿YARN的资源请求，从而将所有原本的YARN任务迁移过来。</p><h2 id="Performance-Optimization"><a href="#Performance-Optimization" class="headerlink" title="Performance Optimization"></a>Performance Optimization</h2><p>Gödel 采用与 Kubernetes 相似的顺序来进行调度决策：<br>1）筛选；<br>2）打分，确定优先顺序；<br>3）选择节点。</p><p>但是Gödel在这个基础上做了一些优化：</p><ol><li><strong>缓存可行节点：</strong> 我们观察到，来自同一用户的一项作业的大约 90% 的部署 Pod 通常具有相同的资源请求。例如，社交媒体团队可能要求运行 20,000 个 HTTP Web 服务器，每个服务器有 4 个 CPU 和 8GB 内存。因此在筛选和打分阶段确定的Node也可以用于相同的后续Pod，直到节点状态改变。</li><li><strong>降低打分百分比：</strong> 扫描集群中的所有节点并进行打分十分耗时，基于调度质量和调度耗时之间的衡量，调度器在筛选步骤中选择（Scheduling Unit+50）个可行节点。</li><li><strong>丰富评分插件：</strong> Gödel 调度器允许通过实现不同的评分插件来定义特定于工作负载的评分策略。</li></ol><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>实验通过Kubemark构建了测试平台，测试平台由 40 台 Debian x86_64 服务器组成，每台服务器包含 256 个逻辑 CPU、2TB 内存和 7TB SSD 存储。我们使用多达 21 台服务器作为 Kubemark 主节点来托管 Gödel 调度程序和其他相关组件，包括后备存储集群。其余 19 台服务器充当空心节点，虚拟托管所有创建的 Pod。</p><h2 id="可拓展性测试"><a href="#可拓展性测试" class="headerlink" title="可拓展性测试"></a>可拓展性测试</h2><p><img src="/2024/05/01/godelPaperRead/scalability.jpg" alt="Gödel的可拓展性实验结果"></p><h3 id="在线工作负载测试"><a href="#在线工作负载测试" class="headerlink" title="在线工作负载测试"></a>在线工作负载测试</h3><p>只使用单调度器，固定Pod的提交速率为2800Pod&#x2F;s（使得单调度器基本饱和），将集群节点数量从100提高到20000，对比Gödel、Kubernetes、更改Etcd为Kubebrain的调度性能，结果如上图3中的图5所示，可以看到Gödel的性能遥遥领先，且在2w的节点下仍然能够保持高吞吐量。</p><h3 id="多调度器测试"><a href="#多调度器测试" class="headerlink" title="多调度器测试"></a>多调度器测试</h3><p>在1w个节点上，将Pod提交速率提高到10000Pod&#x2F;s（使得多调度器基本饱和），禁用了分区模式，调度器在整个集群中调度，结果如上图中的图6所示，可以观察到加速不是线性的，因为运行的调度器越多也就会导致冲突越多，目前也正在研究节点改组等解决方案来解决这个问题。</p><h3 id="离线工作负载测试"><a href="#离线工作负载测试" class="headerlink" title="离线工作负载测试"></a>离线工作负载测试</h3><p><img src="/2024/05/01/godelPaperRead/offline.jpg" alt="Gödel的离线工作负载测试结果"></p><p>在1w个节点中，固定Pod的提交速率为2800Pod&#x2F;s，将Gödel与Kubernetes-volcano（k8s社区中用于离线作业调度的调度器）、YARN进行对比，结果如上图所示，已经可以看的Gödel的性能优势。</p><h3 id="在离线混合工作负载测试"><a href="#在离线混合工作负载测试" class="headerlink" title="在离线混合工作负载测试"></a>在离线混合工作负载测试</h3><p>在1w个节点中，将提交中在线服务的比例分别更改为0%、25%、50%、75%和100%，其余工作负载为离线作业。测试结果如上图中的图7所示，Gödel的调度性能非常稳定。</p><h2 id="拓扑感知调度测试"><a href="#拓扑感知调度测试" class="headerlink" title="拓扑感知调度测试"></a>拓扑感知调度测试</h2><p><img src="/2024/05/01/godelPaperRead/topology-aware.jpg" alt="Gödel的拓扑感知调度测试结果"></p><p>为了验证我们是否可以从上述拓扑感知调度中受益，我们评估了具有和不具有拓扑亲和性的调度器的性能。我们采用不同的调度器调度需要调度到NUMA节点的推荐任务，然后测试调度后各个任务的数据获取延迟，结果如上图所示，可以看到Gödel能够将平均延迟和 P99 延迟分别减少 21% 和 22.8%。</p><h2 id="性能优化分析测试"><a href="#性能优化分析测试" class="headerlink" title="性能优化分析测试"></a>性能优化分析测试</h2><p><img src="/2024/05/01/godelPaperRead/optimization.jpg" alt="Gödel的性能优化分析测试结果"></p><p>为了得到性能优化中缓存可行节点和降低打分百分比这两个操作的优化收益，我们重复运行了在线工作负载测试，然后结果如上图所示，可以看到，可行的节点缓存和降低评分百分比合计贡献了90%以上的性能提升。</p><h1 id="生产经验"><a href="#生产经验" class="headerlink" title="生产经验"></a>生产经验</h1><p><img src="/2024/05/01/godelPaperRead/production.jpg" alt="Gödel在字节跳动的实践经验"></p><p>Gödel已经实际部署在了字节跳动的生产集群中。上图图9展示了在2022年8月2号时，随着上午7点在线工作负载的增加，Gödel调度器自动撤回尽力而为的低优先级离线作业的资源，然后在凌晨3点左右又自动将多余的资源分配给了尽力而为的低优先级离线作业。两个转换在几分钟内无缝完成，无需人工干预。</p><p>在上图10展示了Gödel的集群资源利用率，可以看到其高达60%，而行业平均利用率不到30%。</p><p>在 Gödel 中实施更好的装箱算法有助于减少机器学习工作负载的 GPU Pod 碎片。之前使用 YARN 时，由于碎片问题，我们损失了 30% 的可分配容量，现在已减少到 10%，如上图 11 所示。 </p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文阅读</tag>
      
      <tag>集群调度</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker 面试题汇总(附答案)</title>
    <link href="/2024/04/18/dockerInterview/"/>
    <url>/2024/04/18/dockerInterview/</url>
    
    <content type="html"><![CDATA[<p>建议和这篇一起观看，更加全面一些：<a href="https://slipegg.github.io/2024/04/18/DockerStudy/">万字总结！Docker简介及底层关键技术剖析</a></p><h1 id="Docker-底层原理、概念类问题"><a href="#Docker-底层原理、概念类问题" class="headerlink" title="Docker 底层原理、概念类问题"></a>Docker 底层原理、概念类问题</h1><h2 id="1-Docker-和-LXC-有什么区别？"><a href="#1-Docker-和-LXC-有什么区别？" class="headerlink" title="1. Docker 和 LXC 有什么区别？"></a>1. Docker 和 LXC 有什么区别？</h2><p>LXC是在Linux上相关技术实现的容器，docker则在如下的几个方面进行了改进：</p><p>1、移植性：通过抽象容器配置，容器可以实现一个平台移植到另一个平台。</p><p>2、镜像系统：基于AUFS的镜像系统为容器的分发带来了很多的便利，通是共同的镜像层只需要存储一份，实现高效率的存储。</p><p>3、版本管理：类似于GIT的版本管理理念，用户可以更方便的创建、管理镜像文件。</p><p>4、仓库系统:仓库系统大大降低了镜像的分发和管理的成本。</p><p>5、周边工具：各种现有的工具（配置管理、云平台）对docker的支持，以及基于docker的pass、Cl等系统，让docker的应用更加方便和多样。</p><h2 id="2-Docker-容器有几种状态？"><a href="#2-Docker-容器有几种状态？" class="headerlink" title="2. Docker 容器有几种状态？"></a>2. Docker 容器有几种状态？</h2><p>四种状态：运行、已停止、重新启动、已退出。</p><h2 id="3-Docker-有哪些优缺点？"><a href="#3-Docker-有哪些优缺点？" class="headerlink" title="3. Docker 有哪些优缺点？"></a>3. Docker 有哪些优缺点？</h2><p><strong>docker优点</strong></p><p>1、部署方便</p><p>你一定还有印象，在我们最开始学习编程的时候，搭建环境这一步往往会耗费我们好几个小时的时间，而且其中一个小问题可能需要找很久才能够解决。你还会得到关于环境搭建方面的团队其他成员的求助。而有了容器之后，这些都变得非常容易，你的开发环境就只是一个或者几个容器镜像的地址，最多再需要一个控制部署流程的执行脚本。或者进一步将你的环境镜像以及镜像脚本放入一个git项目，发布到云端，需要的时候将它拉到本地就可以了。</p><p>2、部署安全</p><p>当我们收到一个bug反馈的时候，很多时候心里面的第一反应一定是“我本地是好的啊”！这种情况的发生就在于环境的不一致，我们在开发过程中的调试往往不能保证其他环境的问题，但是我们却要为此买单，这真是一件令人苦恼的事情。有了容器之后，这将很少发生。我们可以通过容器技术将开发环境和测试环境以及生产环境保持版本和依赖上的统一，保证代码在一个高度统一的环境上执行。而测试环境的统一，也同样能解决CI流程对环境的要求。</p><p>3、隔离性好</p><p>不管是开发还是生产，往往我们一台机器上可能需要跑多个服务，而服务各自需要的依赖配置不尽相同，假如说两个应用需要使用同一个依赖，或者两个应用需要的依赖之间会有一些冲突，这个时候就很容易出现问题了。所以同一台服务器上不同应用提供的不同服务，最好还是将其隔离起来。而容器在这方面有天生的优势，每一个容器就是一个隔离的环境，你对容器内部提供服务的要求，容器可以自依赖的全部提供。</p><p>4、快速回滚</p><p>容器之前的回滚机制，一般需要基于上个版本的应用重新部署，且替换掉目前的问题版本。在最初的时代，可能是一套完整的开发到部署的流程，而执行这一套流程往往需要很长的时间。在基于git的环境中，可能是回退某个历史提交，然后重新部署。这些跟容器技术相比都不够快，而且可能会引起新的问题（因为是基于新版本的修改）。而容器技术天生带有回滚属性，因为每个历史容器或者镜像都会有保存，而替换一个容器或者某个历史镜像是非常快速和简单的。</p><p>5、成本低</p><p>这可能是一个最明显和有用的优点了，在容器出现之前，我们往往构筑一个应用就需要一台新的服务器或者一台虚机。服务器的购置成本和运维成本都很高，而虚机需要占用很多不必要的资源。相比之下，容器技术就小巧轻便的多，只需要给一个容器内部构建应用需要的依赖就可以了，这也是容器技术发展迅速的最主要原因。</p><p>6、管理成本更低</p><p>随着大环境的发展，docker等容器的使用和学习的成本也是愈发降低，成为更多开发者和企业的选择。</p><p><strong>docker缺点</strong></p><p>1、隔离性</p><p>基于hypervisor的虚机技术，在隔离性上比容器技术要更好，它们的系统硬件资源完全是虚拟化的，当一台虚机出现系统级别的问题，往往不会蔓延到同一宿主机上的其他虚机。但是容器就不一样了，容器之间共享同一个操作系统内核以及其他组件，所以在收到攻击之类的情况发生时，更容易通过底层操作系统影响到其他容器。当然，这个问题可以通过在虚机中部署容器来解决，可是这样又会引出新的问题，比如成本的增加以及下面要提到的问题：性能。</p><p>2、性能</p><p>不管是虚机还是容器，都是运用不同的技术，对应用本身进行了一定程度的封装和隔离，在降低应用和应用之间以及应用和环境之间的耦合性上做了很多努力，但是随机而来的，就会产生更多的网络连接转发以及数据交互，这在低并发系统上表现不会太明显，而且往往不会成为一个应用的瓶颈（可能会分散于不同的虚机或者服务器上），但是当同一虚机或者服务器下面的容器需要更高并发量支撑的时候，也就是并发问题成为应用瓶颈的时候，容器会将这个问题放大，所以，并不是所有的应用场景都是适用于容器技术的。</p><h2 id="4-什么是Docker容器？"><a href="#4-什么是Docker容器？" class="headerlink" title="4. 什么是Docker容器？"></a>4. 什么是Docker容器？</h2><p>Docker容器在应用层创建了一个抽象，并将应用与所有的依赖关系打包在一起。这使我们能够快速、可靠地部署应用程序。容器不要求我们安装一个不同的操作系统。相反，它们使用底层系统的CPU和内存来执行任务。这意味着，任何容器化的应用程序都可以在任何平台上运行，而不受底层操作系统的影响。我们也可以把容器看作是Docker镜像的运行时实例。</p><h2 id="5-解释一下Docker组件。"><a href="#5-解释一下Docker组件。" class="headerlink" title="5. 解释一下Docker组件。"></a>5. 解释一下Docker组件。</h2><p>三个架构组件包括Docker客户端、主机和注册表。</p><p>Docker客户端。这个组件执行构建和运行操作，与Docker主机通信。<br>Docker主机。这个组件持有Docker守护程序、Docker镜像和Docker容器。该守护程序设置了与Docker注册中心的连接。<br>Docker Registry。这个组件存储Docker镜像。它可以是一个公共注册表，如Docker Hub或Docker Cloud，或一个私人注册表。</p><h2 id="6-虚拟化和容器化之间有什么区别？"><a href="#6-虚拟化和容器化之间有什么区别？" class="headerlink" title="6. 虚拟化和容器化之间有什么区别？"></a>6. 虚拟化和容器化之间有什么区别？</h2><p>虚拟化<br>虚拟化帮助我们在一台物理服务器上运行和托管多个操作系统。在虚拟化中，管理程序给客人操作系统一个虚拟机。虚拟机形成了硬件层的抽象，所以主机上的每个虚拟机都可以作为一个物理机。<br>容器化<br>容器化为我们提供了一个隔离的环境来运行我们的应用程序。我们可以在一台服务器或虚拟机上使用同一操作系统部署多个应用程序。容器形成了应用层的抽象，所以每个容器代表了不同的应用。</p><h2 id="7-描述一下Docker容器的生命周期。"><a href="#7-描述一下Docker容器的生命周期。" class="headerlink" title="7. 描述一下Docker容器的生命周期。"></a>7. 描述一下Docker容器的生命周期。</h2><p>Docker容器会经历以下几个阶段。</p><p>创建一个容器<br>运行该容器<br>暂停容器(可选)<br>解除容器的暂停（可选<br>启动容器<br>停止容器<br>重新启动容器<br>杀死容器<br>销毁容器</p><h2 id="8-Docker-容器有几种在状态？"><a href="#8-Docker-容器有几种在状态？" class="headerlink" title="8. Docker 容器有几种在状态？"></a>8. Docker 容器有几种在状态？</h2><p>starting 运行状态<br>Exited 退出状态<br>Paused 暂停状态<br>healthy 健康状态<br>unhealthy 非健康状态</p><h2 id="9-平时安装进虚拟机的-CentOS-镜像都是-4-4-GB-，为什么-Docker-的镜像才只有-200-MB-？"><a href="#9-平时安装进虚拟机的-CentOS-镜像都是-4-4-GB-，为什么-Docker-的镜像才只有-200-MB-？" class="headerlink" title="9. 平时安装进虚拟机的 CentOS 镜像都是 4.4 GB ，为什么 Docker 的镜像才只有 200 MB ？"></a>9. 平时安装进虚拟机的 CentOS 镜像都是 4.4 GB ，为什么 Docker 的镜像才只有 200 MB ？</h2><p>Docker 镜像仅包含运行所需的最小 runtime 环境，即仅需要 rootfs 即可。对于一个精简的 OS ，rootfs 可以很小，只需要包括最基本的命令、工具和程序库即可，因为底层直接共用 Host 主机的 kernel ，自己只需要提供 rootfs 即可。由此可见对于不同的 Linux 发行版，bootfs 基本是一致的，只有 rootfs 会有差别，因此不同的发行版可以共用 bootfs 。</p><h1 id="Docker-基本操作类问题"><a href="#Docker-基本操作类问题" class="headerlink" title="Docker 基本操作类问题"></a>Docker 基本操作类问题</h1><h2 id="2-容器退出后，-通过-docker-ps-命令查看不到，数据会丢失么？"><a href="#2-容器退出后，-通过-docker-ps-命令查看不到，数据会丢失么？" class="headerlink" title="2. 容器退出后， 通过 docker ps 命令查看不到，数据会丢失么？"></a>2. 容器退出后， 通过 docker ps 命令查看不到，数据会丢失么？</h2><p>容器退出后会处于终止（exited）状态， 此时可以通过docker ps -a查看。</p><p>其中的数据也不会丢失，还可以通过docker [container] start命令来启动它。只有删除掉容器才会清除所有数据。</p><h2 id="2-什么是Docker-Hub？"><a href="#2-什么是Docker-Hub？" class="headerlink" title="2. 什么是Docker Hub？"></a>2. 什么是Docker Hub？</h2><p>Docker hub是一个基于云的注册表服务，允许您链接到代码存储库，构建镜像并测试它们，存储手动推送的镜像以及指向Docker云的链接，以便可以将镜像部署到主机。它为整个开发流程中的容器镜像发现，分发和变更管理，用户和团队协作以及工作流自动化提供了集中资源。</p><h2 id="3-如何临时退出一个正在交互的容器的终端，而不终止它？"><a href="#3-如何临时退出一个正在交互的容器的终端，而不终止它？" class="headerlink" title="3. 如何临时退出一个正在交互的容器的终端，而不终止它？"></a>3. 如何临时退出一个正在交互的容器的终端，而不终止它？</h2><p>按Ctrl+p，后按Ctrl+q，如果按Ctrl+c会使容器内的应用进程终止，进而会使容器终止。</p><h2 id="4-很多应用容器都是默认后台运行的，怎么查看它们的输出和日志信息？"><a href="#4-很多应用容器都是默认后台运行的，怎么查看它们的输出和日志信息？" class="headerlink" title="4. 很多应用容器都是默认后台运行的，怎么查看它们的输出和日志信息？"></a>4. 很多应用容器都是默认后台运行的，怎么查看它们的输出和日志信息？</h2><p>使用docker logs，后面跟容器的名称或者ID信息</p><h2 id="5-可以在一个容器中同时运行多个应用进程吗？"><a href="#5-可以在一个容器中同时运行多个应用进程吗？" class="headerlink" title="5. 可以在一个容器中同时运行多个应用进程吗？"></a>5. 可以在一个容器中同时运行多个应用进程吗？</h2><p>一般不推荐在同一个容器内运行多个应用进程，如果有类似需求，可以通过额外的进程管理机制，比如supervisord来管理所运行的进程</p><h2 id="6-如何从Docker镜像中创建一个Docker容器？"><a href="#6-如何从Docker镜像中创建一个Docker容器？" class="headerlink" title="6. 如何从Docker镜像中创建一个Docker容器？"></a>6. 如何从Docker镜像中创建一个Docker容器？</h2><p>为了从镜像中创建一个容器，我们从Docker资源库中拉出我们想要的镜像并创建一个容器。我们可以使用以下命令。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">docker run -it -d &lt;image_name&gt;<br></code></pre></td></tr></table></figure><p>-it: 这两个选项结合起来表示在交互模式下运行容器*，并且分配一个伪终端（pseudo-TTY）。<br>-d: 这个选项表示在后台（detached）模式下运行容器，即使你退出终端或会话，容器也会继续运行。<br><image_name>: 这里应该替换成你要运行的容器的镜像名称。</p><h2 id="7-有什么常用的-Docker-命令？"><a href="#7-有什么常用的-Docker-命令？" class="headerlink" title="7. 有什么常用的 Docker 命令？"></a>7. 有什么常用的 Docker 命令？</h2><ul><li>docker pull 拉取镜像</li><li>docker create 创建容器</li><li>docker rm 删除容器</li><li>docker ps 列出正在运行的容器列表</li><li>docker run 创建容器并运行指定命令</li><li>docker start 启动容器</li><li>docker stop 停止运行容器</li><li>docker restart 重启容器</li><li>docker rm 删除容器</li><li>docker exec 容器执行指定命令</li><li>docker rmi 删除镜像</li></ul><h2 id="8-如何把主机的东西拷贝到容器内部？"><a href="#8-如何把主机的东西拷贝到容器内部？" class="headerlink" title="8. 如何把主机的东西拷贝到容器内部？"></a>8. 如何把主机的东西拷贝到容器内部？</h2><ul><li>通过 docker cp 命令即可，还能把容器内部内容拷贝到主机</li></ul><h2 id="9-如何让容器随着-Docker-服务启动而自动启动？"><a href="#9-如何让容器随着-Docker-服务启动而自动启动？" class="headerlink" title="9. 如何让容器随着 Docker 服务启动而自动启动？"></a>9. 如何让容器随着 Docker 服务启动而自动启动？</h2><ul><li>创建容器时，加上 –restart&#x3D;always 参数</li><li>创建容器后，通过修改容器配置文件的 RestartPolicy 参数值</li><li>创建容器后，使用 docker update 命令更新容器的 –restart 参数值</li></ul><h2 id="10-如何查看官方镜像服务的默认端口是什么？"><a href="#10-如何查看官方镜像服务的默认端口是什么？" class="headerlink" title="10. 如何查看官方镜像服务的默认端口是什么？"></a>10. 如何查看官方镜像服务的默认端口是什么？</h2><ul><li>可以通过 docker inspect 查看镜像信息，然后找到端口映射一栏</li><li>也可以先用该镜像创建一个容器并运行，通过 docker ps 查看运行端口是什么</li></ul><h2 id="11-如何修改容器的端口映射？"><a href="#11-如何修改容器的端口映射？" class="headerlink" title="11. 如何修改容器的端口映射？"></a>11. 如何修改容器的端口映射？</h2><ul><li>删除容器，重新创建容器，并指定端口映射</li><li>通过容器配置文件修改端口映射</li><li>通过 docker commit 将容器构建为一个全新的镜像，然后再通过该镜像创建新的容器，并指定端口映射</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><a href="https://www.cnblogs.com/stry/p/17041111.html">2022年最全Docker面试题附答案解析大汇总</a></li><li><a href="https://juejin.cn/post/7088894767047639054">排名前20的Docker面试问题（附答案）</a></li><li><a href="https://www.nowcoder.com/discuss/352905402784264192">Docker面试题总结（配答案）</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Docker</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
      <tag>面试题</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>万字总结！Docker简介及底层关键技术剖析</title>
    <link href="/2024/04/18/DockerStudy/"/>
    <url>/2024/04/18/DockerStudy/</url>
    
    <content type="html"><![CDATA[<h1 id="Docker-简介"><a href="#Docker-简介" class="headerlink" title="Docker 简介"></a>Docker 简介</h1><p>Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源。Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）。几乎没有性能开销，可以很容易地在机器和数据中心中运行。最重要的是，他们不依赖于任何语言、框架或包装系统。</p><p>Docker 基于 Linux 内核的 cgroup，namespace，以及 UnionFS 等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。最初实现是基于 LXC，从 0.7 版本以后开始去除 LXC，转而使用自行开发的 libcontainer，从 1.11 版本开始，则进一步演进为使用 runC 和 containerd。</p><pre><code class="hljs">runc 是一个 Linux 命令行工具，用于根据 OCI容器运行时规范 创建和运行容器。containerd 是一个守护程序，它管理容器生命周期，提供了在一个节点上执行容器和管理镜像的最小功能集。</code></pre><p><img src="/2024/04/18/DockerStudy/dockerArc1.jpg" alt="Docker 架构"></p><h2 id="Docker-与LXC-的区别"><a href="#Docker-与LXC-的区别" class="headerlink" title="Docker 与LXC 的区别"></a>Docker 与LXC 的区别</h2><p>LXC的全名为Linux Container，它是一种轻量级的Linux内核容器虚拟化技术，允许在同一主机上运行多个相互隔离的Linux Container，每个容器都有自己的完整的文件系统、网络、进程和资源隔离环境。</p><p>LXC与传统的虚拟机技术不同，LXC不需要运行完整的操作系统镜像。LXC使用Linux内核提供的cgroups和命名空间（Namespaces）功能来实现容器隔离。它有效地将由单个操作系统管理的资源划分到孤立的组中，以更好地在孤立的组之间平衡有冲突的资源使用需求。</p><p>docker 出现之初，便是采用了 lxc 技术作为 docker 底层，对容器虚拟化的控制。后来随着 docker 的发展，它自己封装了 libcontainer （golang 的库）来实现 Cgroup 和 Namespace 控制，从而消除了对 lxc 的依赖。</p><p>现在Docker相较于LXC已经有了十足的发展，其生态也更加完善。主要有以下几个方面的区别。</p><ul><li><strong>抽象级别：</strong> Docker 提供了更高级别的抽象，它强调应用程序和服务的容器化，提供了易于使用的工具和接口，如 Docker CLI、Docker Compose 等, Docker 的目的是为了尽可能减少容器中运行的程序，减少到只运行单个程序，并且通过 Docker 来管理这个程序，有了 Docker，可以从底层应用程序通过 Docker 来配置，网络，存储和编排。而 LXC 更接近于操作系统级的虚拟化，需要更多的系统管理和配置工作，LXC 用正常操作系统环境回避网络、存储等问题，并且因此可以快速兼容所有应用程序和工具，以及任意管理和编制层次，来替代虚拟机。</li><li><strong>镜像构建方式：</strong> Docker 使用 Dockerfile 来定义镜像的构建过程，这使得镜像的构建和管理变得非常简单和可重复。而在 LXC 中，镜像的创建和管理相对复杂，它没有类似Dockerfile的镜像构建方式，它使用基于文件系统的容器模板来创建容器。</li><li><strong>资源隔离：</strong> Docker 相比于 LXC 增加了更多的资源隔离和管理功能，如 CPU、内存、网络等资源的控制。这使得 Docker 更适合于生产环境中的容器化部署。</li><li><strong>占用资源不同：</strong> 相对于LXC，Docker的容器启动速度更快，占用资源更少。这是因为Docker容器使用了更多的技术手段来优化容器启动和运行的效率，例如使用联合文件系统（UnionFS）来共享文件系统，使用镜像层缓存来加速镜像构建，使用Docker镜像仓库等。</li><li><strong>生态系统：</strong> Docker 有着庞大的生态系统，包括 Docker Hub（用于分享和拉取镜像）、Docker Swarm（用于容器编排和集群管理）、Docker Compose（用于多容器应用编排）等工具和服务。相比之下，LXC 的生态系统相对较小。</li></ul><h2 id="Docker-与传统虚拟化的区别"><a href="#Docker-与传统虚拟化的区别" class="headerlink" title="Docker 与传统虚拟化的区别"></a>Docker 与传统虚拟化的区别</h2><p>下面的图片比较了 Docker 和传统虚拟化方式的不同之处。<strong>传统虚拟机技术</strong>是<strong>虚拟出一套硬件</strong>后，在其上<strong>运行一个完整操作系统</strong>，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内<strong>没有自己的内核</strong>，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。</p><p><img src="/2024/04/18/DockerStudy/dockerVsVm.jpeg" alt="Docker与传统虚拟化的区别"></p><p>其区别可以从以下几点展开。</p><table><thead><tr><th>对比项</th><th>Docker 容器</th><th>虚拟机</th></tr></thead><tbody><tr><td>隔离性</td><td>较弱的隔离，属于进程之间的隔离，各个容器共享宿主机的内核</td><td>强隔离，属于系统级别的隔离，会模拟出一整个操作系统和硬件，各个虚拟机之间完全隔离</td></tr><tr><td>启动速度</td><td>秒级</td><td>分钟级</td></tr><tr><td>镜像大小</td><td>一般为 MB</td><td>一般为 GB</td></tr><tr><td>托管主体</td><td>Docker Engine 在操作系统和 Docker 容器之间进行协调。</td><td>虚拟机监控器在计算机的物理硬件和虚拟机之间进行协调。</td></tr><tr><td>运行性能</td><td>接近原生（损耗小于 2%）</td><td>损耗小于 15%</td></tr><tr><td>镜像可移植性</td><td>平台无关</td><td>平台相关</td></tr><tr><td>占用资源量</td><td>Docker 只是一个进程，只需要将应用以及相关的组件打包，在运行时占用很少的资源，单机上可支持上千个容器</td><td>虚拟机是一个完整的操作系统，需要占用大量的磁盘、内存和 CPU 资源，一般一个主机上只能支持几十个虚拟机</td></tr><tr><td>安全性</td><td>1. 容器内的用户从普通用户权限提升为 root 权限，就直接具备了宿主机的 root 权限。<br>2. 容器中没有硬件隔离，使得容器容易受到攻击。</td><td>1. 虚拟机租户 root 权限和主机的 root 虚拟机权限是分离的。<br>2. 硬件隔离技术：防止虚拟机突破和宿主机交互。</td></tr><tr><td>高可用性</td><td>docker对业务的⾼可⽤⽀持是通过快速重新部署实现的。</td><td>虚拟化具备负载均衡，⾼可⽤，容错，迁移和数据保护等经过⽣产实践检验的成熟保障机制，VMware可承诺虚拟机99.999%⾼可⽤，保证业务连续性。</td></tr><tr><td>资源共享</td><td>按需共享，依据cgroups进行控制。</td><td>按固定数量共享，在虚拟机映像的配置要求中设置。</td></tr></tbody></table><h3 id="什么情况下只能用虚拟机"><a href="#什么情况下只能用虚拟机" class="headerlink" title="什么情况下只能用虚拟机"></a>什么情况下只能用虚拟机</h3><ol><li><strong>需要操作系统级别的隔离：</strong>虚拟机提供了更高的隔离性，每个虚拟机都有自己的操作系统，可以实现不同操作系统之间的隔离，虚拟机可以做到这一个主机上同时运行多个不同操作系统的虚拟机，且互不影响。而Docker容器调用的实际上是宿主机的内核，因此容器之间共享宿主机的内核，无法实现操作系统级的隔离，例如如果 Docker 容器中运行的应用程序存在内核漏洞或者容器内部进行了特权操作（例如修改主机文件系统），这可能会导致容器越过 Docker 的隔离性，影响到宿主机或其他容器。也是因此在一些隔离性要求较高的场景下，例如云上的多租户场景，就还是需要使用虚拟机。</li><li><strong>需要更强的资源隔离和控制：</strong>虚拟机可以对 CPU、内存、磁盘空间等以固定的单位进行分配，而Docker 容器的资源隔离和控制较为简单，通常是通过限制容器的 CPU 使用率、内存限制等来实现。</li></ol><p>总的来说，Docker或者说容器技术和虚拟机并非简单的取舍关系，如果你希望一个完全隔离的和资源有保障的环境，那么虚拟机是你的不二选择;如果你只希望进程之间相互隔离，同时拥有轻量化的属性，那么linux容器技术或者Docker，才是更好的选择。</p><h2 id="Docker的重要概念"><a href="#Docker的重要概念" class="headerlink" title="Docker的重要概念"></a>Docker的重要概念</h2><h3 id="镜像（Image）"><a href="#镜像（Image）" class="headerlink" title="镜像（Image）"></a>镜像（Image）</h3><p>当我们使用docker容器时，首先需要首先先下载一个对应的镜像，镜像相比于虚拟机的进行更加轻量，原因在于它实际上主要只是一个rootfs（当然还包括一些额外的配置文件）。对于一个精简的 OS ，rootfs 可以很小，只需要包括最基本的命令、工具和程序库即可，因为底层直接共用 Host 主机的 kernel。</p><p><img src="/2024/04/18/DockerStudy/dockerLayer1.png" alt="镜像分层"></p><p>镜像中的rootfs采取的是分层存储的方式，即每个镜像都是由多个只读层叠加而成。这种分层存储的特性使得镜像的复用、定制、共享变的更为容易。同时，每一层都可以被容器读取，容器的文件系统就是这些层的叠加。镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。</p><p><img src="/2024/04/18/DockerStudy/dockerImage.jpg" alt="Docker镜像结构"></p><p>从上图中我们可以看到，当由 ubuntu:14.04 镜像启动容器时，ubuntu:14.04 镜像的镜像层内容将作为容器的 rootfs；而 ubuntu:14.04 镜像的 json 文件，会由 docker daemon 解析，并提取出其中的容器执行入口 CMD 信息，以及容器进程的环境变量 ENV 信息，最终初始化容器进程。当然，容器进程的执行入口来源于镜像提供的 rootfs。</p><h4 id="rootfs"><a href="#rootfs" class="headerlink" title="rootfs"></a>rootfs</h4><p>rootfs代表了一个系统中的根文件系统，在传统的 Linux 操作系统内核启动时，首先挂载一个只读的 rootfs，当系统检测其完整性之后，再将其切换为读写模式。</p><p>在docker容器中，rootfs是docker容器在启动时内部进程可见的文件系统，即docker容器的根目录。rootfs通常包含一个操作系统运行所需的文件系统，例如可能包含典型的类 Unix 操作系统中的目录系统，如 &#x2F;dev、&#x2F;proc、&#x2F;bin、&#x2F;etc、&#x2F;lib、&#x2F;usr、&#x2F;tmp 及运行docker容器所需的配置文件、工具等。</p><p>docker实现rootfs依靠的实联合挂载技术。</p><h4 id="联合挂载（UnionFS）"><a href="#联合挂载（UnionFS）" class="headerlink" title="联合挂载（UnionFS）"></a>联合挂载（UnionFS）</h4><p>最新的docker采用的联合挂载技术为overlay2。对于overlay2，它的主要作用就是将一堆目录下的内容联合挂载到一个目录下，它包含以下几个目录：</p><ul><li>LowerDir：只读层，包含镜像的各个层。</li><li>UpperDir：可读写层，容器运行时的写入操作都会在这个目录下进行。</li><li>WorkDir：工作基础目录，挂载后内容会被清空，且在使用过程中其内容用户不可见。</li><li>MergeDir：合并目录，是 LowerDir 和 UpperDir 的合并结果,本身没有任何文件，只是一个挂载点。</li></ul><p>在合并的目录中进行操作时，各个目录之间有上下顺序，上层目录的同名文件会遮盖住下层的文件。如果对LowerDir中的文件进行了修改，那么实际的文件是不会改变的，而是会在UpperDir中对其进行拷贝，然后在UpperDir中进行修改，这也称为<strong>写时复制技术</strong>。如果对LowerDir中的文件进行删除，那么实际的文件也不会被删除，而是在UpperDir中创建一个同名文件，并将其标记为删除状态。</p><h4 id="docker镜像的完整分层"><a href="#docker镜像的完整分层" class="headerlink" title="docker镜像的完整分层"></a>docker镜像的完整分层</h4><p>一个容器完整的层应由三个部分组成：</p><ol><li>镜像层：也称为rootfs，提供容器启动的文件系统。rootfs也就是image中提供的文件。</li><li>init层： 用于修改容器中一些文件如&#x2F;etc&#x2F;hostname，&#x2F;etc&#x2F;hosts，&#x2F;etc&#x2F;resolv.conf等。需要这一层的原因是当容器启动时候，这些本该属于image层的文件或目录，比如hostname，用户需要修改，但是image层又不允许修改，所以启动时候通过单独挂载一层init层，通过修改init层中的文件达到修改这些文件目的。</li><li>容器层：使用联合挂载统一给用户提供的可读写目录。当不对容器进行任何操作时，容器层是空的，当容器中有文件写入时，这些文件会被写入到容器层。</li></ol><h3 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h3><p>容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的命名空间、文件系统、网络配置等。</p><p>如上所述，容器在运行时会添加一层可读写的容器层，其生命周期与docker一致。按照 Docker 最佳实践的要求，容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用 数据卷（Volume）、或者 绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。</p><h3 id="厂库"><a href="#厂库" class="headerlink" title="厂库"></a>厂库</h3><p>为了便于镜像的上传和下载，我们就需要一个集中的存储、分发镜像的服务，Docker Registry 就是这样的服务。一个 Docker Registry 中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。</p><p>仓库名经常以 两段式路径 形式出现，比如 jwilder&#x2F;nginx-proxy，前者往往意味着 Docker Registry 多用户环境下的用户名，后者则往往是对应的软件名。</p><p>最常使用的 Registry 公开服务是官方的 <a href="https://hub.docker.com/">Docker Hub</a>，这也是默认的 Registry，并拥有大量的高质量的官方镜像。除此以外，还有 Red Hat 的 <a href="https://quay.io/repository/">Quay.io</a>；Google 的 <a href="https://cloud.google.com/container-registry/">Google Container Registry</a>，Kubernetes 的镜像使用的就是这个服务；代码托管平台 GitHub 推出的 <a href="https://docs.github.com/cn/packages/working-with-a-github-packages-registry/working-with-the-container-registry">ghcr.io</a>。</p><h1 id="Docker-程序架构"><a href="#Docker-程序架构" class="headerlink" title="Docker 程序架构"></a>Docker 程序架构</h1><p><img src="/2024/04/18/DockerStudy/dockerSoftArc.jpg" alt="Docker 程序架构"></p><p>Docker 是一个客户端-服务器（C&#x2F;S）架构程序。Docker 客户端只需要向 Docker 服务器或者守护进程发出请求，服务器或者守护进程将完成所有工作并返回结果。Docker 提供了一个命令行工具以及一整套 RESTful API。你可以在同一台宿主机上运行 Docker 守护进程和客户端，也可以从本地的 Docker 客户端连接到运行在另一台宿主机上的远程 Docker 守护进程。</p><p>Docker 服务端是 Docker 所有后台服务的统称。其中 dockerd 是一个非常重要的后台管理进程，它负责响应和处理来自 Docker 客户端的请求，然后将客户端的请求转化为 Docker 的具体操作。例如镜像、容器、网络和挂载卷等具体对象的操作和管理。</p><p>Docker 从诞生到现在，服务端经历了多次架构重构。起初，服务端的组件是全部集成在 docker 二进制里。但是从 1.11 版本开始， dockerd 已经成了独立的二进制，此时的容器也不是直接由 dockerd 来启动了，而是集成了 containerd、runC 等多个组件。</p><h1 id="Docker-关键底层技术"><a href="#Docker-关键底层技术" class="headerlink" title="Docker 关键底层技术"></a>Docker 关键底层技术</h1><p>Linux 命名空间、控制组和 UnionFS 三大技术支撑了目前 Docker 的实现，也是 Docker 能够出现的最重要原因，此外Docker网络、Docker存储也尤为重要。UnionFS前面已经介绍过了，不再赘述。</p><h2 id="Linux-命名空间-namespace"><a href="#Linux-命名空间-namespace" class="headerlink" title="Linux 命名空间(namespace)"></a>Linux 命名空间(namespace)</h2><p>命名空间是 是 Linux 提供的一种内核级别环境隔离的方法，本质就是对全局系统资源的一种封装隔离。每个容器都有自己单独的命名空间，运行在其中的应用都像是在独立的操作系统中运行一样。命名空间保证了容器之间彼此隔离，互不影响。</p><p>目前linux内核支持以下6种命名空间：</p><ul><li><strong>PID命名空间：</strong> 使得容器内的进程拥有独立的进程空间。在容器中运行ps -ef，只能看到容器内的进程，而看不到宿主机上的进程。</li><li><strong>net命名空间：</strong> pid 命名空间将进程pid情况进行了隔离，但是网络端口还是共享 host 的端口。网络隔离是通过 net 命名空间实现的， 每个 net 命名空间有独立的网络设备，IP 地址，路由表，&#x2F;proc&#x2F;net 目录。这样每个容器的网络就能隔离开来。Docker 默认采用 veth 的方式，将容器中的虚拟网卡同 host 上的一 个Docker 网桥 docker0 连接在一起。</li><li><strong>ipc 命名空间：</strong> ipc全称interprocess communication，指的是一种进程间的交互方法，包括信号量、消息队列和共享内存等。Docker 默认会为每个容器创建一个独立的 IPC 命名空间，这样容器内的进程就可以在一个隔离的 IPC 环境中运行，不会影响到其他容器或者宿主机的进程。</li><li><strong>mnt 命名空间：</strong> mnt 命名空间用于隔离文件系统挂载点，每个容器拥有自己独立的挂载点视图。挂载主要指的是将宿主机的某个目录挂载到自己容器内的某个目录下，通过命名空间的隔离，就可以本本命名空间内记录自己的挂载点，而不会影响到其他容器。</li><li><strong>uts 命名空间：</strong> UTS(“UNIX Time-sharing System”) 命名空间允许每个容器拥有独立的 hostname 和 domain name， 使其在网络上可以被视作一个独立的节点，从而避免在网络传输过程中在依靠主机名进行信息传递时出现冲突。</li><li><strong>user 命名空间：</strong> 每个容器可以有不同的用户和组 id， 也就是说可以在容器内用容器内部的用户执行程序而非主机上的用户。</li></ul><h2 id="控制组（Cgroup）"><a href="#控制组（Cgroup）" class="headerlink" title="控制组（Cgroup）"></a>控制组（Cgroup）</h2><p>控制组是linux内核的一个特性，主要用来对共享资源进行隔离、限制，审计等。避免多个容器同时运行时的系统资源竞争，它最早是由 Google 的程序员 2006 年起提出，Linux 内核自 2.6.24 开始支持。</p><p>Cgroup 可以限制一个进程组的资源使用，包括 CPU、内存、磁盘IO、网络带宽等。在 Docker 中，Cgroup 主要用来限制容器的相关资源使用。</p><p>Cgroups 分 v1 和 v2 两个版本：</p><ul><li>v1 实现较早，功能比较多，但是由于它里面的功能都是零零散散的实现的，所以规划的不是很好，导致了一些使用和维护上的不便。</li><li>v2 的出现就是为了解决 v1 的问题，在最新的 4.5 内核中，Cgroups v2 声称已经可以用于生产环境了，但它所支持的功能还很有限。</li></ul><p>Cgroups 主要包括下面几部分：<br>*** cgroups 本身：** cgroup 是对进程分组管理的一种机制，一个 cgroup 包含一组进程。</p><ul><li><strong>subsystem：</strong> 一个 subsystem 就是一个内核模块，可以调度、限制和监控特定资源的使用情况，他被关联到一颗 cgroup 树之后，就会在树的每个节点（进程组）上做具体的操作。到目前为止，Linux 支持 12 种 subsystem，比如限制 CPU 的使用时间，限制使用的内存，统计 CPU 的使用情况，冻结和恢复一组进程等。</li><li><strong>hierarchy：</strong> 一个 hierarchy 可以理解为一棵 cgroup 树，树的每个节点就是一个进程组，每棵树都会与零到多个 subsystem 关联，也就是可以对树上的每个节点（进程组）做一些对应的subsystem提供的操作，一个 subsystem 只能附加到 一 个 hierarchy 上面。系统中可以有很多颗 cgroup 树，每棵树都和不同的 subsystem 关联，一个进程可以属于多颗树，即一个进程可以属于多个进程组。当一颗 cgroup 树不和任何 subsystem 关联的时候，意味着这棵树只是将进程进行分组，至于要在分组的基础上做些什么，将由应用程序自己决定，systemd 就是一个这样的例子。</li></ul><p>个人理解：</p><ul><li>cgroup 用于对进程进行分组。</li><li>hierarchy 将多个 cgroup 组成一棵树，并提供控制的相关功能，提供了一个控制模板。</li><li>subsystem 则负责资源限制的工作，将 subsystem 和 hierarchy 绑定后，该 hierarchy 上的所有 cgroup 下的进程都会被 subsystem 给限制，但是限制的值可以自定义。</li><li>子 cgroup 会继承父 cgroup 的 subsystem，但是子 cgroup 之后可以自定义自己的配置。</li></ul><p><img src="/2024/04/18/DockerStudy/Cgroups.png" alt="Cgroups 示例"></p><p>比如上图表示两个 hierarchiy，每一个 hierarchiy 中是一颗树形结构，树的每一个节点是一个 cgroup （比如 cpu_cgrp, memory_cgrp）。</p><ul><li>第一个 hierarchiy attach 了 cpu 子系统和 cpuacct 子系统， 因此当前 hierarchiy 中的 cgroup 就可以对 cpu 的资源进行限制，并且对进程的 cpu 使用情况进行统计。</li><li>第二个 hierarchiy attach 了 memory 子系统，因此当前 hierarchiy 中的 cgroup 就可以对 memory 的资源进行限制。</li></ul><p>在每一个 hierarchiy 中，每一个节点（cgroup）可以设置对资源不同的限制权重（即自定义配置）。比如上图中 cgrp1 组中的进程可以使用 60%的 cpu 时间片，而 cgrp2 组中的进程可以使用 20%的 cpu 时间片。</p><h2 id="Docker-网络"><a href="#Docker-网络" class="headerlink" title="Docker 网络"></a>Docker 网络</h2><p>Docker的网络模式主要有以下几种：</p><table><thead><tr><th>模式</th><th>描述</th></tr></thead><tbody><tr><td>bridge</td><td>为每一个容器分配、设置 IP 等，并将容器连接到一个 docker0 虚拟网桥，默认为该模式。</td></tr><tr><td>host</td><td>容器将不会虚拟出自己的网卡，配置自己的 IP 等，而是使用宿主机的 IP 和端口。</td></tr><tr><td>none</td><td>容器有独立的 Network namespace，但并没有对其进行任何网络设置，如分配 veth pair 和网桥连接，IP 等。</td></tr><tr><td>container</td><td>新创建的容器不会创建自己的网卡和配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。</td></tr></tbody></table><h3 id="bridge-模式"><a href="#bridge-模式" class="headerlink" title="bridge 模式"></a>bridge 模式</h3><p><img src="/2024/04/18/DockerStudy/dockerNetworkBridge.jpeg" alt="Docker bridge网络模式"></p><p>bridge 模式是 Docker 默认的网络模式。在Docker服务启动后，会在主机上创建一个名为 docker0 的虚拟网桥，当我们创建一个bridge网络模式的容器时，首先容器会新建一个网络命名空间，然后它会连接到这个虚拟网桥上。连接的方法是创建一对虚拟网卡veth pair设备，其中一个端口连接到容器内部，命名为eth0，另一个端口连接到docker0上，命名为vethxxx模式的名字。这种虚拟网卡利用内存从来进行数据包的收发，当一端收到数据包后会自动转发给另一端，并对外表现为一个独立的网络设备。同时也会从docker0子网中分配一个 IP 给容器使用，并设置 docker0 的 IP 地址为容器的默认网关。</p><p>当容器需要对外通信时，数据包会先被容器内的 veth 网卡接收，然后通过 veth pair 传递给 docker0，再由 docker0 转发给宿主机的物理网卡，然后会对数据包进行Net包装，表现的就像是主机自己发出的数据包一样，最终到达目的地。</p><p>如果需要同一个主机下的容器之间通信，那么需要设置–link参数来允许容器之间的通信，注意默认情况下，容器之间是无法通信的。而随着Docker 1.9版本的发布，Docker官方推荐使用用户自定义的网络来代替–link参数。</p><p>这种模式下的一个大缺点就在于容器都没有一个公有IP，即和宿主机不处于同一个网段。导致的结果是宿主机以外的世界不能直接和容器进行通信。</p><h3 id="host-模式"><a href="#host-模式" class="headerlink" title="host 模式"></a>host 模式</h3><p>host模式相当于Vmware中的NAT模式，与宿主机在同一个网络中，但没有独立IP地址。启动容器使用host模式，容器将不会获得一个独立的Network Namespace，而是和宿主机共用一个Network Namespace。容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。</p><p>使用host模式的容器可以直接使用宿主机的IP地址与外界通信，容器内部的服务端口也可以使用宿主机的端口，不需要进行NAT，host最大的优势就是网络性能比较好，docker host上已经使用的端口就不能再用了，网络的隔离性不好。</p><p><img src="/2024/04/18/DockerStudy/dockerNetworkHost.jpeg" alt="Docker host网络模式"></p><h3 id="none-模式"><a href="#none-模式" class="headerlink" title="none 模式"></a>none 模式</h3><p>使用none模式，Docker 容器拥有自己的 Network Namespace，但是，并不为Docker 容器进行任何网络配置。也就是说，这个 Docker 容器没有网卡、IP、路由等信息。需要我们自己为 Docker 容器添加网卡、配置 IP 等。 None模式示意图:</p><p><img src="/2024/04/18/DockerStudy/dockerNetworkNone.jpeg" alt="Docker none网络模式"></p><h3 id="container-模式"><a href="#container-模式" class="headerlink" title="container 模式"></a>container 模式</h3><p>这个模式指定新创建的容器和已经存在的一个容器共享一个 Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过 lo 网卡设备进行高效通信。 Container模式示意图：</p><p><img src="/2024/04/18/DockerStudy/dockerNetworkContainer.jpeg" alt="Docker container网络模式"></p><h2 id="Docker-存储"><a href="#Docker-存储" class="headerlink" title="Docker 存储"></a>Docker 存储</h2><p>根据前面的UnionFS的介绍我们可知，在默认情况下在Docker容器内创建和修改的所有文件都在可写层，只能在容器内部使用，难以被其他服务共享。且容器删除后，数据也跟着删除。同时写入容器的可写层需要Docker存储驱动管理文件系统。存储驱动使用Linux内核提供的联合文件系统，其性能不如直接写入主机文件系统的Docker卷。所以docker也提供了一些存储持久化的功能，主要可以分为：volume、bind mount和tmpfs。</p><h3 id="Volume"><a href="#Volume" class="headerlink" title="Volume"></a>Volume</h3><p>Volumes 是Docker推荐的挂载方式，它在主机中创建一个数据卷，并对应到容器中的一个目录。与把数据存储在容器的可写层相比，使用Volume可以避免增加容器的容量大小，还可以使存储的数据与容器的生命周期独立。Volumes存储在主机文件系统中由Docker管理的位置，在Linux主机上该位置默认就是&#x2F;var&#x2F;lib&#x2F;docker&#x2F;volumes目录，其他非docker进程不能修改该路径下的文件，完全由docker引擎来管理。Volumes支持使用Volumes驱动，可以让用户将数据存储在远程主机或云提供商处等。可以以命名方式或匿名方式挂载卷：</p><ul><li>匿名卷（Anonymous Volumes）:首次挂载容器未指定名称，Docker为其随机指定一个唯一名称。</li><li>命名卷（Named Volumes）:指定明确名称，和匿名卷其他特性相同。</li></ul><p>卷由Docker创建并管理，卷适合以下应用场景。</p><ul><li>在多个正在运行的容器之间共享数据。（数据共享）</li><li>当Docker主机不能保证具有特定目录结构时，卷有助于将Docker主机的配置与容器运行时解耦。（构建新目录与主机不同）</li><li>当需要将容器的数据存储到远程主机或云提供商处，而不是本地时。（可以远程挂载卷，公有云、灾备等场景）</li><li>当需要在两个Docker主机之间备份、恢复或迁移数据时。（主机间备份迁移）</li></ul><h3 id="Bind-mount"><a href="#Bind-mount" class="headerlink" title="Bind mount"></a>Bind mount</h3><p>Bind mount 模式下可以存储在宿主机器任何一个地方，但是会依赖宿主机器的目录结构，不能通过docker CLI 去直接管理，并且非docker进程和docker进程都可以修改该路径下的文件。</p><p>它的特点：</p><ul><li>主机上进程或容器可以随时修改。</li><li>相比Volumes，功能更受限、性能更高。</li><li>绑定挂载运行访问敏感文件。</li></ul><p>绑定挂载适合以下应用场景。</p><ul><li>在主机和容器之间共享配置文件。</li><li>在Docker主机上的开发环境和容器之间共享源代码或构建工件。</li><li>当Docker主机上的目录结构保证与容器要求的绑定挂载一致时。</li></ul><h3 id="tmpfs"><a href="#tmpfs" class="headerlink" title="tmpfs"></a>tmpfs</h3><p>tmpfs挂载仅限于运行Linux操作系统的Docker主机使用，它只存储在主机的内存中，不会被写到主机的文件系统中，因此不能持久保存容器的应用数据。<br>在不需要将数据持久保存到主机或容器中时，tmpfs挂载最合适。<br>如果容器产生了非持久化数据，那么可以考虑使用tmpfs挂载避免将数据永久存储到任何位置，并且通过避免写入容器的可写层来提高容器的性能。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><a href="https://yeasy.gitbook.io/docker_practice/introduction/what">Docker — 从入门到实践</a></li><li><a href="ttps://cloud.tencent.com/developer/article/1492076">万字详解Docker架构原理、功能及使用</a></li><li><a href="https://www.zhihu.com/question/268288911/answer/335458760">请问docker与lxc是什么关系，有什么区别。？</a></li><li><a href="https://www.quanxiaoha.com/docker/why-use-docker.html">Docker 和虚拟机的区别是什么？</a></li><li><a href="https://aws.amazon.com/cn/compare/the-difference-between-docker-vm/">Docker 与虚拟机之间有什么区别？</a></li><li><a href="https://zhuanlan.zhihu.com/p/374924046">手撕docker文件结构 —— overlayFS，image，container文件结构详解</a></li><li><a href="https://www.lixueduan.com/posts/docker/06-cgroups-1/#2-%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8-cgroups">Docker教程(六)—初探 Linux Cgroups：资源控制的奇妙世界</a></li><li><a href="https://juejin.cn/post/7041923410649153543#heading-7">全网最详细的Docker网络教程详解</a></li><li><a href="https://www.qikqiak.com/k8s-book/docs/7.Docker%E7%9A%84%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F.html">Docker 的网络模式</a></li><li><a href="https://juejin.cn/post/6844904095615025159">8讲Docker | 容器数据存储方式</a></li><li><a href="https://zhuanlan.zhihu.com/p/622614825">Docker存储管理</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Docker</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【MIT6.824】lab3 Fault-tolerant Key/Value Service 实现笔记</title>
    <link href="/2024/04/08/MIT6-824lab3A3B/"/>
    <url>/2024/04/08/MIT6-824lab3A3B/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>lab3A的实验要求如下：</p><p>Your first task is to implement a solution that works when there are no dropped messages, and no failed servers.</p><p>You’ll need to add RPC-sending code to the Clerk Put&#x2F;Append&#x2F;Get methods in client.go, and implement PutAppend() and Get() RPC handlers in server.go. These handlers should enter an Op in the Raft log using Start(); you should fill in the Op struct definition in server.go so that it describes a Put&#x2F;Append&#x2F;Get operation. Each server should execute Op commands as Raft commits them, i.e. as they appear on the applyCh. An RPC handler should notice when Raft commits its Op, and then reply to the RPC.</p><p>You have completed this task when you reliably pass the first test in the test suite: “One client”.</p><p>Add code to handle failures, and to cope with duplicate Clerk requests, including situations where the Clerk sends a request to a kvserver leader in one term, times out waiting for a reply, and re-sends the request to a new leader in another term. The request should execute just once. These notes include guidance on duplicate detection. Your code should pass the go test -run 3A tests.</p><p>lab3B的实验要求如下：</p><p>Modify your kvserver so that it detects when the persisted Raft state grows too large, and then hands a snapshot to Raft. When a kvserver server restarts, it should read the snapshot from persister and restore its state from the snapshot.</p><p>总体而言，我们需要在lab2所实现的raft系统上构建一个简单的key-value存储系统，这个系统需要支持客户端的Put&#x2F;Append&#x2F;Get操作，同时需要支持Raft的持久化和快照功能。本系统的要求是线性一致的，即每个动作都能被当做是在一个唯一的时刻进行原子执行的，具体一致性相关的内容，可查看之前的文章：<a href="https://slipegg.github.io/2024/03/28/linearizability/">分布式系统中的线性一致性</a>。<br>代码可以在<a href="https://github.com/slipegg/MIT6.824">https://github.com/slipegg/MIT6.824</a>中得到。所有代码均通过了1千次的测试。</p><h1 id="lab3A-实现"><a href="#lab3A-实现" class="headerlink" title="lab3A 实现"></a>lab3A 实现</h1><p>lab3A不涉及到Raft的快照功能，主要是要完成整个系统功能的构建。在实验时测试3A时，测试代码将会不断调用客户端的Put&#x2F;Append&#x2F;Get操作，然后检查是否所有的操作都被正确执行。</p><p>首先通过一个map来存储key-value，如下中的KVMachine所示：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> KVMachine <span class="hljs-keyword">struct</span> &#123;<br>KV <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">string</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(kv *KVMachine)</span></span> Get(key <span class="hljs-type">string</span>) (<span class="hljs-type">string</span>, Err) &#123;<br>value, ok := kv.KV[key]<br><span class="hljs-keyword">if</span> !ok &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>, ErrNoKey<br>&#125;<br><span class="hljs-keyword">return</span> value, OK<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(kv *KVMachine)</span></span> Put(key <span class="hljs-type">string</span>, value <span class="hljs-type">string</span>) Err &#123;<br>kv.KV[key] = value<br><span class="hljs-keyword">return</span> OK<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(kv *KVMachine)</span></span> Append(key <span class="hljs-type">string</span>, value <span class="hljs-type">string</span>) Err &#123;<br>oldValue, ok := kv.KV[key]<br><span class="hljs-keyword">if</span> !ok &#123;<br>kv.KV[key] = value<br><span class="hljs-keyword">return</span> OK<br>&#125;<br>kv.KV[key] = oldValue + value<br><span class="hljs-keyword">return</span> OK<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">newKVMachine</span><span class="hljs-params">()</span></span> *KVMachine &#123;<br><span class="hljs-keyword">return</span> &amp;KVMachine&#123;<span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">string</span>)&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>然后是Client端的实现，首先Client在初始化时会随机生成一个数字当做自己的id，同时它也专门维护每个请求的唯一id。Client的Put&#x2F;Append&#x2F;Get操作都是通过RPC调用Server端的Put&#x2F;Append&#x2F;Get操作来实现的，如果Server端返回了错误，告诉当前Server不是leader，那么Client就会重新发送请求到下一个Server去，直到找到leader并执行请求成功了为止。Client端的PutAppend&#x2F;Get操作的实现如下，Get也是类似，就是错误处理稍微不同，不再赘述：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(ck *Clerk)</span></span> PutAppend(key <span class="hljs-type">string</span>, value <span class="hljs-type">string</span>, op <span class="hljs-type">string</span>) &#123;<br>DPrintf(<span class="hljs-string">&quot;&#123;Clinetn-%d&#125; try to %s &#123;&#x27;%v&#x27;: &#x27;%v&#x27;&#125;\n&quot;</span>, ck.clientId, op, key, value)<br>args := PutAppendArgs&#123;Key: key, Value: value, Op: op, ClientId: ck.clientId, RequestId: ck.requestId&#125;<br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-keyword">var</span> reply PutAppendReply<br><span class="hljs-keyword">if</span> ck.servers[ck.leaderId].Call(<span class="hljs-string">&quot;KVServer.PutAppend&quot;</span>, &amp;args, &amp;reply) &amp;&amp; reply.Err == OK &#123;<br>DPrintf(<span class="hljs-string">&quot;&#123;Clinetn-%d&#125; %s &#123;&#x27;%v&#x27;: &#x27;%v&#x27;&#125; success\n&quot;</span>, ck.clientId, op, key, value)<br>ck.requestId++<br><span class="hljs-keyword">break</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br>ck.leaderId = (ck.leaderId + <span class="hljs-number">1</span>) % <span class="hljs-type">int64</span>(<span class="hljs-built_in">len</span>(ck.servers))<br>time.Sleep(<span class="hljs-number">100</span> * time.Millisecond)<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>每个Server端都会维护一个KVMachine，并且也连接到一个专门的raft节点，它的主要作用就是将客户端的请求转化为raft节点的日志，然后等待raft节点将日志提交后接收到raft节点的信息，将日志应用到自己的KVMachine中，然后返回给客户端。</p><p>将客户端请求转化为日志传递给raft部分的代码如下,Get请求也是类似的。注意这里对于重复执行过的Put、Append会直接进行返回，因为运行结果只会是OK，所以直接返回OK即可，而Get请求不需要判断是否重复执行，因为Get请求需要获取的实最新的数据，来一次就执行一次即可。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(kv *KVServer)</span></span> PutAppend(args *PutAppendArgs, reply *PutAppendReply) &#123;<br><span class="hljs-comment">// Your code here.</span><br><span class="hljs-keyword">defer</span> DPrintf(<span class="hljs-string">&quot;&#123;KVServer-%d&#125; finishes %s &#123;%s: %s&#125;, the reply is %v\n&quot;</span>, kv.me, args.Op, args.Key, args.Value, reply)<br>kv.mu.RLock()<br><span class="hljs-keyword">if</span> kv.isDuplicate(args.ClientId, args.RequestId) &#123;<br>kv.mu.RUnlock()<br>reply.Err = OK<br><span class="hljs-keyword">return</span><br>&#125;<br>kv.mu.RUnlock()<br><br>logId, _, isLeader := kv.rf.Start(Op&#123;PutAppendArgs: args&#125;)<br><br><span class="hljs-keyword">if</span> !isLeader &#123;<br>reply.Err = ErrWrongLeader<br><span class="hljs-keyword">return</span><br>&#125;<br><br>DPrintf(<span class="hljs-string">&quot;&#123;KVServer-%d&#125; try to %s &#123;%s: %s&#125; with logId: %d\n&quot;</span>, kv.me, args.Op, args.Key, args.Value, logId)<br><br>kv.mu.Lock()<br>ch_putAppend := kv.getNotifyCh_PutAppend(logId)<br>kv.mu.Unlock()<br><br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> result := &lt;-ch_putAppend:<br>reply.Err = result.Err<br><span class="hljs-keyword">case</span> &lt;-time.After(MaxWaitTime):<br>reply.Err = ErrTimeout<br>&#125;<br><br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>kv.mu.Lock()<br><span class="hljs-built_in">delete</span>(kv.notifyChs_PutAppend, logId)<br>kv.mu.Unlock()<br>&#125;()<br>&#125;<br></code></pre></td></tr></table></figure><p>当raft节点将日志分发给了大部分的节点后，就可以将日志提交，然后提醒Server端将日志应用到自己的KVMachine中。代码如下所示。注意对于Get请求，需要判断这时候节点是不是leader，Term是否还相同，以防止由于applyCh传递时间过长，这时候节点已经不是leader，没有最新的数据了。对于Put、Append操作需要判断是否已经是重复执行过的操作，如果是，直接标记为OK即可，不需要再次执行，同样也需要判断当前还是不是leader，如果是才有权限返回给客户端执行结果。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(kv *KVServer)</span></span> applier() &#123;<br><span class="hljs-keyword">for</span> !kv.killed() &#123;<br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> msg := &lt;-kv.applyCh:<br><span class="hljs-keyword">if</span> msg.CommandValid &#123;<br>kv.mu.Lock()<br><span class="hljs-keyword">if</span> msg.CommandIndex &lt;= kv.lastApplied &#123;<br>DPrintf(<span class="hljs-string">&quot;&#123;KVServer-%d&#125; reveives applied log&#123;%v&#125;&quot;</span>, kv.me, msg)<br>kv.mu.Unlock()<br><span class="hljs-keyword">continue</span><br>&#125;<br>kv.lastApplied = msg.CommandIndex<br><br>op := msg.Command.(Op)<br><span class="hljs-keyword">if</span> op.GetArgs != <span class="hljs-literal">nil</span> &#123;<br>DPrintf(<span class="hljs-string">&quot;&#123;KVServer-%d&#125; apply get %v.&quot;</span>, kv.me, op.GetArgs.Key)<br>value, err := kv.kvMachine.Get(op.GetArgs.Key)<br>reply := GetReply&#123;Err: err, Value: value&#125;<br><br><span class="hljs-keyword">if</span> currentTerm, isLeader := kv.rf.GetState(); isLeader &amp;&amp; currentTerm == msg.CommandTerm &#123;<br><span class="hljs-keyword">if</span> ch, ok := kv.notifyChs_Get[msg.CommandIndex]; ok &#123;<br>ch &lt;- reply<br>&#125;<br>&#125;<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> op.PutAppendArgs != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">var</span> reply PutAppendReply<br><span class="hljs-keyword">if</span> kv.isDuplicate(op.PutAppendArgs.ClientId, op.PutAppendArgs.RequestId) &#123;<br>DPrintf(<span class="hljs-string">&quot;&#123;KVServer-%d&#125; receives duplicated request&#123;%v&#125;\n&quot;</span>, kv.me, msg)<br>reply.Err = OK<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>DPrintf(<span class="hljs-string">&quot;&#123;KVServer-%d&#125; apply %s &#123;%s: %s&#125;.\n&quot;</span>, kv.me, op.PutAppendArgs.Op, op.PutAppendArgs.Key, op.PutAppendArgs.Value)<br><span class="hljs-keyword">if</span> op.PutAppendArgs.Op == <span class="hljs-string">&quot;Put&quot;</span> &#123;<br>reply.Err = kv.kvMachine.Put(op.PutAppendArgs.Key, op.PutAppendArgs.Value)<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> op.PutAppendArgs.Op == <span class="hljs-string">&quot;Append&quot;</span> &#123;<br>reply.Err = kv.kvMachine.Append(op.PutAppendArgs.Key, op.PutAppendArgs.Value)<br>&#125;<br>kv.lastPutAppendId[op.PutAppendArgs.ClientId] = op.PutAppendArgs.RequestId<br>&#125;<br><br><span class="hljs-keyword">if</span> _, isLeader := kv.rf.GetState(); isLeader &#123;<br><span class="hljs-keyword">if</span> ch, ok := kv.notifyChs_PutAppend[msg.CommandIndex]; ok &#123;<br>ch &lt;- reply<br>&#125;<br>&#125;<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>DPrintf(<span class="hljs-string">&quot;&#123;KVServer-%d&#125; receives unknown command&#123;%v&#125;&quot;</span>, kv.me, msg)<br>&#125;<br><br><span class="hljs-keyword">if</span> kv.isNeedSnapshot() &#123;<br>DPrintf(<span class="hljs-string">&quot;&#123;KVServer-%d&#125; needs snapshot\n&quot;</span>, kv.me)<br>kv.snapshot(msg.CommandIndex)<br>&#125;<br>kv.mu.Unlock()<br>&#125; <br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="lab3B-实现"><a href="#lab3B-实现" class="headerlink" title="lab3B 实现"></a>lab3B 实现</h1><p>这里主要需要实现Server的持久化和快照功能，每个Server有一个自己的persister，其结构如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> Persister <span class="hljs-keyword">struct</span> &#123;<br>mu        sync.Mutex<br>raftstate []<span class="hljs-type">byte</span><br>snapshot  []<span class="hljs-type">byte</span><br>&#125;<br></code></pre></td></tr></table></figure><p>其中raftstate部分是raft节点存储自身持久化状态用的，而snapshot节点是用来给Server存储自身状态用的，包括了Server的KVMachine状态以及lastPutAppendId。在Server启动时，会从persister中读取raftstate和snapshot，然后根据raftstate来初始化raft节点，根据snapshot来初始化KVMachine和lastPutAppendId。代码如下所示：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(kv *KVServer)</span></span> reloadBySnapshot(snapshot []<span class="hljs-type">byte</span>) &#123;<br><span class="hljs-keyword">if</span> snapshot == <span class="hljs-literal">nil</span> || <span class="hljs-built_in">len</span>(snapshot) &lt; <span class="hljs-number">1</span> &#123;<br><span class="hljs-keyword">return</span><br>&#125;<br><br><span class="hljs-keyword">var</span> kvMachine KVMachine<br><span class="hljs-keyword">var</span> lastPutAppendId <span class="hljs-keyword">map</span>[<span class="hljs-type">int64</span>]<span class="hljs-type">int64</span><br><br>r := bytes.NewBuffer(snapshot)<br>d := labgob.NewDecoder(r)<br><span class="hljs-keyword">if</span> d.Decode(&amp;kvMachine) != <span class="hljs-literal">nil</span> ||<br>d.Decode(&amp;lastPutAppendId) != <span class="hljs-literal">nil</span> &#123;<br>DPrintf(<span class="hljs-string">&quot;&#123;KVServer-%d&#125; reloadBySnapshot failed\n&quot;</span>, kv.me)<br>&#125;<br><br>DPrintf(<span class="hljs-string">&quot;&#123;KVServer-%d&#125; reloadBySnapshot succeeded\n&quot;</span>, kv.me)<br>kv.lastPutAppendId = lastPutAppendId<br>kv.kvMachine = kvMachine<br>&#125;<br></code></pre></td></tr></table></figure><p>当Server在apply节点时，按照要求，如果raft的日志信息过大，就触发快照功能，将Server的状态保存到snapshot中，同时让raft节点生成快照。如下所示：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(kv *KVServer)</span></span> snapshot(lastAppliedLogId <span class="hljs-type">int</span>) &#123;<br>w := <span class="hljs-built_in">new</span>(bytes.Buffer)<br>e := labgob.NewEncoder(w)<br><span class="hljs-keyword">if</span> mr, lr := e.Encode(kv.kvMachine), e.Encode(kv.lastPutAppendId); mr != <span class="hljs-literal">nil</span> ||<br>lr != <span class="hljs-literal">nil</span> &#123;<br>DPrintf(<span class="hljs-string">&quot;&#123;KVServer-%d&#125; snapshot failed. kvMachine length: %v, result: &#123;%v&#125;, lastPutAppendId: &#123;%v&#125;, result: &#123;%v&#125;,&quot;</span>,<br>kv.me, <span class="hljs-built_in">len</span>(kv.kvMachine.KV), mr, kv.lastPutAppendId, lr)<br><span class="hljs-keyword">return</span><br>&#125;<br><br>data := w.Bytes()<br>kv.rf.Snapshot(lastAppliedLogId, data)<br>DPrintf(<span class="hljs-string">&quot;&#123;KVServer-%d&#125; snapshot succeeded\n&quot;</span>, kv.me)<br>&#125;<br></code></pre></td></tr></table></figure><p>由于快照的引入，Server也可能需要apply快照，即对上述的applier函数再多加一个msg类型的判断，如下所示：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> msg.SnapshotValid &#123;<br>kv.mu.Lock()<br>kv.reloadBySnapshot(msg.Snapshot)<br>kv.lastApplied = msg.CommandIndex<br>kv.mu.Unlock()<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="相关问题"><a href="#相关问题" class="headerlink" title="相关问题"></a>相关问题</h1><h2 id="为什么Get操作不能直接读leader的本地数据？"><a href="#为什么Get操作不能直接读leader的本地数据？" class="headerlink" title="为什么Get操作不能直接读leader的本地数据？"></a>为什么Get操作不能直接读leader的本地数据？</h2><p>在Raft系统中，当面临网络分区情况时，原本的leader如果位于一个小分区，那么他就不知道其实大分区中已经有了一个新leader了，这样如果client还是连接的原本的leader，并且是直接读取该leader的本地数据，那么就会面临读取到过时数据的问题，导致系统线性不一致。</p><p>所以解决这个问题的关键在于确定节点真的是leader，这里采取的是一个简单的方法，即将这个Get操作作为一个log日志放入raft系统中，直到raft系统将这个log日志提交后，才返回。实际上还有优化的空间，一个方法是在raft接受到了一个Get操作后，立刻执行心跳，如果接收到了过半的节点的心跳回复，那么就证明了这个节点是真的leader，这样就可以直接返回数据了，这就避免了将Get操作放入raft系统中的开销。还有一种方法是叫做Lease Read，它的吞吐更大，详情可参考<a href="https://blog.mrcroxx.com/posts/code-reading/etcdraft-made-simple/6-readonly/">深入浅出etcd&#x2F;raft —— 0x06 只读请求优化</a>。</p><h2 id="applier中是否有机会出现重复执行的put、append操作？"><a href="#applier中是否有机会出现重复执行的put、append操作？" class="headerlink" title="applier中是否有机会出现重复执行的put、append操作？"></a>applier中是否有机会出现重复执行的put、append操作？</h2><p>有机会出现。例如当客户端发送后，Server将其提交给了Raft，但是Raft没有在规定时间内返回，那么就会返回超时，然后客户端再去循环提交一轮，再一次提交给这个节点的时候，节点此时可能还是没有收到Raft的返回，所以会再次提交给Raft，这样就会出现重复提交的情况。而在applier中就会只执行第一次提交的操作，后续的提交都会被忽略。</p><h2 id="只用lastPutAppendId记录最后一次的Put、Append操作的id是否可行？"><a href="#只用lastPutAppendId记录最后一次的Put、Append操作的id是否可行？" class="headerlink" title="只用lastPutAppendId记录最后一次的Put、Append操作的id是否可行？"></a>只用lastPutAppendId记录最后一次的Put、Append操作的id是否可行？</h2><p>可行。因为系统中Put、Append操作的结果只会是ok，所以不需要记录每次的Put、Append操作的id，同时由于raft系统中一旦apply了就是永久apply了，并且前面的操作也都apply了，不存在回退的情况，所以如果当前操作的id小于最新一次Put、Append操作的id，那么就说明是重复执行了，直接返回ok即可。</p><h1 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h1><p>代码通过了1k次的测试，如下图所示。</p><p><img src="/2024/04/08/MIT6-824lab3A3B/result.jpg" alt="测试结果"></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://blog.mrcroxx.com/posts/code-reading/etcdraft-made-simple/6-readonly/">深入浅出etcd&#x2F;raft —— 0x06 只读请求优化</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>MIT6.824</category>
      
      <category>Lab</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
      <tag>MIT6.824</tag>
      
      <tag>Go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【MIT6.824】lab2C-persistence, lab2D-log compaction 实现笔记</title>
    <link href="/2024/04/08/MIT6-824lab2C2D/"/>
    <url>/2024/04/08/MIT6-824lab2C2D/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>lab2C的实验要求如下</p><p>Complete the functions persist() and readPersist() in raft.go by adding code to save and restore persistent state. You will need to encode (or “serialize”) the state as an array of bytes in order to pass it to the Persister. Use the labgob encoder; see the comments in persist() and readPersist(). labgob is like Go’s gob encoder but prints error messages if you try to encode structures with lower-case field names. For now, pass nil as the second argument to persister.Save(). Insert calls to persist() at the points where your implementation changes persistent state. Once you’ve done this, and if the rest of your implementation is correct, you should pass all of the 2C tests.</p><p>lab2D的实验要求如下</p><p>Implement Snapshot() and the InstallSnapshot RPC, as well as the changes to Raft to support these (e.g, operation with a trimmed log). Your solution is complete when it passes the 2D tests (and all the previous Lab 2 tests).</p><p>总体而言， lab2C需要我们实现关键数据的持久化，lab2D需要我们通过快照实现日志的压缩。代码可以在<a href="https://github.com/slipegg/MIT6.824">https://github.com/slipegg/MIT6.824</a>中得到。所有代码均通过了1千次的测试。</p><h1 id="lab2C-实现"><a href="#lab2C-实现" class="headerlink" title="lab2C 实现"></a>lab2C 实现</h1><p>在实验时测试2C时，测试代码将会尝试将某些节点从网络中断开，然后一段时间后再依据这些断开的节点的持久化的信息重新生成一个新的节点并加入到网络中，测试代码将会检测加入这个节点后是否与预期相同。</p><p>在初始化节点的时候，会传入一个Persister对象，这个对象充当一个硬盘的角色，用于持久化数据，后续在测试重新生成节点时，就需要传入旧节点的Persister对象，以便新节点能够从硬盘中读取旧节点的数据进行复原。</p><p>参考raft论文，我们需要持久化的数据有：</p><ul><li>currentTerm</li><li>votedFor</li><li>log entries</li></ul><p>在raft.go中，我们需要实现persist和readPersist函数，用于持久化和读取数据。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// persist saves Raft&#x27;s persistent state to stable storage,</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> persist() &#123;<br>rf.persister.Save(rf.encodeState(), rf.persister.snapshot)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> encodeState() []<span class="hljs-type">byte</span> &#123;<br>w := <span class="hljs-built_in">new</span>(bytes.Buffer)<br>e := labgob.NewEncoder(w)<br>e.Encode(rf.currentTerm)<br>e.Encode(rf.votedFor)<br>e.Encode(rf.logs)<br><span class="hljs-keyword">return</span> w.Bytes()<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// readPersist restores previously persisted state.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> readPersist(data []<span class="hljs-type">byte</span>) &#123;<br><span class="hljs-keyword">if</span> data == <span class="hljs-literal">nil</span> || <span class="hljs-built_in">len</span>(data) &lt; <span class="hljs-number">1</span> &#123; <span class="hljs-comment">// bootstrap without any state?</span><br><span class="hljs-keyword">return</span><br>&#125;<br><span class="hljs-keyword">var</span> currentTerm <span class="hljs-type">int</span><br><span class="hljs-keyword">var</span> votedFor <span class="hljs-type">int</span><br><span class="hljs-keyword">var</span> logs []LogEntry<br>r := bytes.NewBuffer(data)<br>d := labgob.NewDecoder(r)<br><span class="hljs-keyword">if</span> d.Decode(&amp;currentTerm) != <span class="hljs-literal">nil</span> ||<br>d.Decode(&amp;votedFor) != <span class="hljs-literal">nil</span> ||<br>d.Decode(&amp;logs) != <span class="hljs-literal">nil</span> &#123;<br>Debug(dError, <span class="hljs-string">&quot;S%v failed to read persist&quot;</span>, rf.me)<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>Debug(dInfo, <span class="hljs-string">&quot;S%v read persist successfully&quot;</span>, rf.me)<br>rf.currentTerm = currentTerm<br>rf.votedFor = votedFor<br>rf.logs = logs<br>rf.lastApplied = rf.getFirstIndex()<br>rf.commitIndex = rf.getFirstIndex()<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>然后我们需要在每次修改了持久化数据的地方调用persist函数，然后在初始化节点时调用readPersist函数来读取持久化数据，整体难度不大。</p><h1 id="lab2D-实现"><a href="#lab2D-实现" class="headerlink" title="lab2D 实现"></a>lab2D 实现</h1><p>在实验时测试2D时，测试代码在接收到apply的命令id为9结尾时，就会调用节点的Snapshot函数进行快照，将日志压缩。代码需要做到在压缩日志后，仍然能够准确地运行。</p><p>首先需要完成快照生成的函数，如下所示,每次会传入需要快照到的日志index，以及当这个节点为止的状态机的快照数据，系统保证传入的日志index一定是已经apply过的。由于已经将状态机的内容放入到了snapshot中，所以其实包括index在内的前面的所有日志都可以删除了，但是由于在同步日志信息时，需要上一个日志的term信息，所以我们会单独保留id为index的日志的id和term信息，放在logs的第一位。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> Snapshot(index <span class="hljs-type">int</span>, snapshot []<span class="hljs-type">byte</span>) &#123;<br>rf.mu.Lock()<br><span class="hljs-keyword">defer</span> rf.mu.Unlock()<br><span class="hljs-keyword">if</span> index &lt;= rf.getFirstIndex() &#123;<br>Debug(dSnap, <span class="hljs-string">&quot;S%v ignores the snapshot request with end index %v, because the index is not bigger than the first index %v&quot;</span>, rf.me, index, rf.getFirstIndex())<br><span class="hljs-keyword">return</span><br>&#125;<br><br>rf.logs = <span class="hljs-built_in">append</span>([]LogEntry&#123;&#123;index, rf.logs[index-rf.getFirstIndex()].Term, <span class="hljs-literal">nil</span>&#125;&#125;, rf.logs[index-rf.getFirstIndex()+<span class="hljs-number">1</span>:]...)<br>rf.persister.Save(rf.encodeState(), snapshot)<br>Debug(dSnap, <span class="hljs-string">&quot;S%v applies the snapshot with end index %v, now the len(logs)=%v&quot;</span>, rf.me, index, <span class="hljs-built_in">len</span>(rf.logs))<br>&#125;<br></code></pre></td></tr></table></figure><p>由于快照的引入，现在logs中的第一个日志可能不再是0了，所以之前代码中所有从logs中依据日志index获取日志的代码都要修改为：<code>rf.logs[index-rf.getFirstIndex()]</code>。</p><p>同时快照的引入还会导致在leader与follower进行日志同步时，需要的同步的日志可能已经没有了，所以这时候需要直接将整个日志发送给对方。</p><p>需要发送的快照请求如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> genInstallSnapshotRequest() *InstallSnapshotRequest &#123;<br><span class="hljs-keyword">return</span> &amp;InstallSnapshotRequest&#123;<br>Term:             rf.currentTerm,<br>LeaderId:         rf.me,<br>LastIncludeIndex: rf.getFirstIndex(),<br>LastIncludeTerm:  rf.logs[<span class="hljs-number">0</span>].Term,<br>Data:             rf.persister.ReadSnapshot(),<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>follower接收到快照请求后，需要进行如下处理,主要就是检查这个快照有没有过期，是不是真的比自己当前commit的日志还要新，如果是的话，就将自己的日志全部删除，只保留快照中给的最后一个日志，作为logs中的第一个日志，然后再唤起applyCond进行快照的apply。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> InstallSnapshot(request *InstallSnapshotRequest, reply *InstallSnapshotReply) &#123;<br>rf.mu.Lock()<br>Debug(dSnap, <span class="hljs-string">&quot;S%v &#123;term: %v, commitIndex: %v&#125;, received from S%v with InstallSnapshotRequest &#123;%v&#125; &quot;</span>, rf.me, rf.currentTerm, rf.commitIndex, request.LeaderId, request)<br><span class="hljs-keyword">defer</span> rf.mu.Unlock()<br><br>reply.Term = rf.currentTerm<br><span class="hljs-keyword">if</span> request.Term &lt; rf.currentTerm &#123;<br><span class="hljs-keyword">return</span><br>&#125;<br><span class="hljs-keyword">if</span> request.Term &gt; rf.currentTerm &#123;<br>rf.currentTerm = request.Term<br>rf.votedFor = <span class="hljs-number">-1</span><br>rf.persist()<br>&#125;<br>rf.changeState(Follower)<br><br><span class="hljs-keyword">if</span> request.LastIncludeIndex &lt;= rf.commitIndex &#123;<br><span class="hljs-keyword">return</span><br>&#125;<br><br>rf.persister.Save(rf.encodeState(), request.Data)<br>rf.commitIndex = request.LastIncludeIndex<br>rf.logs = []LogEntry&#123;&#123;request.LastIncludeIndex, request.LastIncludeTerm, <span class="hljs-literal">nil</span>&#125;&#125; <span class="hljs-comment">//2D遇到的bug所在</span><br>Debug(dSnap, <span class="hljs-string">&quot;S%v installs snapshot from S%v, now the commitIndex is %v&quot;</span>, rf.me, request.LeaderId, rf.commitIndex)<br><br>rf.waitApplySnapshotRequest = *request<br>rf.applyCond.Signal()<br>&#125;<br></code></pre></td></tr></table></figure><p>如果leader接收到回复表示快照已经更新成功了，那么就更新这个节点的nextIndex和matchIndex。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> handleInstallSnapshotReply(peer <span class="hljs-type">int</span>, request *InstallSnapshotRequest, reply *InstallSnapshotReply) &#123;<br><span class="hljs-keyword">if</span> reply.Term &gt; rf.currentTerm &#123;<br>rf.changeState(Follower)<br>rf.currentTerm = reply.Term<br>rf.votedFor = <span class="hljs-number">-1</span><br>rf.persist()<br>Debug(dWarn, <span class="hljs-string">&quot;S%v found higher term %v in InstallSnapshotReply %v from S%v, changes to follower&quot;</span>, rf.me, reply.Term, reply, peer)<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>rf.nextIndex[peer] = request.LastIncludeIndex + <span class="hljs-number">1</span><br>rf.matchIndex[peer] = request.LastIncludeIndex<br>Debug(dLog, <span class="hljs-string">&quot;S%v has installed snapshot to S%v, now the S%v&#x27;s nextIndex is %v&quot;</span>, rf.me, peer, peer, rf.nextIndex[peer])<br>rf.updateCommitIndexForLeader()<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>注意为了能够有序地进行快照的apply，对原本的applier函数进行了修改，同时增加了waitApplySnapshotRequest来记录最新需要apply的快照请求。</p><p>其主要思想是每次唤起applyCond时，先检查是否有新的快照请求，即waitApplySnapshotRequest的Term是否为-1，如果不为-1，那么就进行快照的apply，快照apply了之后再把waitApplySnapshotRequest的Term设置为-1。如果没有新的快照请求，那么就进行日志的apply。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> applier() &#123;<br><span class="hljs-keyword">for</span> !rf.killed() &#123;<br>rf.mu.Lock()<br><span class="hljs-keyword">for</span> rf.lastApplied &gt;= rf.commitIndex &#123;<br>rf.applyCond.Wait()<br>&#125;<br><br><span class="hljs-keyword">if</span> rf.waitApplySnapshotRequest.Term != <span class="hljs-number">-1</span> &#123;<br><span class="hljs-keyword">if</span> rf.lastApplied &lt; rf.waitApplySnapshotRequest.LastIncludeIndex &#123;<br>rf.mu.Unlock()<br><br>rf.applyCh &lt;- ApplyMsg&#123; <span class="hljs-comment">//Question: two applyCh update way, how to update orderly?</span><br>SnapshotValid: <span class="hljs-literal">true</span>,<br>Snapshot:      rf.waitApplySnapshotRequest.Data,<br>SnapshotTerm:  rf.waitApplySnapshotRequest.LastIncludeTerm,<br>SnapshotIndex: rf.waitApplySnapshotRequest.LastIncludeIndex,<br>&#125;<br><br>rf.mu.Lock()<br>rf.lastApplied = rf.waitApplySnapshotRequest.LastIncludeIndex<br>Debug(dSnap, <span class="hljs-string">&quot;S%v applies snapshot from S%v, now the lastApplied is %v&quot;</span>, rf.me, rf.waitApplySnapshotRequest.LeaderId, rf.lastApplied)<br><br>&#125;<br>rf.waitApplySnapshotRequest = InstallSnapshotRequest&#123;Term: <span class="hljs-number">-1</span>&#125;<br>rf.mu.Unlock()<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>commitIndex, lastApplied := rf.commitIndex, rf.lastApplied<br><span class="hljs-keyword">if</span> rf.getFirstIndex() != <span class="hljs-number">0</span> &amp;&amp; lastApplied+<span class="hljs-number">1</span>-rf.getFirstIndex() &lt;= <span class="hljs-number">0</span> &#123;<br>Debug(dWarn, <span class="hljs-string">&quot;S%v has no log to apply, because lastApplied %v &lt; firstIndex %v&quot;</span>, rf.me, lastApplied, rf.getFirstIndex())<br>rf.mu.Unlock()<br><span class="hljs-keyword">continue</span><br>&#125;<br>entries := <span class="hljs-built_in">make</span>([]LogEntry, commitIndex-lastApplied)<br>Debug(dInfo, <span class="hljs-string">&quot;S%v pre to apply log entries. LastApplied: %v, FirstIndex: %v, commitIndex: %v)&quot;</span>,<br>rf.me, lastApplied, rf.getFirstIndex(), commitIndex)<br><span class="hljs-built_in">copy</span>(entries, rf.logs[lastApplied+<span class="hljs-number">1</span>-rf.getFirstIndex():commitIndex+<span class="hljs-number">1</span>-rf.getFirstIndex()])<br>rf.mu.Unlock()<br><br><span class="hljs-keyword">for</span> _, entry := <span class="hljs-keyword">range</span> entries &#123;<br>rf.applyCh &lt;- ApplyMsg&#123;<br>CommandValid: <span class="hljs-literal">true</span>,<br>Command:      entry.Command,<br>CommandIndex: entry.Index,<br>CommandTerm:  entry.Term,<br>&#125;<br>&#125;<br><br>rf.mu.Lock()<br>Debug(dInfo, <span class="hljs-string">&quot;S%v finishes applying log entries(startId: %v, length: %v), now rf.lastApplied = %v&quot;</span>,<br>rf.me, lastApplied+<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(entries), rf.lastApplied)<br>rf.lastApplied = commitIndex<br>rf.mu.Unlock()<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><p>当时写的时候也感觉不是特别复杂，但是后面测试的时候发现这里还是有很多需要注意的点，容易导致错误。快照的引入导致的一个重要的问题是我们现在有两种方式来更新状态机的数据，一种是通过日志的apply，一种是通过快照的apply。</p><p>一开始的写法是在接收到快照请求进行InstallSnapshot的处理的时候新起了一个go协程来直接对快照进行apply，但是这会导致一系列的问题。</p><p>一开始我们对这两者的并发做什么限制，那么这就有可能出现下面这种情况：</p><ol><li>follower节点接受到快照同步请求，并且开启一个协程开始进行快照的apply</li><li>在快照的apply之前，follower节点接收到下一个日志的同步的请求，开始进行日志的apply</li></ol><p>这两个apply的顺序其实是不确定的，很有可能就会出现先进行日志的apply，然后再进行快照的apply，这样就会导致状态机的数据不一致，所以需要控制在快照进行apply的时候，不允许进行日志的apply。</p><p>然后我采用的方法是控制节点的lastApplied值，即在开启协程进行快照的apply前将lastApplied值设置为-1，然后在快照的apply结束后再将lastApplied设置为快照的index值，然后在日志进行apply的时候，对lastApplied进行判断，如果lastApplied值为-1，那么就进行锁等待，直到lastApplied值不为-1，然后再进行日志的apply。但是这种方法在测试的时候会发现，进行1000次测试大约会有0~3次的可能出现错误，错误的原因是在进行日志的apply的时候，需要apply的日志已经在logs中没有了，导致了取值的错误，也就是并发控制没有成功，在进行了快照的apply后，日志的apply依旧在进行。</p><p>经过debug发现这是由于出现了如下这种情况：</p><ol><li>followe节点接收到日志同步的请求，开启一个协程进行日志的apply</li><li>leader节点已经进行了快照，然后由于超时又给该follower节点发送了日志同步的请求</li><li>follower节点接收到快照同步的请求，设置lastApplied为-1，然后开启一个协程进行快照的apply</li><li>follower节点结束了日志的apply，将lastApplied设置为日志的index，然后follower节点继续检查，发现lastApplied不为-1，且lastApplied小于commitIndex，所以继续进行日志的apply,然后在logs中取日志时发现该日志已经没有了，导致错误。</li></ol><p>所以通过lastApplied进行并发控制并不可行，最后采用的方法是添加了snapApplyCount变量，每次在进行快照的apply时，将snapApplyCount加1，快照的apply结束后将snapApplyCount减1，然后在进行日志的apply时，如果snapApplyCount不为0，那么就进入锁等待。</p><p>注意在完成快照的apply后，有可能节点已经接收到了leader同步来的其他日志，所以需要在结束后检查是否有新的日志需要apply，如果需要就唤起日志的apply。最后处理快照同步请求的代码如上述的InstallSnapshot所示，日志apply的代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> applier() &#123;<br><span class="hljs-keyword">for</span> !rf.killed() &#123;<br>rf.mu.Lock()<br><span class="hljs-keyword">for</span> rf.snapApplyCount != <span class="hljs-number">0</span> || rf.lastApplied &gt;= rf.commitIndex &#123;<br>rf.applyCond.Wait()<br>&#125;<br><br>commitIndex, lastApplied := rf.commitIndex, rf.lastApplied<br><span class="hljs-keyword">if</span> rf.getFirstIndex() != <span class="hljs-number">0</span> &amp;&amp; lastApplied+<span class="hljs-number">1</span>-rf.getFirstIndex() &lt;= <span class="hljs-number">0</span> &#123;<br>rf.mu.Unlock()<br><span class="hljs-keyword">continue</span><br>&#125;<br>entries := <span class="hljs-built_in">make</span>([]LogEntry, commitIndex-lastApplied)<br>Debug(dInfo, <span class="hljs-string">&quot;S%v pre to apply log entries. LastApplied: %v, FirstIndex: %v, commitIndex: %v)&quot;</span>,<br>rf.me, lastApplied, rf.getFirstIndex(), commitIndex)<br><span class="hljs-built_in">copy</span>(entries, rf.logs[lastApplied+<span class="hljs-number">1</span>-rf.getFirstIndex():commitIndex+<span class="hljs-number">1</span>-rf.getFirstIndex()])<br>rf.mu.Unlock()<br><br><span class="hljs-keyword">for</span> _, entry := <span class="hljs-keyword">range</span> entries &#123;<br>rf.applyCh &lt;- ApplyMsg&#123;<br>CommandValid: <span class="hljs-literal">true</span>,<br>Command:      entry.Command,<br>CommandIndex: entry.Index,<br>CommandTerm:  entry.Term,<br>&#125;<br>&#125;<br><br>rf.mu.Lock()<br>Debug(dInfo, <span class="hljs-string">&quot;S%v finishes applying log entries(startId: %v, length: %v), now rf.lastApplied = %v&quot;</span>,<br>rf.me, lastApplied+<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(entries), rf.lastApplied)<br>rf.lastApplied = commitIndex<br>rf.mu.Unlock()<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>但是上述方法后面经过测试发现也还是有少量的bug，bug的主要原因在于如下这种情况：</p><ol><li>follower节点接收到最后日志为x的快照同步请求，开启一个协程进行快照的apply</li><li>follower节点又接收到最后日志为x+10的快照同步请求，开启一个协程进行快照的apply</li><li>follower先完成了x+10的快照的apply，然后才完成了x的快照的apply，但是这时候它会将lastApplied设置为x，同时apply的顺序也出现了错误。</li></ol><p>纵观上面的问题的一大根源在于我们出现了多个apply的协程，而没有对协程进行很好的并发控制，所以最后采取了上述的发型，将所有的apply都放在一个协程中进行，优先进行快照的apply，进测试可以准确地通过。</p><h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p>最终对lab2中所有的测试进行了1000次的测试，全部通过。</p><p><img src="/2024/04/08/MIT6-824lab2C2D/result.jpg" alt="测试结果"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>整个lab2中感觉难度最大的还是lab2B，因为需要实现的功能比较多，需要多多参考raft论文中的论文，最为印象深刻的就是lab2D中的并发问题了，这种问题确实在一开始实现的时候比较难想到，需要通过实验发现，而这种1000次测试才出现一两次错误的问题就更加难发现了，需要有全面的日志记录和多次重复实验的系统才行，后面有机会也分享一下有关日志记录和重复实验相关的内容。</p>]]></content>
    
    
    <categories>
      
      <category>MIT6.824</category>
      
      <category>Lab</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
      <tag>MIT6.824</tag>
      
      <tag>Go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kubernetes 架构及部署、调度、状态管理流程简介</title>
    <link href="/2024/04/02/k8sArchitecture/"/>
    <url>/2024/04/02/k8sArchitecture/</url>
    
    <content type="html"><![CDATA[<p>Kubernetes简称k8s，是用于自动部署、扩展和管理“容器化应用程序”的开源系统。该系统由Google设计并捐赠给Cloud Native Computing Foundation来使用。 它旨在提供“跨主机集群的自动部署、扩展以及运行应用程序容器的平台”。 它支持一系列容器工具，包括Docker等。它是当前绝对主流的容器管理平台。目前阿里（ACK）、字节（ Gödel ）、美团（LAR）内部的资源管理系统都基于k8s。</p><h1 id="K8s-架构"><a href="#K8s-架构" class="headerlink" title="K8s 架构"></a>K8s 架构</h1><p><img src="/2024/04/02/k8sArchitecture/arc.png" alt="k8s架构图"></p><p>K8s中的一些重要组件的简介如下：</p><ul><li>Etcd：基于Raft的分布式键值存储系统，保存了整个集群的状态。</li><li>Pod：集群中运行部署服务的最小单元，一个Pod可由多个Docker及网络、存储组件组成。</li><li>API Server：所有资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制</li><li>Controller manager：负责维护集群的状态，比如故障检测、自动扩展、滚动更新等；</li><li>Scheduler：负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上；</li><li>Kubelet：负责维护节点内的Pods和他们上面的容器，同时也负责Volume（CVI）和网络（CNI）的管理；</li><li>Kube-Proxy：负责为 Service 提供 cluster 内部的服务发现和负载均衡</li></ul><h2 id="Etcd"><a href="#Etcd" class="headerlink" title="Etcd"></a>Etcd</h2><p>Etcd主要用于保存集群所有的网络配置和对象的状态信息。整个 Kubernetes 系统中一共有两个服务需要用到 etcd 用来协同和存储配置，分别是：</p><ul><li>网络插件 flannel、对于其它网络插件也需要用到 etcd 存储网络的配置信息</li><li>Kubernetes 本身，包括各种对象的状态和元信息配置</li></ul><p>Etcd是基于Raft的分布式键值存储系统，可以查考我之前的<a href="https://slipegg.github.io/2023/12/26/RaftPaperRead/">关于Raft的文章</a>。</p><p>我们在安装 Flannel 的时候配置了 FLANNEL_ETCD_PREFIX&#x3D;”&#x2F;kube-centos&#x2F;network” 参数，这是 Flannel 查询 etcd 的目录地址。</p><p>查看 Etcd 中存储的 flannel 网络信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ etcdctl --ca-file=/etc/kubernetes/ssl/ca.pem --cert-file=/etc/kubernetes/ssl/kubernetes.pem --key-file=/etc/kubernetes/ssl/kubernetes-key.pem <span class="hljs-built_in">ls</span> /kube-centos/network -r<br>2018-01-19 18:38:22.768145 I | warning: ignoring ServerName <span class="hljs-keyword">for</span> user-provided CA <span class="hljs-keyword">for</span> backwards compatibility is deprecated<br>/kube-centos/network/config<br>/kube-centos/network/subnets<br>/kube-centos/network/subnets/172.30.31.0-24<br>/kube-centos/network/subnets/172.30.20.0-24<br>/kube-centos/network/subnets/172.30.23.0-24<br>```查看 flannel 的配置：```bash<br>$ etcdctl --ca-file=/etc/kubernetes/ssl/ca.pem --cert-file=/etc/kubernetes/ssl/kubernetes.pem --key-file=/etc/kubernetes/ssl/kubernetes-key.pem get /kube-centos/network/config<br>2018-01-19 18:38:22.768145 I | warning: ignoring ServerName <span class="hljs-keyword">for</span> user-provided CA <span class="hljs-keyword">for</span> backwards compatibility is deprecated<br>&#123;<span class="hljs-string">&quot;Network&quot;</span>: <span class="hljs-string">&quot;172.30.0.0/16&quot;</span>, <span class="hljs-string">&quot;SubnetLen&quot;</span>: 24, <span class="hljs-string">&quot;Backend&quot;</span>: &#123; <span class="hljs-string">&quot;Type&quot;</span>: <span class="hljs-string">&quot;host-gw&quot;</span>&#125; &#125;<br></code></pre></td></tr></table></figure><p>Kubernetes 使用 etcd v3 的 API 操作 etcd 中的数据。所有的资源对象都保存在 &#x2F;registry 路径下，如下：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs stylus">ThirdPartyResourceData<br>apiextensions<span class="hljs-selector-class">.k8s</span><span class="hljs-selector-class">.io</span><br>apiregistration<span class="hljs-selector-class">.k8s</span><span class="hljs-selector-class">.io</span><br>certificatesigningrequests<br>clusterrolebindings<br>clusterroles<br>configmaps<br>controllerrevisions<br>controllers<br>daemonsets<br>deployments<br>events<br>horizontalpodautoscalers<br>ingress<br>limitranges<br>minions<br>monitoring<span class="hljs-selector-class">.coreos</span><span class="hljs-selector-class">.com</span><br>namespaces<br>persistentvolumeclaims<br>persistentvolumes<br>poddisruptionbudgets<br>pods<br>ranges<br>replicasets<br>resourcequotas<br>rolebindings<br>roles<br>secrets<br>serviceaccounts<br>services<br>statefulsets<br>storageclasses<br>thirdpartyresources<br></code></pre></td></tr></table></figure><p>如果你还创建了 CRD（自定义资源定义），则在此会出现 CRD 的 API。</p><h2 id="API-Server"><a href="#API-Server" class="headerlink" title="API Server"></a>API Server</h2><p>API Server是K8s的核心组件之一，它类似于linux系统中的系统调用。一个核心的API设计原则是所有的API都应该是声明式的，即用户只需要告诉K8s自己想要的状态，而不需要告诉K8s如何去做。例如告诉K8s我需要3个Pod的副本，K8s会自动去创建这3个Pod的副本，而不去告诉K8s我要再新建一个副本，因为API是有可能被丢弃或者重复执行的，但是声明式的API是幂等的，即重复执行的结果是一样的。</p><h2 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a>Pod</h2><p>Pod 是 Kubernetes 中最小的调度单元，它是一个或多个容器的集合（目前K8s也支持了其他类型的虚拟化产品），同时也可以在Pod中包含存储、网络配置等共享资源。Pod 是 Kubernetes 中的原子调度单位，Kubernetes 会将 Pod 中的容器一起调度到同一个节点上，确保它们能够正常运行。</p><p>目前 Kubernetes 中的业务主要可以分为长期伺服型（long-running）、批处理型（batch）、节点后台支撑型（node-daemon）和有状态应用型（stateful application）；分别对应的小机器人控制器为 Deployment、Job、DaemonSet 和 StatefulSet</p><h2 id="Controller-manager"><a href="#Controller-manager" class="headerlink" title="Controller manager"></a>Controller manager</h2><p>Controller Manager 就是集群内部的管理控制中心，由负责不同资源的多个 Controller 构成，共同负责集群内的 Node、Pod 等所有资源的管理，比如当通过 Deployment 创建的某个 Pod 发生异常退出时，RS Controller 便会接受并处理该退出事件，并创建新的 Pod 来维持预期副本数。</p><p>几乎每种特定资源都有特定的 Controller 维护管理以保持预期状态，而 Controller Manager 的职责便是把所有的 Controller 聚合起来：</p><ul><li>提供基础设施降低 Controller 的实现复杂度</li><li>启动和维持 Controller 的正常运行</li></ul><p>Kubernetes 中常见的几种类型的 Controller有如下这些：</p><ul><li>Replication Controller 用于确保在集群中始终运行指定数量的 Pod 实例。如果由于某种原因导致 Pod 实例数低于预期值，Replication Controller 会自动启动新的 Pod 实例，以满足配置的副本数目。</li><li>ReplicaSet 是 Replication Controller 的升级版本，它支持更灵活的 Pod 选择方式，并提供了更强大的标签选择器功能。在新的 Kubernetes 集群中，建议使用 ReplicaSet 而不是 Replication Controller，它一般不单独使用，而是作为 Deployment 的理想状态参数使用。</li><li>Deployment 用于管理应用程序的发布和更新。它可以创建 ReplicaSet，并在需要时启动新的 Pod 实例，以确保应用程序的副本数量符合所需的状态。Deployment 还支持滚动更新、版本回滚等功能，使得应用程序的部署和更新变得更加灵活和可控。</li><li>StatefulSet 用于管理有状态应用程序的部署，例如数据库。与 ReplicaSet 不同，StatefulSet 会为每个 Pod 实例分配稳定的网络标识符和持久化存储，确保在 Pod 重启或迁移时能够保持状态。</li><li>DaemonSet 用于在集群中的每个节点上运行一个副本（或者根据节点标签进行选择）。它通常用于部署一些系统级别的后台服务，如日志收集器、监控代理等。</li><li>Job 用于一次性任务的管理，例如批处理作业。CronJob 则是定时任务的管理器，它可以周期性地执行指定的任务，类似于 Linux 系统中的 cron 任务。</li></ul><h2 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h2><p>kube-scheduler 是 Kubernetes 的调度器，主要负责整个集群资源的调度功能，根据特定的调度算法和策略，将 Pod 调度到最优的工作节点上面去，从而更加合理、更加充分的利用集群的资源。</p><p>它的调度流程可以看下面的<a href="#schedule">K8s调度流程:</a>里的内容。</p><p>值得注意的是，由于K8s原生的调度器是只支持一个一个单独调度，所以对于批处理作业调度的场景不受用，例如需要gang调度，即需要同时多个Pod一起上台才能运行，这时一个个调度就有死锁以及浪费资源的问题，所以目前K8s社区退出了<a href="https://volcano.sh/zh/">Volcano</a>调度器，值得去关注一下。</p><h2 id="Kubelet"><a href="#Kubelet" class="headerlink" title="Kubelet"></a>Kubelet</h2><p>Kubelet 是 Kubernetes 集群中每个节点上的代理，负责维护容器的生命周期，同时与容器运行时（如 Docker）进行交互，确保容器正常运行。Kubelet 会定期从 API Server 获取 Pod 的配置信息，然后创建和管理 Pod 中的容器，同时监控容器的状态，并上报给 API Server。</p><h2 id="Kube-Proxy"><a href="#Kube-Proxy" class="headerlink" title="Kube-Proxy"></a>Kube-Proxy</h2><p>Kube-proxy 是 kubernetes 工作节点上的一个网络代理组件，运行在每个节点上。Kube-proxy维护节点上的网络规则，实现了Kubernetes Service 概念的一部分 。它的作用是使发往 Service 的流量（通过ClusterIP和端口）负载均衡到正确的后端Pod。</p><p>kube-proxy 监听 API server 中 资源对象的变化情况，包括以下三种：</p><ul><li>service</li><li>endpoint&#x2F;endpointslices</li><li>node</li><li>然后根据监听资源变化操作代理后端来为服务配置负载均衡。</li></ul><h1 id="K8s-部署流程"><a href="#K8s-部署流程" class="headerlink" title="K8s 部署流程"></a>K8s 部署流程</h1><p>在 Kubernetes 中，一个控制器至少追踪一种类型的 Kubernetes 资源。这些资源对象有一个代表期望状态的 spec 字段。 该资源的控制器负责所属对象当前状态接近期望状态，如下是一个部署nginx的例子：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Deployment</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-deployment</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">replicas:</span> <span class="hljs-number">3</span>  <span class="hljs-comment"># 副本数量</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">matchLabels:</span><br>      <span class="hljs-attr">app:</span> <span class="hljs-string">nginx</span><br>  <span class="hljs-attr">template:</span><br>    <span class="hljs-attr">metadata:</span><br>      <span class="hljs-attr">labels:</span><br>        <span class="hljs-attr">app:</span> <span class="hljs-string">nginx</span><br>    <span class="hljs-attr">spec:</span><br>      <span class="hljs-attr">containers:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">nginx</span><br>          <span class="hljs-attr">image:</span> <span class="hljs-string">nginx:latest</span>  <span class="hljs-comment"># Docker版本</span><br>          <span class="hljs-attr">ports:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">80</span><br>          <span class="hljs-attr">resources:</span><br>            <span class="hljs-attr">requests:</span><br>              <span class="hljs-attr">cpu:</span> <span class="hljs-string">&quot;100m&quot;</span>    <span class="hljs-comment"># 请求 100 毫核 CPU</span><br>              <span class="hljs-attr">memory:</span> <span class="hljs-string">&quot;128Mi&quot;</span>    <span class="hljs-comment"># 请求 128 兆字节内存</span><br>            <span class="hljs-attr">limits:</span><br>              <span class="hljs-attr">cpu:</span> <span class="hljs-string">&quot;200m&quot;</span>    <span class="hljs-comment"># 最大限制 200 毫核 CPU</span><br>              <span class="hljs-attr">memory:</span> <span class="hljs-string">&quot;256Mi&quot;</span>    <span class="hljs-comment"># 最大限制 256 兆字节内存</span><br><br></code></pre></td></tr></table></figure><p>控制器需要保证所属对象一直处于期望状态，但是这就有一个问题，如何探测到变化。因为如何持续通过API Server去查询Etcd中资源的状态，会导致API Server的压力过大，所以K8s采用了Informer的机制。具体如下：</p><ol><li>提前Cache住Etcd中的内容，减少API Server调用。使用 Informer 实例的 Lister() 方法， List&#x2F;Get Kubernetes 中的 Object 时，Informer 不会去请求 Kubernetes API，而是直接查找缓存在本地内存中的数据，依赖Etcd的List&amp;Watch机制，客户端及时获知这些对象的状态变化，然后更新本地缓存，这样就在客户端为这些API对象维护了一份和Etcd数据库中几乎一致的数据，然后控制器等客户端就可以直接访问缓存获取对象的信息，而不用去直接访问apiserver。通过这种方式，Informer 既可以更快地返回结果，又能减少对 Kubernetes API 的直接调用。</li><li>Watch机制及时通知变化。Informer 通过 Kubernetes Watch API 监听某种 resource 下的所有事件。Watch API 本质上就是一种 APIServer 主动向控制器等客户端推送 Kubernetes 资源修改、创建的一种机制。这样我们就可以获取到资源的变更，及时更新对象状态。</li></ol><p><img src="/2024/04/02/k8sArchitecture/deploy.jpg" alt="k8s部署流程图"></p><p>如上图所示，K8s的部署流程主要分为以下几个步骤：</p><ol><li>kubectl向apiserver发送部署请求（例如使用 kubectl create -f deployment.yml）</li><li>apiserver将 Deployment 持久化到etcd；etcd与apiserver进行一次http通信。</li><li>controller manager通过watch api监听 apiserver ，deployment controller看到了一个新创建的deplayment对象更后，将其从队列中拉出，根据deployment的描述创建一个ReplicaSet并将 ReplicaSet 对象返回apiserver并持久化回etcd。以此类推，当replicaset控制器看到新创建的replicaset对象，将其从队列中拉出，根据描述创建pod对象。</li><li>接着scheduler调度器看到未调度的pod对象，根据调度规则选择一个可调度的节点，加载到pod描述中nodeName字段，并将pod对象返回apiserver并写入etcd。</li><li>kubelet在看到有pod对象中nodeName字段属于本节点，将其从队列中拉出，通过容器运行时创建pod中描述的容器。</li></ol><p><a id="schedule"></a></p><h1 id="K8s-调度流程"><a href="#K8s-调度流程" class="headerlink" title="K8s 调度流程"></a>K8s 调度流程</h1><p><img src="/2024/04/02/k8sArchitecture/schedule.png" alt="k8s调度流程图"></p><p>Scheduler 的调度策略启动配置目前支持三种方式，配置文件 &#x2F; 命令行参数 &#x2F; ConfigMap。调度策略可以配置指定调度主流程中要用哪些过滤器 (Predicates)、打分器 (Priorities) 、外部扩展的调度器 (Extenders)，以及最新支持的 SchedulerFramwork 的自定义扩展点 (Plugins)。</p><p>Scheduler 在启动的时候通过 K8s 的 informer 机制以 List+Watch 从 kube-apiserver 及时感知获取调度需要的数据例如：Pods、Nodes、Persistant Volume(PV), Persistant Volume Claim(PVC) 等等，并将这些数据做一定的预处理作为调度器的的 Cache。</p><p>通过 Informer 将需要调度的 Pod 插入 Queue 中，Pipeline 会循环从 Queue Pop 等待调度的 Pod 放入 Pipeline 执行。调度流水线 (Schedule Pipeline) 主要有三个阶段。</p><center>Scheduler Thread→Wait Thread →Bind Thread</center><p>在Scheduler Thread阶段，对Pod一个个串行调度，流程为 Filter -&gt; Score -&gt; Reserve：</p><ol><li>Filter：筛选出符合 Pod Spec 描述的 Nodes</li><li>Score：对筛选出的 Nodes 进行打分和排序</li><li>Reserve：将Pod调度到得分最高的Node中，并更新自己的NodeCache</li></ol><p>在Wait Thread（异步并行）阶段：等待 Pod 关联的资源的就绪。例如等待 PVC 的 PV 创建成功，或者 Gang 调度中等待关联的 Pod 调度成功等等。<br>在Bind Thread（异步并行）阶段：将 Pod 和 Node 的关联持久化 Kube APIServer，如果失败则重新调度。</p><h1 id="K8s-状态管理"><a href="#K8s-状态管理" class="headerlink" title="K8s 状态管理"></a>K8s 状态管理</h1><p>K8s中对Node节点的状态管理主要有两种方式，一种是通过Lease（租约）的方式，一种是通过NodeStatus上报的方式。</p><p>节点中的kubelet通过Lease更新维持存活状态（2019年 k8s v1.17 正式加入）。具体来说，每个节点有一个lease对象，各节点的kubelet定期更新自己的lease对象（默认10s一次），每次更新的内容较少，比较轻量。如果没有及时收到更新，就可以怀疑Node损坏，开始进一步处理。</p><p>同时kubelet也会定期（默认10秒）计算一次NodeStatus（时间独立计算），只有发生有意义的变化或者不上报持续时间超过了参数node-status-update-period（默认5m）时，kubelet才上报NodeStatus。NodeStatus上报数据大，一般包含节点的资源状态、运行的Pod信息、节点Ip、节点版本等。</p><p>注意Lease机制的提出主要是为了解决大规模场景下频繁进行大型NodeStatus上报导致的性能问题，同时也可以更快的发现节点的异常。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><a href="https://jimmysong.io/kubernetes-handbook/concepts/">Kubernetes 架构</a></li><li><a href="https://blog.ihypo.net/15763910382218.html">Kubernetes Controller Manager 工作原理</a></li><li><a href="Volcano">Volcano</a></li><li><a href="https://zhuanlan.zhihu.com/p/338462784">一文看懂 Kubelet</a></li><li><a href="https://zhuanlan.zhihu.com/p/337806843">一文看懂 Kube-proxy</a></li><li><a href="https://zhuanlan.zhihu.com/p/410211543">K8s deployment部署一个pod的流程</a></li><li><a href="https://juejin.cn/post/6844904041097461774">从零开始入门 K8s | 调度器的调度流程和算法介绍</a></li><li><a href="https://www.cnblogs.com/WJQ2017/p/17090603.html">kubelet上报心跳机制</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>k8s</category>
      
      <category>基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>k8s</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式系统中的线性一致性</title>
    <link href="/2024/03/28/linearizability/"/>
    <url>/2024/03/28/linearizability/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>**  **指的是在同一个系统中，不同客户端操作看到的数据之间的关系。<br>这里重点关注的是网络键值存储系统中的一致性模型。</p><p>首先为什么这有可能出现问题呢？主要是来源于分布式系统中特有的问题，包括：</p><ul><li>并发读&#x2F;写</li><li>副本</li><li>缓存</li><li>故障、恢复</li><li>重传</li><li>…</li></ul><p>这些问题就有可能导致系统出现意想不到的场景，比如如下是一个简单的生产者代码：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">put</span><span class="hljs-params">(<span class="hljs-string">&quot;result&quot;</span>, <span class="hljs-number">27</span>)</span></span><br><span class="hljs-function"><span class="hljs-title">put</span><span class="hljs-params">(<span class="hljs-string">&quot;done&quot;</span>, true)</span></span><br></code></pre></td></tr></table></figure><p>下面是一个消费者代码：</p><figure class="highlight isbl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs isbl"><span class="hljs-variable"><span class="hljs-keyword">while</span></span> <span class="hljs-function"><span class="hljs-title">get</span>(<span class="hljs-string">&quot;done&quot;</span>) <span class="hljs-variable">!</span>= <span class="hljs-variable"><span class="hljs-literal">true</span></span></span><br><span class="hljs-function">    <span class="hljs-variable">pause</span></span><br><span class="hljs-function"><span class="hljs-variable">v</span> = <span class="hljs-title">get</span>(<span class="hljs-variable"><span class="hljs-class">result</span></span>)</span><br></code></pre></td></tr></table></figure><p>在分布式系统中，如果不清楚系统的一致性模型，那么v的值实际上也是难以确认的，因为消费者在读取的时候可能是在一个副本上读取，而生产者在写入的时候可能是在另一个副本上写入，这样就有可能出现v的值不是27的情况。</p><h1 id="线性一致性（linearizability）"><a href="#线性一致性（linearizability）" class="headerlink" title="线性一致性（linearizability）"></a>线性一致性（linearizability）</h1><p>在线性一致性模型中每个操作似乎都在调用和响应之间的某个时刻以原子方式即时执行。<br>它是一种强一致性模型，它符合程序员的直觉，但是也会导致排除掉一些可能的优化机会。</p><p>如图1所示是一个多客户端并发操作的例子，注意每个方框的最左边是操作开始的时刻，最右边是操作成功获得相应的时刻。</p><p><img src="/2024/03/28/linearizability/history-1.svg" alt="图1"></p><p>这段历史是线性一致的，因为如图2中的橙色所示，我们可以在每个操作中找到一个可能执行的时间点，组成这样的正确的顺序历史：Put(“x”, “0”), Get(“x”) -&gt; “0”, Put(“x”, “1”), Get(“x”) -&gt; “1”。</p><p><img src="/2024/03/28/linearizability/history-1-linearization.svg" alt="图2"></p><p>而相反的下面图3这个就不是一个线性一致的历史，因为无法找到一个正确的顺序历史。</p><p><img src="/2024/03/28/linearizability/history-2.svg" alt="图3"></p><p>对于由于网络等因素导致的重传，如下：</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gherkin">C1: |<span class="hljs-string">--------Wx1---------</span>|<span class="hljs-string"> （由于重传）</span><br><span class="hljs-string">C2：</span>|<span class="hljs-string">-Wx2-</span>|<span class="hljs-string"> </span><br><span class="hljs-string">C3：</span>|<span class="hljs-string">-Rx1-</span>|<span class="hljs-string"> </span>|<span class="hljs-string">-Rx2-</span>|<span class="hljs-string"> </span>|<span class="hljs-string">-Rx1-</span>|<br></code></pre></td></tr></table></figure><p>这理论上是可能存在的，但是如果系统表现成这样，那么这个系统就不是线性一致的。所以这也就要求了线性一致性系统中必须要处理重传的重复请求。</p><p>线性一致性系统的主要优点在于：</p><ol><li>客户端读取到的都是最新的值</li><li>所有的客户端看到的都是相同的数据</li><li>所有客户端以相同的顺序看到数据的更改</li></ol><p>如何实现线性一致性呢？主要是需要依赖于一个不会奔溃的串行服务器，让它来为所有童虎到达的客户端请求选择执行的顺序，并按顺序依次执行，一次一个，在开始下一个之前回复每一个请求。</p><p>但是如果想要容错就需要备份了，所有请求都发送到主服务器，选择串行顺序，然后转发到备份，备份以相同的顺序执行，主服务器仅在备份都执行后才回复客户端。</p><p>事实上由于请求都发往主服务器，而不能利用备份服务器的能量，所以主服务器可能会成为瓶颈。</p><h1 id="线性一致性测试"><a href="#线性一致性测试" class="headerlink" title="线性一致性测试"></a>线性一致性测试</h1><p>对系统进行线性一致性的检查是一个NP难的问题。<br>对其NP难的证明可以从一个子集问题出发进行说明，如下是一个系统的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Adder</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self._total = <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">self, value</span>):<br>        self._total += value<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self._total<br></code></pre></td></tr></table></figure><p>考虑如图4所示的历史：</p><p><img src="/2024/03/28/linearizability/subset-sum.svg" alt="图4"></p><p>那么这个线性检测的问题就转化为了一个集合S&#x3D;{s<sub>1</sub>, s<sub>2</sub>, …, s<sub>n</sub>}，是否存在一个子集S’，使得S’的和等于目标值t。<br>当且仅当子集和问题的答案为“是”时，该历史才可线性化。即系统中存在于这个子集中的Add操作在Get操作之前执行，其余的Add操作在Get操作之后执行。</p><p>由于存在这种NP难的特性，对于一个分布式系统中的测试往往是通过多样化的执行、故障注入来完成的。即在进行了一系列的操作后，记录历史日志，然后对历史日志进行线性化检测，看是否存在一个合理的操作顺序。</p><h1 id="其他一致性模型"><a href="#其他一致性模型" class="headerlink" title="其他一致性模型"></a>其他一致性模型</h1><p>除了线性一致性外，还有其他一致性模型，比如：</p><ol><li><strong>Eventual Consistency（最终一致性）：</strong><br> 在最终一致性模型中，系统保证如果没有新的更新操作发生，那么最终所有节点都会收敛到相同的值。这意味着系统可能会在一段时间内出现不一致状态，但最终会达到一致状态。最终一致性通常用于分布式系统中为了提高性能而牺牲一致性的情况。</li><li><strong>Causal Consistency（因果一致性）：</strong><br> 因果一致性是相对于事件发生的因果关系来保证的一致性模型。如果事件 A 在事件 B 之前发生，那么任何观察到事件 B 的节点都必须也能够观察到事件 A。因此，因果一致性要求对于有因果关系的事件必须保持一致性，而对于无因果关系的事件则允许并发。</li><li><strong>Fork Consistency（分支一致性）：</strong><br> 分支一致性是一种介于最终一致性和因果一致性之间的模型。它允许系统中的分支出现，即允许有多个不同的历史状态。在分支一致性中，系统保证对于单个分支内部的一致性，并且最终所有分支都会收敛到一致状态。</li><li><strong>Serializability（串行化一致性）：</strong><br> 串行化一致性是指系统保证所有并发执行的操作按照某种顺序执行时，产生的结果与它们依次顺序执行时的结果相同。这意味着系统能够模拟所有操作按照某个全局顺序执行的效果，从而保证了强一致性。</li><li><strong>Sequential Consistency（顺序一致性）：</strong><br> 顺序一致性是一种强一致性模型，要求系统中的所有操作必须按照它们发生的顺序进行执行。即使是在分布式系统中，对于每个节点来说，所有操作的执行顺序也必须与它们在全局中发生的顺序相一致。</li></ol><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><a href="https://anishathalye.com/testing-distributed-systems-for-linearizability/">测试分布式系统的线性化</a></li><li><a href="http://nil.csail.mit.edu/6.5840/2023/notes/l-linearizability.txt">6.5840 2023 Lecture 9: Consistency, Linearizability</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>MIT6.824</category>
      
      <category>其他</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
      <tag>MIT6.824</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【MIT6.824】lab2B-log replication 实现笔记</title>
    <link href="/2024/03/19/MIT6-824lab2B/"/>
    <url>/2024/03/19/MIT6-824lab2B/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>lab2B的实验要求如下：</p><p>Implement the leader and follower code to append new log entries, so that the go test -run 2B tests pass.</p><ul><li><strong>Hint:</strong> Run git pull to get the latest lab software.</li><li><strong>Hint:</strong> Your first goal should be to pass TestBasicAgree2B(). Start by implementing Start(), then write the code to send and receive new log entries via AppendEntries RPCs, following Figure 2. Send each newly committed entry on applyCh on each peer.</li><li><strong>Hint:</strong> You will need to implement the election restriction (section 5.4.1 in the paper).</li><li><strong>Hint:</strong> One way to fail to reach agreement in the early Lab 2B tests is to hold repeated elections even though the leader is alive. Look for bugs in election timer management, or not sending out heartbeats immediately after winning an election.</li><li><strong>Hint:</strong> Your code may have loops that repeatedly check for certain events. Don’t have these loops execute continuously without pausing, since that will slow your implementation enough that it fails tests. Use Go’s condition variables, or insert a time.Sleep(10 * time.Millisecond) in each loop iteration.</li><li><strong>Hint:</strong> Do yourself a favor for future labs and write (or re-write) code that’s clean and clear. For ideas, re-visit our the Guidance page with tips on how to develop and debug your code.</li><li><strong>Hint:</strong> If you fail a test, look over the code for the test in config.go and test_test.go to get a better understanding what the test is testing. config.go also illustrates how the tester uses the Raft API.</li></ul><p>主要的要求就是在lab2A完成领导者选举的基础上实现日志的复制，代码可以在<a href="https://github.com/slipegg/MIT6.824">https://github.com/slipegg/MIT6.824</a>中得到。</p><h1 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h1><p>由于整个lab是在模拟环境中进行的，所以我们需要先简单连接一下实验是如何测试和运行的。</p><p>查看测试脚本可知，每次客户端提交用户请求都是通过调用leader的Start函数来实现的，故Start函数在接收到了日志后就需要主动开始日志复制的过程。</p><p>而当leader将日志复制到大多数节点后，除了各个节点自己需要标定这个日志已经提交了外，还需要将这个日志已经提交了的信息返回给客户端，这个信息的结构为ApplyMsg，它通过applyCh这个channel来实现的，实际代码中我们可能需要启用一个go协程来在需要时进行异步执行，如下所示。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> ApplyMsg <span class="hljs-keyword">struct</span> &#123;<br>CommandValid <span class="hljs-type">bool</span><br>Command      <span class="hljs-keyword">interface</span>&#123;&#125;<br>CommandIndex <span class="hljs-type">int</span><br><br><span class="hljs-comment">// For 2D:</span><br>SnapshotValid <span class="hljs-type">bool</span><br>Snapshot      []<span class="hljs-type">byte</span><br>SnapshotTerm  <span class="hljs-type">int</span><br>SnapshotIndex <span class="hljs-type">int</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> applier() &#123;<br><span class="hljs-keyword">for</span> !rf.killed() &#123;<br>rf.mu.Lock()<br><span class="hljs-keyword">for</span> rf.lastApplied &gt;= rf.commitIndex &#123;<br>rf.applyCond.Wait()<br>&#125;<br><br>commitIndex, lastApplied := rf.commitIndex, rf.lastApplied<br>entries := <span class="hljs-built_in">make</span>([]LogEntry, commitIndex-lastApplied)<br><span class="hljs-built_in">copy</span>(entries, rf.logs[lastApplied+<span class="hljs-number">1</span>:commitIndex+<span class="hljs-number">1</span>])<br>Debug(dTest, <span class="hljs-string">&quot;S%v commitIndex: %v, lastApplied: %v, entries: %v&quot;</span>, rf.me, commitIndex, lastApplied, entries)<br>rf.mu.Unlock()<br><br><span class="hljs-keyword">for</span> _, entry := <span class="hljs-keyword">range</span> entries &#123;<br><span class="hljs-comment">// entry: committed log entry</span><br>rf.applyCh &lt;- ApplyMsg&#123;<br>CommandValid: <span class="hljs-literal">true</span>,<br>Command:      entry.Command,<br>CommandIndex: entry.Index,<br>&#125;<br>&#125;<br><br>rf.mu.Lock()<br>Debug(dCommit, <span class="hljs-string">&quot;S%v applies log entries(startId: %v, length: %v)&quot;</span>, rf.me, lastApplied+<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(entries))<br>rf.lastApplied = commitIndex<br>rf.mu.Unlock()<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="日志复制代码"><a href="#日志复制代码" class="headerlink" title="日志复制代码"></a>日志复制代码</h1><p>在具体实现时，发现Raft论文中的代码结构图对于编写整个代码非常有帮助，所以在这里也贴出来。</p><p><img src="/2024/03/19/MIT6-824lab2B/RaftStruct.jpg" alt="Raft论文中的代码结构图"></p><p>项目的整体流程及思路我整理成了如下的过程.</p><p><img src="/2024/03/19/MIT6-824lab2B/p1.jpg" alt="客户端发送日志后触发日志复制"></p><ul><li><strong>Start:</strong> leader节点接受新的命令，将命令添加到自己的日志中，并向其他所有节点发送日志复制请求。</li><li><strong>ReplicateLog:</strong> 由于日志复制可能会失败，所以需要一个循环来不断重试，直到日志复制成功。复制时通过RPC来调度其他节点的AppendEntires函数，并在得到返回结果后调用handleAppendResponse进行处理.</li></ul><p><img src="/2024/03/19/MIT6-824lab2B/p2.jpg" alt="节点处理日志添加请求及处理日志添加返回结果"></p><ul><li><strong>AppendEntires:</strong> 节点接受到日志复制请求后，必须先要判定对方是不是term大于等于自己的term，如果不是就是过时的leader，直接拒绝。由于这个函数也会被当做心跳包来使用，所以收到后还需要自动转变为follower。然后再判断leader中记录的要复制的前一个日志preLog是不是和自己的一致，如果不一致，有两种可能：<ol><li>自己的日志更短，都没复制到preLog这一步，所以直接拒绝，并主动在reply中返回自己的最后一个日志的id。</li><li>有preLog，但是日志的term不一致，也就是自己有冗余的错误的日志，这里是可删可不删后面的日志，论文中采取的方法是返回错误，然后一个一个往前找对得上的日志，而由于这个速度太慢了，会导致测试不通过，所以这里采取的方法是返回本节点的preLog的term，这个term肯定是比leader更小的，然后等待leader找到这个term的最后一个日志，尝试全部复制过来，这样可以加速日志的复制。<br>如果都一致了，就加入到自己的日志中，然后再去对比参看leader有没有新commit日志，如果有就更新自己的commitIndex，并将他们apply，返回给客户端。</li></ol></li><li><strong>handleAppendResponse:</strong> 这个函数是用来处理AppendEntires的返回结果的，首先需要判定自己还是不是leader，term有没有变，如果不是leader或者term变了，就不继续处理。如果返回成功，那么就更新自身记录的对应节点的matchId和nextId，如果返回失败,则对应有几种可能：<ol><li>发现比自己term还高的节点，说明自己的term过时了，需要转变为follower。</li><li>对方的日志比自己以为的要短，需要将该节点nextId往前移动到对应的位置。</li><li>对方的preLog的term不一致，那么就需要找到perLog的term对应的最后一个日志，然后将nextId移动到这个位置的下一个位置。</li></ol></li></ul><p><img src="/2024/03/19/MIT6-824lab2B/p3.jpg" alt="leader尝试更新日志及新的投票规则"></p><ul><li><strong>TryApplyForLeader:</strong> 这里把所有的matchId倒序排序，然后查看中间这个位置的matchId是不是变化了，如果变化了，就去查看这个最新的newCommitId对应的term是不是等于自己的term，如果不是，还是不处理，这对应了论文中的5.4.2节中的规则；如果是，就更新自己的commitIndex，并将这个日志apply。</li><li><strong>Vote:</strong> 如果投票的请求的term比自己的term小，那么就是过时的请求，直接拒绝。如果相同，同时自己已经投票给了其他节点，那么也拒绝。如果请求的term比自己的term大，那么就转变为follower，并更新term。（这一步是为了处理有些时候有的节点进入了网络分区，term不断变大，新接入之后发起投票，这是否应该大伙都转为follower，但是可能受限于日志不符合，不能成为leader，然后大家在新的term中重新选举，统一得到一个leader。）然后检查请求的前一个日志是否是最新的，最新的规则是要么这个前一个日志的term比自己的term大，要么term相同但是index相同或者更大，如果不是，就拒绝。最后如果都通过了，就投票给对方。</li></ul><h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p>使用了之前写的自动测试实验脚本的测试结果如下，可以看到它通过了1000次的测试。</p><p><img src="/2024/03/19/MIT6-824lab2B/result.jpg" alt="实验结果"></p><h1 id="测试实例-TestBackup2B分享"><a href="#测试实例-TestBackup2B分享" class="headerlink" title="测试实例-TestBackup2B分享"></a>测试实例-TestBackup2B分享</h1><p>测试过程中被TestBackup2B困扰了很久这里分享一下这个测试示例。</p><p><img src="/2024/03/19/MIT6-824lab2B/p4.jpg" alt="TestBackup2B"></p><p>可以看到测试主要是通过网络中断来进行测试的。一开始这个测试没通过，经过查看日志得知是在T5时刻没有选举出正确的leader，两个原因：</p><ol><li>在选举时判断每个节点最后的日志是不是最新的时候写错了，只比较自己的最后的日志相较于Candidate的最后的日志是不是一样长，而没有比较Candidate的最后的日志的term是不是比自己的大，这就导致了在T5时刻本来应该只有S2才能被选举出来，但是我确认S0和S1也可以被选举出来。</li><li>在比较最后的日志前没有提前先判断对方的term是不是比自己的term大，由于S1在disconnect阶段一直在尝试重新选举，所以其term会很大，如果其他节点在接收到S1投票请求后没有转变为follower，并更新term会导致S1一直拒绝其他人的选举投票，而自己又由于日志不够新，被S2拒绝，导致选举一直无法完成。</li></ol>]]></content>
    
    
    <categories>
      
      <category>MIT6.824</category>
      
      <category>Lab</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
      <tag>MIT6.824</tag>
      
      <tag>Go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文阅读】Not All Resources are Visible:Exploiting Fragmented Shadow Resources in Shared-State Scheduler Architecture</title>
    <link href="/2024/03/14/ShadowResources/"/>
    <url>/2024/03/14/ShadowResources/</url>
    
    <content type="html"><![CDATA[<h1 id="论文信息"><a href="#论文信息" class="headerlink" title="论文信息"></a>论文信息</h1><p><strong>论文地址：</strong> <a href="https://dl.acm.org/doi/10.1145/3620678.3624650">Not All Resources are Visible: Exploiting Fragmented Shadow Resources in Shared-State Scheduler Architecture</a></p><p><strong>收录会议：</strong> 云计算顶会-ACM Symposium on Cloud Computing(SoCC2023)</p><p><strong>作者：</strong> 交通大学-李超教授团队</p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p><strong>资源</strong>：一个集群中有成千上万台机器。</p><p><strong>请求：</strong> 百万级的请求并发，请求需求更低，运行时间更短，到达秒级甚至毫秒级的运行时间，如下图所示。</p><p><img src="/2024/03/14/ShadowResources/requestTrace.png" alt="图1. a为谷歌集群数据集中任务的cpu和内存占用率的分布，b为阿里巴巴集群数据集中任务运行时间的分布"></p><p><strong>调度：</strong> 主要有三种集群调度架构，如图2所示，单体式架构由于拓展性和灵活性不足，不适合大规模集群，两级式架构资源利用率低，共享状态架构具有高拓展性，更为流行。</p><p><img src="/2024/03/14/ShadowResources/scheduleArc.png" alt="图2. a为单体式架构，b为两级式架构，c为共享状态调度架构"></p><p>共享状态架构的具体介绍：</p><ul><li>有一个管理员维护了中央状态视图CSV。</li><li>存在多个并行调度器，调度范围是全局，调度依据是本地状态视图LSV，并将调度决策提交到CSV中，以避免与其他调度器发生冲突。</li><li>CSV 定期更新每个调度器拥有的本地状态视图 (LSV)，并具有固定的更新延迟。</li><li>最初的共享状态设计会在每次成功的资源分配操作时更新，但在实际集群中，更新延迟通常为秒级，以减少更新带来的系统开销。</li></ul><p>对低开销的追求使得每个调度器的LSV间歇性地过时，因为它们在更新延迟内对于已释放资源的最新状态是不可见的，本文将这些资源称为“影子资源”。<br>影子资源的数量与同步时间间隔和任务运行时间有关，根据理论和实验分析，它会占到已分配资源的2~13%，同时减少同步时间间隔会给调度系统带来较高的同步开销，难以实现，同时云中任务粒度小，会导致影子分散，所以考虑对其的利用是必要的。</p><p>但是之前的相关研究主要集中在优化调度策略来有效管理可见资源，如更高的利用率，更低的延迟，而忽略了对于影子资源利用的研究。</p><h1 id="创新与贡献"><a href="#创新与贡献" class="headerlink" title="创新与贡献"></a>创新与贡献</h1><p>考虑利用影子资源有两点需要注意：</p><ol><li>由于影子资源存在时间短，所以需要敏捷、高效地利用。</li><li>要灵活、透明，避免干扰正常的调度。</li></ol><p>故本文提出了RMiner机制来对影子资源进行利用，它包含三个协作组件：</p><ol><li>shadow resource manager：负责收集影子资源。</li><li>RM filter：筛选适合给影子资源利用的任务。</li><li>RM scheduler：负责将筛选出的任务分配给影子资源。</li></ol><p>针对不同的集群管理目标，RMiner 提供 SafeRM 和 SmartRM 两种资源挖掘模式，以平衡资源利用率最大化和冲突最小化</p><p>总体创新点如下：</p><ol><li>发现了共享状态调度架构中的影子资源，并从理论上和实验上对其进行了分析。</li><li>提出了RMiner机制，对影子资源进行了利用。</li><li>构建了RMiner的模拟器，实验证明了RMiner可以以较小的开销极大地提高集群性能。</li></ol><h1 id="理论分析"><a href="#理论分析" class="headerlink" title="理论分析"></a>理论分析</h1><p>经过理论分析，本文得出了瞬时影子资源的期望式：</p><p><img src="/2024/03/14/ShadowResources/expectation.jpg" alt="影子资源期望式"></p><p>即影子资源总量主要与状态更新延迟d<sub>u</sub>和集群中分配的资源数量r<sub>run</sub>成正比，而与任务的平均执行时间η成反比。</p><p>根据谷歌数据集、fuxi2.0、Borg的数据，假设任务的执行时间为4s<del>5s,状态更新延迟为0.3\</del>1.0s，那么影子资源占已分配资源的3~12.5%。<br>这是值得被考虑的，同时随着轻量云任务的增多，影子资源的利用也会变得更加重要。</p><p>通过对阿里巴巴集群数据集的随机采样，并进行了10中不同配置的实验，记录了影子资源的分布情况，与实验分析基本一致，如图3所示。</p><p><img src="/2024/03/14/ShadowResources/fig3.jpg" alt="图3. 影子资源理论与实验结果对比"></p><h1 id="RMiner机制设计"><a href="#RMiner机制设计" class="headerlink" title="RMiner机制设计"></a>RMiner机制设计</h1><p><img src="/2024/03/14/ShadowResources/fig4.jpg" alt="图4. RMiner机制"></p><p>RMiner机制包含三个协作组件，如图4中的蓝色所示：</p><ol><li>Shadow Resource Manager 通过新设计的索引，探测并管理最新的影子资源。</li><li>RM Filter选择适合影子资源的任务（RM Tasks）到任务队列中</li><li>RM Scheduler负责灵活地将影子资源分配给RM任务。</li></ol><p>RMiner的两大设计原则：</p><ol><li>避免入侵：不对原始调度系统做侵入式修改，原始调度系统依旧不需要知道影子资源的存在，并且不会和影子资源的分配发生冲突。</li><li>平衡性能：RMiner 面临着最大化利用不可见资源和最小化与可见调度冲突的权衡。过度利用影子资源可能会导致大量抢占式执行，从而降低集群的整体性能，反之亦然。</li></ol><h2 id="Shadow-Resource-Manager"><a href="#Shadow-Resource-Manager" class="headerlink" title="Shadow Resource Manager"></a>Shadow Resource Manager</h2><p><img src="/2024/03/14/ShadowResources/fig5.jpg" alt="图5. Shadow Resource Manager"></p><p>Shadow Resource Manager 通过图5所示的6种索引来探测并管理最新的影子资源：</p><ol><li>Shadow Resource Id: 用于标识影子资源的唯一ID。</li><li>Survival Time: 用于标识影子资源的存活时间。</li><li>Machine Id: 用于标识影子资源所在的机器。(注意同一机器的影子资源会被合并)</li><li>Available Resource: 用于标识影子资源的可用资源。</li><li>Occupied Resource: 用于标识影子资源的已占用资源。</li><li>Allocated Tasks: 用于标识影子资源已分配的任务。</li></ol><p>当中央状态视图同步集群状态并监控资源R的释放时，影子状态视图立即通过Echo State机制感知到该信息，并通过Echo State机制将新发现的影子资源合并到影子状态视图中。</p><p>注意在每次状态更新时，Shadow Resource Manager 会将所有空闲的影子资源释放，而只会继续管理已经被占用了的影子资源。</p><p>RM任务分配和运行结束释放都不用更新CSV，即CSV还是会一直认为这时候这些资源是空闲的，这样做是为了不影响原本的整个系统。</p><p>具体来说，它通过Echo State机制来迅速侦测新的影子资源，这种机制使得影子资源视图能够与CSV同步，但是主机影子资源的状态更新信息会被CSV忽略，而只会被Shadow Resource Manager处理，以避免影响原本的系统</p><pre><code class="hljs">问题：相当于是一种增量式的更新？但是问题在于这种大规模增量式的更新是否也会导致manager的状态更新延迟？延迟会有多严重？而且如果这里假设了这样子可以与最新的资源状态保持同步，那么这种方法能不能用到普通的调度器的同步上。或许直接预测可能的影子资源状态会更好？</code></pre><h2 id="RM-Filter"><a href="#RM-Filter" class="headerlink" title="RM Filter"></a>RM Filter</h2><p>RM Filter 是会在任务分配给各个调度器之前提前进行，任务选取有以下3个原则：</p><ol><li>过滤的任务应该与影子资源的短暂和碎片化属性相匹配。</li><li>其次，过滤后的任务应该能被抢先杀死或迁移，因为为了避免入侵，我们优先执行普通任务而不是 RM 任务，这样可以避免影响原始调度系统。</li><li>不选取太多任务，以免形成性能瓶颈。具体来说会考虑5个因素：<ol><li>RM任务队列的长度，表示RM调度器的工作负载；（负相关）</li><li>来自影子资源管理器的当前影子资源量； （正相关）</li><li>当前任务提交率，表示集群的工作负载；（正相关）</li><li>RM任务调度的成功率；（正相关）</li><li>调度系统当前的更新延迟。（正相关）</li></ol></li></ol><p>实际上还可以通过强化学习来进行任务的筛选，但是这不是本文的重点。</p><h2 id="RM-Scheduler"><a href="#RM-Scheduler" class="headerlink" title="RM Scheduler"></a>RM Scheduler</h2><p><img src="/2024/03/14/ShadowResources/fig6.jpg" alt="图6. RM Scheduler"></p><p>RM Scheduler 的执行如图6所示。它有两种调度模式：</p><ol><li><strong>虚线：</strong> 调度足够在影子资源上执行的任务，直接分配给影子资源，对CSV透明。（这种才叫RM任务）实际上就是将影子资源倒序排列，遍历选取合适的资源进行分配。</li><li><strong>实线：</strong> 调度不能在影子资源上执行的任务，当做是普通的调度器进行调度。流程如下：<ol><li>提交资源分配决定给影子状态管理视图；</li><li>影子资源管理视图返回信号没有足够的影子资源；</li><li>提交调度决策给CSV，就像普通的调度器一样；</li><li>如果调度成功就直接执行。</li></ol></li></ol><p>可以看出实际上RM Scheduler在执行时既需要拥有对影子资源的视图，也需要拥有对CSV的视图。</p><h2 id="Resource-Miner-优化"><a href="#Resource-Miner-优化" class="headerlink" title="Resource Miner 优化"></a>Resource Miner 优化</h2><p><strong>影子资源等待延迟：</strong> 当通过CSV更新，调度器对影子资源可见到这部分影子资源实际上被分配出去的这段时间。</p><p>可以探索RMiner去利用这段时间的资源。</p><p>举例，如图7所示，T0时刻R释放，成为了一种影子资源，CSV通过echo state更新给了RMiner，RMiner在T1时刻将任务放置到了这部分资源上（注意这时候不需要更新CSV），T2时刻进行了CSV更新，注意这时候调度器也认为原本被分配的影子资源也还是可以利用的，在T3时刻，调度器进行了一次普通的任务分配，没有冲突，但是在T4时刻，调度器将任务发送给了影子资源，这时候和影子资源的分配产生了冲突。其中T2~T4这段时间就是影子资源的<strong>等待延迟</strong>。</p><p>   <strong>问题：</strong> 为什么不告诉CSV这部分资源已经被分配了？这样就可以避免后续的冲突了。</p><p><img src="/2024/03/14/ShadowResources/fig7.jpg" alt="图7. 影子资源的等待延迟"></p><p>对影子资源的高利用率和低冲突率的权衡，所导致的对等待延迟时刻的影子资源的利用方式，使得本文提出了两种资源挖掘模式：</p><p><img src="/2024/03/14/ShadowResources/fig8.jpg" alt="图8. RMiner的两种资源挖掘模式对比"></p><h3 id="SafeRM-Mode"><a href="#SafeRM-Mode" class="headerlink" title="SafeRM Mode"></a>SafeRM Mode</h3><p>RMiner只在影子资源的存在时间对其进行利用，而不再等待延迟时间内对其进行利用，以最大程度避免冲突。在SafeRM模式下，RM Filter会优先考虑任务运行时间短的任务。RM调度器主要将短任务给小的影子资源。</p><p>当然由于RM任务的工作时长难以确定，所以RM任务也可能会超过影子资源存活时间，这是会尝试先迁移，如果不行再杀死。</p><h3 id="SmartRM-Mode"><a href="#SmartRM-Mode" class="headerlink" title="SmartRM Mode"></a>SmartRM Mode</h3><p>在影子资源的存在时间和等待延迟时间内对其进行利用，以最大程度提高资源利用率。在SmartRM模式下，RM Filter首先考虑任务的资源需求和驱逐成本，并优先考虑低优先的任务。RM调度器主要讲资源需求大的任务分配给尽量多空闲资源的合适的影子资源。</p><p>当冲突发生时，RM调度器会先杀死低优先级的RM任务，然后再尝试为其迁移。</p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>实验时，在谷歌集群模拟系统上添加了RM相关的组件。实验任务为2k+。模拟的节点为1500个同构节点，每个节点64个CPU，16个内存。</p><p>实验的任务主要来自阿里巴巴集群数据集。更新延迟为0.5s，调度器调度速率为每秒1000个任务，调度器数量分别设置为8和16，任务平均执行时间为5s，指数分布，平均一个作业包含12个任务，任务达到速率有1.43和0.7，前者在300秒内生成了200多个作业，即约2400个任务。</p><p>实验主要想回答3个问题：</p><ol><li>RMiner 能为共享状态架构带来哪些性能提升？ </li><li>在当前的共享状态调度器中采用RMiner的成本是多少？ </li><li>引入的优化如何有助于性能改进？</li></ol><h2 id="资源利用率"><a href="#资源利用率" class="headerlink" title="资源利用率"></a>资源利用率</h2><p><img src="/2024/03/14/ShadowResources/fig9.jpg" alt="图9. 资源利用率"></p><p>   图是真好看啊！</p><p>条形图表示 CPU 利用率的改进。显然，RMiner 通过挖掘影子资源来提高集群 CPU 利用率。不同场景下，影子资源占用集群资源的1.5%~5.0%。通过利用资源等待延迟方面的资源，SafeRM 的性能优于 NoRM 1.5% 至 4%，SmartRM 的性能优于 NoRM 1.6% 至 5.8%。</p><p>更具体地说，RMiner 在 8 个调度程序场景（平均利用率为 36.9%）下比在 16 个调度程序（平均利用率为 71.8%）下工作得更好，因为更少的调度程序可以更容易地为影子资源找到合适的 RM 任务（因为资源利用率低） 。此外，RMiner 在较高的任务提交率（2 倍）下表现更好，因为更多的任务提供了更多可供利用的已释放资源。</p><p>我们还将每个设置下的影子资源利用率报告为标记线。通过记录总体影子资源和分配的影子资源，SafeRM 使用了 26% 到 82% 的影子资源，SmartRM 使用了 58% 到 112% 的影子资源。 SafeRM 更加保守，仅限制影子资源生存时间的任务，而 SmartRM 则更加激进，在资源等待延迟中利用影子资源，甚至超过了不可见影子资源的上限。</p><h2 id="任务吞吐量"><a href="#任务吞吐量" class="headerlink" title="任务吞吐量"></a>任务吞吐量</h2><p><img src="/2024/03/14/ShadowResources/fig10.jpg" alt="图10. 任务吞吐量"></p><p>图 10 (a) 显示了阿里巴巴跟踪的改进，其中 SafeRM 比 NoRM 实现了高达 10% 的吞吐量提升，SmartRM 实现了高达 28% 的吞吐量提升在高工作负载（任务提交率）下，RMiner 比低工作负载表现更好，因为更多已完成的任务产生更多的影子资源。</p><p>此外，我们在图 10(b) 中比较了 Google 跟踪上三种方案的吞吐量。结果表明，SafeRM 实现了 2% 到 9% 的改进，SmartRM 实现了 10% 到 28% 的改进，这与阿里巴巴的结果类似，进一步验证了 RMiner 的性能。</p><h2 id="任务等待延迟"><a href="#任务等待延迟" class="headerlink" title="任务等待延迟"></a>任务等待延迟</h2><p><img src="/2024/03/14/ShadowResources/fig11.jpg" alt="图11. 任务等待延迟"></p><p>我们在图 11 中展示了作业等待时间的结果。它表明 RMiner 在较低工作负载下的表现与 NoRM 类似，因为在这种情况下任务不需要在队列中等待。然而，在更高的工作负载（1.75x和2x）下，并行提交的任务更多，普通调度器几乎已经达到了调度能力。 RMiner 的表现非常出色，因为它利用了更多短期任务来减少整体排队延迟。 RMiner 在 8 个调度程序下将作业等待时间缩短高达 25.4%，在 16 个调度程序下将作业等待时间缩短高达 10.4%。更多的调度器减少了并发调度任务的压力，但会导致更多的调度冲突。此外，我们进一步在 Google 的跟踪上验证了改进，发现 RMiner 在 8 个调度器下实现了 59.9% 的改进，在 16 个调度器下实现了 24.9% 的改进。</p><h2 id="任务冲突"><a href="#任务冲突" class="headerlink" title="任务冲突"></a>任务冲突</h2><p><img src="/2024/03/14/ShadowResources/fig12.jpg" alt="图12. 任务冲突"></p><p>我们记录了 16 个调度程序设置的不同工作负载级别下的冲突。图 12 报告了性能改进和引发的冲突之间的关系。图 12（a）显示了基线和 SafeRM 之间的比较，这表明 SafeRM 在最坏情况下导致冲突增加不到 3%，从而将资源利用率和任务吞吐量提高了 4%。平均而言，与当前的共享状态调度程序相比，SafeRM 造成的冲突多了 0.5%，这与性能收益相比是可以接受的。</p><p>此外，我们在图 12 (b) 中报告了 SmartRM 的结果。同样，SmartRM 在最坏的情况下会导致冲突增加 3%，资源利用率提高 6%，吞吐量提高 13%。 SmartRM 的平均冲突成本为 0.73%，由于挖矿策略更加激进，比 SafeRM 略高。我们还发现，在较高工作负载下，冲突成本更加严重，因为更多并发任务提交使 SmartRM 更容易与正常调度程序发生冲突。综上所述，从工作冲突的角度来看，成本与绩效的提升相比可以忽略不计。</p><h2 id="总体分析"><a href="#总体分析" class="headerlink" title="总体分析"></a>总体分析</h2><p>RMiner 的额外开销也是回答问题 3 的一个重要方面。不幸的是，工业模拟器没有对调度开销进行建模，因此我们进行了全面的理论分析。 RMiner的开销包括影子资源管理开销和RM调度开销。影子资源管理器占用额外的内存空间来存储和更新影子资源状态索引，大约是CSV空间的3%-12.5%。在较高工作负载下，管理算法的频率很频繁，但通过哈希映射，操作的复杂度为 O(1)，从而导致可接受的计算开销。总体而言，影子资源的管理所产生的开销可以忽略不计。</p><p>至于额外的调度开销，当前的共享状态调度器设计配备了数十个具有全局状态视图的并行分布式调度器。 RMiner 增加了一个 RM 调度器，大大增强了当前设计的可见性，并且 RM 调度器的调度成本比传统的并行调度器要低，因为调度范围和实体都比以前更小。因此，RMiner 的调度开销比当前共享状态设计大约增加了个位数。总体而言，与集群性能的显着提升相比，在当前共享状态调度器中采用 RMiner 的成本可以忽略不计。</p><h2 id="RM模式对比"><a href="#RM模式对比" class="headerlink" title="RM模式对比"></a>RM模式对比</h2><p>实验中，SafeRM保留更新延迟的过滤阈值以保证最小化冲突。 SmartRM的默认阈值也是更新延迟，我们将过滤器阈值调整为2x更新延迟和4x更新延迟来比较性能。前者发生冲突的可能性较低，被定义为保守派SmartRM（SmartRM-C）。相反，后者被定义为激进的SmartRM（SmartRM-A）。此外，我们改变了 0.5 秒的默认更新延迟来调查对结果的影响。实验在 1x 工作负载级别和 16 个并行调度器下进行。</p><p><img src="/2024/03/14/ShadowResources/fig13.jpg" alt="图13. RM模式对比-任务吞吐率和利用率"></p><p><img src="/2024/03/14/ShadowResources/fig14.jpg" alt="图14. RM模式对比-任务冲突"></p><p>查看图13，与直觉相反，将更多任务过滤到 RMiner (SmartRM-A) 会提高资源利用率，同时降低任务吞吐量。这是因为此设置留给普通调度程序的短期任务较少，而普通调度程序往往会将重量级任务调度到集群，集群会同时占用更多资源，但总共完成的任务较少。因此，我们需要仔细控制过滤原则，以避免 RMiner 中的过度过滤和欠过滤任务。更新延迟也会影响 RMiner 的性能。更新延迟越大，资源浪费越大，导致任务吞吐量和资源利用率降低。在较高的更新延迟下，SmartRM-A 在利用率方面的表现比在较低情况下更差，因为 RMiner 的改进被正常调度程序的退化所掩盖，但它在利用率方面的表现几乎相同，因为在这种情况下执行了更多的重量级任务。</p><p>此外，我们在图 14 中报告了冲突的详细信息。我们记录了由于冲突而终止的任务，并将数量标准化为 RM 任务。该指标的值越低意味着与正常调度发生冲突的 RM 任务就越少。显然，SafeRM 很少与正常调度发生冲突。对于SmartRM来说，过滤器阈值越高，杀死RM任务的比例就越高，导致与并行调度器的冲突更多。性能改进和冲突成本之间存在权衡，权衡的两侧代表了RMiner的不同设计目标：最高的性能改进或对正常系统的最低侵入。总体而言，不同的RMiner以可接受的成本实现了相当大的性能提升，并且可以针对不同的目标进行灵活配置。</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文阅读</tag>
      
      <tag>集群调度</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux控制台输出多种样式彩色字符及原理解析</title>
    <link href="/2024/03/02/colorfulEcho/"/>
    <url>/2024/03/02/colorfulEcho/</url>
    
    <content type="html"><![CDATA[<h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h1><p>之前在做MIT6.824的实验的时候，有<a href="https://blog.josejg.com/debugging-pretty/">助教资料</a>在说明如何输出彩色的字符来让日志更加清晰。所以对Linux控制台如何输出多种样式的彩色字符以及它的原理产生了兴趣，学习了之后在这里记录一下。</p><h1 id="2-原理"><a href="#2-原理" class="headerlink" title="2. 原理"></a>2. 原理</h1><p>Linux控制台输出彩色字符的原理是通过ANSI转义码来实现的。ANSI转义码是一种控制字符，用于控制文本终端的行为。包括但不限于控制光标位置、颜色、清屏等。</p><p>下面这是一段输出蓝色字符的控制台代码：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;\033[34mHello\033[0m&quot;</span><br></code></pre></td></tr></table></figure><p>在vscode的终端显示结果如下：</p><p><img src="/2024/03/02/colorfulEcho/eg1.jpg" alt="输出结果"></p><p>下面对这段代码逐个进行解析：</p><ul><li>-e：表示开启转义字符的解析，如果不加这个参数，\033会被当做普通字符输出。</li><li>\033：表示转义字符的开始。在ASCII字符集中，十进制的33代表了Escape字符（也可以写为\033或\x1B），它通常用于表示控制序列的开始。</li><li>[34m：表示设置颜色。34代表蓝色，m表示设置颜色的转义序列的结束。</li><li>[0m：表示重置为默认设置。0代表默认设置，m表示设置颜色的转义序列的结束。如果不设置为默认设置，后续的字符都会被设置为蓝色。</li></ul><h1 id="3-转义代码"><a href="#3-转义代码" class="headerlink" title="3. 转义代码"></a>3. 转义代码</h1><p>主要与输出字符格式相关的转义代码的格式如下，可以单独使用也可以利用;来混合使用：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">\033[显示方式;前景色;背景色m<br></code></pre></td></tr></table></figure><p>下面是一些常用的转义代码：</p><h2 id="1-显示方式"><a href="#1-显示方式" class="headerlink" title="1. 显示方式"></a>1. 显示方式</h2><p>代码及对应显示方式如下：</p><ul><li>0：所有属性关闭，恢复到默认值。</li><li>1：粗体或者高亮。</li><li>2：弱化（低亮）。(不是所有终端都支持)</li><li>3：斜体。(不是所有终端都支持)</li><li>4：下划线。</li><li>5,6：闪烁。(不是所有终端都支持)</li><li>7：反显，即前景色和背景色交换。</li><li>8：隐藏字符。</li><li>9：删除线。(不是所有终端都支持)</li><li>10：将文本的前景色设置为默认颜色。</li><li>21：双下划线。(不是所有终端都支持)</li></ul><p>在vscode的终端显示结果如下：</p><p><img src="/2024/03/02/colorfulEcho/eg2.jpg" alt="显示方式"></p><h2 id="2-前景色"><a href="#2-前景色" class="headerlink" title="2. 前景色"></a>2. 前景色</h2><p>代码及对应颜色如下：</p><ul><li>30：黑色。</li><li>31：红色。</li><li>32：绿色。</li><li>33：黄色。</li><li>34：蓝色。</li><li>35：洋红。</li><li>36：青色。</li><li>37：白色。</li></ul><p>在vscode的终端显示结果如下（注意37号白色被终端自动修改了以能够显示清楚）：</p><p><img src="/2024/03/02/colorfulEcho/eg3.jpg" alt="前景色"></p><p>而38号前景色是用于设置前景色的其他模式，包括两种：</p><ol><li>使用 ANSI 256 色模式设置前景色，例如：\033[38;5;196m。这里的5表示使用 ANSI 256 色模式，196表示使用ANSI 256 色模式中的第 196 种颜色</li><li>使用 TrueColor 模式设置前景色，例如：\033[38;2;255;0;0m。这里的2表示使用 TrueColor 模式，255;0;0表示RGB颜色值</li></ol><p>39号表示重置前景色为默认颜色。</p><h2 id="3-背景色"><a href="#3-背景色" class="headerlink" title="3. 背景色"></a>3. 背景色</h2><p>代码及对应颜色如下：</p><ul><li>40：黑色。</li><li>41：红色。</li><li>42：绿色。</li><li>43：黄色。</li><li>44：蓝色。</li><li>45：洋红。</li><li>46：青色。</li><li>47：白色。</li></ul><p>在vscode的终端显示结果如下（注意47号白色被终端自动修改了以能够显示清楚）：</p><p><img src="/2024/03/02/colorfulEcho/eg4.jpg" alt="背景色"></p><p>同样的，48号背景色是用于设置背景色的其他模式，包括使用 ANSI 256 色模式设置背景色和使用 TrueColor 模式设置背景色。<br>49号表示重置背景色为默认颜色。</p><h2 id="4-其他"><a href="#4-其他" class="headerlink" title="4. 其他"></a>4. 其他</h2><p>还有一些其他比较有意思的转义代码，不过格式就不是\033[显示方式;前景色;背景色m了，如下：</p><ul><li><code>\033[n*A</code> :光标上移n行 </li><li><code>\033[nB</code>:光标下移n行 </li><li><code>\033[nC</code>:光标右移n行 </li><li><code>\033[nD</code>:光标左移n行 </li><li><code>\033[y</code>;xH :设置光标位置 </li><li><code>\033[2J</code> :清屏 </li><li><code>\033[K</code>:清除从光标到行尾的内容 </li><li><code>\033[s</code>:保存光标位置 </li><li><code>\033[u</code>:恢复光标位置 </li><li><code>\033[?25l</code>:隐藏光标 </li><li><code>\033[?25h</code>:显示光标</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><a href="https://blog.csdn.net/TomorrowAndTuture/article/details/116448273">Linux 命令行输出不同颜色的文本</a></li><li><a href="https://www.linuxquestions.org/questions/linux-software-2/adding-colors-to-your-motd-105038/">Adding colors to your motd?</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在Unbuntu上安装Go以及解决Vscode上Go插件无法安装的问题</title>
    <link href="/2024/03/01/ubuntuInstallGo/"/>
    <url>/2024/03/01/ubuntuInstallGo/</url>
    
    <content type="html"><![CDATA[<h1 id="1-下载-Go-压缩包"><a href="#1-下载-Go-压缩包" class="headerlink" title="1. 下载 Go 压缩包"></a>1. 下载 Go 压缩包</h1><p>在写这篇文章的时候，Go 的最新版为 1.22.0。在我们下载安装包时，请浏览Go 官方下载页面,并且检查一下是否有新的版本可用。</p><p>以 root 或者其他 sudo 用户身份运行下面的命令，下载并且解压 Go 二进制文件到&#x2F;usr&#x2F;local目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget -c https://dl.google.com/go/go1.22.0.linux-amd64.tar.gz -O - | tar -xz -C /usr/local<br></code></pre></td></tr></table></figure><h1 id="2-调整环境变量"><a href="#2-调整环境变量" class="headerlink" title="2. 调整环境变量"></a>2. 调整环境变量</h1><p>通过将 Go 目录添加到$PATH环境变量，系统将会知道在哪里可以找到 Go 可执行文件。</p><p>这个可以通过执行下面命令将go添加到&#x2F;etc&#x2F;profile文件（系统范围内安装）或者替换为$HOME&#x2F;.profile文件（当前用户安装）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;export PATH=$PATH:/usr/local/go/bin&#x27;</span> &gt;&gt; /etc/.profile<br></code></pre></td></tr></table></figure><p>保存文件，并且重新加载新的PATH 环境变量到当前的 shell 会话：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">source</span> ~/.profile<br></code></pre></td></tr></table></figure><h1 id="3-验证-Go-安装过程"><a href="#3-验证-Go-安装过程" class="headerlink" title="3. 验证 Go 安装过程"></a>3. 验证 Go 安装过程</h1><p>通过打印 Go 版本号，验证安装过程。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">go version<br></code></pre></td></tr></table></figure><p>输出应该像下面这样：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">go</span> version go1.<span class="hljs-number">22</span>.<span class="hljs-number">0</span> linux/amd64<br></code></pre></td></tr></table></figure><h1 id="4-安装Vscode插件"><a href="#4-安装Vscode插件" class="headerlink" title="4. 安装Vscode插件"></a>4. 安装Vscode插件</h1><p>首先在vscode中搜索安装Go插件，点击第一个名称为Go的插件进行安装。<br>然后由于网络防火墙的原因，有部分组件无法下载。<br>需要在命令行中输入以下命令替换go的下载源：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">go <span class="hljs-built_in">env</span> -w GO111MODULE=on<br>go <span class="hljs-built_in">env</span> -w GOPROXY=https://goproxy.io,direct<br></code></pre></td></tr></table></figure><p>替换好关闭vscode重新打开，会弹出install all，点击等待安装即可。<br>如果没有弹出就按crtl+shift+p，输入go install&#x2F;update tools，点击等待安装即可。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><a href="https://cloud.tencent.com/developer/article/1623121">如何在 Ubuntu 20.04 上安装 Go</a></li><li><a href="https://zhuanlan.zhihu.com/p/387853200">解决vscode安装go插件失败的问题</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>Go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在CentOS上使用源码安装Python3.7，不与系统Python2.7冲突，同时支持pip3（脚本安装，亲测有效）</title>
    <link href="/2024/03/01/centosInstallPython/"/>
    <url>/2024/03/01/centosInstallPython/</url>
    
    <content type="html"><![CDATA[<p>该脚本主要是在Centos系统上使用源码安装Python3.7，安装后可以调用python3和pip3来进行使用，同时不与系统Python2.7冲突，还额外加入了腾讯的pip源来加速pip3下载包。</p><p>脚本使用方法如下：</p><ol><li>创建文件 <code>install_py37.sh</code>，写入以下 shell 脚本</li><li>赋予执行权限，<code>chmox +x install_py37.sh</code></li><li>执行脚本，<code>./install_py37.sh</code></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/env bash</span><br><br><span class="hljs-comment">## 下载 Python 源码，如果已下载源码在脚本当前目录下，可注释跳过下载步骤</span><br>wget https://www.python.org/ftp/python/3.7.12/Python-3.7.12.tgz<br><br><span class="hljs-comment">## 安装编译依赖组件</span><br>yum -y install wget zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gcc make libffi-devel xz-devel<br><br><span class="hljs-comment">## 解压安装</span><br><span class="hljs-comment"># 解压到/usr/local/src目录</span><br>tar zvxf Python-3.7.12.tgz -C /usr/local/src<br><span class="hljs-built_in">cd</span> /usr/local/src/Python-3.7.12<br><span class="hljs-comment"># 编译前配置</span><br>./configure prefix=/usr/local/python3 --enable-shared<br><span class="hljs-comment"># 编译构建</span><br>make -j8<br><span class="hljs-comment"># 安装Python</span><br>make install<br><span class="hljs-comment"># 清理编译产出的中间文件</span><br>make clean<br><span class="hljs-comment"># 链接构建产出的Python可执行文件到/usr/local/bin目录</span><br><span class="hljs-built_in">ln</span> -s /usr/local/python3/bin/python3 /usr/local/bin/python3<br><span class="hljs-comment"># 链接构建产出的pip3可执行文件到/usr/local/bin目录</span><br><span class="hljs-built_in">ln</span> -s /usr/local/python3/bin/pip3 /usr/local/bin/pip3<br><span class="hljs-comment"># 链接构建产出的Python动态库</span><br><span class="hljs-built_in">ln</span> -s /usr/local/python3/lib/libpython3.7m.so.1.0 /usr/lib/libpython3.7m.so.1.0<br><span class="hljs-comment"># 配置动态库</span><br>ldconfig<br><br><span class="hljs-comment">## 检查Python版本是否安装成功</span><br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;\033[1;42;37m[<span class="hljs-subst">$(date <span class="hljs-string">&quot;+%Y/%m/%d %H:%M:%S&quot;</span>)</span>] [Check]: 检查Python版本\033[0m&quot;</span><br>python3 --version<br><span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;\033[1;42;37m[<span class="hljs-subst">$(date <span class="hljs-string">&quot;+%Y/%m/%d %H:%M:%S&quot;</span>)</span>] [Check]: 检查Python版本\033[0m&quot;</span><br><br><span class="hljs-comment">## pypi下载源配置</span><br><span class="hljs-built_in">mkdir</span> ~/.pip3/<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;extra-index-url = https://mirrors.cloud.tencent.com/pypi/simple&quot;</span> &gt;&gt; ~/.pip3/pip.conf<br></code></pre></td></tr></table></figure><p>主要是参考了这篇文章：<a href="https://tencent.github.io/CodeAnalysis/zh/advanced/install_python37_on_centos.html">CentOS 7 安装 Python 3.7</a><br>不同点在于将原本的链接路径和安装结果改为了python3和pip3。</p>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【MIT6.824】lab2A实现笔记</title>
    <link href="/2024/02/27/MIT6-824lab2A/"/>
    <url>/2024/02/27/MIT6-824lab2A/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>实现了MIT6.824中的lab2A，即leader选举的部分。</p><h1 id="Raft结构及初始化"><a href="#Raft结构及初始化" class="headerlink" title="Raft结构及初始化"></a>Raft结构及初始化</h1><p>为一个Raft中的节点增加的变量主要有：</p><ul><li>currentTerm: 当前任期</li><li>votedFor: 为谁投票, -1表示没有投票，注意一个任期只能投一次票</li><li>state: 当前节点的状态</li><li>heartbeatTimeout: 心跳超时计数器</li><li>electionTimeout: 选举超时计数器</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// A Go object implementing a single Raft peer.</span><br><span class="hljs-keyword">type</span> Raft <span class="hljs-keyword">struct</span> &#123;<br>mu               sync.RWMutex        <span class="hljs-comment">// Lock to protect shared access to this peer&#x27;s state</span><br>peers            []*labrpc.ClientEnd <span class="hljs-comment">// RPC end points of all peers</span><br>persister        *Persister          <span class="hljs-comment">// Object to hold this peer&#x27;s persisted state</span><br>me               <span class="hljs-type">int</span>                 <span class="hljs-comment">// this peer&#x27;s index into peers[]</span><br>dead             <span class="hljs-type">int32</span>               <span class="hljs-comment">// set by Kill()</span><br>currentTerm      <span class="hljs-type">int</span><br>votedFor         <span class="hljs-type">int</span><br>state            NodeState<br>heartbeatTimeout *time.Timer<br>electionTimeout  *time.Timer<br>&#125;<br><br><span class="hljs-comment">// NodeState represents the state of a node in the raft protocol</span><br><span class="hljs-keyword">type</span> NodeState <span class="hljs-type">uint8</span><br><br><span class="hljs-keyword">const</span> (<br>Follower NodeState = <span class="hljs-literal">iota</span><br>Candidate<br>Leader<br>)<br></code></pre></td></tr></table></figure><p>初始化Make函数如下，注意为新添加的变量进行初始化，可以看到初始化之后就会启动一个ticker的goroutine来让节点不断运行。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Make</span><span class="hljs-params">(peers []*labrpc.ClientEnd, me <span class="hljs-type">int</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">persister *Persister, applyCh <span class="hljs-keyword">chan</span> ApplyMsg)</span></span> *Raft &#123;<br>rf := &amp;Raft&#123;<br>peers:            peers,<br>persister:        persister,<br>me:               me,<br>dead:             <span class="hljs-number">0</span>,<br>currentTerm:      <span class="hljs-number">0</span>,<br>votedFor:         <span class="hljs-number">-1</span>,<br>state:            Follower,<br>heartbeatTimeout: time.NewTimer(time.Duration(StableHeartbeatTimeout())),<br>electionTimeout:  time.NewTimer(time.Duration(RandomizedElectionTimeout())),<br>&#125;<br><br><span class="hljs-comment">// Your initialization code here (2A, 2B, 2C).</span><br><br><span class="hljs-comment">// initialize from state persisted before a crash</span><br>rf.readPersist(persister.ReadRaftState())<br><br><span class="hljs-comment">// start ticker goroutine to start elections</span><br><span class="hljs-keyword">go</span> rf.ticker()<br><br><span class="hljs-keyword">return</span> rf<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="计时函数"><a href="#计时函数" class="headerlink" title="计时函数"></a>计时函数</h1><p>计时函数如上所述有两个：</p><ul><li>heartbeatTimeout: 倒计时结束时，需要向其他节点发送心跳，以维持自己的leader地位</li><li>electionTimeout: 倒计时结束时，需要转化为candidate开始选举，如果在倒计时结束前收到了leader的心跳，则重置倒计时。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> ticker() &#123;<br><span class="hljs-keyword">for</span> rf.killed() == <span class="hljs-literal">false</span> &#123;<br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> &lt;-rf.heartbeatTimeout.C:<br>rf.mu.Lock()<br><span class="hljs-keyword">if</span> rf.state == Leader &#123;<br>rf.broadcastHeartbeat()<br>rf.heartbeatTimeout.Reset(StableHeartbeatTimeout())<br>&#125;<br>rf.mu.Unlock()<br><span class="hljs-keyword">case</span> &lt;-rf.electionTimeout.C:<br>rf.mu.Lock()<br>rf.changeState(Candidate)<br>rf.currentTerm++<br>rf.startElection()<br>rf.electionTimeout.Reset(RandomizedElectionTimeout())<br>rf.mu.Unlock()<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="选举leader"><a href="#选举leader" class="headerlink" title="选举leader"></a>选举leader</h1><p>选举leader主要依靠发送RequestVote RPC来进行，选举的过程如下：</p><ol><li>electionTimeout计时器到期，节点转化为candidate状态，增加currentTerm并开始选举</li><li>发送RequestVote RPC给其他节点，请求投票</li><li>接收到其他节点的投票结果。</li></ol><p>按照Raft论文的描述可以将选举结果分为三种：</p><ol><li>得到了大多数节点的投票，成为leader</li><li>有其他节点成为了leader，自己转化为follower。如何感知到其他节点成为了leader呢？有两种手段：<ol><li>通过RequestVoteReply中的Term字段，如果Term比自己的大，则说明有其他节点成为了leader</li><li>接受到了其他节点的心跳，说明有其他节点成为了leader</li></ol></li><li>大家平分选票，没有leader产生，等待electionTimeout计时器到期，重新开始选举</li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> startElection() &#123;<br>request := rf.genRequestVoteRequest()<br>DPrintf(<span class="hljs-string">&quot;&#123;Node %v&#125; starts election with RequestVoteRequest %v&quot;</span>, rf.me, request)<br>rf.votedFor = rf.me<br>grantedVoteNum := <span class="hljs-number">1</span><br><br><span class="hljs-comment">// Your code here (2A, 2B).</span><br><span class="hljs-keyword">for</span> peer := <span class="hljs-keyword">range</span> rf.peers &#123;<br><span class="hljs-keyword">if</span> peer != rf.me &#123;<br><span class="hljs-keyword">if</span> peer == rf.me &#123;<br><span class="hljs-keyword">continue</span><br>&#125;<br><br><span class="hljs-keyword">go</span> rf.electionRequestOnce(peer, &amp;grantedVoteNum, request)<br>&#125;<br>&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> electionRequestOnce(peer <span class="hljs-type">int</span>, grantedVoteNum *<span class="hljs-type">int</span>, request *RequestVoteArgs) &#123;<br>reply := <span class="hljs-built_in">new</span>(RequestVoteReply)<br><span class="hljs-keyword">if</span> rf.sendRequestVote(peer, request, reply) &#123;<br>rf.mu.Lock()<br><span class="hljs-keyword">defer</span> rf.mu.Unlock()<br>DPrintf(<span class="hljs-string">&quot;&#123;Node %v&#125; received RequestVoteReply &#123;%v&#125; from &#123;Node %v&#125;&quot;</span>, rf.me, reply, peer)<br><span class="hljs-keyword">if</span> rf.currentTerm == request.Term &amp;&amp; rf.state == Candidate &#123;<br><span class="hljs-keyword">if</span> reply.VoteGranted &#123;<br>*grantedVoteNum++<br><span class="hljs-keyword">if</span> *grantedVoteNum &gt; <span class="hljs-built_in">len</span>(rf.peers)/<span class="hljs-number">2</span> &#123;<br>rf.changeState(Leader)<br>rf.broadcastHeartbeat()<br>&#125;<br>&#125;<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> reply.Term &gt; rf.currentTerm &#123;<br>DPrintf(<span class="hljs-string">&quot;&#123;Node %v&#125; found higher term %v in RequestVoteReply %v from &#123;Node %v&#125;&quot;</span>, rf.me, reply.Term, reply, peer)<br>rf.currentTerm = reply.Term<br>rf.votedFor = <span class="hljs-number">-1</span><br>rf.changeState(Follower)<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>节点在进行投票时的规则如下：</p><ol><li>如果自己的term比对方大，则拒绝投票</li><li>如果在当前term中已经投过票给其他candidate，则拒绝投票</li><li>其余情况下投票给对方，并更新自己的term与votedFor，并直接转化为follower状态</li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> RequestVote(args *RequestVoteArgs, reply *RequestVoteReply) &#123;<br><span class="hljs-comment">// Your code here (2A, 2B).</span><br>rf.mu.Lock()<br><span class="hljs-keyword">defer</span> rf.mu.Unlock()<br><span class="hljs-keyword">defer</span> DPrintf(<span class="hljs-string">&quot;&#123;Node %v&#125;&#x27;s state is &#123;state: %v, term: %v&#125;, the RequestVoteReply is &#123;%v&#125;&quot;</span>, rf.me, rf.state, rf.currentTerm, reply)<br><br><span class="hljs-keyword">if</span> args.Term &lt; rf.currentTerm || (args.Term == rf.currentTerm &amp;&amp; rf.votedFor != <span class="hljs-number">-1</span> &amp;&amp; rf.votedFor != args.CandidateId) &#123;<br>reply.Term, reply.VoteGranted = rf.currentTerm, <span class="hljs-literal">false</span><br><span class="hljs-keyword">return</span><br>&#125;<br><span class="hljs-keyword">if</span> args.Term &gt; rf.currentTerm &#123;<br>rf.currentTerm, rf.votedFor = args.Term, <span class="hljs-number">-1</span><br>rf.changeState(Follower)<br>&#125;<br><span class="hljs-keyword">if</span> !rf.isLogUpToDate(args.LastLogIndex, args.LastLogTerm) &#123;<br>reply.Term, reply.VoteGranted = rf.currentTerm, <span class="hljs-literal">false</span><br><span class="hljs-keyword">return</span><br>&#125;<br><br>rf.votedFor = args.CandidateId<br><span class="hljs-comment">// now the term of the candidate must equal to the current term of the rf</span><br>reply.Term, reply.VoteGranted = rf.currentTerm, <span class="hljs-literal">true</span><br>&#125;<br><br><span class="hljs-keyword">type</span> RequestVoteArgs <span class="hljs-keyword">struct</span> &#123;<br>Term         <span class="hljs-type">int</span><br>CandidateId  <span class="hljs-type">int</span><br>LastLogIndex <span class="hljs-type">int</span><br>LastLogTerm  <span class="hljs-type">int</span><br>&#125;<br><span class="hljs-keyword">type</span> RequestVoteReply <span class="hljs-keyword">struct</span> &#123;<br>Term        <span class="hljs-type">int</span><br>VoteGranted <span class="hljs-type">bool</span><br>&#125;<br><br></code></pre></td></tr></table></figure><p>注意在状态转化时需要对计时器进行相应的修改，如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> changeState(newState NodeState) &#123;<br><span class="hljs-keyword">if</span> rf.state == newState &#123;<br><span class="hljs-keyword">return</span><br>&#125;<br>DPrintf(<span class="hljs-string">&quot;&#123;Node %v&#125; changes state from %s to %s&quot;</span>, rf.me, rf.state, newState)<br>rf.state = newState<br><br><span class="hljs-keyword">switch</span> newState &#123;<br><span class="hljs-keyword">case</span> Follower:<br>rf.heartbeatTimeout.Stop()<br>rf.electionTimeout.Reset(RandomizedElectionTimeout())<br><span class="hljs-keyword">case</span> Candidate:<br><span class="hljs-keyword">case</span> Leader:<br>rf.broadcastHeartbeat()<br>rf.heartbeatTimeout.Reset(StableHeartbeatTimeout())<br>rf.electionTimeout.Stop()<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="心跳广播"><a href="#心跳广播" class="headerlink" title="心跳广播"></a>心跳广播</h1><p>理论上心跳发送应该与日志复制用的是同一种RPC，但是lab2A不需要实现日志复制，所以这里的日志复制进行了简化，能发送心跳来维持自己的leader地位即可。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> replicateOneRound(peer <span class="hljs-type">int</span>) &#123;<br><span class="hljs-keyword">if</span> rf.state != Leader &#123;<br><span class="hljs-keyword">return</span><br>&#125;<br><br>request := rf.genAppendEntriesRequest(peer)<br>reply := <span class="hljs-built_in">new</span>(AppendEntriesReply)<br><span class="hljs-keyword">if</span> rf.sendAppendEntries(peer, request, reply) &#123;<br>DPrintf(<span class="hljs-string">&quot;&#123;Node %v&#125; received AppendEntriesReply &#123;%v&#125; from &#123;Node %v&#125;&quot;</span>, rf.me, reply, peer)<br>&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span></span> AppendEntries(args *AppendEntriesRequest, reply *AppendEntriesReply) &#123;<br>DPrintf(<span class="hljs-string">&quot;&#123;Node %v&#125; received AppendEntriesRequest &#123;%v&#125;&quot;</span>, rf.me, args)<br>rf.changeState(Follower)<br>rf.electionTimeout.Reset(RandomizedElectionTimeout())<br>reply.Term, reply.Success = rf.currentTerm, <span class="hljs-literal">true</span><br>&#125;<br><br><span class="hljs-keyword">type</span> AppendEntriesRequest <span class="hljs-keyword">struct</span> &#123;<br>Term     <span class="hljs-type">int</span><br>LeaderId <span class="hljs-type">int</span><br>&#125;<br><span class="hljs-keyword">type</span> AppendEntriesReply <span class="hljs-keyword">struct</span> &#123;<br>Term    <span class="hljs-type">int</span><br>Success <span class="hljs-type">bool</span><br>&#125;<br></code></pre></td></tr></table></figure><h1 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h1><p>运行结果如下，能通过所有测试：</p><p><img src="/2024/02/27/MIT6-824lab2A/result.jpg" alt="运行结果"></p>]]></content>
    
    
    <categories>
      
      <category>MIT6.824</category>
      
      <category>Lab</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
      <tag>MIT6.824</tag>
      
      <tag>Go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文阅读】In Search of an Understandable Consensus Algorithm</title>
    <link href="/2023/12/26/RaftPaperRead/"/>
    <url>/2023/12/26/RaftPaperRead/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>共识一致性算法常用在分布式系统中，一个系统会有一个领导者，如GFS，我们需要有多个领导者副本来提高系统的容错性。但是之前的共识性算法经常采用Paxos，但是该算法很难理解。所以本文的作者重点面向可理解性提出了一个新的共识性算法Raft。主要做法是将大步骤分解成小步骤，然后尽量降低复杂度。</p><p>在具体关注其实现之前强烈建议去<a href="https://thesecretlivesofdata.com/raft/">raft可视化</a>中去学习一下基本的流程，以对其有个大概的印象，然后还可以参考这部分的介绍来学习动画中的内容：<a href="https://www.cnblogs.com/Finley/p/14467602.html">看动画轻松学会 Raft 算法 </a></p><h1 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>raft系统中各个成员有3种状态：<strong>leader, follower, or candidate</strong></p><p><img src="/2023/12/26/RaftPaperRead/serverState.jpg" alt="server state"></p><p>每一次开始选举leader到下一次为止都是一个term，一个term开始选举时也可能因为平分选票而导致选举leader失败，这样就会进入下一term的选举</p><p><img src="/2023/12/26/RaftPaperRead/term.jpg" alt="term"></p><p>服务器采用RPC进行通信，主要有两种信息：</p><ol><li><strong>RequestVote</strong>，选举投票</li><li><strong>AppendEntries</strong>，复制日志条目（也当做心跳使用）</li></ol><h2 id="leader选举"><a href="#leader选举" class="headerlink" title="leader选举"></a>leader选举</h2><p>每一个服务器在一定范围内随机生成一个等待时间，如果在该时间内没有收到leader的心跳，那么就认为leader下线了，就给自己的term+1，然后发起投票，希望自己成为leader。所以这也就需要保证让等待时间大于心跳信息发送的间隔时间。</p><p>服务器发起投票后有以下3种结果：</p><ol><li>获得包括自己在内超过所有服务器半数的投票，自己成为leader</li><li>收到其他term&gt;&#x3D;自己的leader的信息，说明已经有leader了，自己变为follower</li><li>由于平分选票，谁都不能成为leader，再次等待随机时间后，再发起一轮投票</li></ol><p>为了防止选举到的leader没有全部的commit的日志，规定：</p><ol><li>发起投票的服务器如果没有自己拥有的日志新，则不给它投票。因为已经commit的日志肯定在超过半数的服务器上有留存，那么一个没有全部commit的日志的服务器就必然不能拿到超过半数的同意票。</li><li>新leader上台时，不会去尝试复制旧的日志，然后提交，它只会去专注于提交新的日志，并在将新的日志复制给了大半的服务器后，将之前所有的可能没提交的一并提交。这样子就避免了下图中(d)可能出现的错误情况。</li></ol><p><img src="/2023/12/26/RaftPaperRead/errorStatus.jpg" alt="errorStatus"></p><h2 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h2><p>leader会接收用户发来的请求，并生成日志，然后将日志发送给各个follower，如果有包括自己在内超一半的服务器拥有了改日志，就将日志（也包含之前可能未提交的日志）commit，然后返回给用户执行结果。</p><p>raft还通过以下特性来保持日志的一致性：</p><ol><li>相同term相同index的日志内容相同</li><li>如果两个服务器某处日志的term和index都相同，那么他们之前的所有日志也相同</li></ol><p>第一条的保证是来自于每个leader创建了日志之后不会再修改。<br>第二条的保证使用的是归纳法的思想，每次发送的AppendEntries都包含前一个日志的信息，必须要前一个日志信息相同才可以接受，否则就拒绝，然后leader会不断尝试依次递减发送上一个日志（leader会为每一个follower维护一个nextIndex，代表其需要发送的日志id），直到找到相同的为止，然后将往后的日志都发送过去。当然这部分匹配可以进行优化。</p><p>各个主机上的log条目可能千奇百怪，但是注意到只有超过一半的服务器拥有的日志才是可能提交的日志，才需要永久性保存，其他都是没有提交的日志，可以进行删除更新即可分析清楚。</p><p><img src="/2023/12/26/RaftPaperRead/possibleLogStatus.jpg" alt="possible Log Status"></p><h2 id="成员变更"><a href="#成员变更" class="headerlink" title="成员变更"></a>成员变更</h2><p>当集群中成员需要进行改变的，一个方式是停掉集群，然后各自修改配置，这时安全的，但是会导致部分时间集群服务不可用。另一种方法是在线修改，但是直接的在线修改可能会导致如下的问题，即加入server4、5之后，由于部分主机1，,还不知道，所以会导致出现两个leader。</p><p><img src="/2023/12/26/RaftPaperRead/errorMemberChange.jpg" alt="errorMemberChange"></p><p>Raft提出的解决方案是采用两阶段的方法执行成员变更。</p><p>首先集群配置进行更新的时候，会将原本的配置Cold和新配置Cnew联合起来形成Cold，new，leader会将其复制给原本记录的其他人，一旦服务器收到了，就会把最新的配置设置为当前使用的，提交必须要要保证new和old中都有过半的服务器被使用了，然后再将Cnew复制给其他new中的服务器，一旦Cnew也被过半的new中的服务器收到了，就提交，然后整体配置就转为了Cnew。如下图所示，就避免了Cold和Cnew都能同时做决策的情况。</p><p><img src="/2023/12/26/RaftPaperRead/changeConfigure.jpg" alt="changeConfigure"></p><p>但是仍然还有几个问题需要解决：</p><ol><li>新加入的服务器难以快速跟上进度。Raft将其先作为非投票的成为加入到集群中，赶上后再转为正常。</li><li>leader可能不是new中的一部分。在Cnew提交后再进行将leader下线，所以在前面一段时间，其实leader在管理不属于他的集群。</li><li>不在Cnew被删除的服务器可能会影响集群可用性，因为他们不会再收到心跳，然后就会不断发起投票。Raft的解决办法是如果服务器认为leader还存在，即还没有等待超时，就会忽略投票请求，不会更新其term和给他投票。</li></ol><h2 id="日志压缩"><a href="#日志压缩" class="headerlink" title="日志压缩"></a>日志压缩</h2><p>长时间的运行会导致日志的堆积，可以通过生成快照将状态拷贝下来，然后再将不需要的日志删除，如下图所示。</p><p><img src="/2023/12/26/RaftPaperRead/snapshot.jpg" alt="snapshot"></p><p>注意快照需要包含最后一个日志的信息，以让下一个日志生成的时候进行检查。</p><p>每个服务器独立进行快照生成，而不是由leader统一生成和发送，这是为了降低网络带宽消耗，降低系统复杂度。</p><p>新加入的服务器，或者特殊情况下的follower可能会需要leader将快照整个发送给它来初始化状态，follower在接收到到快照后会把快照最后一项之前的所有log删除。</p><p>此外还需要注意快照生成的频率，简单的方法是快照到一定大小后就进行生成。还需要避免写入快照对系统的影响，这可以通过写时复制的方法进行支持。</p><h2 id="客户交互"><a href="#客户交互" class="headerlink" title="客户交互"></a>客户交互</h2><p>客户端启动时，随机选择服务器，如果不是leader，该服务器会返回相关信息来帮助客户找到leader。如果leader宕机，客户请求会超时，然后再次尝试随机选择服务器来连接。</p><p>我们希望提供线性语义，但是raft实际上可能一个操作执行多次，例如leader在提交了之后马上宕机，然后没来得及返回给用户，然后用户可能会再次发送该请求，导致其二次执行。解决方法是让客户的每个请求都分配一个序号，如果接收到已经执行过的序号，就理解响应但是忽略执行。</p><p>对于只读操作，如果返回请求的leader马上被其他服务器替换，那么就面临返回过时信息的问题。所以raft需要保证新上台的leader知道哪些是已经执行了的，所以新上台的leader需要提交一个无操作的条目，来同步。raft也让leader在处理只读请求时与大多数成员交换心跳信息来处理此问题。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><a href="https://raft.github.io/">https://raft.github.io/</a></li><li><a href="https://raft.github.io/raft.pdf">https://raft.github.io/raft.pdf</a></li><li><a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/lecture-06-raft1">https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/lecture-06-raft1</a></li><li><a href="https://willzhuang.github.io/2018/03/04/Raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/">https://willzhuang.github.io/2018/03/04/Raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/</a></li><li><a href="https://thesecretlivesofdata.com/raft/">https://thesecretlivesofdata.com/raft/</a></li><li><a href="https://www.cnblogs.com/Finley/p/14467602.html">https://www.cnblogs.com/Finley/p/14467602.html</a></li><li><a href="https://acehi.github.io/thesecretlivesofdata-cn/raft/">https://acehi.github.io/thesecretlivesofdata-cn/raft/</a></li><li><a href="https://zhuanlan.zhihu.com/p/32052223">https://zhuanlan.zhihu.com/p/32052223</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>MIT6.824</category>
      
      <category>论文</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
      <tag>MIT6.824</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文阅读】The Design of a Practical System for Fault-Tolerant Virtual Machines</title>
    <link href="/2023/12/12/Fault-TolerantVirtualMachinesPaperRead/"/>
    <url>/2023/12/12/Fault-TolerantVirtualMachinesPaperRead/</url>
    
    <content type="html"><![CDATA[<p><code>为了更有效的做论文阅读笔记，之后都打算将每篇论文笔记的内容控制在较少的字数范围内，毕竟原论文摆在那里，将其翻译照抄过来也没什么意思，将论文读薄才是最重要的。( •̀ ω •́ )✧</code></p><p>“The Design of a Practical System for Fault-Tolerant Virtual Machines”是MIT6.824推荐阅读的论文之一，它介绍了一种通过主备机制来进行单核虚拟机级别的容错方法。</p><h1 id="相关背景"><a href="#相关背景" class="headerlink" title="相关背景"></a>相关背景</h1><p>本文考虑的主要是fail-stop故障，例如电源线拔掉了，爆炸了，网络离线了等情况，而这也才能用复制的方法容错，普通的程序错误导致的故障也无法通过复制来解决。</p><p>容错一般有两种方法：</p><ol><li><strong>状态转移：</strong>拷贝主虚拟机的所有状态到另一个虚拟机上</li><li><strong>复制状态机：</strong>将虚拟机认为是一个状态机，只拷贝具体的操作</li></ol><p>明显复杂状态机对宽带要求更低，但是其设计更为复杂，本文采用的是复制状态机的方法。但是后面VMWare团队有推出多核虚拟机级别的容错，该方法采用的是类似状态转移的方法。</p><p>容错一般还可以分为应用层容错和主机层容错，<strong>本文是主机层</strong>，在这有容错的虚拟机上可以运行任何应用。</p><h1 id="设计概述"><a href="#设计概述" class="headerlink" title="设计概述"></a>设计概述</h1><p><img src="/2023/12/12/Fault-TolerantVirtualMachinesPaperRead/arc.jpg" alt="架构"></p><p>设计主要解决的问题是如何保证两个VM的状态一直保持一致。两个主副VM之间会通过Logging channel进行连接，主VM会将其<strong>任何会导致两者状态不一致的命令或者非确定性事件命令</strong>都通过Logging channel发送给副VM，副VM会读取该channel来执行相同的操作，但是该执行的输出会被忽略掉。</p><p>传递指令需要特别注意的是一些<strong>非确定性事件</strong>，该事件主要有两类分别是随时到达的<strong>客户端输入</strong>和在不同时刻不同的VM上会产生不同的结果的<strong>怪异指令</strong>，例如生成随机数、获取当前时间、获取主机id等。</p><pre><code class="hljs">非确定性事件还包括CPU并发，因为指令交织的顺序难以保证，例如两个并发的线程同时向一块数据加锁，那么主副VM上哪个线程能拿到锁其实是不确定的，但是本文是针对单CPU的，没有提及这个问题</code></pre><p>可以猜测传递的日志中主要有三样东西：</p><ol><li><strong>事件发生时的指令序号</strong>，即自机器启动以来指令的相对序号</li><li><strong>日志类型</strong></li><li><strong>数据</strong>，如果是网络数据包日志，那么就包含对应的数据，如果是怪异指令，那么就是其在主虚拟机上执行的结果</li></ol><p>需要注意的是为了保证副VM的执行不会超过主VM，副VM只有的channel里面有指令的时候才会继续运行，即<strong>副VM永远会落后主VM一个指令</strong>，不然就会一直停止等待，或者检测到主VM挂了，自己上台当主VM</p><h1 id="输出控制"><a href="#输出控制" class="headerlink" title="输出控制"></a>输出控制</h1><p>系统通过网络数据包来与用户进行交互，文章的目标是让用户接收到返回信息时该指令一定是在两个VM上都能执行了的，它避免的是如下的场景：</p><ul><li>主虚拟机给了用户返回，但是由于其马上crash了，没有将指令及时传给副VM，那么后面通过副VM上台时，该命令其实是没执行的，但是用户会以为其已经执行了</li></ul><p><img src="/2023/12/12/Fault-TolerantVirtualMachinesPaperRead/output.jpg" alt="输出控制"></p><p>解决方法是：<strong>主VM输出返回必须要在发送了日志且副VM返回了确认接收之后</strong></p><p>当然这也有可能会导致重复输出，因为主VM输出后马上奔溃，而副VM上台后还没有执行这个命令，那么后面再执行时就会导致重复输出，而文中提到由于有TCP的规则在，由于输出的是完全一致的数据包，该重复输出会被TCP的协议解决掉。</p><h1 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h1><p>主副VM之间需要知道对方有没有存活，文中使用了UDP心跳来检测服务器是否奔溃，此外也通过监控日志流量（因为定时器中断的存在，日志流量应该是有规律的）来探查，如果超过特点时间，就可能发生故障了，但是这依然会存在<strong>脑裂</strong>的问题，如果只是两个VM之间的网络出问题了，那么副VM如果这时上台就会出现两个主VM。文中采用的解决方案是通过<strong>Test-and-Set</strong>方案，它会在共享存储中执行一个原子性的测试设置操作。如果操作成功，VM就会被允许上线，如果不成功就说明另外一个还在运行。如果采用的不是共享存储，那么也会引入一个第三方的决策者来进行判断。</p><p>如果是副VM奔溃了，则会重新起一个副VM，该VM来自对主VM的完全拷贝。</p><p>同时为了保证容错的副VM上台后，不会需要太长时间才能把剩余的命令消费掉，已经为了防止channel的缓冲区被填满，<strong>副VM会和主VM保持一定的指令数间隔</strong>，文中提到执行延迟应不小于100ms，如果副VM跟不上主VM的处理速度，系统会分配给主VM更少的Cpu周期数来平衡两者的速度。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://pdos.csail.mit.edu/6.824/papers/vm-ft.pdf">https://pdos.csail.mit.edu/6.824/papers/vm-ft.pdf</a></li><li><a href="https://zhuanlan.zhihu.com/p/523109983">https://zhuanlan.zhihu.com/p/523109983</a></li><li><a href="https://pdos.csail.mit.edu/6.824/notes/l-vm-ft.txt">https://pdos.csail.mit.edu/6.824/notes/l-vm-ft.txt</a></li><li><a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/lecture-04-vmware-ft">https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/lecture-04-vmware-ft</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>MIT6.824</category>
      
      <category>论文</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
      <tag>MIT6.824</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文阅读】The Google file System</title>
    <link href="/2023/12/05/TheGoogleFileSystemPaperRead/"/>
    <url>/2023/12/05/TheGoogleFileSystemPaperRead/</url>
    
    <content type="html"><![CDATA[<p>The Google file System论文是MIT6.824中推荐阅读的论文，他是Google早期的三大论文之一，由于课程并不需要实现这个系统，所以就对整部论文中的关键点进行介绍总结。</p><h1 id="相关背景"><a href="#相关背景" class="headerlink" title="相关背景"></a>相关背景</h1><p>为了满足Google快速增长的数据处理需求，Google需要自己构建一套文件系统——The Google file System(GFS)。而这套文件系统也必须是分布式的文件系统才足以满足要求，但是我们都知道这面临着很多困难：</p><ul><li>分布式的文件系统会使用大量的主机，而这会使得主机出错成为常态</li><li>为了解决时不时的一部分主机出错带来的影响，我们需要对文件进行拷贝放置到多个主机上</li><li>一旦文件有多份，我们就需要就其产生的一致性问题进行解决</li><li>而保证一致性就又会导致系统的低性能</li><li>一致性和低性能的取舍一直是一个研究的重点问题</li></ul><p>GFS就在解决上述问题，同时他也着重于解决自己场景下的问题，其设计的特点如下：</p><ul><li>故障设备经常发生</li><li>文件比传统标准更大，数GB大小的文件是十分常见的</li><li>系统负载主要来自两种读操作：大规模的流式读取和小规模的随机读取</li><li>系统负载还来自很多对文件的大规模追加写入</li><li>同时设计应用程序和文件系统API便于提高整个系统的灵活性</li></ul><h1 id="设计概述"><a href="#设计概述" class="headerlink" title="设计概述"></a>设计概述</h1><p><img src="/2023/12/05/TheGoogleFileSystemPaperRead/GFSarch.png" alt="图1 GFS架构"></p><p>如图1所示，一个GFS集群包括单个master（主服务器）和多个chunkserver（块服务器），并被多个client（客户端）访问。每个节点通常为一个运行着用户级服务进程的Linux主机。</p><h2 id="chunk"><a href="#chunk" class="headerlink" title="chunk"></a>chunk</h2><p>文件被划分为若干个64MB大小的chunk（块）。每个chunk被一个不可变的全局唯一的64位chunk handle（块标识符）唯一标识，chunk handle在chunk被创建时由主节点分配。chunkserver将chunk作为Linux文件存储到本地磁盘中，通过chunk handle和byte range（字节范围）来确定需要被读写的chunk和chunk中的数据。为了可靠性考虑，每个chunk会在多个chunkserver中有副本。默认存储三份副本，用户也可以为不同的命名空间的域指定不同的副本级别。</p><p>64MB大小的chunk其实并没有带来内部碎片，因为每个chunk的副本被作为普通的Linux文件存储在chunkserver上，linux文件上是以几KB为单位进行存储空间分配的，其仅在需要时扩展。懒式空间分配（lazy space allocation）避免了内部碎片（internal fragmentation）带来的空间浪费。</p><p>同时一个较大的chunk带来了以下的优势：</p><ol><li>减少了client与master交互的次数，</li><li>使得client可以在一个chunk上执行更多的操作</li><li>减小了master中存储的云数据的大小</li></ol><p>需要注意的是如果多个client访问同一个文件，那么存储这这些文件的chunkserver会成为hot spot（热点）。但是因为应用程序大部分都顺序地读取包含很多chunk的大文件，所以hot spot不是主要问题。而如果出现这个问题，一个潜在的长期解决方案是在让client在这种场景下从其他client读取数据。</p><h2 id="master"><a href="#master" class="headerlink" title="master"></a>master</h2><p>master维护系统所有的元数据。元数据包括命名空间（namespace）、访问控制（access control）信息、文件到chunk的映射和chunk当前的位置。master还控制系统级活动如chunk租约（chunk lease）管理、孤儿chunk垃圾回收（garbage collection of orphaned chunks）和chunkserver间的chunk迁移（migration）。master周期性地通过心跳（HeartBeat）消息与每个chunkserver通信，向其下达指令并采集其状态信息。</p><p>文件和块的命名空间、文件到chunk的映射这两种类型还通过将变更记录到一个操作日志（operation log）的方式持久化存储在master的磁盘上。具体来说需要将操作日志备份到多台远程主机上，且只有当当前操作记录条目被本地和远程主机均写入到了磁盘后才能向客户端发出响应。master会在操作记录被写入前批量合并一些操作记录来减少写入和备份操作对整个系统吞吐量的影响。master会对其状态创建一个检查点（checkpoint），这样master就可以从磁盘加载最后一个检查点并重放该检查点后的日志来恢复状态。因为创建一个检查点需要一段时间，所以master被设计为可以在不推迟新到来的变更的情况下创建检查点。创建检查点时，master会切换到一个新的日志文件并在一个独立的线程中创建检查点，这个新的检查点包含了在切换前的所有变更。</p><p>master不会持久化存储chunk的位置信息，而是在启动时和当chunkserver加入集群时向chunkserver询问其存储的chunk信息。这样相比于持久化，消除了当chunkserver加入或离开集群、更改名称、故障、重启等问题时，保持master和chunkserver同步的问题。</p><h2 id="chunk-server"><a href="#chunk-server" class="headerlink" title="chunk server"></a>chunk server</h2><p>chunk副本分配到chunk server策略有两个目标：最大化数据<strong>可靠性</strong>和<strong>可用性</strong>、<strong>最大化网络带宽利用</strong>。对于这两个目标，仅将副本分散在所有机器上是不够的，这样做只保证了容忍磁盘或机器故障且只充分利用了每台机器的网络带宽。我们必须<strong>在机架间分散chunk的副本</strong>。这样可以保证在一整个机架都被损坏或离线时（例如，由交换机、电源电路等共享资源问题引起的故障），chunk的一些副本仍存在并保持可用状态。除此之外，这样还使对chunk的流量（特别是读流量）<strong>能够充分利用多个机架的总带宽</strong>。而另一方面，其代价就是<strong>写流量必须流经多个机架</strong>，导致一定程度的速度损耗。</p><p>chunk副本的创建可能由三个原因引起：chunk创建、重做副本（re-replication）和重均衡（rebalance）。</p><p><strong>chunk创建</strong>时，选择chunk server主要需要考虑以下因素：</p><ol><li>希望在磁盘利用率低于平均值的chunkserver上放置副本，以平衡chunkserver间的磁盘利用率</li><li>希望限制每台chunkserver上最近创建的chunk的数量。尽管创建chunk本身开销很小，但由于创建后一般会接着马上大量写，所以需要平衡限制写入流量</li><li>希望将chunk的副本跨机架分散。</li></ol><p><strong>重做副本</strong>一般是因为chunk被损坏了或者chunk server不可用了，或者目标副本数增加了，重做副本需要有优先级：</p><ol><li>当前chunk副本数与目标副本数之差越大优先级就越高</li><li>更倾向于优先为还存在的文件的chunk重做副本，而不是优先为最近被删除的文件重做。</li><li>为了最小化故障对正在运行的应用程序的影响，我们提高了所有正在阻塞client进程的chunk的优先级。</li></ol><p>重做副本选择chunk server所考虑的因素与chunk 创建一样，但是为了防止克隆操作的流量远高于client流量的情况发生，master需要对整个集群中活动的克隆操作数和每个chunkserver上活动的<strong>克隆操作数进行限制</strong>。除此之外，在克隆操作中，每个chunkserver还会<strong>限制对源chunkserver的读请求</strong>，以限制每个克隆操作占用的总带宽。</p><p>每隔一段时间master会对副本进行<strong>重均衡</strong>：master会检测当前的副本分布并移动副本位置，使磁盘空间和负载更加均衡。同样，在这个过程中，master会逐渐填充一个新的chunkserver，而不会立刻让来自新chunk的高负荷的写入流量压垮新的chunkserver。新副本放置位置的选择方法与上文中讨论过的类似。此外，master必须删除一个已有副本。通常，master会选择删除空闲磁盘空间低于平均的chunkserver上的副本，以均衡磁盘空间的使用。</p><h2 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h2><p>被链接到应用程序中的GFS client的代码实现了文件系统API并与master和chunkserver通信，代表应用程序来读写数据。</p><p>GFS支持如创建（create）、删除（delete）、打开（open）、关闭（close）、读（read）、写（write）文件等常用操作。此外，GFS还支持快照（snapshot）和追加记录（record append）操作。</p><h2 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h2><p>在文件被删除后，GFS不会立刻回收可用的物理存储空间。master仅在周期性执行懒式垃圾回收时回收物理存储空间，其中垃圾回收分为文件级垃圾回收和chunk级垃圾回收。</p><h3 id="文件级垃圾回收"><a href="#文件级垃圾回收" class="headerlink" title="文件级垃圾回收"></a>文件级垃圾回收</h3><p>当一个文件被应用程序删除时，master会像执行其他操作时一样立刻将删除操作写入日志。但是master不会立刻对资源进行回收，而是将待删除的文件重命名为一个带有删除时间戳的隐藏文件名。当master周期性地扫描文件系统命名空间时，它会删除已经存在超过三天（用户可以配置这个间隔时间）的这种隐藏文件。在文件被彻底删除之前，仍可通过该文件被重命名后的特殊的新文件名对其进行访问，也可以通过将其重命名为正常文件的方式撤销删除。当隐藏文件被从命名空间中移除时，其在内存中的元数据也会被删除。这种方式可以有效地切断文件和其对应的chunk的链接。</p><h3 id="chunk级垃圾回收"><a href="#chunk级垃圾回收" class="headerlink" title="chunk级垃圾回收"></a>chunk级垃圾回收</h3><p>chunk成为无法被任何文件访问到的孤儿chunk的原因可能是chunk的创建可能仅在部分chunkserver上成功而在其他chunkserver上失败，或者chunk在进行删除时某些chunk server没有收到相应的消息。</p><p>在进行chunk级垃圾回收时，master会周期性扫描chunk命名空间，并找出孤儿chunk，删除这些chunk的元数据。在chunkserver周期性地与master进行心跳消息交换时，chunkserver会报告其拥有的chunk的子集，而master会回复这些chunk中元数据已经不存在的chunk的标识。chunkserver可以自由地删除这些元数据已经不存在的chunk的副本。</p><p>该垃圾回收机制的优点：</p><ol><li>这种方法在设备经常出现故障的大规模可伸缩分布式系统中非常简单可靠。chunk的创建可能仅在部分chunkserver上成功而在其他chunkserver上失败，这样会导致系统中出现master不知道的副本。且副本删除消息可能会丢失，这样master在其自身和chunkserver故障时都必须重新发送该消息。垃圾回收机制为清理那些不知道是否有用的副本提供了一个统一且可靠的方法。</li><li>垃圾回收机制将对存储空间的回收操作合并为master的后台活动，如周期性扫描命名空间和周期性地与chunkserver握手。因此，垃圾回收机制可以分批回收存储空间并平摊回收的开销。另外，垃圾回收仅在master相对空闲时执行。这样，master可以更迅速的相应需要及时响应的来自client的请求。</li><li>延迟回收存储空间可以防止意外的不可逆删除操作。</li></ol><p>该垃圾回收机制的缺点：</p><ol><li>当用户存储空间紧张时，延迟回收会让用户难以释放存储空间。</li><li>快速创建并删除临时文件的应用程序可能无法立刻重用存储空间。</li></ol><p>为了解决这个问题，用户可以再次显示删除已删除文件时，加快了对存储空间的回收。同时，允许用户对不同的命名空间应用不同的副本与回收策略。例如，用户可以指定某个目录树下的所有文件都不需要副本，且当这个目录树下的文件被删除时立刻且无法撤销地将其从文件系统中移除。</p><h1 id="读操作"><a href="#读操作" class="headerlink" title="读操作"></a>读操作</h1><p>如图1所示，具体读操作在流程如下：</p><ol><li>client会将读取的文件名，读取的是第几个chunk发送给master</li><li>master返回给client该chunk的chunk handle以及其所在的所有chunkserver</li><li>client接收信息，并进行缓存，然后选择距离其最近的chunkserver（可以直接通过ip规律决定）来发起询问，请求对应chunk handle中byte范围的内容</li><li>被询问的chunkserver根据自己保存的chunk handle与具体linux文件的对应关系来读取文件（实际应该就是以chunk handle命名的文件），并返回对应的内容</li><li>client获取到对应的内容，如果还需要接着读取，可以依据缓存信息直接向client发起读取请求</li></ol><h1 id="写操作"><a href="#写操作" class="headerlink" title="写操作"></a>写操作</h1><p><img src="/2023/12/05/TheGoogleFileSystemPaperRead/write.png" alt="图2 写操作"></p><h2 id="租约"><a href="#租约" class="headerlink" title="租约"></a>租约</h2><p>虽然每个chunk有多个副本，但是为了保证副本间变更的一致性，master向其中一份副本授权一个变更的租约，称这个副本为primary（有时也可代指primary副本所在的chunkserver），其余的副本称为Secondary。租约的时间为60秒。然而，一旦chunk被变更，primary就可以向master请求延长租约时间，或者（通常为）接受来自master的租约时间延长操作。这些租约延长请求和租约授权请求依赖master与chunkserver间周期性地心跳消息来实现。即使master与一个primary的通信丢失，master仍可以在旧租约过期后安全地向另一个副本授权新的租约，以此来避免同时产生多个primary。</p><h2 id="数据流"><a href="#数据流" class="headerlink" title="数据流"></a>数据流</h2><p>在进行写时，需要将数据传递给每个chunk server，为了高效地利用网络，其对数据流与控制流进行了解耦。为了充分利用机器的网络带宽，数据会沿着chunkserver链线性地推送。假设client正准备将数据推送给S1~S4。client会将数据发送给最近的chunkserver，比如S1。S1会将数据传递给S2至S4中离它最近的chunkserver，比如S2。同样，S2会将数据传递给S3至S4中离它最近的chunkserver，以此类推。由于其网络拓扑非常简单，所以可以通过IP地址来准确地估算出网络拓扑中的“距离”。</p><p>当chunkserver收到一部分数据时，它会立刻开始将数据传递给其他chunkserver。因为我们使用全双工的交换网络，所以流水线可以大幅减少时延。发送数据不会减少接受数据的速度。如果没有网络拥塞，理论上将$B$个字节传输给$R$个副本所需的时间为$B&#x2F;T+RL$，其中$T$是网络的吞吐量，$L$是两台机器间的传输时延。通常，我们的网络连接吐吞量$T$为$100Mbps$，传输时延$L$远小于$1ms$。</p><h2 id="写流程"><a href="#写流程" class="headerlink" title="写流程"></a>写流程</h2><p>如图2所示，写流程如下：</p><ol><li>client向master询问哪个chunkserver持有指定chunk的租约及该chunk的其他副本的位置。如果没有chunkserver持有租约，那么master会选择一个副本对其授权（这一步在图中没有展示）</li><li>master回复primary副本的标识符和其他副本（也称secondary）的位置。client也对其进行缓存</li><li>client将数据通过数据流的方式推送到所有副本</li><li>一旦所有副本都确认收到了数据，client会向primary发送一个write请求。primary会为其收到的所有的变更（可能来自多个client）分配连续的编号，这一步提供了重要的顺序。primary对在本地按照该顺序应用变更</li><li>primary将write请求继续传递给其他secondary副本。每个secondary副本都按照primary分配的顺序来应用变更。</li><li>所有的secondary副本通知primary其完成了变更操作。</li><li>primary回复client。任意副本遇到的任何错误都会被报告给client。即使错误发生，write操作可能已经在primary或secondary的任意子集中被成功执行。（如果错误在primary中发生，那么操作将不会被分配顺序，也不会被继续下发到其他副本。）只要错误发生，该请求都会被认为是失败的，且被修改的区域的状态为inconsistent。client中的代码会通过重试失败的变更来处理这种错误。首先它会重试几次步骤（3）到步骤（7），如果还没有成功，再从write请求的初始操作开始重试。成功后该区域会被修正为consistent状态</li></ol><p>如果应用程序发出的一次write请求过大或跨多个chunk，GFS的client代码会将其拆分成多个write操作。拆分后的write请求都按照上文中的控制流执行，但是可能存在与其他client的并发的请求交叉或被其他client的并发请求覆盖的情况。因此，共享的文件区域最终可能包含来自不同client的片段。但共享的文件区域中的内容最终是相同的，因为每个操作在所有副本上都会以相同的顺序被成功执行。</p><h2 id="原子性record-append"><a href="#原子性record-append" class="headerlink" title="原子性record append"></a>原子性record append</h2><p>在传统的write操作中，client会指定数据写入的偏移量。然而在record append中，client仅需指定待追加的数据。GFS会为其选择一个偏移量，在该偏移量处至少一次地原子性地将数据作为一个连续的字节序列追加到文件，并将该偏移量返回给client。</p><p>record append被大量应用在的有多个来自不同机器的client向同一个文件并发append数据的分布式应用程序中。如果通过传统的write操作，那么client还需要额外的复杂且开销很高的同步操作（例如分布式锁管理）。</p><p>record append仅在primary端稍有点额外的逻辑。在client将数据推送到文件中最后一个chunk的所有chunk server之后，client会向primary发送一个请求。primary会检查当新记录追加到该chunk之后，是否会导致该chunk超过其最大大小限制（64MB）。如果会超，primary会将该chunk填充到最大的大小，并通知secondary也做相同的填充操作，再回复客户端，使其在下一个chunk上重试该操作。record append操作限制了每次最多写入最大chunk大小的四分之一的数据，以保证在最坏的情况下产生的碎片在可接受的范围内。在一般情况下，添加的记录大小都在不会超过chunk的最大限制，这样primary会向数据追加到它的副本中，并通知secondary在与其追加的偏移量相同的位置处写入数据，并将最终成功操作的结果返回给client。</p><p>如果record append操作在任何一个副本中失败，就会返回失败，使得client会重试操作。这样会导致同一个chunk的<strong>不同副本中可能包含不同的数据</strong>，这些数据可能是同一条记录的部分或完整的副本。GFS不保证所有副本在字节级别一致，其只保证record append的数据<strong>作为一个单元被原子性地至少写入一次</strong>。这一点很容易证明，因为数据必须在某个chunk的所有副本的相同偏移位置处写入。此外，在record append之后，每个副本都至少与最后一条记录一样长。这样，任何未来的新记录都会被分配到一个更高的偏移位置或者一个新chunk，即使另一个副本成为了primary也能保证这个性质。这样，被record append操作<strong>成功写入的区域</strong>在一致性方面都将是<strong>defined状态</strong>（因此也是consistent的），而这些<strong>defined区域间的文件区域是inconsistent的（因此也是undefined的）</strong>。我们应用程序会通过章节2.7.2中讨论的方式处理inconsistent的区域。</p><h2 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h2><p><img src="/2023/12/05/TheGoogleFileSystemPaperRead/consistent.jpg" alt="图3 一致性"></p><p><strong>一致性：</strong>一个文件区域的任意一个副本被任何client读取总能得到相同的数据<br><strong>确定性：</strong>client总能读取到其写入的信息</p><p>在没有并发的情况下写入成功时，写入的内容是一致且确定的<br>在有并发的情况下写入成功时，写入的内容是一致但非确定的，因为写入的内容可能混合了多个请求</p><p>写入操作操作可能为write或record append，其中对于record append，GFS可能会在记录的中间插入填充（padding）和或重复的记录。它们占用的区域状态为inconsistent的，通常情况下，它们的数量远少于用户数据。</p><p>GFS会保证被写入成功的的区域各个副本都是一致的，主要通过以下手段：</p><ol><li>chunk执行变更时，其所有副本按照相同的顺序应用变更</li><li>使用chunk版本号（chunk version）来检测因chunkserver宕机而错过了变更的陈旧的chunk副本。陈旧的chunk副本永远不会在执行变更时被使用，也不会在master返回client请求的chunk的位置时被使用。它们会尽早地被作为垃圾回收。</li><li>即使在变更被成功应用的很长时间后，设备故障仍然可以损坏（corrupt）会销毁（destroy）数据。GFS通过master和所有chunkserver周期性握手的方式来确定故障的chunkserver，并通过校验和（checksunmming）的方式检测数据损坏。一旦出现问题，数据会尽快地从一个合法的副本恢复。一个chunk只有在GFS作出反应前（通常在几分钟内）失去了所有的副本，chunk才会不可逆地丢失。即使在这种情况下，chunk也仅变得不可用而非返回错误的数据。</li></ol><h3 id="应用程序影响"><a href="#应用程序影响" class="headerlink" title="应用程序影响"></a>应用程序影响</h3><p>GFS应用程序可以通过一些简单的技术来使用其宽松的一致性模型，且这些技术已经因其他目标而被使用。</p><p>在实际使用中，我们所有的应用程序都通过append而不是overwrite的方式对文件进行变更。其中一个典型的引用场景是：一个write从头到尾地生成一个文件。它会周期性地为已经写入的文件数据创建检查点，并在所有数据都被写入文件后自动将其重命名为一个永久的文件名。检查点可能包含应用程序级别的校验和。reader会验证文件仅处理跟上最新的检查点的文件区域，这些区域的状态一定的“defined”的。尽管这种方法有一致性和并发问题，它仍很好地满足了我们的需求。append的效率远高于随机写入，且在应用程序故障时更容易恢复。检查点机制允许writer在重启时增量写入，并能够防止reader处理那些虽然已经被成功写入文件但是从应用程序的角度看仍然不完整的文件数据。</p><p>另一种典型的用途是，许多write并发地向同一个文件append数据以获得合并后的结果或文件作为生产者-消费者队列使用。record append的“至少一次追加（append-at-least-once）”语义保证了每个write的输出。</p><p>而reader偶尔需要<strong>处理填充和重复的数据</strong>。每条被writer准备好的记录包含如校验和的额外信息，这样，记录的合法性就可被校验。一个reader通过校验和来识别并丢弃额外的填充和记录。如果rearder无法容忍偶尔发生的重复（如果重复的记录可能触发非幂等（non-idempotent）运算），它可以使用记录中的唯一标识符来对齐进行过滤。通常，在命名应用程序相关的实体时（如web文档），总会使用唯一的标识符。这些记录I &#x2F; O (除去重复)的功能在我们的应用程序共享的库代码中，并适用于Google的其他文件接口实现。通过这些库，带有极少的重复的记录，总会被以相同顺序交付给reader。</p><h1 id="容错处理"><a href="#容错处理" class="headerlink" title="容错处理"></a>容错处理</h1><h2 id="chunk副本"><a href="#chunk副本" class="headerlink" title="chunk副本"></a>chunk副本</h2><p>每个chunk会在不同机架的多个chunkserver上存有副本。用户可以为不同命名空间的文件制定不同的副本级别。副本级别默认为3。当有chunkserver脱机或通过校验和检测到损坏的副本时，master根据需求克隆现有的副本以保证每个chunk的副本数都是饱和的。</p><h2 id="master副本"><a href="#master副本" class="headerlink" title="master副本"></a>master副本</h2><p>master的状态同样有副本，master的操作日志和检查点被<strong>在多台机器上复制</strong>。只有当变更在被日志记录并被写入，master本地和所有master副本的磁盘中后，这个变更才被认为是已提交的。为了简单起见，一个master进程既要负责处理所有变更又要负责处理后台活动，如垃圾回收等从内部改变系统的活动。当master故障时，其几乎可以立刻重启。如果运行master进程的机器故障或其磁盘故障，在GFS之外的负责监控的基础架构会在其它持有master的操作日志副本的机器上启动一个新的master进程。client仅通过一个规范的命名来访问master结点（例如gfs-test），这个规范的命名是一个DNS别名，其可以在master重新被分配到另一台机器时被修改为目标机器。</p><p>此外，“影子”master节点（“shadow” master）<strong>可以提供只读的文件系统访问</strong>，即使在主master结点脱机时它们也可以提供服务。因为这些服务器可能稍稍滞后于主master服务器（通常滞后几分之一秒），所以这些服务器是影子服务器而非镜像服务器。这些影子master服务器增强了那些非正在被变更的文件和不介意读到稍旧数据的应用程序的可用性。实际上，由于文件内容是从chunkserver上读取的，所以应用程序不会读取到陈旧的文件内容。能够在一个很短的时间窗口内被读取到的陈旧的数据只有文件元数据，如目录内容和访问控制信息。</p><p>为了让自己的元数据跟随主master变化，影子master服务器会持续读取不断增长的操作日志副本，并像主master一样按照相同的顺序对其数据结构应用变更。像主master一样，影子master服务器也会在启动时从chunkserver拉取数据来获取chunk副本的位置（启动后便很少拉取数据），并频繁地与chunkserver交换握手信息来监控它们的状态。<strong>只有因主master决定创建或删除副本时，影子master服务器上的副本位置才取决于主master服务器</strong>。</p><h2 id="数据完整性"><a href="#数据完整性" class="headerlink" title="数据完整性"></a>数据完整性</h2><p>每个chunkserver都<strong>使用校验和来检测存储的数据是否损坏</strong>。由于GFS集群通常在数百台机器上有数千chunk磁盘，所以集群中经常会出现磁盘故障，从而导致数据损坏或丢失。我们可以<strong>通过chunk的其他副本来修复损坏的chunk</strong>，但不能通过比较chunkserver间的副本来检测chunk是否损坏。除此之外，即使内容不同的副本中的数据也可能都是合法的：GFS中变更的语义（特别是前文中讨论过的record append）不会保证副本完全相同。因此，<strong>每个chunkserver必须能够通过维护校验和的方式独立的验证副本中数据的完整性</strong>。</p><p><strong>一个chunk被划分为64KB的block</strong>。<strong>每个block有其对应的32位校验和</strong>。就像其他元数据一样，校验和也在内存中保存且会被通过日志的方式<strong>持久化存储</strong>。校验和与用户数据是分开存储的。</p><p>对于读取操作，无论请求来自client还是其他chunkserver，<strong>chunkserver都会在返回任何数据前校验所有包含待读取数据的block的校验和</strong>。因此，chunkserver不会将损坏的数据传给其他机器。如果一个block中数据和记录中低的校验和不匹配，那么chunkserver会给请求者返回一个错误，<strong>并向master报告校验和不匹配</strong>。随后，请求者会从其他副本读取数据，<strong>而master会从该chunk的其他副本克隆这个chunk</strong>。当该chunk新的合法的副本被安置后，master会通知报告了校验和不匹配的chunkserver删除那份损坏的副本。</p><p>校验和对读取性能的影响很小。因为我们的大部分读操作至少会读跨几个block的内容，我们只需要读取并校验相对少量的额外数据。GFS客户端代码通过尝试将读取的数据与需要校验的block边界对其的方式，进一步地减小了校验开销。除此之外，chunkserver上校验和的查找与比较不需要I&#x2F;O操作，且校验和计算操作经常与其他操作在I&#x2F;O上重叠，因此几乎不存在额外的I&#x2F;O开销。</p><p>因为向chunk末尾append数据的操作在我们的工作负载中占主要地位，所以我们对这种写入场景的校验和计算做了大量优化。在<strong>append操作</strong>时，<strong>我们仅增量更新上一个block剩余部分的校验和，并为append的新block计算新校验和</strong>。即使最后一个block已经损坏且目前没被检测到，增量更新后的该block的新校验和也不会与block中存储的数据匹配。在下一次读取该block时，GFS会像往常一样检测到数据损坏。</p><p>相反，如果<strong>write操作</strong>覆盖了一个chunk已存在的范围，那么我们<strong>必须读取并验证这个范围的头一个和最后一个block</strong>，再执行write操作，最后计算并记录新的校验和。如果我们没有在写入前校验头一个和最后一个block，新的校验和可能会掩盖这两个block中没被覆写的区域中存在的数据损坏问题。因为写入会修改头一个和后一个block的部分内容，且会重新计算校验和，如果该内容以损坏，然后又重新计算了校验和，就会掩盖损坏内容。</p><p>chunkserver可以<strong>在空闲期间扫描并验证非活动的chunk的内容</strong>。这样可以让我们检测到很少被读取的chunk中的数据损坏。一旦检测到数据损坏，master可以创建一个新的未损坏的副本并删除损坏的副本。这样可以防止master将chunk的非活动的但是已损坏的副本识别成数据合法的副本。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>总体而言GFS提供了一个大规模分布式存储的一个良好的解决方案，也让我对分布式存储有了更深的影响，其中其数据流与控制流解耦，租约设计，弱一致性换取高性能，具体的分布式读写操作，分布式数据容错方案都给我留下了深刻的印象。</p><p>但是GFS也被提出具有一定的问题，其问题主要来自于master节点保存的内容过多，master节点的容错率不强等。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="http://research.google.com/archive/gfs.html">http://research.google.com/archive/gfs.html</a></li><li><a href="https://pdos.csail.mit.edu/6.824/schedule.html">https://pdos.csail.mit.edu/6.824/schedule.html</a></li><li><a href="https://blog.mrcroxx.com/posts/paper-reading/gfs-sosp2003/">https://blog.mrcroxx.com/posts/paper-reading/gfs-sosp2003/</a></li><li><a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/lecture-03-gfs/3.1">https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/lecture-03-gfs/3.1</a></li><li><a href="https://www.youtube.com/watch?v=WLad7CCexo8&ab_channel=BitTiger%E5%AE%98%E6%96%B9%E9%A2%91%E9%81%93BitTigerOfficialChannel">https://www.youtube.com/watch?v=WLad7CCexo8&ab_channel&#x3D;BitTiger%E5%AE%98%E6%96%B9%E9%A2%91%E9%81%93BitTigerOfficialChannel</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>MIT6.824</category>
      
      <category>论文</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
      <tag>MIT6.824</tag>
      
      <tag>论文阅读</tag>
      
      <tag>GFS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>IDEA远程开发选项丢失修复方法</title>
    <link href="/2023/12/01/IDEA%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91%E9%80%89%E9%A1%B9%E4%B8%A2%E5%A4%B1%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95/"/>
    <url>/2023/12/01/IDEA%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91%E9%80%89%E9%A1%B9%E4%B8%A2%E5%A4%B1%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p>今天打开IDEA发现远程开发选项没有了：</p><p><img src="/2023/12/01/IDEA%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91%E9%80%89%E9%A1%B9%E4%B8%A2%E5%A4%B1%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95/%E6%8D%9F%E5%9D%8F%E7%95%8C%E9%9D%A2.jpg" alt="损坏界面"></p><p>发现全网也没有什么提到过这个错误的，所有捣鼓了好久还进行了IDEA的重装也一直都没有解决，最后查看<a href="https://www.jetbrains.com/help/idea/2023.2/jetbrains-gateway.html#plugin_install">IDEA官方的介绍文档</a>才发现了问题所在：<strong>Remote Development Gateway插件被关闭了</strong></p><p>故而解决方法就是点击IDEA的设置选项卡，在插件(plugs)选项中重新勾选<code>Remote Development Gateway</code>来启用该插件即可</p><p><img src="/2023/12/01/IDEA%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91%E9%80%89%E9%A1%B9%E4%B8%A2%E5%A4%B1%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95.jpg" alt="解决方法"></p><p>点击启用后可以发现远程开发选项又回来了：</p><p><img src="/2023/12/01/IDEA%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91%E9%80%89%E9%A1%B9%E4%B8%A2%E5%A4%B1%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95/%E4%BF%AE%E5%A4%8D%E5%90%8E%E7%95%8C%E9%9D%A2.jpg" alt="修复后界面"></p><p>所以还是要多从官方的信息源找起啊</p>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
    <tags>
      
      <tag>IDEA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【MIT6.824】lab 1 MapReduce实现总结</title>
    <link href="/2023/11/22/MIT6-824lab1/"/>
    <url>/2023/11/22/MIT6-824lab1/</url>
    
    <content type="html"><![CDATA[<p>MIT6.824是一门经典的分布式课程，课程链接：<a href="https://pdos.csail.mit.edu/6.824/labs/lab-mr.html">https://pdos.csail.mit.edu/6.824/labs/lab-mr.html</a>，对于lab 1我们需要在提供的代码框架的基础上补充coordinator和worker的代码，以实现分布式的MapReduce程序。</p><p>本人在借鉴了部分其他人的设计思想的基础上，独立完成了所有的代码，最后设计的实现能够通过所有的测试脚本。</p><p>实现的代码厂库：<a href="https://github.com/slipegg/MIT6.824/tree/main/6.5840">https://github.com/slipegg/MIT6.824/tree/main/6.5840</a></p><h1 id="实现目标"><a href="#实现目标" class="headerlink" title="实现目标"></a>实现目标</h1><p>在给定的代码框架中实现一个单词计数的MapReduce程序。原本的框架中已经给了一个在本地串行执行单词计数的独立程序，并提供了一个通过UNIX-domain sockets实现的RPC(<a href="https://slipegg.github.io/2023/11/14/RPC%E4%BB%8B%E7%BB%8D/">RPC介绍</a>)，我们需要完成的部分有：</p><ol><li>设计coordinator和worker之间交流的流程和格式，以方便worker向coordinator申请任务，coordinator将taks发送给worker，worker把task的完成情况返回给coordinator</li><li>coordinator对Map类型的task和Reduce类型的task进行管理，需要初始化这些任务，需要记录任务完成的情况，并生成新的任务，直到全部完成</li><li>worker如何完成Map类型以及Reduce类型task</li></ol><h1 id="总体设计"><a href="#总体设计" class="headerlink" title="总体设计"></a>总体设计</h1><p><strong>worker</strong>会不断向coordinator发送心跳，申请任务，拿到任务后进行map或者renduce类型的task的执行，在执行完毕后发送请求给coordinator以表示该任务完成了。当coordinator告诉其所有任务都完成时，他会结束运行</p><p><strong>coordinator</strong>只维护task的状态不维护各个worker的状态。worker向其发送心跳申请任务时，coordinator会去遍历任务，取出还没有发送的任务或者过了太长时间都没有完成的任务返回回去，如果没有，就返回一个等待任务。coordinator接收到worker的某个任务完成的请求时会改变这个任务的状态，如果当前阶段所有的任务都完成了就转向下一个阶段，知道转到了所有MapReduce任务都完成的阶段。</p><p>整体流程如下图所示：</p><p><img src="/./MIT6-824lab1/MapReduce.png" alt="MapReduce流程"></p><h1 id="rpc信息传递设计"><a href="#rpc信息传递设计" class="headerlink" title="rpc信息传递设计"></a>rpc信息传递设计</h1><h2 id="Heartbeat"><a href="#Heartbeat" class="headerlink" title="Heartbeat"></a>Heartbeat</h2><p>worker通过rpc向coordinator发送心跳（Heartbeat）来申请任务。如下：</p><ul><li><p>关键结构体定义如下，HeartbeatRequest是个空结构，HeartbeatResponse承载了coordinator返回给worker的信息，这里的信息实际上是运行map类型和reduce类型的task所必须的信息的集合。所有的返回都需要JobType来标明其类型，需要id来标明其是哪个作业，<strong>对于map类型作业</strong>，其额外需要FilePath来获取任务的输入，还需要NReduce来决定输出的数量，<strong>对于reduce类型作业</strong>，其额外需要NMap来辅助获取map类型的中间输出。</p>  <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> HeartbeatRequest <span class="hljs-keyword">struct</span> &#123;<br>&#125;<br><br><span class="hljs-keyword">type</span> HeartbeatResponse <span class="hljs-keyword">struct</span> &#123;<br>    FilePath <span class="hljs-type">string</span><br>    JobType  JobType<br>    NReduce  <span class="hljs-type">int</span><br>    NMap     <span class="hljs-type">int</span><br>    Id       <span class="hljs-type">int</span><br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>调用请求如下，它会调用coordinator的heartbeat函数来处理，并将任务返回到response中。</p>  <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go">call(<span class="hljs-string">&quot;Coordinator.Heartbeat&quot;</span>, &amp;HeartbeatRequest&#123;&#125;, &amp;response)<br></code></pre></td></tr></table></figure></li></ul><h2 id="Report"><a href="#Report" class="headerlink" title="Report"></a>Report</h2><p>worker完成任务后通过rpc向coordinator发送回复。如下：</p><ul><li><p>关键结构体设计如下。ReportRequest通过phase和id来联合表示是哪个任务完成了。</p>  <figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">type</span> <span class="hljs-type">ReportRequest</span> struct &#123;<br>    <span class="hljs-type">Id</span>    int<br>    <span class="hljs-type">Phase</span> <span class="hljs-type">SchedulePhase</span><br>&#125;<br><br><span class="hljs-keyword">type</span> <span class="hljs-type">ReportResponse</span> struct &#123;<br>&#125;<br><br></code></pre></td></tr></table></figure></li><li><p>调用请求如下,它会调用coordinator的Report函数来处理，来将该任务标记为运行结束。</p>  <figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs lisp">call(<span class="hljs-string">&quot;Coordinator.Report&quot;</span>, <span class="hljs-symbol">&amp;ReportRequest</span>&#123;Id: id, Phase: phase&#125;, <span class="hljs-symbol">&amp;ReportResponse</span>&#123;&#125;)<br></code></pre></td></tr></table></figure></li></ul><h1 id="coordinator设计"><a href="#coordinator设计" class="headerlink" title="coordinator设计"></a>coordinator设计</h1><p>coordinator会衍生出2个额外的协程，一个负责给rpc注册，并响应rpc传来的函数调用请求，一个负责给worker选择task生成resopnse</p><h2 id="rpc函数调用处理"><a href="#rpc函数调用处理" class="headerlink" title="rpc函数调用处理"></a>rpc函数调用处理</h2><p>给rpc注册的程序就是原本框架提供的代码，具体代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// start a thread that listens for RPCs from worker.go</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Coordinator)</span></span> server() &#123;<br>rpc.Register(c)<br>rpc.HandleHTTP()<br><span class="hljs-comment">//l, e := net.Listen(&quot;tcp&quot;, &quot;:1234&quot;)</span><br>sockname := coordinatorSock()<br>os.Remove(sockname)<br>l, e := net.Listen(<span class="hljs-string">&quot;unix&quot;</span>, sockname)<br><span class="hljs-keyword">if</span> e != <span class="hljs-literal">nil</span> &#123;<br>log.Fatal(<span class="hljs-string">&quot;listen error:&quot;</span>, e)<br>&#125;<br><span class="hljs-keyword">go</span> http.Serve(l, <span class="hljs-literal">nil</span>)<br>&#125;<br><br></code></pre></td></tr></table></figure><p>其相应的也是上面提到的hearbeat和report事件。比较有go特色的的地方在于如何等待另一个进程生成对应的回应，采用的是如下的代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> heartbeatMsg <span class="hljs-keyword">struct</span> &#123;<br>response *HeartbeatResponse<br>ok       <span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Coordinator)</span></span> Heartbeat(request *HeartbeatRequest, response *HeartbeatResponse) <span class="hljs-type">error</span> &#123;<br>msg := heartbeatMsg&#123;response, <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;)&#125;<br>c.heartbeatCh &lt;- msg<br>&lt;-msg.ok<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>构建msg将信息传递过去给c.heartbeach，然后等待msg.ok准备就绪，也就是response填好了数据，再返回。Report也是同理</p><h2 id="task管理"><a href="#task管理" class="headerlink" title="task管理"></a>task管理</h2><p>在coordinator初始化时会生成一个schedule协程来负责task生成和管理</p><ul><li>task有4种类型Map类型、Reduce类型、等待类型和完成类型，Map类型和Reduce类需要worker进行实际处理，等待类型只需要worker去sleep一段时间就好了，然后再去询问有没有新任务，完成类型的任务发送过来之后worker就可以结束运行了</li><li>task有3个状态，分别为等待、运行、完成，一开始初始化时为等待状态，交给worker运行后为运行状态，worker发送report回来说明自己运行完毕后为完成状态。</li><li>coordinator有三个阶段分别为Map阶段、Reduce阶段和Complete阶段，一开始为Map阶段，其需要处理Map类型的task，当Map类型的task全部完成后需要转变到Reduce阶段，处理Reduce类型的task，当Reduce类型的状态也全部完成后就转为Complete状态，可以结束运行了。</li></ul><p>schedule代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Coordinator)</span></span> schedule() &#123;<br>c.initMapPhase()<br><br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> msg := &lt;-c.heartbeatCh:<br>isAllTaskDoneInPhase := c.selectANewTask(msg.response)<br><span class="hljs-keyword">if</span> isAllTaskDoneInPhase &#123;<br>c.switchPhase()<br>c.selectTaskAfterSwitchPhase(msg.response)<br>&#125;<br>log.Printf(<span class="hljs-string">&quot;Coordinator: Heartbeat response: %v\n&quot;</span>, msg.response)<br>msg.ok &lt;- <span class="hljs-keyword">struct</span>&#123;&#125;&#123;&#125;<br><br><span class="hljs-keyword">case</span> msg := &lt;-c.reportCh:<br><span class="hljs-keyword">if</span> msg.request.Phase == c.phase &#123;<br>log.Printf(<span class="hljs-string">&quot;Coordinator: Worker has finished %v-task%d\n&quot;</span>, c.phase, msg.request.Id)<br>c.tasks[msg.request.Id].status = Finished<br>&#125;<br>msg.ok &lt;- <span class="hljs-keyword">struct</span>&#123;&#125;&#123;&#125;<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>生成一个新任务时需要去遍历查看是否有处于等待状态的任务或者是运行时间过久（说明worker可能已经挂掉了）的任务，然后将其分配出去，主要代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Coordinator)</span></span> selectANewTask(response *HeartbeatResponse) <span class="hljs-type">bool</span> &#123;<br>isAllTaskDone, isNewTaskScheduled := <span class="hljs-literal">true</span>, <span class="hljs-literal">false</span><br><br><span class="hljs-keyword">for</span> id, task := <span class="hljs-keyword">range</span> c.tasks &#123;<br><span class="hljs-keyword">switch</span> task.status &#123;<br><span class="hljs-keyword">case</span> Idle:<br>isAllTaskDone, isNewTaskScheduled = <span class="hljs-literal">false</span>, <span class="hljs-literal">true</span><br>c.tasks[id].status, c.tasks[id].startTime = Working, time.Now()<br>c.scheduleTaskToResponse(id, response)<br><br><span class="hljs-keyword">case</span> Working:<br>isAllTaskDone = <span class="hljs-literal">false</span><br><span class="hljs-keyword">if</span> time.Since(task.startTime) &gt; MaxTaskRunInterval &#123;<br>isNewTaskScheduled = <span class="hljs-literal">true</span><br>c.tasks[id].startTime = time.Now()<br>c.scheduleTaskToResponse(id, response)<br>&#125;<br><br><span class="hljs-keyword">case</span> Finished:<br>&#125;<br><br><span class="hljs-keyword">if</span> isNewTaskScheduled &#123;<br><span class="hljs-keyword">break</span><br>&#125;<br>&#125;<br><br><span class="hljs-keyword">if</span> !isNewTaskScheduled &amp;&amp; !isAllTaskDone &#123;<br>response.JobType = WaitJob<br>&#125;<br><br><span class="hljs-keyword">return</span> isAllTaskDone<br>&#125;<br></code></pre></td></tr></table></figure><p>当coordinator进行Complete阶段后其实并不会再去处理其他事情，比如给worker发送运行结束的指令，而是直接给doneCh赋值，然后以此退出运行</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Coordinator)</span></span> Done() <span class="hljs-type">bool</span> &#123;<br>&lt;-c.doneCh<br>log.Printf(<span class="hljs-string">&quot;Coordinator: Done\n&quot;</span>)<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span><br>&#125;<br></code></pre></td></tr></table></figure><h1 id="worker-设计"><a href="#worker-设计" class="headerlink" title="worker 设计"></a>worker 设计</h1><h2 id="运行流程"><a href="#运行流程" class="headerlink" title="运行流程"></a>运行流程</h2><p>worker就是不断地发送heartbeat命令然后获取任务进行运行，直到接收到了Complete任务或者发送heartbeat失败，就可以结束运行了。如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Worker</span><span class="hljs-params">(mapf <span class="hljs-keyword">func</span>(<span class="hljs-type">string</span>, <span class="hljs-type">string</span>)</span></span> []KeyValue,<br>reducef <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(<span class="hljs-type">string</span>, []<span class="hljs-type">string</span>)</span></span> <span class="hljs-type">string</span>) &#123;<br><br><span class="hljs-keyword">for</span> &#123;<br>response := doHeartbeat()<br>log.Printf(<span class="hljs-string">&quot;Worker: receive coordinator&#x27;s response, new job is %v \n&quot;</span>, response)<br><br><span class="hljs-keyword">switch</span> response.JobType &#123;<br><span class="hljs-keyword">case</span> MapJob:<br>doMapTask(mapf, response)<br><span class="hljs-keyword">case</span> ReduceJob:<br>doReduceTask(reducef, response)<br><span class="hljs-keyword">case</span> WaitJob:<br>time.Sleep(<span class="hljs-number">1</span> * time.Second)<br><span class="hljs-keyword">case</span> CompleteJob:<br><span class="hljs-keyword">return</span><br><span class="hljs-keyword">default</span>:<br><span class="hljs-built_in">panic</span>(fmt.Sprintf(<span class="hljs-string">&quot;worker get an unexpected jobType %v&quot;</span>, response.JobType))<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Map类型task"><a href="#Map类型task" class="headerlink" title="Map类型task"></a>Map类型task</h2><p>Map类型的task的处理如下所示，总体就是调用mapF统计文件中各个单词的数量，并记录到中间文件中，由于将中间结果写入到文件中是可以并行运行的，所以这里启动了多个协程来进行处理</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">doMapTask</span><span class="hljs-params">(mapF <span class="hljs-keyword">func</span>(<span class="hljs-type">string</span>, <span class="hljs-type">string</span>)</span></span> []KeyValue, response *HeartbeatResponse) &#123;<br>wordCountList := getWordCountListOfFile(mapF, response.FilePath)<br><br>intermediate := splitWordCountListToReduceNNum(wordCountList, response.NReduce)<br><br><span class="hljs-keyword">var</span> writeIntermediateFilewg sync.WaitGroup<br><span class="hljs-keyword">for</span> reduceNumber, splitedWordCountList := <span class="hljs-keyword">range</span> intermediate &#123;<br>writeIntermediateFilewg.Add(<span class="hljs-number">1</span>)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(reduceNumber <span class="hljs-type">int</span>, splitedWordCountList []KeyValue)</span></span> &#123;<br><span class="hljs-keyword">defer</span> writeIntermediateFilewg.Done()<br>writeIntermediateFile(response.Id, reduceNumber, splitedWordCountList)<br>&#125;(reduceNumber, splitedWordCountList)<br>&#125;<br>writeIntermediateFilewg.Wait()<br><br>doReport(response.Id, MapPhase)<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Reduce类型task"><a href="#Reduce类型task" class="headerlink" title="Reduce类型task"></a>Reduce类型task</h2><p>Reduce类型task的处理如下所示，总体就是把对应的中间文件读出来，将结果通过reduceF进行聚集，输出到最终的文件中</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">doReduceTask</span><span class="hljs-params">(reduceF <span class="hljs-keyword">func</span>(<span class="hljs-type">string</span>, []<span class="hljs-type">string</span>)</span></span> <span class="hljs-type">string</span>, response *HeartbeatResponse) &#123;<br>wordCountList := getWordCountListFromIntermediateFile(response.NMap, response.Id)<br><br>wordCountMap := gatherAndSortIntermediateWordCountList(wordCountList)<br><br><span class="hljs-keyword">var</span> buf bytes.Buffer<br>reducIntermediateWordCount(reduceF, wordCountMap, &amp;buf)<br><br>fileName := generateReduceResultFileName(response.Id)<br>atomicWriteFile(fileName, &amp;buf)<br><br>doReport(response.Id, ReducePhase)<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="原子写入文件"><a href="#原子写入文件" class="headerlink" title="原子写入文件"></a>原子写入文件</h2><p>这里采用了一种原子写入的方式，以防止多个worker都需要写入同一个文件名的文件时可能出现的问题。总体思想就是先写入到一个临时文件中，然后再将其改名为对应的文件名，如果临时文件没有写成功，就用defer命令将其删除。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">atomicWriteFile</span><span class="hljs-params">(filename <span class="hljs-type">string</span>, reader io.Reader)</span></span> (err <span class="hljs-type">error</span>) &#123;<br>tmpFileName, err := writeToTmpFile(filename, reader)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;cannot write to temp file: %v&quot;</span>, err)<br>&#125;<br><br><span class="hljs-keyword">if</span> err := os.Rename(tmpFileName, filename); err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;cannot rename temp file: %v&quot;</span>, err)<br>&#125;<br><br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">writeToTmpFile</span><span class="hljs-params">(filename <span class="hljs-type">string</span>, reader io.Reader)</span></span> (tmpFileName <span class="hljs-type">string</span>, err <span class="hljs-type">error</span>) &#123;<br>dir, file := filepath.Split(filename)<br><span class="hljs-keyword">if</span> dir == <span class="hljs-string">&quot;&quot;</span> &#123;<br>dir = <span class="hljs-string">&quot;.&quot;</span><br>&#125;<br><br>tmpFile, err := os.CreateTemp(dir, file)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>, fmt.Errorf(<span class="hljs-string">&quot;cannot create temp file: %v&quot;</span>, err)<br>&#125;<br><span class="hljs-keyword">defer</span> tmpFile.Close()<br><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>os.Remove(tmpFile.Name())<br>&#125;<br>&#125;()<br><br>_, err = io.Copy(tmpFile, reader)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>, fmt.Errorf(<span class="hljs-string">&quot;cannot write to temp file: %v&quot;</span>, err)<br>&#125;<br><span class="hljs-keyword">if</span> err := tmpFile.Close(); err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>, fmt.Errorf(<span class="hljs-string">&quot;cannot close temp file: %v&quot;</span>, err)<br>&#125;<br><br><span class="hljs-keyword">return</span> tmpFile.Name(), <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><h1 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h1><p>coordinator运行结果:</p><p><img src="/./MIT6-824lab1/coordinator%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C.jpg" alt="coordinator运行结果"></p><p>worker运行结果:</p><p><img src="/./MIT6-824lab1/worker%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C.jpg" alt="worker运行结果"></p><p>中间文件：</p><p><img src="/./MIT6-824lab1/%E4%B8%AD%E9%97%B4%E6%96%87%E4%BB%B6.jpg" alt="中间文件"></p><p>输出结果：</p><p><img src="/./MIT6-824lab1/%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C.jpg" alt="输出结果"></p><p>测试脚本结果：</p><p><img src="/./MIT6-824lab1/%E6%B5%8B%E8%AF%95%E8%84%9A%E6%9C%AC%E7%BB%93%E6%9E%9C.jpg" alt="测试脚本结果"></p><h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><p>最后进行脚本测试的时候发现early_exit这个点总是通不过，这个脚本会捕捉最早退出运行的进程，然后拷贝所有输出文件，然后再在所有进程都退出的时候拷贝所有输出文件，以此对比两个文件是否相同，来判断是否coordinator和所有的woker都在任务全部完成后再退出。</p><p>后面仔细查看不通过的原因发现是因为其依靠下面的部分来进行捕捉退出的进程,本机器上使用的是<code>wait -n</code>,但是实际查看发现其并没有正确地在相关进程退出时进行触发，而是一开始就触发了，其触发时coordinator和所有worker其实都还在前台运行了，后面讲这部分改成了if里面的测试，就可以正常捕捉退出的进程然后顺利通过了。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">jobs</span> &amp;&gt; /dev/null<br><span class="hljs-keyword">if</span> [[ <span class="hljs-string">&quot;<span class="hljs-variable">$OSTYPE</span>&quot;</span> = <span class="hljs-string">&quot;darwin&quot;</span>* ]]<br><span class="hljs-keyword">then</span><br>  <span class="hljs-comment"># bash on the Mac doesn&#x27;t have wait -n</span><br>  <span class="hljs-keyword">while</span> [ ! -e <span class="hljs-variable">$DF</span> ]<br>  <span class="hljs-keyword">do</span><br>    <span class="hljs-built_in">sleep</span> 0.2<br>  <span class="hljs-keyword">done</span><br><span class="hljs-keyword">else</span><br>  <span class="hljs-comment"># the -n causes wait to wait for just one child process,</span><br>  <span class="hljs-comment"># rather than waiting for all to finish.</span><br>  <span class="hljs-built_in">wait</span> -n<br><span class="hljs-keyword">fi</span><br></code></pre></td></tr></table></figure><p>从看MapReduce论文到学go再到能看懂作业要求，再到能看懂别人写的代码，再到能自己独立完成这部分代码总共断断续续持续了一个月，能够感受到自己在这之中的不断的精进，MapReduce的设计确实也很巧妙，go总体的设计确实很适合分布式，MIT6.824确实不愧是一名深受好评的课，学一下是很有必要的，希望自己后面也能都将其他部分啃下来了。</p><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ol><li><a href="https://github.com/OneSizeFitsQuorum/MIT6.824-2021">https://github.com/OneSizeFitsQuorum/MIT6.824-2021</a></li><li><a href="https://github.com/PKUFlyingPig/MIT6.824">https://github.com/PKUFlyingPig/MIT6.824</a></li><li><a href="https://github.com/szw2021/MIT6.824-2021/tree/practice/src">https://github.com/szw2021/MIT6.824-2021/tree/practice/src</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>MIT6.824</category>
      
      <category>Lab</category>
      
    </categories>
    
    
    <tags>
      
      <tag>go</tag>
      
      <tag>分布式</tag>
      
      <tag>MIT6.824</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RPC介绍</title>
    <link href="/2023/11/14/RPC%E4%BB%8B%E7%BB%8D/"/>
    <url>/2023/11/14/RPC%E4%BB%8B%E7%BB%8D/</url>
    
    <content type="html"><![CDATA[<pre><code class="hljs">最近在学MIT6.824的lab1——MapReduce，发现其中使用到了RPC来让work和coordinator之间通信，故而乘机学习一下。</code></pre><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>RPC（Remote Procedure Call，远程过程调用）是一种在分布式系统中进行进程间通信的协议。它允许一个程序（客户端）调用另一个程序（服务器）上的函数或过程，就像调用本地函数一样，而不必关心底层网络细节。</p><p>在 RPC 中，客户端和服务器可以在不同的机器上，甚至在不同的网络上。RPC 提供了一种抽象，使得远程调用看起来就像是本地调用一样。通过 RPC，程序可以通过网络传输数据和调用远程函数，使得分布式系统中的组件可以协同工作。</p><p>其整体流程如下图所示：</p><p><img src="https://pic4.zhimg.com/45366c44f775abfd0ac3b43bccc1abc3_b" alt="RPC流程"></p><p>对于RPC需要关注的主要有三点：</p><ul><li><strong>通信协议：</strong> RPC可以基于TCP或者HTTP协议，一般而言TCP的协议更快</li><li><strong>寻址：</strong> 远程提供服务器需要提供服务所在地址，例如IP和端口</li><li><strong>数据序列化：</strong> 远程调用无法依据内存进行参数和结果传递，所以需要规定序列化的格式，例如Json格式</li></ul><p>常用的RPC框架有如下这些： </p><ul><li>Thrift：thrift是一个软件框架，用来进行可扩展且跨语言的服务的开发。它结合了功能强大的软件堆栈和代码生成引擎，以构建在 C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk, and OCaml 这些编程语言间无缝结合的、高效的服务。</li><li>gRPC：一开始由 google 开发，是一款语言中立、平台中立、开源的远程过程调用(RPC)系统。</li><li>Dubbo：Dubbo是一个分布式服务框架，以及SOA治理方案。其功能主要包括：高性能NIO通讯及多协议集成，服务动态寻址与路由，软负载均衡与容错，依赖分析与降级等。Dubbo是阿里巴巴内部的SOA服务化治理方案的核心框架，Dubbo自2011年开源后，已被许多非阿里系公司使用。</li><li>Spring Cloud：Spring Cloud由众多子项目组成，如Spring Cloud Config、Spring Cloud Netflix、Spring Cloud Consul 等，提供了搭建分布式系统及微服务常用的工具，如配置管理、服务发现、断路器、智能路由、微代理、控制总线、一次性token、全局锁、选主、分布式会话和集群状态等，满足了构建微服务所需的所有解决方案。Spring Cloud基于Spring Boot, 使得开发部署极其简单。</li></ul><h1 id="GO语言示例"><a href="#GO语言示例" class="headerlink" title="GO语言示例"></a>GO语言示例</h1><p>在 Go 语言中，标准库提供了一个 net&#x2F;rpc 包，用于实现 RPC。基本的使用流程包括注册对象、注册服务、处理请求等。以下是一个简单的 Go RPC 例子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;net&quot;</span><br><span class="hljs-string">&quot;net/rpc&quot;</span><br>)<br><br><span class="hljs-comment">// 定义一个用于 RPC 的对象</span><br><span class="hljs-keyword">type</span> MyService <span class="hljs-keyword">struct</span>&#123;&#125;<br><br><span class="hljs-comment">// 定义一个 RPC 方法</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *MyService)</span></span> Multiply(args *Args, reply *<span class="hljs-type">int</span>) <span class="hljs-type">error</span> &#123;<br>*reply = args.A * args.B<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-comment">// 定义传递给 RPC 方法的参数结构</span><br><span class="hljs-keyword">type</span> Args <span class="hljs-keyword">struct</span> &#123;<br>A, B <span class="hljs-type">int</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-comment">// 注册服务</span><br>rpc.Register(<span class="hljs-built_in">new</span>(MyService))<br><br><span class="hljs-comment">// 创建监听器</span><br>listener, err := net.Listen(<span class="hljs-string">&quot;tcp&quot;</span>, <span class="hljs-string">&quot;:1234&quot;</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-built_in">panic</span>(err)<br>&#125;<br><br><span class="hljs-comment">// 处理连接</span><br><span class="hljs-keyword">for</span> &#123;<br>conn, err := listener.Accept()<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">continue</span><br>&#125;<br><span class="hljs-keyword">go</span> rpc.ServeConn(conn)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>在该例子中，MyService 结构体中的 Multiply 方法被注册为 RPC 服务。通过监听端口 1234，该服务可以接收客户端的 RPC 调用请求。客户端可以通过 net&#x2F;rpc 包中的函数来发起远程调用。RPC 在分布式系统中广泛用于实现不同节点之间的通信和协作。</p><p>以下是一个简单的 Go RPC 客户端的调用代码示例,程序需要确保 RPC 客户端的网络协议和端口与服务器端一致，这样它们才能正确地进行通信。在这个例子中，服务器端监听的是 TCP 端口 1234。：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-string">&quot;net/rpc&quot;</span><br>)<br><br><span class="hljs-comment">// 定义传递给 RPC 方法的参数结构</span><br><span class="hljs-keyword">type</span> Args <span class="hljs-keyword">struct</span> &#123;<br>A, B <span class="hljs-type">int</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-comment">// 连接 RPC 服务器</span><br>client, err := rpc.Dial(<span class="hljs-string">&quot;tcp&quot;</span>, <span class="hljs-string">&quot;localhost:1234&quot;</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-built_in">panic</span>(err)<br>&#125;<br><span class="hljs-keyword">defer</span> client.Close()<br><br><span class="hljs-comment">// 准备 RPC 调用的参数</span><br>args := Args&#123;<span class="hljs-number">3</span>, <span class="hljs-number">4</span>&#125;<br><br><span class="hljs-comment">// 调用 Multiply 方法</span><br><span class="hljs-keyword">var</span> result <span class="hljs-type">int</span><br>err = client.Call(<span class="hljs-string">&quot;MyService.Multiply&quot;</span>, args, &amp;result)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-built_in">panic</span>(err)<br>&#125;<br><br><span class="hljs-comment">// 打印结果</span><br>fmt.Printf(<span class="hljs-string">&quot;Result of 3 * 4: %d\n&quot;</span>, result)<br>&#125;<br></code></pre></td></tr></table></figure><p>在这个例子中，rpc.Dial 函数用于连接到服务器，然后通过 client.Call 方法调用远程的 Multiply 方法。在调用过程中，需要传递参数结构 Args 和一个用于接收结果的变量。最后，打印出调用结果:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Result</span> of <span class="hljs-number">3</span> * <span class="hljs-number">4</span>: <span class="hljs-number">12</span><br></code></pre></td></tr></table></figure><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ul><li><a href="https://jaminzhang.github.io/architecture/RPC-Introduction/">https://jaminzhang.github.io/architecture/RPC-Introduction/</a></li><li><a href="https://zhuanlan.zhihu.com/p/187560185">https://zhuanlan.zhihu.com/p/187560185</a></li><li><a href="https://cloud.tencent.com/developer/article/2021745">https://cloud.tencent.com/developer/article/2021745</a></li><li><a href="https://chat.openai.com/">ChatGPT</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>MIT6.824</category>
      
      <category>其他</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
      <tag>MIT6.824</tag>
      
      <tag>Go</tag>
      
      <tag>RPC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何写出优雅的代码</title>
    <link href="/2023/11/09/%E5%A6%82%E4%BD%95%E5%86%99%E5%87%BA%E4%BC%98%E9%9B%85%E7%9A%84%E4%BB%A3%E7%A0%81/"/>
    <url>/2023/11/09/%E5%A6%82%E4%BD%95%E5%86%99%E5%87%BA%E4%BC%98%E9%9B%85%E7%9A%84%E4%BB%A3%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>最近在写模拟器的代码，现在需要对整体的架构都进行一个大更改，而当我回过头去看时发现好多代码都写得很丑，越写越像屎山代码，需要对整体进行一轮迭代，故而正好趁此机会来学习一下如何写一个优雅的代码。写之前看了很多博客，这里记录一下对自己比较有启发的点。</p><h1 id="什么是优雅的代码"><a href="#什么是优雅的代码" class="headerlink" title="什么是优雅的代码"></a>什么是优雅的代码</h1><pre><code class="hljs">这一个衡量标准很直接：WTF min</code></pre><p><img src="https://camo.githubusercontent.com/ded622d3db4ad28f7b47098ae182c09dc1d629c90f487a885f683527825ecc94/687474703a2f2f692e737461636b2e696d6775722e636f6d2f65545a76572e6a7067" alt="优雅的代码"></p><p>代码最后还是需要给人读的，需要认识到：</p><pre><code class="hljs">任何一个傻瓜都能写出计算机可以理解的代码。唯有写出人类容易理解的代码，才是优秀的程序员。—— Martin Fowler</code></pre><p>好的代码最重要的特点：整洁</p><pre><code class="hljs">整洁的代码如同优美的散文。—— Grady Booch</code></pre><h1 id="如何保证代码整洁"><a href="#如何保证代码整洁" class="headerlink" title="如何保证代码整洁"></a>如何保证代码整洁</h1><h2 id="1-有意义的命名"><a href="#1-有意义的命名" class="headerlink" title="1. 有意义的命名"></a>1. 有意义的命名</h2><p>命名要尽可能地输出多的信息，让人能快速理解这个类、变量或者函数的含义、功能。<strong>花时间来取名是值得的</strong></p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 创建后的天数</span><br><span class="hljs-comment">**/</span><br><span class="hljs-built_in">int</span> d;<br></code></pre></td></tr></table></figure><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs abnf">int daysSinceCreation<span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure><p>后一种命名就能够更加凸显变量的含义了。</p><p>命名是越短越好的，但是为了能够清晰表达意思，取长名字也是值得的。</p><p>尽量不要取相似的名字以让人困惑。</p><h2 id="2-优雅的注释"><a href="#2-优雅的注释" class="headerlink" title="2. 优雅的注释"></a>2. 优雅的注释</h2><p>一份优雅的代码本身就应该具有足够的表达力，不需要注释就能看懂。<strong>注释的存在往往是弥补我们无法用代码清晰表达意图的情况</strong>。当发现自己需要对某处的代码写注释时就需要考虑是不是应该用更好的代码对其进行替代了。</p><pre><code class="hljs">好代码&gt;&gt;坏代码+注释</code></pre><p>注释应该只需要注重解释上层的东西，包括设计的意图、功能，而不需要解释执行的细节，这由代码来进行展示。</p><p>注释不要去写能由git记录的信息。</p><h2 id="3-简洁的函数"><a href="#3-简洁的函数" class="headerlink" title="3. 简洁的函数"></a>3. 简洁的函数</h2><p>控制函数的长度，一般不要长于一个屏幕的大小，也就是<strong>控制在30行以内</strong></p><p><strong>if语句、else语句、while语句等，其中的代码应该只有一行</strong>，该行通常是一个调用语句，这样不但能保持短小，还可以给调用方法命名一个有说明性的名字，进一步增加代码的可读性</p><p>函数的功能要单一，具有原子性，以方便函数复用。最简单的规则就是看看该方法是否能在拆出一个方法，且拆出去的方法是不同于该方法的诠释和实现。</p><p>需要保证函数中的抽象层级一致。</p><p>不要返回null或者特殊对象等，不要传入null。</p><p>函数参数不要超过3个，如果超过就需要考虑将其抽象为类。</p><h2 id="4-整齐的代码结构"><a href="#4-整齐的代码结构" class="headerlink" title="4. 整齐的代码结构"></a>4. 整齐的代码结构</h2><p>一个文件的代码数量需要<strong>控制在200行以内</strong>，最多不要超过500行。</p><p>关系紧密的代码放在一起</p><ul><li>变量声明放在其使用的位置</li><li>函数的调用者要放在被调用者上面，以从上到下展示调用依赖顺序</li></ul><p>对象暴露行为，隐藏数据，调用对象时不应该了解该对象的内部情况。</p><p>一组代码代表一个完整的思路，不同组的代码中间要用空行间隔。</p><h2 id="5-重构代码"><a href="#5-重构代码" class="headerlink" title="5. 重构代码"></a>5. 重构代码</h2><p>好代码不是一蹴而就的，重构代码是必要的。</p><p>重复的代码肯定是可以抽象出一个上层函数的。</p><ul><li>都同一个类中就考虑将其提炼出一个函数</li><li>不在同一个类中，就需要考虑创建一个共享的地方，可以是一个工具类，以便多个类都可以使用它</li><li>只是相似的话，可以重拍顺序，将相同的部分提料出来</li></ul><p>过长的函数可以通过提取函数的方式来缩短。</p><p>如果一个类不是单一职责的，则可能会导致一旦其变化就需要修改多个其他类，或者不同类的变化都需要修改这个类，这时就需要考虑对其重构，划定职责。</p><p>有时候会发现三四个相同的字段，在多个类和函数中均出现，这时候说明有必要给这一组字段建立一个类，将其封装起来。</p><p>以查询代替临时变量，也就是对于复杂的赋值表达式，使用函数来进行替代。</p><p>对于复杂过长的函数，可能将其转化为一个类进行重构。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>写一份优雅的代码远比写一份能跑的代码难，但是这是值得的。想如何写代码远比写代码来得更加重要，写代码时的角度需要变化，不要以自己的角度去看自己写的代码，而是要以一个代码阅读者的角度来审视自己的代码。</p><h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><ul><li><a href="https://mp.weixin.qq.com/s?__biz=MzAxNDEwNjk5OQ==&mid=2650403801&idx=1&sn=5dab2af09f753fd089fe0f1f56260b10&chksm=83953bc1b4e2b2d79f78028ed6e79651167d85bf67453af791d9304fa4003eed73d9f2957fc7&scene=21#wechat_redirect">阿里工程师谈，什么是好的代码？</a></li><li><a href="https://developer.aliyun.com/article/1117703">一文详解｜如何写出优雅的代码</a></li><li><a href="https://www.zhihu.com/question/28492982">如何写出优雅的代码？</a></li><li><a href="https://juejin.cn/post/7016992016521232421">如何写出优雅的代码？</a></li><li><a href="https://github.com/CodingDocs/advanced-programmer/blob/master/docs/%E5%85%AB%E7%82%B9%E5%BB%BA%E8%AE%AE%E5%8A%A9%E6%82%A8%E5%86%99%E5%87%BA%E4%BC%98%E9%9B%85%E7%9A%84Java%E4%BB%A3%E7%A0%81.md">八点建议助您写出优雅的Java代码</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
    <tags>
      
      <tag>代码风格</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文阅读】MapReduce: Simplified Data Processing on Large Clusters</title>
    <link href="/2023/11/05/MapReducePaperRead/"/>
    <url>/2023/11/05/MapReducePaperRead/</url>
    
    <content type="html"><![CDATA[<p>原博客链接：<a href="https://tanxinyu.work/mapreduce-thesis/">https://tanxinyu.work/mapreduce-thesis/</a></p><h1 id="相关背景"><a href="#相关背景" class="headerlink" title="相关背景"></a>相关背景</h1><p>在 20 世纪初，包括本文作者在内的 Google 的很多程序员，为了处理海量的原始数据，已经实现了数以百计的、专用的计算方法。这些计算方法用来处理大量的原始数据，比如，文档抓取（类似网络爬虫的程序）、Web 请求日志等等；也为了计算处理各种类型的衍生数据，比如倒排索引、Web 文档的图结构的各种表示形势、每台主机上网络爬虫抓取的页面数量的汇总、每天被请求的最多的查询的集合等等。</p><h1 id="要解决的问题"><a href="#要解决的问题" class="headerlink" title="要解决的问题"></a>要解决的问题</h1><p>大多数以上提到的数据处理运算在概念上很容易理解。然而由于输入的数据量巨大，因此要想在可接受的时间内完成运算，只有将这些计算分布在成百上千的主机上。如何处理并行计算、如何分发数据、如何处理错误？所有这些问题综合在一起，需要大量的代码处理，因此也使得原本简单的运算变得难以处理。</p><h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>为了解决上述复杂的问题，本文设计一个新的抽象模型，使用这个抽象模型，用户只要表述想要执行的简单运算即可，而不必关心并行计算、容错、数据分布、负载均衡等复杂的细节，这些问题都被封装在了一个库里面：利用一个输入 key&#x2F;value pair 集合来产生一个输出的 key&#x2F;value pair 集合。</p><p>MapReduce 库的用户可以用两个函数表达这个计算：Map 和 Reduce。</p><ul><li>用户自定义的 Map 函数接受一个输入的 key&#x2F;value pair 值，然后产生一个中间 key&#x2F;value pair 值的集合。MapReduce 库把所有具有相同中间 key 值 I 的中间 value 值集合在一起后按照一定的规律传递给 reduce 函数。</li><li>用户自定义的 Reduce 函数接受一个中间 key 的值 I 和相关的一个 value 值的集合。Reduce 函数合并这些 value 值，形成一个较小的 value 值的集合。一般的，每次 Reduce 函数调用只产生 0 或 1 个输出 value 值。通常 Map 通过一个迭代器把中间 value 值提供给 Reduce 函数，这样 Reduce Worker 就可以处理无法全部放入内存中的大量的 value 值的集合。<br>在概念上，用户定义的 Map 和 Reduce 函数都有相关联的类型：</li></ul><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs livescript"><span class="hljs-keyword">map</span><span class="hljs-function"><span class="hljs-params">(k1,v1)</span> -&gt;</span><span class="hljs-keyword">list</span>(k2,v2)<br>reduce<span class="hljs-function"><span class="hljs-params">(k2,<span class="hljs-keyword">list</span>(v2))</span> -&gt;</span><span class="hljs-keyword">list</span>(v2)<br></code></pre></td></tr></table></figure><p>比如，输入的 key 和 value 值与输出的 key 和 value 值在类型上推导的域不同。此外，中间 key 和 value 值与输出 key 和 value 值在类型上推导的域相同。</p><h1 id="执行流程"><a href="#执行流程" class="headerlink" title="执行流程"></a>执行流程</h1><p>通过将 Map 调用的输入数据自动分割为 M 个数据片段的集合，Map 调用被分布到多台机器上执行。输入的数据片段能够在不同的机器上并行处理。使用分区函数将 Map 调用产生的中间 key 值分成 R 个不同分区（例如，hash(key) mod R），Reduce 调用也被分布到多台机器上执行。分区数量（R）和分区函数由用户来指定。</p><p><img src="https://tanxinyu.work/mapreduce-thesis/mapreduce.png" alt="执行流程"></p><p>上图展示了 MapReduce 实现中操作的全部流程。当用户调用 MapReduce 函数时，将发生下面的一系列动作：</p><ol><li>用户程序首先调用的 MapReduce 库将输入文件分成 M 个数据片度，每个数据片段的大小一般从 16MB 到 64MB（可以通过可选的参数来控制每个数据片段的大小）。然后用户程序在机群中创建大量的程序副本。</li><li>这些程序副本中的有一个特殊的程序–master。副本中其它的程序都是 worker 程序，由 master 分配任务。有 M 个 Map 任务和 R 个 Reduce 任务将被分配，master 将一个 Map 任务或 Reduce 任务分配给一个空闲的 worker。</li><li>被分配了 map 任务的 worker 程序读取相关的输入数据片段，从输入的数据片段中解析出 key&#x2F;value pair，然后把 key&#x2F;value pair 传递给用户自定义的 Map 函数，由 Map 函数生成并输出的中间 key&#x2F;value pair，并缓存在内存中。</li><li>缓存中的 key&#x2F;value pair 通过分区函数分成 R 个区域，之后周期性的写入到本地磁盘上。缓存的 key&#x2F;value pair 在本地磁盘上的存储位置将被回传给 master，由 master 负责把这些存储位置再传送给 Reduce worker</li><li>当 Reduce worker 程序接收到 master 程序发来的数据存储位置信息后，使用 RPC 从 Map worker 所在主机的磁盘上读取这些缓存数据。当 Reduce worker 读取了所有的中间数据后，通过对 key 进行排序后使得具有相同 key 值的数据聚合在一起。由于许多不同的 key 值会映射到相同的 Reduce 任务上，因此必须进行排序。如果中间数据太大无法在内存中完成排序，那么就要在外部进行排序。</li><li>Reduce worker 程序遍历排序后的中间数据，对于每一个唯一的中间 key 值，Reduce worker 程序将这个 key 值和它相关的中间 value 值的集合传递给用户自定义的 Reduce 函数。Reduce 函数的输出被追加到所属分区的输出文件。</li><li>当所有的 Map 和 Reduce 任务都完成之后，master 唤醒用户程序。在这个时候，在用户程序里的对 MapReduce 调用才返回。</li></ol><h1 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h1><h2 id="worker-故障"><a href="#worker-故障" class="headerlink" title="worker 故障"></a>worker 故障</h2><p>master 与 worker 之间同步心跳，对于失效的 worker，根据其类型来做进一步处理：</p><ul><li>Map worker 故障：由于 Map 任务将数据临时存储在本地，所以需要重新执行。</li><li>Reduce worker 故障：由于 Reduce 任务将数据存储在全局文件系统中 ，所以不需要重新执行。</li></ul><h2 id="master-故障"><a href="#master-故障" class="headerlink" title="master 故障"></a>master 故障</h2><p>MapReduce 任务重新执行</p><h2 id="故障语义保证"><a href="#故障语义保证" class="headerlink" title="故障语义保证"></a>故障语义保证</h2><p>当用户提供的 Map 和 Reduce 操作是输入确定性函数（即相同的输入产生相同的输出）时，MapReduce 的分布式实现在任何情况下的输出都和所有程序没有出现任何错误、顺序的执行产生的输出是一样的。</p><ul><li>Map worker 任务的原子提交：每个 Map 任务生成 R 个本地临时文件，当一个 Map 任务完成时，worker 发送一个包含 R 个临时文件名的完成消息给 master。如果 master 从一个已经完成的 Map 任务再次接收到一个完成消息，master 将忽略这个消息；</li><li>Reduce worker 任务的原子提交：当 Reduce 任务完成时，Reduce worker 进程以原子的方式把临时文件重命名为最终的输出文件。如果同一个 Reduce 任务在多台机器上执行，针对同一个最终的输出文件将有多个重命名操作执行。MapReduce 依赖底层文件系统提供的重命名操作的原子性来保证最终的文件系统状态仅仅包含一个 Reduce 任务产生的数据。</li></ul><h1 id="存储位置优化"><a href="#存储位置优化" class="headerlink" title="存储位置优化"></a>存储位置优化</h1><p>核心思想：本地读文件以减少流量消耗</p><p>MapReduce 的 master 在调度 Map 任务时会考虑输入文件的位置信息，尽量将一个 Map 任务调度在包含相关输入数据拷贝的机器上执行；如果上述努力失败了，master 将尝试在保存有输入数据拷贝的机器附近的机器上执行 Map 任务（例如，分配到一个和包含输入数据的机器在一个交换机里的 worker 机器上执行）。</p><h1 id="任务粒度"><a href="#任务粒度" class="headerlink" title="任务粒度"></a>任务粒度</h1><p>理想情况下，M 和 R 应当比集群中 worker 的机器数量要多得多。在每台 worker 机器都执行大量的不同任务能够提高集群的动态的负载均衡能力，并且能够加快故障恢复的速度：失效机器上执行的大量 Map 任务都可以分布到所有其他的 worker 机器上去执行。</p><p>实际使用时建议用户选择合适的 M 值，以使得每一个独立任务都是处理大约 16M 到 64M 的输入数据（这样，上面描写的输入数据本地存储优化策略才最有效），另外，也建议把 R 值设置使用的 worker 机器数量的小倍数。比如：M&#x3D;200000，R&#x3D;5000，使用 2000 台 worker 机器。</p><h1 id="备用任务"><a href="#备用任务" class="headerlink" title="备用任务"></a>备用任务</h1><p>影响一个 MapReduce 的总执行时间最通常的因素是“落伍者”：在运算过程中，如果有一台机器花了很长的时间才完成最后几个 Map 或 Reduce 任务，导致 MapReduce 操作总的执行时间超过预期。</p><p>为了解决落伍者的问题，当一个 MapReduce 操作接近完成的时候，master 调度备用（backup）任务进程来执行剩下的、处于处理中状态（in-progress）的任务。无论是最初的执行进程、还是备用（backup）任务进程完成了任务，MapReduce 都把这个任务标记成为已经完成。此个机制通常只会占用比正常操作多几个百分点的计算资源。但能减少近 50% 的任务完成总时间。</p><h1 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h1><h2 id="分区函数"><a href="#分区函数" class="headerlink" title="分区函数"></a>分区函数</h2><p>MapReduce 缺省的分区函数是使用 hash 方法(比如，hash(key) mod R) 进行分区。hash 方法能产生非常平衡的分区。然而，有的时候，其它的一些分区函数对 key 值进行的分区将非常有用。比如，输出的 key 值是 URLs，有的用户希望每个主机的所有条目保持在同一个输出文件中。为了支持类似的情况，MapReduce 库的用户需要提供专门的分区函数。例如，使用“hash(Hostname(urlkey))mod R”作为分区函数就可以把所有来自同一个主机的 URLs 保存在同一个输出文件中。</p><h2 id="顺序保证"><a href="#顺序保证" class="headerlink" title="顺序保证"></a>顺序保证</h2><p>MapReduce 确保在给定的分区中，中间 key&#x2F;value pair 数据的处理顺序是按照 key 值增量顺序处理的。这样的顺序保证对每个分成生成一个有序的输出文件，这对于需要对输出文件按 key 值随机存取的应用非常有意义，对在排序输出的数据集也很有帮助。</p><h2 id="Combiner-函数"><a href="#Combiner-函数" class="headerlink" title="Combiner 函数"></a>Combiner 函数</h2><p>在某些情况下，Map 函数产生的中间 key 值的重复数据会占很大的比重，并且，用户自定义的 Reduce 函数满足结合律和交换律。在 2.1 节的词数统计程序是个很好的例子。由于词频率倾向于一个 zipf 分布（齐夫分布），每个 Map 任务将产生成千上万个这样的记录。所有的这些记录将通过网络被发送到一个单独的 Reduce 任务，然后由这个 Reduce 任务把所有这些记录累加起来产生一个数字。MapReduce 允许用户指定一个可选的 combiner 函数，combiner 函数首先在本地将这些记录进行一次合并，然后将合并的结果再通过网络发送出去。</p><p>Combiner 函数在每台执行 Map 任务的机器上都会被执行一次。一般情况下，Combiner 和 Reduce 函数是一样的。Combiner 函数和 Reduce 函数之间唯一的区别是 MapReduce 库怎样控制函数的输出。Reduce 函数的输出被保存在最终的输出文件里，而 Combiner 函数的输出被写到中间文件里，然后被发送给 Reduce 任务。</p><p>部分的合并中间结果可以显著的提高一些 MapReduce 操作的速度。</p><h2 id="输入和输出的类型"><a href="#输入和输出的类型" class="headerlink" title="输入和输出的类型"></a>输入和输出的类型</h2><p>支持常用的类型，可以通过提供一个简单的 Reader 接口实现来支持一个新的输入类型。Reader 并非一定要从文件中读取数据，比如可以很容易的实现一个从数据库里读记录的 Reader，或者从内存中的数据结构读取数据的 Reader。</p><h2 id="副作用"><a href="#副作用" class="headerlink" title="副作用"></a>副作用</h2><p>在某些情况下，MapReduce 的使用者发现，如果在 Map 或 Reduce 操作过程中增加辅助的输出文件会比较省事。MapReduce 依靠程序 writer 把这种“副作用”变成原子的和幂等的。通常应用程序首先把输出结果写到一个临时文件中，在输出全部数据之后，在使用系统级的原子操作 rename 重新命名这个临时文件。</p><h2 id="跳过损坏的记录"><a href="#跳过损坏的记录" class="headerlink" title="跳过损坏的记录"></a>跳过损坏的记录</h2><p>每个 worker 进程都设置了信号处理函数捕获内存段异常（segmentation violation）和总线错误（bus error）。 在执行 Map 或者 Reduce 操作之前，MapReduce 库通过全局变量保存记录序号。如果用户程序触发了一个系统信号，消息处理函数将用“最后一口气”通过 UDP 包向 master 发送处理的最后一条记录的序号。当 master 看到在处理某条特定记录不止失败一次时，master 就标志着条记录需要被跳过，并且在下次重新执行相关的 Map 或者 Reduce 任务的时候跳过这条记录。</p><h2 id="本地执行"><a href="#本地执行" class="headerlink" title="本地执行"></a>本地执行</h2><p>支持本地串行执行以方便调试</p><h2 id="状态信息"><a href="#状态信息" class="headerlink" title="状态信息"></a>状态信息</h2><p>master 支持嵌入 HTTP 服务器以显示一组状态信息页面，用户可以监控各种执行状态。状态信息页面显示了包括计算执行的进度，比如已经完成了多少任务、有多少任务正在处理、输入的字节数、中间数据的字节数、输出的字节数、处理百分比等等</p><h2 id="计数器"><a href="#计数器" class="headerlink" title="计数器"></a>计数器</h2><p>MapReduce 库使用计数器统计不同事件发生次数。比如，用户可能想统计已经处理了多少个单词、已经索引的多少篇 German 文档等等。</p><p>这些计数器的值周期性的从各个单独的 worker 机器上传递给 master（附加在 ping 的应答包中传递）。master 把执行成功的 Map 和 Reduce 任务的计数器值进行累计，当 MapReduce 操作完成之后，返回给用户代码。</p><p>计数器当前的值也会显示在 master 的状态页面上，这样用户就可以看到当前计算的进度。当累加计数器的值的时候，master 要检查重复运行的 Map 或者 Reduce 任务，避免重复累加（之前提到的备用任务和失效后重新执行任务这两种情况会导致相同的任务被多次执行）。</p><h1 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h1><p>分布式的 Grep：Map 函数输出匹配某个模式的一行，Reduce 函数是一个恒等函数，即把中间数据复制到输出。</p><ul><li>计算 URL 访问频率：Map 函数处理日志中 web 页面请求的记录，然后输出 (URL,1)。Reduce 函数把相同 URL 的 value 值都累加起来，产生 (URL, 记录总数）结果。<br>网络链接倒排：Map 函数在源页面（source）中搜索所有的链接目标（target）并输出为 (target,source)。Reduce 函数把给定链接目标（target）的链接组合成一个列表，输出 (target,list(source))。</li><li>每个主机的检索词向量：检索词向量用一个（词，频率）列表来概述出现在文档或文档集中的最重要的一些词。Map 函数为每一个输入文档输出（主机名，检索词向量），其中主机名来自文档的 URL。Reduce 函数接收给定主机的所有文档的检索词向量，并把这些检索词向量加在一起，丢弃掉低频的检索词，输出一个最终的（主机名，检索词向量）。</li><li>倒排索引：Map 函数分析每个文档输出一个（词，文档号）的列表，Reduce 函数的输入是一个给定词的所有（词，文档号），排序所有的文档号，输出（词，list（文档号）)。所有的输出集合形成一个简单的倒排索引，它以一种简单的算法跟踪词在文档中的位置。<br>分布式排序：Map 函数从每个记录提取 key，输出 (key,record)。Reduce 函数不改变任何的值。这个运算依赖分区机制和排序属性。</li></ul><h1 id="经验分享"><a href="#经验分享" class="headerlink" title="经验分享"></a>经验分享</h1><ul><li>约束编程模式使得并行和分布式计算非常容易，也易于构造容错的计算环境；</li><li>网络带宽是稀有资源。大量的系统优化是针对减少网络传输量为目的的：本地优化策略使大量的数据从本地磁盘读取，中间文件写入本地磁盘、并且只写一份中间文件也节约了网络带宽。</li><li>多次执行相同的任务可以减少硬件配置不平衡带来的负面影响，同时解决了由于机器失效导致的数据丢失问题。</li></ul><h1 id="创新之处"><a href="#创新之处" class="headerlink" title="创新之处"></a>创新之处</h1><ul><li>通过简单的接口实现了自动的并行化和大规模的分布式计算，通过使用 MapReduce 模型接口实现了在大量普通 PC 机上的高性能计算。</li><li>向工业界证明了 MapReduce 模型在分布式计算上的可行性，拉开了分布式计算的序幕并影响了其后所有的计算框架，包括现在流行的批处理框架 Spark 和流处理框架 Flink 都很受其影响。</li></ul><h1 id="不足之处"><a href="#不足之处" class="headerlink" title="不足之处"></a>不足之处</h1><ul><li>基于历史局限性和当时的成本考虑，没有利用内存去更高效的处理数据，不过也为 Spark 提供了思路。</li><li>没有将资料调度和计算调度分离，使得 MapReduce 系统看起来较为冗杂。在开源的 Hadoop 生态中，MapReduce 现只关注于计算，具体的资源调度由 Yarn 管理。</li></ul><h1 id="相关系统"><a href="#相关系统" class="headerlink" title="相关系统"></a>相关系统</h1><ul><li>分布式存储系统：GFS&#x2F;Colossus&#x2F;HDFS</li><li>批处理框架：Spark</li><li>流处理框架：Flink</li><li>高可用机制：Chubby&#x2F;ZooKeeper</li></ul><h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><ul><li><a href="http://nil.csail.mit.edu/6.824/2020/notes/l01.txt">6.824 讲义</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/video/1.html">6.824 视频</a></li><li><a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/mapreduce-osdi04.pdf">论文</a></li><li><a href="https://github.com/Cxka/paper/blob/0a72fe0b354b65bac25e45163163eb2573f1faf2/map-reduce/map-reduce-cn.pdf">中文翻译</a></li><li><a href="https://blog.mrcroxx.com/posts/paper-reading/mapreduce-osdi04/">其他优质博客</a></li></ul><h1 id="补充MapReduce论文示例代码"><a href="#补充MapReduce论文示例代码" class="headerlink" title="补充MapReduce论文示例代码"></a>补充MapReduce论文示例代码</h1><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;mapreduce/mapreduce.h&quot;</span></span><br><br><span class="hljs-comment">// User’s map function</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">WordCounter</span> : <span class="hljs-keyword">public</span> Mapper &#123;<br>  <span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">Map</span><span class="hljs-params">(<span class="hljs-type">const</span> MapInput&amp; input)</span> </span>&#123;<br>      <span class="hljs-type">const</span> string&amp; text = input.<span class="hljs-built_in">value</span>();<br>      <span class="hljs-type">const</span> <span class="hljs-type">int</span> n = text.<span class="hljs-built_in">size</span>();<br>      <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; ) &#123;<br>        <span class="hljs-comment">// Skip past leading whitespace</span><br>        <span class="hljs-keyword">while</span> ((i &lt; n) &amp;&amp; <span class="hljs-built_in">isspace</span>(text[i]))<br>          i++;<br><br>        <span class="hljs-comment">// Find word end</span><br>        <span class="hljs-type">int</span> start = i;<br>        <span class="hljs-keyword">while</span> ((i &lt; n) &amp;&amp; !<span class="hljs-built_in">isspace</span>(text[i]))<br>          i++;<br>        <br>        <span class="hljs-keyword">if</span> (start &lt; i)<br>          <span class="hljs-built_in">Emit</span>(text.<span class="hljs-built_in">substr</span>(start,i-start),<span class="hljs-string">&quot;1&quot;</span>);<br>      &#125;<br>  &#125;<br>&#125;;<br><span class="hljs-built_in">REGISTER_MAPPER</span>(WordCounter);<br><br><span class="hljs-comment">// User’s reduce function</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Adder</span> : <span class="hljs-keyword">public</span> Reducer &#123;<br>  <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">Reduce</span><span class="hljs-params">(ReduceInput* input)</span> </span>&#123;<br>    <span class="hljs-comment">// Iterate over all entries with the</span><br>    <span class="hljs-comment">// same key and add the values</span><br>    int64 value = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">while</span> (!input-&gt;<span class="hljs-built_in">done</span>()) &#123;<br>      value += <span class="hljs-built_in">StringToInt</span>(input-&gt;<span class="hljs-built_in">value</span>());<br>      input-&gt;<span class="hljs-built_in">NextValue</span>();<br>    &#125;<br><br>    <span class="hljs-comment">// Emit sum for input-&gt;key()</span><br>    <span class="hljs-built_in">Emit</span>(<span class="hljs-built_in">IntToString</span>(value));<br>  &#125;<br>&#125;;<br><span class="hljs-built_in">REGISTER_REDUCER</span>(Adder);<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span>** argv)</span> </span>&#123;<br>  <span class="hljs-built_in">ParseCommandLineFlags</span>(argc, argv);<br><br>  MapReduceSpecification spec;<br><br>  <span class="hljs-comment">// Store list of input files into &quot;spec&quot;</span><br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; argc; i++) &#123;<br>    MapReduceInput* input = spec.<span class="hljs-built_in">add_input</span>();<br>    input-&gt;<span class="hljs-built_in">set_format</span>(<span class="hljs-string">&quot;text&quot;</span>);<br>    input-&gt;<span class="hljs-built_in">set_filepattern</span>(argv[i]);<br>    input-&gt;<span class="hljs-built_in">set_mapper_class</span>(<span class="hljs-string">&quot;WordCounter&quot;</span>);<br>  &#125;<br><br>  <span class="hljs-comment">// Specify the output files:</span><br>  <span class="hljs-comment">// /gfs/test/freq-00000-of-00100</span><br>  <span class="hljs-comment">// /gfs/test/freq-00001-of-00100</span><br>  <span class="hljs-comment">// ...</span><br>  MapReduceOutput* out = spec.<span class="hljs-built_in">output</span>();<br>  out-&gt;<span class="hljs-built_in">set_filebase</span>(<span class="hljs-string">&quot;/gfs/test/freq&quot;</span>);<br>  out-&gt;<span class="hljs-built_in">set_num_tasks</span>(<span class="hljs-number">100</span>);<br>  out-&gt;<span class="hljs-built_in">set_format</span>(<span class="hljs-string">&quot;text&quot;</span>);<br>  out-&gt;<span class="hljs-built_in">set_reducer_class</span>(<span class="hljs-string">&quot;Adder&quot;</span>);<br><br>  <span class="hljs-comment">// Optional: do partial sums within map</span><br>  <span class="hljs-comment">// tasks to save network bandwidth</span><br>  out-&gt;<span class="hljs-built_in">set_combiner_class</span>(<span class="hljs-string">&quot;Adder&quot;</span>);<br><br>  <span class="hljs-comment">// Tuning parameters: use at most 2000</span><br>  <span class="hljs-comment">// machines and 100 MB of memory per task</span><br>  spec.<span class="hljs-built_in">set_machines</span>(<span class="hljs-number">2000</span>);<br>  spec.<span class="hljs-built_in">set_map_megabytes</span>(<span class="hljs-number">100</span>);<br>  spec.<span class="hljs-built_in">set_reduce_megabytes</span>(<span class="hljs-number">100</span>);<br><br>  <span class="hljs-comment">// Now run it</span><br>  MapReduceResult result;<br>  <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">MapReduce</span>(spec, &amp;result)) <span class="hljs-built_in">abort</span>();<br><br>  <span class="hljs-comment">// Done: ’result’ structure contains info</span><br>  <span class="hljs-comment">// about counters, time taken, number of</span><br>  <span class="hljs-comment">// machines used, etc.</span><br><br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>MIT6.824</category>
      
      <category>论文</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>分布式</tag>
      
      <tag>MIT6.824</tag>
      
      <tag>论文阅读</tag>
      
      <tag>MapReduce</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>git学习记录</title>
    <link href="/2023/11/04/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"/>
    <url>/2023/11/04/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<p>网站学习链接：<a href="https://learngitbranching.js.org/?locale=zh_CN">https://learngitbranching.js.org/?locale=zh_CN</a></p><p>经验贴：<a href="https://zhuanlan.zhihu.com/p/383960650">https://zhuanlan.zhihu.com/p/383960650</a></p><ul><li><code>git brach -b &lt;branchName&gt;</code> 新建一个<code>branchName</code>分支，并切换到那个分支</li><li><code>git checkout branchName^</code> 使得HEAD指向<code>branchName</code>的前一个分支，有几个<code>^</code>就代表前移几个，如果<code>branchName</code> 有多个parent，那么<code>^num</code> 就是指选择跳到第几个parent</li><li><code>git checkout branchName~2</code> 使得HEAD指向<code>branchName</code> 的前2个分支，如果没有后面的数字就是默认1</li><li><code>git checkout HEAD~^2~2</code> ,<code>git branch -f bugWork HEAD~^2^</code>git的操作符还支持链式操作</li><li><code>git revert</code>用于撤销提交，生成一条新的提交来覆盖之前的修改，保留修改历史，语法：<code>git revert &lt;commit&gt;</code> ，其中，<code>&lt;commit&gt;</code>是<strong>要撤销的提交</strong>的哈希值或引用</li><li><code>git reset</code>用于重置分支的指针，可以选择保留或丢弃之前的修改，改变提交历史，语法：<code>git reset &lt;commit&gt;</code> ，其中，<code>&lt;commit&gt;</code>是<strong>要重置到的目标提交</strong>的哈希值或引用<ul><li><code>-soft</code>：重置分支的指针，但不改变工作区和暂存区的内容。之前的修改将被保留在暂存区中，你可以随时重新提交它们</li><li><code>-mixed</code>（默认选项）：重置分支的指针，并清除暂存区的内容。之前的修改将保留在工作区中，但不会自动提交</li><li><code>-hard</code>：重置分支的指针，并清除暂存区和工作区的内容。之前的修改将完全丢失，慎用该选项</li></ul></li><li>使用<code>git reset</code>会改变分支的提交历史。如果你在公共分支上使用<code>git reset</code>，并将其推送到远程仓库，可能会导致其他人的问题。因此，在公共分支上通常更推荐使用<code>git revert</code></li><li><code>git rebase &lt;branch&gt; &lt;based_branch&gt;</code> 可以指定将branch对based_branch进行rebase</li><li><code>git cherry-pick commit1 commit2</code> 可以将两个commit放到HEAD后面,注意commit的顺序就是这里排列的顺序</li><li><code>git rebase -i HEAD~4</code> 是一个 Git 命令，用于以<strong>交互方式</strong>进行历史提交的重新整理（rebase）。该命令允许你修改最近的 4 个提交，可以根据需要修改这些操作命令。常见的操作命令包括 “pick”（保留提交）、”edit”（修改提交）、”reword”（修改提交信息）、”squash”（合并提交）等</li><li><code>git rebase</code></li><li><code>git branch -f main caption</code> 用于将分支<code>main</code>的指针强制移动到指定的提交<code>caption</code>上</li><li><code>git commit --amend</code>是一个用于修改最近一次提交的Git命令</li><li><code>git tag tagName commitName</code> 给c1提交赋上v0标签</li><li><code>git push origin &lt;tagname&gt;</code> 将tag推送到远程</li><li><code>git describe &lt;commit&gt;</code> 如果不指定<code>&lt;commit&gt;</code>，则默认使用当前所在的提交。如果这个<code>&lt;commit&gt;</code> 有标签就输出相应的标签，如果没有就会去找最近的标签，生成一个描述，格式为<code>&lt;tag&gt;-&lt;num&gt;-g&lt;hash&gt;</code>，其中<code>&lt;tag&gt;</code>是最近的标签，<code>&lt;num&gt;</code>是指定提交与最近标签之间的提交数，<code>&lt;hash&gt;</code>是指定提交的简短哈希值</li><li><code>git fetch</code> 会获取远程厂库的所有分支的所有提交记录，并把<code>orgin/xxx</code> 指向对应的远程提交，但是它并不会更改本地的内容还有本地的分支</li><li><code>git pull</code> 实际上是<code>git fetch</code>和<code>git merge</code>的合集，它会获取远程更新并与当前对应分支合并</li><li><code>git pull --rebase</code> 是<code>git fetch</code> 和<code>git rebase</code> 的合集，它会获取远程更新并对其进行rebase</li><li><code>git push</code> 实际上会merge本地拷贝的<code>origin/xxxx</code>分支然后再提交</li><li><code>git checkout -b foo origin/main</code> 可以把<code>foo</code>和远程分支<code>origin/main</code>绑定起来</li><li><code>git branch -u o/main foo</code> 使得foo分支直接绑定远程分支main，如果当前分支就是foo，就可省略foo</li><li><code>git branch -m &lt;old_branch_name&gt; &lt;new_branch_name&gt;</code> 可以修改branch的名字</li><li><code>git push origin main</code> 将本地 <code>main</code> 分支的提交推送到远程仓库 <code>origin</code> 的 <code>main</code> 分支的命令</li><li><code>git push origin &lt;source&gt;:&lt;destination&gt;</code> 将本地 <code>&lt;source&gt;</code> 分支的提交推送到远程仓库 <code>origin</code> 的 <code>&lt;destination&gt;</code> 分支的命令。这样可以将本地的修改共享给其他协作者，并将本地分支映射到远程仓库的不同分支。<code>source</code>既可以是<code>branch</code>的名字也可以是某个指定的提交位置例如<code>HEAD~2</code></li><li><code>git fetch origin &lt;source&gt;:&lt;destination&gt;</code> 将远程的厂库<code>origin</code>的<code>source</code>分支更新到本地<code>destination</code>分支。注意<code>source</code>也是既可以是分支名也可以是某个指定的提交位置。注意这样子的<code>o/xxxx</code>分支不会进行变化</li><li><code>git push origin :side</code> 会删除远程的side分支</li><li><code>git fetch origin :bugFix</code> 会在本地创建一个bugFix分支</li><li><code>git pull origin foo</code> 相当于：<code>git fetch origin foo; git merge o/foo</code></li><li><code>git pull origin bar~1:bugFix</code> 相当于：<code>git fetch origin bar~1:bugFix; git merge bugFix</code></li></ul>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
    <tags>
      
      <tag>git</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>博客基础使用指南</title>
    <link href="/2023/11/04/%E5%8D%9A%E5%AE%A2%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"/>
    <url>/2023/11/04/%E5%8D%9A%E5%AE%A2%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</url>
    
    <content type="html"><![CDATA[<h1 id="在本地写文章"><a href="#在本地写文章" class="headerlink" title="在本地写文章"></a>在本地写文章</h1><pre><code class="hljs">指令需要在根目录下的控制台中运行</code></pre><ul><li>直接创建新文章：<code>hexo new a</code></li><li>新建草稿：<code>hexo new draft b</code></li><li>将草稿变成发布文章：<code>hexo publish b</code></li><li>文章首部内容示例：  <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> <span class="hljs-string">我就是标题</span><br><span class="hljs-attr">date:</span> <span class="hljs-number">2021-09-25 23:32:04</span><br><span class="hljs-attr">comments:</span> <span class="hljs-literal">true</span> <span class="hljs-comment">#是否可评论 </span><br><span class="hljs-attr">layout:</span> <span class="hljs-string">post</span> <span class="hljs-comment"># 公开文章 </span><br><span class="hljs-attr">toc:</span> <span class="hljs-literal">true</span> <span class="hljs-comment">#是否显示文章目录 </span><br><span class="hljs-attr">tags:</span>   <span class="hljs-comment">#标签 </span><br><span class="hljs-bullet">-</span> <span class="hljs-string">我就是新的标签1</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">老子是新的标签2</span><br><span class="hljs-meta">---</span><br></code></pre></td></tr></table></figure></li></ul><h1 id="部署运行"><a href="#部署运行" class="headerlink" title="部署运行"></a>部署运行</h1><ul><li>清理缓存： <code>hexo clean</code></li><li>生成静态网页并部署到远程github厂库：<code>hexo g -d</code></li><li>启动服务：<code>hexo s</code></li><li>本地访问的链接：<code>http://localhost:4000/</code></li><li>远程访问链接：<code>https://slipegg.github.io/</code></li></ul><h1 id="备忘录"><a href="#备忘录" class="headerlink" title="备忘录"></a>备忘录</h1><p>站点访问统计:<a href="https://console.leancloud.app/apps">国际版LeanCloud</a></p><p>注意下面的部署文章没有提到要在LeadCloud里创建Comment数据库，以及设置权限，修改serverUrl配置，修改完成后评论功能才能正常使用。</p><p>github推送使用的是git，所以依赖的其实是本地的私钥</p><p>部署的参考文档：</p><ul><li><a href="https://blog.csdn.net/yaorongke/article/details/119089190">https://blog.csdn.net/yaorongke/article/details/119089190</a></li><li><a href="https://blog.csdn.net/PaperJack/article/details/120479912">https://blog.csdn.net/PaperJack/article/details/120479912</a></li><li><a href="https://iyichen.xyz/2022/01/hexo-leancloud-valine-access-fail/">https://iyichen.xyz/2022/01/hexo-leancloud-valine-access-fail/</a></li><li><a href="https://zhengyujie.github.io/2019/08/18/valine%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/">https://zhengyujie.github.io/2019/08/18/valine%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
    <tags>
      
      <tag>博客</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2023/11/04/hello-world/"/>
    <url>/2023/11/04/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>测试文章</title>
    <link href="/2021/06/10/test/"/>
    <url>/2021/06/10/test/</url>
    
    <content type="html"><![CDATA[<p>这是一篇测试文章</p><img src="/2021/06/10/test/test.jpg" class="" title="图片引用方法一"><p><img src="/2021/06/10/test/test.jpg" alt="图片引用方法二"></p><p><img src="/images/test.jpg" alt="图片引用方法三"></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
